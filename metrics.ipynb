{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-04 10:49:15,821 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/pinecone_plugins'])\n",
      "2025-01-04 10:49:15,826 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference\n",
      "2025-01-04 10:49:15,827 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone\n",
      "2025-01-04 10:49:15,841 - sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: cpu\n",
      "2025-01-04 10:49:15,842 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: paraphrase-MiniLM-L6-v2\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import ebooklib\n",
    "from dotenv import load_dotenv\n",
    "# from env_tokens import TELEGRAM_BOT_TOKEN, MISTRAL_API_ENDPOINT, PINECONE_API_KEY\n",
    "from telegram import Update\n",
    "from telegram.ext import ApplicationBuilder, CommandHandler, MessageHandler, filters, ContextTypes\n",
    "from mistralai import Mistral\n",
    "from pinecone import Pinecone, ServerlessSpec\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from ebooklib import epub\n",
    "from bs4 import BeautifulSoup\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "TELEGRAM_BOT_TOKEN = os.getenv(\"TELEGRAM_BOT_TOKEN\")\n",
    "MISTRAL_API_ENDPOINT = os.getenv(\"MISTRAL_API_ENDPOINT\")\n",
    "PINECONE_API_KEY = os.getenv(\"PINECONE_API_KEY\")\n",
    "\n",
    "# Enable logging\n",
    "logging.basicConfig(\n",
    "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s', level=logging.INFO\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Токен Telegram бота\n",
    "TELEGRAM_BOT_TOKEN = TELEGRAM_BOT_TOKEN\n",
    "\n",
    "# API endpoint Mistral\n",
    "MISTRAL_API_ENDPOINT = MISTRAL_API_ENDPOINT\n",
    "MISTRAL_MODEL = 'mistral-medium'  # Replace with the name of your Mistral model\n",
    "MISTRAL_CLIENT = Mistral(api_key=MISTRAL_API_ENDPOINT)\n",
    "\n",
    "# API endpoint Pinecone\n",
    "PINECONE_API_KEY = PINECONE_API_KEY\n",
    "PINECONE_ENVIRONMENT = 'us-east-1'\n",
    "INDEX_NAME = 'interview-qa2'\n",
    "\n",
    "# Initialize Pinecone\n",
    "pc = Pinecone(api_key=PINECONE_API_KEY)\n",
    "\n",
    "# Initialize SentenceTransformer model\n",
    "model = SentenceTransformer('paraphrase-MiniLM-L6-v2')\n",
    "#model = SentenceTransformer('intfloat/multilingual-e5-large')\n",
    "\n",
    "ind_text_dict = {}\n",
    "\n",
    "\n",
    "async def start(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:\n",
    "    await update.message.reply_text(\n",
    "        'Hi! I am your Mistral RAG bot. Send me a message and I will retrieve and generate a response for you.')\n",
    "\n",
    "\n",
    "async def handle_message(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:\n",
    "    user_message = update.message.text\n",
    "    logger.info(f\"Received message: {user_message}\")\n",
    "\n",
    "    # Step 1: Retrieve relevant documents from the vector database\n",
    "    retrieved_docs = retrieve_documents(user_message)\n",
    "\n",
    "    # Step 2: Generate a response using Mistral API\n",
    "    response = generate_response(user_message, retrieved_docs)\n",
    "\n",
    "    await update.message.reply_text(response)\n",
    "\n",
    "\n",
    "def retrieve_documents(query: str):\n",
    "    # Convert the query to a vector\n",
    "    query_vector = model.encode(query).tolist()\n",
    "\n",
    "    # Query the Pinecone index with keyword arguments\n",
    "    index = pc.Index(INDEX_NAME)\n",
    "    results = index.query(vector=query_vector, top_k=5, include_metadata=True)\n",
    "    \n",
    "    # Log the retrieved results for debugging\n",
    "    logger.info(f\"Retrieved results: {results}\")\n",
    "\n",
    "    retrieved_docs = []\n",
    "    for match in results['matches']:\n",
    "        doc_id = match['id']\n",
    "        try:\n",
    "            retrieved_docs.append(ind_text_dict[doc_id])\n",
    "        except KeyError:\n",
    "            logger.warning(f\"Document ID {doc_id} not found in local dictionary.\")\n",
    "    \n",
    "    return retrieved_docs\n",
    "\n",
    "\n",
    "\n",
    "def generate_response(query: str, documents: list):\n",
    "    \"\"\"Generate a response using Mistral API.\"\"\"\n",
    "    prompt = f\"\"\"\n",
    "    You are an AI assistant designed to help users prepare for ML engineer interviews. \n",
    "    You have access to a knowledge base with information in English. \n",
    "    When a user asks a question, you should retrieve the relevant information from the knowledge base and then translate the response into the russian language.\n",
    "    Knowledge base: {documents}\n",
    "    \n",
    "    Here is the user's question:\n",
    "    [{query}]\n",
    "    \n",
    "    Please provide the answer only in the russian language.\n",
    "        \"\"\"\n",
    "\n",
    "    # Send the prompt to Mistral API\n",
    "    try:\n",
    "        response = MISTRAL_CLIENT.chat.complete(\n",
    "            model=MISTRAL_MODEL,\n",
    "            messages=[{'role': \"user\", 'content': prompt}]\n",
    "        )\n",
    "        return response.choices[0].message.content.strip()\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error generating response: {e}\")\n",
    "        return \"Sorry, I couldn't generate a response at the moment.\"\n",
    "\n",
    "\n",
    "def extract_text_from_epub(file_path):\n",
    "    book = epub.read_epub(file_path)\n",
    "    text = []\n",
    "    for item in book.get_items_of_type(ebooklib.ITEM_DOCUMENT):\n",
    "        soup = BeautifulSoup(item.get_body_content(), 'html.parser')\n",
    "        text.append(soup.get_text())\n",
    "    return ' '.join(text)\n",
    "\n",
    "\n",
    "def generate_embeddings(documents):\n",
    "    embeddings = []\n",
    "    for text_id, text in documents.items():\n",
    "        embedding = model.encode(text)\n",
    "        embeddings.append({'id': text_id, 'values': embedding.tolist()})\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/ebooklib/epub.py:1395: UserWarning: In the future version we will turn default option ignore_ncx to True.\n",
      "  warnings.warn('In the future version we will turn default option ignore_ncx to True.')\n",
      "/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/ebooklib/epub.py:1423: FutureWarning: This search incorrectly ignores the root element, and will be fixed in a future version.  If you rely on the current behaviour, change it to './/xmlns:rootfile[@media-type]'\n",
      "  for root_file in tree.findall('//xmlns:rootfile[@media-type]', namespaces={'xmlns': NAMESPACES['CONTAINERNS']}):\n",
      "2025-01-04 10:49:26,273 - langchain_text_splitters.base - WARNING - Created a chunk of size 3558, which is longer than the specified 2000\n",
      "2025-01-04 10:49:26,275 - langchain_text_splitters.base - WARNING - Created a chunk of size 3734, which is longer than the specified 2000\n",
      "2025-01-04 10:49:26,275 - langchain_text_splitters.base - WARNING - Created a chunk of size 2100, which is longer than the specified 2000\n",
      "2025-01-04 10:49:26,276 - langchain_text_splitters.base - WARNING - Created a chunk of size 2200, which is longer than the specified 2000\n",
      "2025-01-04 10:49:26,276 - langchain_text_splitters.base - WARNING - Created a chunk of size 2645, which is longer than the specified 2000\n",
      "2025-01-04 10:49:26,276 - langchain_text_splitters.base - WARNING - Created a chunk of size 3578, which is longer than the specified 2000\n",
      "2025-01-04 10:49:26,277 - langchain_text_splitters.base - WARNING - Created a chunk of size 2457, which is longer than the specified 2000\n",
      "2025-01-04 10:49:26,277 - langchain_text_splitters.base - WARNING - Created a chunk of size 3057, which is longer than the specified 2000\n",
      "2025-01-04 10:49:26,278 - langchain_text_splitters.base - WARNING - Created a chunk of size 2300, which is longer than the specified 2000\n",
      "2025-01-04 10:49:26,278 - langchain_text_splitters.base - WARNING - Created a chunk of size 2069, which is longer than the specified 2000\n",
      "2025-01-04 10:49:26,279 - langchain_text_splitters.base - WARNING - Created a chunk of size 2998, which is longer than the specified 2000\n",
      "2025-01-04 10:49:26,279 - langchain_text_splitters.base - WARNING - Created a chunk of size 2381, which is longer than the specified 2000\n",
      "2025-01-04 10:49:26,280 - langchain_text_splitters.base - WARNING - Created a chunk of size 2212, which is longer than the specified 2000\n",
      "2025-01-04 10:49:26,280 - langchain_text_splitters.base - WARNING - Created a chunk of size 3890, which is longer than the specified 2000\n",
      "2025-01-04 10:49:26,280 - langchain_text_splitters.base - WARNING - Created a chunk of size 2033, which is longer than the specified 2000\n",
      "2025-01-04 10:49:26,281 - langchain_text_splitters.base - WARNING - Created a chunk of size 2084, which is longer than the specified 2000\n",
      "2025-01-04 10:49:26,281 - langchain_text_splitters.base - WARNING - Created a chunk of size 3145, which is longer than the specified 2000\n",
      "2025-01-04 10:49:26,282 - langchain_text_splitters.base - WARNING - Created a chunk of size 2097, which is longer than the specified 2000\n",
      "2025-01-04 10:49:26,283 - langchain_text_splitters.base - WARNING - Created a chunk of size 10857, which is longer than the specified 2000\n",
      "2025-01-04 10:49:26,283 - langchain_text_splitters.base - WARNING - Created a chunk of size 4209, which is longer than the specified 2000\n",
      "2025-01-04 10:49:26,284 - langchain_text_splitters.base - WARNING - Created a chunk of size 2009, which is longer than the specified 2000\n",
      "2025-01-04 10:49:26,284 - langchain_text_splitters.base - WARNING - Created a chunk of size 4212, which is longer than the specified 2000\n",
      "2025-01-04 10:49:26,285 - langchain_text_splitters.base - WARNING - Created a chunk of size 4179, which is longer than the specified 2000\n",
      "2025-01-04 10:49:26,285 - langchain_text_splitters.base - WARNING - Created a chunk of size 8014, which is longer than the specified 2000\n",
      "2025-01-04 10:49:26,286 - langchain_text_splitters.base - WARNING - Created a chunk of size 2610, which is longer than the specified 2000\n",
      "2025-01-04 10:49:26,286 - langchain_text_splitters.base - WARNING - Created a chunk of size 3027, which is longer than the specified 2000\n",
      "2025-01-04 10:49:26,287 - langchain_text_splitters.base - WARNING - Created a chunk of size 4196, which is longer than the specified 2000\n",
      "2025-01-04 10:49:26,287 - langchain_text_splitters.base - WARNING - Created a chunk of size 6160, which is longer than the specified 2000\n",
      "2025-01-04 10:49:26,288 - langchain_text_splitters.base - WARNING - Created a chunk of size 4795, which is longer than the specified 2000\n",
      "2025-01-04 10:49:26,288 - langchain_text_splitters.base - WARNING - Created a chunk of size 2752, which is longer than the specified 2000\n",
      "2025-01-04 10:49:26,289 - langchain_text_splitters.base - WARNING - Created a chunk of size 6163, which is longer than the specified 2000\n",
      "2025-01-04 10:49:26,289 - langchain_text_splitters.base - WARNING - Created a chunk of size 2366, which is longer than the specified 2000\n",
      "2025-01-04 10:49:26,289 - langchain_text_splitters.base - WARNING - Created a chunk of size 10731, which is longer than the specified 2000\n",
      "2025-01-04 10:49:26,290 - langchain_text_splitters.base - WARNING - Created a chunk of size 2914, which is longer than the specified 2000\n",
      "2025-01-04 10:49:26,290 - langchain_text_splitters.base - WARNING - Created a chunk of size 2179, which is longer than the specified 2000\n",
      "2025-01-04 10:49:26,291 - langchain_text_splitters.base - WARNING - Created a chunk of size 3263, which is longer than the specified 2000\n",
      "2025-01-04 10:49:26,291 - langchain_text_splitters.base - WARNING - Created a chunk of size 5926, which is longer than the specified 2000\n",
      "2025-01-04 10:49:26,292 - langchain_text_splitters.base - WARNING - Created a chunk of size 3612, which is longer than the specified 2000\n",
      "2025-01-04 10:49:26,292 - langchain_text_splitters.base - WARNING - Created a chunk of size 5279, which is longer than the specified 2000\n",
      "2025-01-04 10:49:26,293 - langchain_text_splitters.base - WARNING - Created a chunk of size 3509, which is longer than the specified 2000\n",
      "2025-01-04 10:49:26,293 - langchain_text_splitters.base - WARNING - Created a chunk of size 5445, which is longer than the specified 2000\n",
      "2025-01-04 10:49:26,294 - langchain_text_splitters.base - WARNING - Created a chunk of size 5758, which is longer than the specified 2000\n",
      "2025-01-04 10:49:26,294 - langchain_text_splitters.base - WARNING - Created a chunk of size 7696, which is longer than the specified 2000\n",
      "2025-01-04 10:49:26,295 - langchain_text_splitters.base - WARNING - Created a chunk of size 2288, which is longer than the specified 2000\n",
      "2025-01-04 10:49:26,295 - langchain_text_splitters.base - WARNING - Created a chunk of size 3284, which is longer than the specified 2000\n",
      "2025-01-04 10:49:26,296 - langchain_text_splitters.base - WARNING - Created a chunk of size 4738, which is longer than the specified 2000\n",
      "2025-01-04 10:49:26,296 - langchain_text_splitters.base - WARNING - Created a chunk of size 4448, which is longer than the specified 2000\n",
      "2025-01-04 10:49:26,298 - langchain_text_splitters.base - WARNING - Created a chunk of size 2359, which is longer than the specified 2000\n",
      "2025-01-04 10:49:26,298 - langchain_text_splitters.base - WARNING - Created a chunk of size 3771, which is longer than the specified 2000\n",
      "2025-01-04 10:49:26,299 - langchain_text_splitters.base - WARNING - Created a chunk of size 2926, which is longer than the specified 2000\n",
      "2025-01-04 10:49:26,299 - langchain_text_splitters.base - WARNING - Created a chunk of size 2665, which is longer than the specified 2000\n",
      "2025-01-04 10:49:26,300 - langchain_text_splitters.base - WARNING - Created a chunk of size 5496, which is longer than the specified 2000\n",
      "2025-01-04 10:49:26,300 - langchain_text_splitters.base - WARNING - Created a chunk of size 2160, which is longer than the specified 2000\n",
      "2025-01-04 10:49:26,300 - langchain_text_splitters.base - WARNING - Created a chunk of size 3287, which is longer than the specified 2000\n",
      "2025-01-04 10:49:26,301 - langchain_text_splitters.base - WARNING - Created a chunk of size 2399, which is longer than the specified 2000\n",
      "2025-01-04 10:49:26,301 - langchain_text_splitters.base - WARNING - Created a chunk of size 3368, which is longer than the specified 2000\n",
      "2025-01-04 10:49:26,302 - langchain_text_splitters.base - WARNING - Created a chunk of size 5063, which is longer than the specified 2000\n",
      "2025-01-04 10:49:26,302 - langchain_text_splitters.base - WARNING - Created a chunk of size 4978, which is longer than the specified 2000\n",
      "2025-01-04 10:49:26,303 - langchain_text_splitters.base - WARNING - Created a chunk of size 2920, which is longer than the specified 2000\n",
      "2025-01-04 10:49:26,303 - langchain_text_splitters.base - WARNING - Created a chunk of size 5209, which is longer than the specified 2000\n",
      "2025-01-04 10:49:26,304 - langchain_text_splitters.base - WARNING - Created a chunk of size 3833, which is longer than the specified 2000\n",
      "2025-01-04 10:49:26,305 - langchain_text_splitters.base - WARNING - Created a chunk of size 3980, which is longer than the specified 2000\n",
      "2025-01-04 10:49:26,305 - langchain_text_splitters.base - WARNING - Created a chunk of size 2542, which is longer than the specified 2000\n",
      "2025-01-04 10:49:26,305 - langchain_text_splitters.base - WARNING - Created a chunk of size 7362, which is longer than the specified 2000\n",
      "2025-01-04 10:49:26,306 - langchain_text_splitters.base - WARNING - Created a chunk of size 2905, which is longer than the specified 2000\n",
      "2025-01-04 10:49:26,306 - langchain_text_splitters.base - WARNING - Created a chunk of size 3168, which is longer than the specified 2000\n",
      "2025-01-04 10:49:26,307 - langchain_text_splitters.base - WARNING - Created a chunk of size 3106, which is longer than the specified 2000\n",
      "2025-01-04 10:49:26,307 - langchain_text_splitters.base - WARNING - Created a chunk of size 2966, which is longer than the specified 2000\n",
      "2025-01-04 10:49:26,308 - langchain_text_splitters.base - WARNING - Created a chunk of size 2201, which is longer than the specified 2000\n",
      "2025-01-04 10:49:26,308 - langchain_text_splitters.base - WARNING - Created a chunk of size 3706, which is longer than the specified 2000\n",
      "2025-01-04 10:49:26,309 - langchain_text_splitters.base - WARNING - Created a chunk of size 3044, which is longer than the specified 2000\n",
      "2025-01-04 10:49:26,309 - langchain_text_splitters.base - WARNING - Created a chunk of size 2334, which is longer than the specified 2000\n",
      "2025-01-04 10:49:26,310 - langchain_text_splitters.base - WARNING - Created a chunk of size 3158, which is longer than the specified 2000\n",
      "2025-01-04 10:49:26,310 - langchain_text_splitters.base - WARNING - Created a chunk of size 2287, which is longer than the specified 2000\n",
      "2025-01-04 10:49:26,310 - langchain_text_splitters.base - WARNING - Created a chunk of size 7851, which is longer than the specified 2000\n",
      "2025-01-04 10:49:26,311 - langchain_text_splitters.base - WARNING - Created a chunk of size 2046, which is longer than the specified 2000\n",
      "2025-01-04 10:49:26,311 - langchain_text_splitters.base - WARNING - Created a chunk of size 2035, which is longer than the specified 2000\n",
      "2025-01-04 10:49:26,312 - langchain_text_splitters.base - WARNING - Created a chunk of size 2822, which is longer than the specified 2000\n",
      "2025-01-04 10:49:26,313 - langchain_text_splitters.base - WARNING - Created a chunk of size 4001, which is longer than the specified 2000\n",
      "2025-01-04 10:49:26,314 - langchain_text_splitters.base - WARNING - Created a chunk of size 2231, which is longer than the specified 2000\n",
      "2025-01-04 10:49:26,315 - langchain_text_splitters.base - WARNING - Created a chunk of size 5772, which is longer than the specified 2000\n",
      "2025-01-04 10:49:26,315 - langchain_text_splitters.base - WARNING - Created a chunk of size 8028, which is longer than the specified 2000\n",
      "2025-01-04 10:49:26,315 - langchain_text_splitters.base - WARNING - Created a chunk of size 4411, which is longer than the specified 2000\n",
      "2025-01-04 10:49:26,316 - langchain_text_splitters.base - WARNING - Created a chunk of size 2773, which is longer than the specified 2000\n",
      "2025-01-04 10:49:26,316 - langchain_text_splitters.base - WARNING - Created a chunk of size 5297, which is longer than the specified 2000\n",
      "2025-01-04 10:49:26,317 - langchain_text_splitters.base - WARNING - Created a chunk of size 6885, which is longer than the specified 2000\n",
      "2025-01-04 10:49:26,317 - langchain_text_splitters.base - WARNING - Created a chunk of size 3768, which is longer than the specified 2000\n",
      "2025-01-04 10:49:26,317 - langchain_text_splitters.base - WARNING - Created a chunk of size 5378, which is longer than the specified 2000\n",
      "2025-01-04 10:49:26,318 - langchain_text_splitters.base - WARNING - Created a chunk of size 7639, which is longer than the specified 2000\n",
      "2025-01-04 10:49:26,318 - langchain_text_splitters.base - WARNING - Created a chunk of size 4154, which is longer than the specified 2000\n",
      "2025-01-04 10:49:26,319 - langchain_text_splitters.base - WARNING - Created a chunk of size 3608, which is longer than the specified 2000\n",
      "2025-01-04 10:49:26,319 - langchain_text_splitters.base - WARNING - Created a chunk of size 4098, which is longer than the specified 2000\n",
      "2025-01-04 10:49:26,320 - langchain_text_splitters.base - WARNING - Created a chunk of size 2534, which is longer than the specified 2000\n",
      "2025-01-04 10:49:26,320 - langchain_text_splitters.base - WARNING - Created a chunk of size 4100, which is longer than the specified 2000\n",
      "2025-01-04 10:49:26,321 - langchain_text_splitters.base - WARNING - Created a chunk of size 3694, which is longer than the specified 2000\n",
      "2025-01-04 10:49:26,321 - langchain_text_splitters.base - WARNING - Created a chunk of size 3591, which is longer than the specified 2000\n",
      "2025-01-04 10:49:26,321 - langchain_text_splitters.base - WARNING - Created a chunk of size 3148, which is longer than the specified 2000\n",
      "2025-01-04 10:49:26,322 - langchain_text_splitters.base - WARNING - Created a chunk of size 2065, which is longer than the specified 2000\n",
      "2025-01-04 10:49:26,322 - langchain_text_splitters.base - WARNING - Created a chunk of size 3237, which is longer than the specified 2000\n",
      "2025-01-04 10:49:26,323 - langchain_text_splitters.base - WARNING - Created a chunk of size 3531, which is longer than the specified 2000\n",
      "2025-01-04 10:49:26,323 - langchain_text_splitters.base - WARNING - Created a chunk of size 3862, which is longer than the specified 2000\n",
      "2025-01-04 10:49:26,323 - langchain_text_splitters.base - WARNING - Created a chunk of size 2563, which is longer than the specified 2000\n",
      "2025-01-04 10:49:26,324 - langchain_text_splitters.base - WARNING - Created a chunk of size 3844, which is longer than the specified 2000\n",
      "2025-01-04 10:49:26,324 - langchain_text_splitters.base - WARNING - Created a chunk of size 2086, which is longer than the specified 2000\n",
      "2025-01-04 10:49:26,325 - langchain_text_splitters.base - WARNING - Created a chunk of size 4252, which is longer than the specified 2000\n",
      "2025-01-04 10:49:26,325 - langchain_text_splitters.base - WARNING - Created a chunk of size 7390, which is longer than the specified 2000\n",
      "2025-01-04 10:49:26,326 - langchain_text_splitters.base - WARNING - Created a chunk of size 2273, which is longer than the specified 2000\n",
      "2025-01-04 10:49:26,326 - langchain_text_splitters.base - WARNING - Created a chunk of size 3019, which is longer than the specified 2000\n",
      "2025-01-04 10:49:26,326 - langchain_text_splitters.base - WARNING - Created a chunk of size 2779, which is longer than the specified 2000\n",
      "2025-01-04 10:49:26,327 - langchain_text_splitters.base - WARNING - Created a chunk of size 2835, which is longer than the specified 2000\n",
      "2025-01-04 10:49:26,327 - langchain_text_splitters.base - WARNING - Created a chunk of size 2570, which is longer than the specified 2000\n",
      "2025-01-04 10:49:26,328 - langchain_text_splitters.base - WARNING - Created a chunk of size 3454, which is longer than the specified 2000\n",
      "2025-01-04 10:49:26,328 - langchain_text_splitters.base - WARNING - Created a chunk of size 3972, which is longer than the specified 2000\n",
      "2025-01-04 10:49:26,329 - langchain_text_splitters.base - WARNING - Created a chunk of size 2029, which is longer than the specified 2000\n",
      "2025-01-04 10:49:26,329 - langchain_text_splitters.base - WARNING - Created a chunk of size 2924, which is longer than the specified 2000\n",
      "2025-01-04 10:49:26,332 - langchain_text_splitters.base - WARNING - Created a chunk of size 3306, which is longer than the specified 2000\n",
      "2025-01-04 10:49:26,336 - langchain_text_splitters.base - WARNING - Created a chunk of size 8481, which is longer than the specified 2000\n",
      "2025-01-04 10:49:26,337 - langchain_text_splitters.base - WARNING - Created a chunk of size 2419, which is longer than the specified 2000\n",
      "2025-01-04 10:49:26,337 - langchain_text_splitters.base - WARNING - Created a chunk of size 4844, which is longer than the specified 2000\n",
      "2025-01-04 10:49:26,338 - langchain_text_splitters.base - WARNING - Created a chunk of size 7062, which is longer than the specified 2000\n",
      "2025-01-04 10:49:26,338 - langchain_text_splitters.base - WARNING - Created a chunk of size 2376, which is longer than the specified 2000\n",
      "2025-01-04 10:49:26,339 - langchain_text_splitters.base - WARNING - Created a chunk of size 5008, which is longer than the specified 2000\n",
      "2025-01-04 10:49:26,339 - langchain_text_splitters.base - WARNING - Created a chunk of size 2961, which is longer than the specified 2000\n",
      "2025-01-04 10:49:26,340 - langchain_text_splitters.base - WARNING - Created a chunk of size 5556, which is longer than the specified 2000\n",
      "2025-01-04 10:49:26,340 - langchain_text_splitters.base - WARNING - Created a chunk of size 7890, which is longer than the specified 2000\n",
      "2025-01-04 10:49:26,341 - langchain_text_splitters.base - WARNING - Created a chunk of size 5965, which is longer than the specified 2000\n",
      "2025-01-04 10:49:26,341 - langchain_text_splitters.base - WARNING - Created a chunk of size 2080, which is longer than the specified 2000\n",
      "2025-01-04 10:49:26,342 - langchain_text_splitters.base - WARNING - Created a chunk of size 2510, which is longer than the specified 2000\n",
      "2025-01-04 10:49:26,342 - langchain_text_splitters.base - WARNING - Created a chunk of size 7993, which is longer than the specified 2000\n",
      "2025-01-04 10:49:26,343 - langchain_text_splitters.base - WARNING - Created a chunk of size 2766, which is longer than the specified 2000\n",
      "2025-01-04 10:49:26,343 - langchain_text_splitters.base - WARNING - Created a chunk of size 2938, which is longer than the specified 2000\n",
      "2025-01-04 10:49:26,343 - langchain_text_splitters.base - WARNING - Created a chunk of size 4552, which is longer than the specified 2000\n",
      "2025-01-04 10:49:26,344 - langchain_text_splitters.base - WARNING - Created a chunk of size 3701, which is longer than the specified 2000\n",
      "2025-01-04 10:49:26,344 - langchain_text_splitters.base - WARNING - Created a chunk of size 2389, which is longer than the specified 2000\n",
      "2025-01-04 10:49:26,345 - langchain_text_splitters.base - WARNING - Created a chunk of size 9571, which is longer than the specified 2000\n",
      "2025-01-04 10:49:26,345 - langchain_text_splitters.base - WARNING - Created a chunk of size 2148, which is longer than the specified 2000\n",
      "2025-01-04 10:49:26,346 - langchain_text_splitters.base - WARNING - Created a chunk of size 2617, which is longer than the specified 2000\n",
      "2025-01-04 10:49:26,346 - langchain_text_splitters.base - WARNING - Created a chunk of size 3551, which is longer than the specified 2000\n",
      "2025-01-04 10:49:26,347 - langchain_text_splitters.base - WARNING - Created a chunk of size 3217, which is longer than the specified 2000\n",
      "2025-01-04 10:49:26,347 - langchain_text_splitters.base - WARNING - Created a chunk of size 2859, which is longer than the specified 2000\n",
      "2025-01-04 10:49:26,347 - langchain_text_splitters.base - WARNING - Created a chunk of size 9345, which is longer than the specified 2000\n",
      "2025-01-04 10:49:26,348 - langchain_text_splitters.base - WARNING - Created a chunk of size 2416, which is longer than the specified 2000\n",
      "2025-01-04 10:49:26,348 - langchain_text_splitters.base - WARNING - Created a chunk of size 5800, which is longer than the specified 2000\n",
      "2025-01-04 10:49:26,349 - langchain_text_splitters.base - WARNING - Created a chunk of size 3103, which is longer than the specified 2000\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a282aecf141420b8dfa1ecfd9de4c8d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5516c424ae724da28a3c0bfeadb3992b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df70e385581c44ea911b39c568ed7167",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05c7171340fb4e17a719bd418cece8f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "300926a21a7a4700b2e63e3efc2cf94c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef5d970d7d4341b58df490583c71f11f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d70e3065d5e4b51b4443428ceaf5e77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce75b098ebcb41faa1cc31fed8dd3a74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be20c1c173d045b0bc525fbf10e904b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29ee76616071422aac36731e2828cf5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "971adb4c2d404595836ed51592a49e45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6189a25d7eab4b18b005c047c74a013a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1992f13625f04da6943da52d8713934d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59d23ea5f2e849f7b442ec47d31d1c9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b07c38433cbd4584b89b42258b8f9b44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a46bc78041094a209b5fa54cbea15335",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "779e4e81dd56484dafc16a149b5d867b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae3b8cae36074f11a74e74b8e156a2f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "972f19b6b803482eacf62022688aa50e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c31ab6e83bb64b40b15b255ed85497ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58d222ecec1b46d9b6eb275a521e6ca8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6717676d866042f5bc23f4d149a3b29e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "711be049c5a74029a495a4c97255329d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98db37fdec19423d9018f0c12cab8ba3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bbddaf6ec84844cebcf1b04e221c9feb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "723ff48ea2a14bfe9f5e4268350ed736",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b69915f8fe104703baaddbbaa206cd1c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "329436269f2c4bf0abcc21b3d66285f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e3620310dac4346b5b2e47f8c5bd859",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d1d001e2b5f46eebf45b8951b5d7120",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1b2e4e30bbd4a86aeeeeb46774345e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d927359a027c4a57af7032914f278052",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32f81a6ad1604c358f1a82860c19a4c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "031294acd0ed4a6f828e4b26ff759ba2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4cd8448f659f4203b36feaf19efe7a3d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f66ec8bc33d4ba1b20ccc1db2b34981",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce56fc44e8824399af3afc619469c5f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e30ee895b434fb6aa9cfb087fc3db71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba58ad450b83470bb5512c0adddd8b6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "abd7234dfd204923a010204c169a7a8f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "504c0a3207c1444e86fb4790f17eacff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47114ad419e043deb5f7ca1f1c276192",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7172f7f0a61442bbbe23171884274a9f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fabc8acfc103436c9bf176b5b24fdaf9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ec36c7baea54a2a88ec0f6423505b30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54fa3716584f4827bd55c928236f7f2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a3d68c6039d48c9b74db3b718d045df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78f691ac110048c78082f239c40563d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96e18a42f14048f692b6a52152bf2297",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c0cc0a29f6f48f7b416945292ece84f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db6c032fbc1144568f7ddbc85cf63968",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fdcd0f8bd1d944e3817d6ae0f0bec4a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "392dff9c79fc413880832a813128c672",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0e7b8aecd084688b881c280d1cf6c73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "331db2de65ab4889a833de8da874ff88",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50688c7232ce4a9ea7450d027abe4c5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "afc3956a960e44e3a009d6d412a2d71e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37d483b5fdce42c7b6e6331e8904498e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8a58c64755342eb8e2523e947dccc88",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec1d3e9560654b2799e80d4944867175",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2469f7699b6b472db96094046da08390",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "880e34e13209472ca0ed252c55765468",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "125b1a5e7d5047dc8d1062c48e6307f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "371744e0cade422e84e48bd941bccc32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42fc177b7ef6430e870ad0bee926f30c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94431e0679c04437ad695d6e789d7250",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d90190f1de8043e387d8431c86269aa7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "402bd3efa89c47a0bc7f8754de0280c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b570ef50a404a0cb94347b860d0a026",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b7c8b18276648abaf9cc9cf79ea6bec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb819f4cd6d54eb1bfe6d8c1f0e237dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "593003e4327b40ac89a94c4c3e3afd84",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0aeb439cda84a35aa4c9022bed8bb59",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ddc1bab083042b6ad77793885ac58a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31e2d354af0e4398bc35aa81e3f72356",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e3db0ecd648412cac2f5cfad99f58f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0af92faea28b4e6b87266abfc3cbb204",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "422fe0ff8694480eb05fa4d332ad1851",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ceed5cf62cff4078b676c1933d9e5755",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c63d9cd1cf4f4b07bf7ce8663d66a99e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03a2b11eabcd4b1596c9062b8e781e09",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b0d633a9ac7441b9e7d85e47996f875",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb423bfd92ec46be9c1dac21a0ebe4f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9feb13c224614770b92b16f1e6f5abda",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d51785cf3b6048cd8be2cd4d45d36e87",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "881aa8d366b74b688cf7eadd92bd1a9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9040a94e08ed4f418326ce6805b16bee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f84de0b36c754d17857d215aa7e1a279",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b555d402cba74c14b285fbb67e7a45ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6073c2cce65e469c9bc9359efad5ce71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a69952536e174a2b8e889df7e32c9c9f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab171f6bd6cf493ebc48ac052bf15e39",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83e14d6d53c7431ca678fede1e7d7feb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5516f4daa004fc3bdeb3b00ed12c837",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "476931c9162447c18bce7a4f3019b722",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22a5b8e959424d4c87b91315d594d60f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5601dd3c80ea42eca75ed60e2c2af15b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25b2cf51880b4dafb2dcd3ab97695280",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "242b1ecb341e463491f968389c6339dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "734a210fd91e4784898d7327f632da73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "feb5a868792e437d9f68be583deb015d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac7649d65b3c4c3e913411b3c7750dd3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50cfeb1a3077466e82a7572b088b045a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24cc79cd7206400bb1957a4718df051e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "444d80ee35954597af25a46bc6977d50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ce62fa37a63436a9380f7a9399fb59c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b1b95b7fe5347d89b98e9065eda0b49",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1b401aa0b90435580ef6dda020ec2b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1b0055181e74ac4b6b768c336b1f7c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ae58329d94a41d0846a2717a492d9cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce847e05477e4fba9ea5796e8433fa67",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3089db7254714ad5a3d06ccda5146bb7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa7b93482073475f8df0418d73632327",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1766219b29a475b9d8fa76cddd04114",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "babb2d8237934b96aaf12b6de0cf4ed5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "892a526a21bd4c0d97f135bba7f9b0c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1791812abc8e42048ec3fa510eec08df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af016e5e551348a89e4ef45d7cb28cae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40cac72d989143a7b1123043eef4581d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd2741957a794925b001f49bc4b34372",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "871670ae5a244b6e8a6f203753eb48df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd15f3c41aaa4d0691161c3b6961a2d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd82ba9382834045809e644130453e6c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09b92b6928824deebca96acb6698fd87",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78d02f526e7a4c588bd2907150859038",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4e70c435c1248aa8f1c2be94a7f8e05",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb58b6d857844d5689eb267460de7beb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5adef1897ffb4861a1deb9320ec62397",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d7064f08a6342c287e58d10209e9afd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13df2ca9348b44159337ca44cd3ed2b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7b2b93d775142fa9c794e4afe00bd63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ede47ef30c04f9684cf8d6fac8b88c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95945a746e564b4e82f39804cc2ef8ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b13fb664cf304209b1aa53fc3b0a5ff8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "248c8da094824a3491fb067f902f453c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "037dee0c23de4b1294d40d2feb28f9a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b884b1b09d7347aab2ff03033dbb63cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c3a64b56f2844d1a4b60d9909d1d9da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b06e39b3a28c433b80d88afe17589ee2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b394d8bf4354f468f94a3889a73abaf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92d4865cec55418ab7e5c36c96a95863",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05c1ad00b5bf42a7903cee8a6d7ed7e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2397830185a54f78818d072189734b78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e767355cf534c0e870b9e6081cfe308",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e98f0c9ccb954ad592a5b8a6ad7f6c66",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f92089b9e2c4ee5bce0be510775073d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0febfd850554bdb98bb25298119f7d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a8cff2608b940ef96c7d6fd168562ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b67e5158d0fb483eb7700bcbfe1f56c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fed2391107db4939bb41c195b1d0e92b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd4aac4b4bfc464dbdb02af7fb5e9e91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "825ebb71fce84fc38394f123849b4b79",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "357f7667db8e462ea93e4876ca83008a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00b173f704f446bdb3581ceb9fea699d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8714f8a586242e2810a5cc4f84d7274",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f3d674530c64ab6a393d3fa111af57c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2134e31d54aa4c6e890c2539d1bbca41",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "991b8f0857e64e1db949e0649084f549",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1d7b1d8b3754cc48fcfe5500b717132",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6bd61ca034b242c1a171250c97eabd82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ef4dab8e78c40bf8a098b1ea7fb15e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de94ff9b27d346db9b10080f194b7df9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e744593d3c5d446da6dfb84c883fca75",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8cea354e63ad4a4489e6e65788264221",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b45ffa3f9cf141ee9ea7412778b13041",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a858ba3f196245c3b0933901035d8abc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5324edc25730474594cedff7df994c09",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd263bed189e42b88943df396e655619",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70bf59d6abe54f3a9de1cbc788d014c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f7b0aeb72a1490a951626e8caa18fe5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50052ed6d8ec4ae099c71ce3670ef203",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3abdac26d50c4a67a7b1cb92450fa7e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "123e510eb12d44829950c7de141c2204",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3981587bedd44ab8d8e88a4536149ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "926e2ba0bbce46a0b00c106273a1a3d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "923e6433a8274069b92287be077bb585",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d46a5688042d4241bb03c04ac148db93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e5aed9aa1504f8fba99f3e14d9a05d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe82c487482646b5a9ef0fec5a3f723b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2fdb0c358f64065bd3856b49a6ec08f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee16d44ece004ff6aa1cce3134a412c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a155a981f69423ea2b3998f4cea22e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e094dcd1e4446879a6b2e29bb61e178",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f86c596db03745f08ef46f393d742903",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5cd51d618bd140f9a3afd392b38bd535",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b34810d5c918419ebaa112bd6481e466",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf20c417f7d84a37902d926e7a977a5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c7fa2baadbb408bb840915b1f68eda8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c47c5211c3c9414da8a55862520cb510",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f92dace84a7948a7af244431c16830bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98372eda84274c20b74ca7727fd802ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bac3629abecd4971a57d1b128688fc8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e835c2e33993483f90d3ec29015a1dcb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dca2654a7bf14dcd9d6ac070bf0e1bed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fdce3007b5534a44b8833751abac2794",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b966e8a301f846cb8f688cae980ae030",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04b76ea98f854f83a8332e37b2aa7f6a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "527f98681e374c78aef063bd5179a07b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c09688c4779c4edfadaf1f6eaa4b0cdc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d4e21070c134f9fb52da0939f6182e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "707738eaaa6b4f3a88a658344d842601",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4bfcbf5ada347428522816dcb36abce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a20c4631962d4d3ea9132a62465c0f76",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36c9466f22fd472bb9eb8f02eb1c799f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32eaf045e5604fa9a73f7931bccbcebd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b09ad1da64d4f52b39247f998292cda",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69b2528193d34bc28e699513a17cdd85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8133e0c700f44742a7dc55bbf414e16b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81c1999951a041b5ba7b5d1731853434",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53f463403ba24a41bf94bc845101ed94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8648d73897d4641ad55ea374763116d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34bb175487c348ebad81ae61530d6bd0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25e4f2b4854f49b78f2b4173005312ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39169f5c3c6f4ed7b5f069a51619231d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c36dbb214069407dbd062a5d597bc5e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc2c4cae83b945eeb76bf8180e88172d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b944243b88b64a15884ebacde788159c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09f3c5b1e6124037a12553dfc6a4d6bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20fbda7235314c588c765940d0f47130",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3319f261171f47bd9c23f694f14cb5e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e687fa9ed50243c4bc8ac7332cdf3d86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7328ec0ac3834b2dac0d8c3ddbe07126",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8f58cd34d664afcba7bb084f6b0b5e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2eae9e9fa4914cf98dccb8690ec5c054",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "315834457a444c43887c5a525f5e4cba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f3f68931dbb4196a76a71fac7a7a1db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1121ea83d3f34f09a82a545f15693a24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f240a2cabbc42f29904873c83c39351",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d573829bc824b27aacde48abb2e9807",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d756708e96c4476bd30be8e661dd0f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8727ccc4f53c4910b1c93e53059ff6f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5edccc1bb994462196951821b7574edc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7fa3f65de5641d58c06d6a3031e128f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed2b6bb47f7840bdba8d76f18bc9f2da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1808652ef132439eb52a00c1f5c2949a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc0c7ad3324046779aa517f8c2ebde72",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e247e0f2b85448795c7f1e0e1f4abb9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37ea63fe72eb4069a35c08a5d0ca3771",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ed723b3b1574e68aed63f8696a295ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5dacf4b8f2c46a6ac5dc0841600e22c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5a6635e685c4459965170969ebf44c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80792d96ca02424eb7a3da9b8bc652a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9743d76aa6d9405f8c1ad22043316ef3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f5f1facbba74cb8bff79c4afc882e9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb5ca3634b1044abb12aeea48e675885",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b93b088f04e4d54ba5c5b4c0e3ce51b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5731e2d998714dc1beec3f483584a125",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67a1db207e7b4344a0ed5dbfad41e7bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c8ec338ebe74931a08b5d0f3d4f909d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "043f99d2e2fc459d9d3dfaaeef41ecec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14c40e33cc7441d68fe4d6181dd7c577",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd774fa365c442259ff1fc9221926e16",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03d9b80508de46428e037056e8249539",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2b90207791d49a3ac1c3b304fcf7c01",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b7a589f5b79485a90b2f7e022aaeb95",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1aef0cbdd340427bbcf254aac1074f38",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "772a2610da6d48bfb7f8d47392dbd47b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e2e6d6429934239b92f7903dae5151d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bbb3f5211d9f4c198d280746510d4e26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8d6cd53ed20478fa587617eaa149747",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f0673d474454f7bb60015d1d8bc8212",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ca02ff802f14cb38149f72692fb100d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e2e6668767e40908ad454d86eb1bced",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31a385e140c44736bb6bc735d3062086",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "edaede2c30974c0bbd29b769d0d3437f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50b754f9dfd04ecbb1ea583f64e9bb4f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9d4d8e29c95412eb6e737fe034d653c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01ec5c5cb21d4f8bb630224bfc156fee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d36f7c6dcdbf49d79dfc683ede623ec4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10a6e890cad14e10bdb4730f622ef4a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b22dccf5a4a843c7a306e5ec3b34df97",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2681b8a96024bf6aedd11bedd353cde",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03edcc44ea1847459289708b0e8eff2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95de2538328942c29674e334fc8ef524",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "193755f78051439a859c5bcfa1d61440",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd482859d36b40698f4cf8b61f6fdb33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84c8e3c153154a8fa058f972f01cbff6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd75495f67cb49b99443e73ae3948dae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1dfa2b85c746457c9703c7c4a1fad996",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e074622d1644f879b69d7c59af19ae1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0973cb356a07465abcc2722433d00863",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32f14b31cfa846649a6241789b83d933",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d32c4e508ee74a96971b886a115f63b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a16a3187dd84930ae0850a7bfa62500",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b72478b20de4745bc149e9512544c2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b06033f5ede04f7d9d6c55858153fceb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2d418e1b4374c7099f42c8171bf2ac6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bbdc1e7f3ef94139be76f2c36ffadd4e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2dba7a83a4c4562abf19782eb7e8796",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b31e8faf68a0408fb0742f4a345da09d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a194fb7de294ae3b829a505ad221a58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "515788d4dfd54d9b9daf1797a5b3e087",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1236d0cde6cc48fd8275e1f3f76c7bcf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3935ccf3b624bb2a8572401f25df70d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0571daca4aab4c05847ea6719e6edeef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27b789846a7a43619ed970b4f419d702",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3af9e7e816834dcdabc9bc8fa06021d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e4f51e0ae8b4c24b27508311e32b681",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b9ddca1768742238b006418de9fcebd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eafa09b31cc842d2996fecbf3f2ac0df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4edc78a5484f4b5184604dcd8aacd86b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3797d861df0e43aeb70e387bfd3350b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93be31d700b44a1e97dc8bd8353f72c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1d7095bfbcc4c7699846e91e79d7cad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bcfcf71b318b4c4e8fb50f854f118d76",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d39f8fb9107a4f6d9bf35e6b2eb9d9c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d16cb7f0c324523b614f19634be552b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36ea14cfdc504223a144d1b292613430",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc0ab9461aa847ebb08c2444a7316b81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ec5fb3ff9ac47aa860390e99d0ec5fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4afdb2cf95f8433d9edcc034e55f3ab2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4625503756574b14ab04533479554d03",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a620ab17a634bb5bb274f517751338e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a510ba78833d49478a71da83e6a9b181",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4527acfee74b4f0cb9d230b62a8a3dfe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49dce298e37b43faab4953409fac8e21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1d82a87e2604ba2a3fbacc14f7c17c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6936a7cd6c94fe3acc2199a30dd230d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "568c40dc3b2042c596a570337a495e4d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2751b48f5174463927057f51c1a5326",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a30b572f24e440ab31d2b7741b8adfb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "654b1657850f4ad4a8cd49d0241dc93e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a125d0d32ec043a2b48f3b172ac94682",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b9890e8e6ae4b9d858f81a2565c6124",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c61319db1d5344a7b5cfa29a74c18b5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a588769f425a4090aca55e9d9f2d1897",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "897d2d46a9a847439277d12dfe4b476b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2123f8ed49ab4470a6a0c62467bb7290",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d2dec68e39c4528be01a605434ca082",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e9df4d1b8234da8bf9982324a84cc5f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c135ca7a4cac40c2947e82810bac53a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17e40a1b84e74d21a39099ac9c5ada85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9db8314271541d1ac85bb7d7d4d2cf7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d749094698fb4e728dbccc0d4cd66881",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8805fff44165433c913d2bda5b6febbe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d632878ad6541b1aa8714af63e2055d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66907dac98e9495faa6c362c4fcb9dab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d55b482c0bbe47d3a57055ab307453fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd51bcdc19ff403c86af19fa726af779",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c633a1f7f4849d8a730a8361e28a9e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d73cfdc0ae54d40b1c2b181bb655b7c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ad6d2aab6d049ac854b8cd24b68bc0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "602631957f5c40539b341d8d68190f03",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97fc512ab9dd4f79b90c47d2c6a63c02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4fbb39641a6c494593ee3fb8f1ed04e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6b35350ba1f4a6d8a761949cbd733c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ab20caeba6644b1a2103d89600a0b1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c0cdd797fa941e0bc6a01a7570d147b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "286437d2129c4b4a9382bf9b4fe5bffd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c64af04fa84e4c18b5dd813dcee488ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a07910b6ae1475f8271a1b6a76a4800",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "518e59d34f44415ca0956dce82409016",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b78b84cb2fc74f2785dd8cdf4b7b56c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ae74b2b5b8b42a8b083c5fb992b0a49",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88d5d4f93bec45799f386f1184a8b8a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c23155a968fe4482ae7fea1f154fb0dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47137f801c9249ee8e65ae7d64bcf54d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b62e9275cfc4ba7879b1a488805925e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2b01dacb8ce48d3aecf89f90c354aca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb959f3202bc4d0aa826479749861deb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "362790da431a4b0d824ab920fdf7ac15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22a1f5c0289a4a7aa8e0bbb0150a2155",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "612a584408d14dc08073047581fcaeb2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8459715df33a45a79da7f15d1ae89e45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "074aebaaeee9498ca48322b562bd492a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6916c3f87bf749009dcc79f418f8c682",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6a8060813a64cc1b25db634dea8aea7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16f1301e06aa4da0a316a80f90cf0b68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "273c5de969054d3a94c43f7dc6f4a690",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0252aea3334412bb5be3691477cf415",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37b4b116e2ff4e78aed50aae20978aa3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df2084f9a596461492ebc6031ab10906",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "253712e3171b4a92a2cafc6cf2311609",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c63a2356cc7458aa2e1e0fa8737d31e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9970df3110141769a04442277734096",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "469a362f504a4a13bc04c5850953d9cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45e9d0253af4473ab505febc5ba8cb12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b0bca2d487f43a89542d7d09bd0904c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f77d975303945d4a492ae990da7d2b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9cebe51542a4498951e1920d6671085",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cfd66cf510fb44d39dbc721da1c58b51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9349b3b48d5340609c77db2b65fcbb96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1d08a7f69bc40c7921c07ca63a02f9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "088bc4049b524061adeb515a462da2bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31b4013ae3dd4317b93339ead931703e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41a8f7ef51454017890ced1513b6acf7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29e44ea092324d09a56664b00ab335d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee620739dce14ed981383f9acd2f54bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "547a358cfa7840f489eb09374dbc775b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "970f92c6fc364ed5bcf42a16ae524440",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "090312fdaadf4af6a6c48ebbaedcd25f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e342668224440b9a48a7d9d14dddb4b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "715742ea5be846f6bca1a48f7a4b9fac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec7160f48076484fb6583080c4539419",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f2fb22089174c85b8f580c2e21a78b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f13fbd1247341fa85f8a136747b55a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1184e57d8eef408f9dfbbfbf331ed6a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "233a8c7d7a734ccd86ef5098a665c903",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ffb9223805de454594af2b36121781f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "157e6c9bfc5740f49db14fb15a41ab6c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4cad97da11d54a68bad7d560bdf978a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cbc78acbb3b34d1a87a7d654c441421e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f04b654948074cac89a37cfef463852a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9b7b0e22ba841348854f39d7d031fee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8e09917ff1d41d4929ecfe554a90748",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1228a0a9bc574feab62a1d44c0205c19",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "271c7858bde6446f9e8e7e48b0741d42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97df14a7e54848f79fa03b1a4082bbb1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a10676c047a14f919bdff54ae2178ff6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5f16349c58e47649af7172258070534",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da392cf056364f21804a2c8a8f08e92a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98d64681a2ac497a8d432b6a6abc50c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dbb081360f694824ba3dccfb81253c9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64c11c0a2a574fe78f445e9de86c12f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5bf3c4d866de4e99b2721ceb4258034e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5104dfb2cef444f38453cd6d6160c3fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b960be8489343ad8becc1cdc6da7645",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94ca2225eedb4eee8791577e4ddc2149",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c58f8c7387ea4f9aa4c4362c41362e06",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c955c993560048e698125714629757c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd1ef63f49d84d388cdcff71736daec4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f35cfb56d1f4adfbcec41f952702b57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "446b6e7586ab408db806890676affb1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98c4467567c54a1e9413e0d1661b6a31",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ef5513de1934caf8bf88f7fd24e9593",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34bbcefc036842d297d365af59f77e50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5edd7b0e1c284cb293abd5c0aa1ae5c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66d8fee1c4ec4f359e0a6f788bc7abff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "acc96659985e484790ac702537e5fa2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "838160f13da2422d9812c464c28f0f8f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69dfbf3bace146be80f4ec69dcfdbb9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d754b3218094033a1ba70a1af4f38c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "585d2da5d36d48958827c4bd8eb55c16",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c599eae68e84b168859b5ac90d87adf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fcb03efed4d145f0a6d2b4fef9e3e7db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c842905101604bebb0d4810b7b151df9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6f714a43134494cb0d4cc348741a92f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "112a03ba0d284cde86869a6cc2b41ce9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4deba534a624e33b50653bc79680c04",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9be56cea19614d6b9a58a60707e4cacb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41742b75db7b4733ac9a6afd0bb8cea5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f252e697aba4d3ba314b81d82bbc35d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd0dda62fce64fd8a357de832ef041e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "229f46d0b37440a09f0ff15d612bb019",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "355fe3b6d8454ee4b0db516afe11a4fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e96d3f0b7b0348c19a67b79a90b8ce32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44944d8fc72a4327a92a009aa8cfd563",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b645e2bd9ac49d193e42a90b1ba3bf3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "566d86be800548428822e0279e41a4fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "feb430f2ef7f42f8950605a347d0a1cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee1d282f589347fabee931c8aa42e1dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68f531d44580445bbc48e78a4647ad49",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2d146fd9d914ce99fc46b94372a1420",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a7a3d90d20240698405c1f8c74b4c96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc44482aa2784b4bbd06bf05a9a0d235",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6454bdd7c1da47158074cc83498dc842",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87c14e48a10b4489b3c5066ae9338512",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dbc89745ab1843938b7282e430b3a45c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b2a5d72574b446ba0e744d861469628",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2a556dc7e86453eba1c6f366651c326",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "071cc38185294f93a736c944086da5c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "290ce8a95912418b98bd89300a298af2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35cf6f56ec7d495295879b21f692b8f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e964c3cda3964daf923c91f2c46ae6ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2eaabd25d00147d080ee6c3ab80e5c0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cbfc31aa207247a0bff63be47cd57013",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb969dc1740047da93040873ad8dd3ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "613c36eb07184178b5ce716c5eb34f26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89ba394c9fdf45d7bb5861b170af16bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b95e3c5d8bc44e09a8a5f49b9d03f187",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1a364b431154013ad77a437ebaf961a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d9ae5829e914ce99cc15a7f6c0c04e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7faef13dfbd64635b42ee3800fc39bb1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3de2801d36f4b858b7e93550c38831c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6544e8f708ca437f97d70960c4c13ea4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca26083b9ffb4caeb5e709c4d63a882f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc3ede359fca47c7a71108fea66e5545",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e62960e0302490e9966c7ee841548f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1ccd7f0bf744dc2abb6bf89237eae20",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b6f78ffbfc744c88a4c71328199fea8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb3b10eaa1d045cf90d59453dcb0691b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d22733fe43e0423e9f48984df50b5b37",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0b9f0c97f4b437da0c26dfc7e381216",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "487643906ea946cf98d923117e9b56b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7bca629104d54b08afe8cb16655f3212",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e3486f4b11b499492b458344541d19a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "881712a5b7ce432386a02ce2ddf1786d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f42471f13fa74cc8a364d23cb4f0a459",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef291257302a47d0b475e8692ff399a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ad9bf93c9bc48fa9f0c62aea96741d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f770a43adef34fc39d4c40baf4b75613",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b574ce242fe4659a81f65ce0166e16d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c11a6ab4c786419c92a907d3e1fa5fd3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e8036d316d8435a86728cabb32ed76e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9109d941d4342f0a7748af0a16152fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "075fa34e3b3345cdacad229e0891fc6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39b7d18bb82b476d94d0c68aab592543",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76292c4d69004e6896cc68cd6fa8d5d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d649707e88304d839bff85a35eca392c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18b24abdd22445e69882974d5bc6249e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89d6ffa561b846b89fd41762eca98838",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22c079babee24a3c8be0dec2c24915d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44952249582b449dbce22d2e6ac8ec1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bace128d447347d4a4e5000f2e2521cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad64572ca0234096a257bd84f7dcbb48",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ad53cdb7dd14d19aa25fe64d5724fec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a8fc012b01e4bc49eba739141d63683",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "103044eaee154270a0fc1318b1a24bf7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "efc3adaa75a74086bbf2d5f45efbfcd0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f20f2e3d88b248189b08cb7d2e25e4ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a70a83d0241472fa67d35da4f5f7bd3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e7e2136fb4347cf982161266d38753b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a583bca3ef0437fbae8de65f383140f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17f334c9fad94ffa989287addf471fdd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3aa699da95d4fd193d4d6e01aa65f97",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b8791b3b47b4e87ad35a8da15113a30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1b3587122fb420b9726bc3660509fbd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea86091501be473284691b9dff425e38",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf4bd34448304a11b2763bad53eda01c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd3b8746b95f4f8c93cd69cbc34b4fe7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38b9cafc49b94b69a9bd1493e80d4e02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "573d2f4d32c84fb696fc02bc370bd6c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7df5e76ef1184e849aadd4c0f7890d27",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14b394e536064a9f82612c1679da6824",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f6db5dea57a4644b6c7bd43d3605d5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a114563d2db8447da4cfaabc19acb3b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "415e33b2afb8421bab3feaa5ff2ea749",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c87f3c7b2a54afcbc84819ba3a530da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b936b582fd5c4368b614a736b846ebd6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0be85593e21140b5980a5ceb3f1c6dd8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4542cd51132e45f5a19aa17327974fdb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d16e1038e384c1b984d621392b3f7d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e5da0acdb59447cb3e0a941d9a1d40f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0099b43199b44d3abec90e2d6145c851",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00f7c945bdb04a1a9d52d7d0be719e34",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca20643acf2a4496b25632c94f70fa8c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09d571fd2d2a4d6e9894ed43d25c2e52",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ff130083f6a433f88f336edc8520eb6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32a4b87a8af24141811bb2288196e9ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5325c7138ab648dd88bed9d758d8ab85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91407c7e772043eb8ce2012c79b7a286",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01172cf2b78a43a0b9b6a7d7847f1e5f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e3dc9d73b634272a6a6e8adc0347da0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3950bbce5d984550b566c17633127303",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5eb29c30c745480f844f0c81d11f9340",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f37f551254764786b0b6c3b2319c89f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6965974db85443f8b6c51fe0eb0683f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cdf462c4913d43e98169e3a5add66624",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24443befdb464bb995bbf6c5e9dd8808",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a14f4a6dbb664aa094068cb28a22e2f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08f12b1c0060436abc4fba23985a9773",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5a9d50461a54dc9adf7a8e0cf458887",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ff812c2278049feb26912af047fdb1e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4163478d3aee4a1c90b8236284903e48",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2eed03c58f8f4c10b4567b4daa982acb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de127b4a3ed54d088ffbc51b3dd2e840",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e10bab08e6494991950eb8b905936ac0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9199d579cf76442fac4f46f37fb09083",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d36eda5dc62846bf81fd974631aaf077",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e0684880faf4b9da8ea8e59edc08313",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d55526f3c1d40908a6f8ffe6a70c02f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61c48f4a23f4497f8bf31230ea4ca6ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b0eafff4c90409188ee8e4ff5de0ad1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ebc25864cfcb46999df427b6e927911d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25e5acbe0b044b3cacc4ca070efa6def",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf7ead8145cc4916a4a1f841d6efa398",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "134f28366e5c4a2580d3926748a5ff60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9975d5a6adb54b8f8c64d32e676ecb74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b7f209bbd48491f9360b739a1357be8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71d383c0360d41bd95ce7ea0e2108ea6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c01c0e1b66be40e5ba2e2d64a18d007b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0818eecf775f491c8c1e73e282179436",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31e02e940be14647aa278f135d035bd5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd8a7058987a46b5abc55aca8513ce03",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "549cbaf60a2f4a60979111c0f9d3e0e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d1454b5e72645428fb640ab8eeb8b9f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d16447b627e410291ccbdf111f28021",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d6d8a0d55b74ae089b1bd49f64d3eb8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dcaca64a76f74fe1bccba6edef5ac583",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af188f638f0041f0a6d2758b4c03be81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2979caa38ce24c699f513ce18e391435",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48441cd1234841f69b27e8024f5fbd78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f7a6203e3df44158bf3ef682e424b67",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d98fe4bf1004d81b43bf6c90ff1dabb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d7dbd4e29bf4c0daccb067d53bed9ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7ed08d91c204bf79dcd129b2b96affc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b31c743c6596450aa9348825db8f3706",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82d9005a8ed2465d90b94c43823f2e73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b1f7116291d4871baaac64da6493273",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "defd6f3fd46246c2a6dfbb0092cd33dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "515cda6560b74614ac0850e5f420b8ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7f8fd05393c4ef6ba2185f9e7f94050",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4ce86e26b374e64881b350fae9ae406",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a4b36bf5ca94ecab5b400d766a795b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf2ebd9c19104e45ac8af25d584a1d90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf0900bc1ce64a2fb5768f7df1cd484c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15d90293c83d46a5af00a0097e79ae89",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa24722cac6e4ad69ec5b959a5591450",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30d2b78ba746437fa7090c6508a4fcc7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2660498f091645c79d7f7b05da6f3715",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12ed814fa7254bb4b24378d67b133f31",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90b33464d3f6447f9ba4719f356728b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7dd67fb9c18d432c9fe51eabde543e06",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dcf02e3e99c44585ac5a968fc6dffcb5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8afa0e2cfd1f437c8208a16bd29c254a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df745834991e4553ab0070ce5e93e1f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42b37e397cdc46ba905ea7a15cd8d301",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c62321f6ddc4d51b2b6b0c389960908",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25715b96317b43c1ad6fe4c9462163b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8d82e399f8b49aaaa3c0ad4d17c5b15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "158414deeacb4532b36bc49a61d099da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d4b64538f0d4cc78f65a9c57cf24153",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee118dce6fa74b0297ee9336bceabaa5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "527d3960649541f9bb0591a5637dbd89",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37d082308706478e99138481421b9d59",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74fbd587a9824b909d910ff713c7841e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ae3c333f49f484aa53b6d131dd09902",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6c092a6b75f43dcace97ad8d2568df7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32afd4022747454ba748679de097c202",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a6e61a8b7374d458c5cd951cd32b74a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2ce416f777f433cb3f5a9e81cc0ebfb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2261f379ce574d73945cc8cb384bf501",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22e0285e29594b87b7fc30688b2de233",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c78107152bf043a4911bb5312e921453",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7fb6d0e717c447a18827f73e6cd06cb4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40574023f0904329a6276cc8e7631d7a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cec5217621fb41bd923688fd6fe0e95b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4930d6c206734611be186e35916c634b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42133be77c49443db879948d3fee6f6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f414121eb573455dae029e1bdc1e2f8e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d1a4af3a5404ca38d799ccddadf9079",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "230e3ffb08f4451ebb9767ca369d350c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a5042011a43438d9129a2031dd93a98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df1d042e485642e39a375025c65e1393",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d996db917ff4b718aa8871377f59456",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c85b03f35b64af8a318b30a33442946",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1109aab8a1ed4aeab70974873d19db68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "209df7ad0a6a42e1a9833477e57ad208",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a9df3d6723a497e88d90f5d240f5b96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69657866ecbb41ca9f55e5c979435124",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e9ea5ac82144f4c9d9eb16db3b105ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb32573868d147278b704c572d95070c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad407825418e4ea48ac4aec4d9bad416",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5312b0614594b6eaf17b8f15b47897b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2f95762cbf84d04bc439b52ee5f4658",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc02273c0f3343679869448188d5446e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e21866e4a953429b89da11fb837351bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8aeb9bb1b1d741109fa0a5b88e5f2829",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f6905b7399942758ee617b164afaa3e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae1e08a420104186859eb12800d7744e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad1a3a100da44ff2b21a7651063339de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "255b38c671cd41149625eb471ec65345",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18d3e98fb061414b82e6ab79051b277f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3463434d56a48a2b2735fc75623322d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6fbf3aff9a2049bb8e81e9f650482bca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c658c45ce1674a609c1200f70a1e56aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cfbb08d1ddca4a579dd3cc3e744f361d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4bef7c5b70ae409390cd5efa04b175f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9869a473d54348ad9e68942bed549a64",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc20d35c7271411e8416d15c7eb10e47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "300a92f1df1a459896272ea2fe3ade13",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7d1262516c54e17a327d7dcf3d52c79",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19f4506d57ba4570b887e329aef9a76b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a72c8d7ebb1d48be9e38d0ef3154d2bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0aecc41c23354c9a8cdd611e063a6c1d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa688b0119e84504840ca2922f45c998",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c71a5804610b422b9b3365a929189251",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5419be1b743e49eeaae16f7ad39a49bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ed0b7064fb54fd2adb6a09e54ed2c34",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c028489f7794918b05d1dc5172796c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34189e09b90c4a26bb8f45f5e158f8e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d995ffc507a464db8859c5cfed99b00",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e136e9576a3640b393c3d417ee22e82c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9311820c37445d59f3ef53305841252",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a566c3112b8a41f5b77dcbd2ff02b869",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "839419b11b804152b0e22f121f44eac4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c349085589ad483d94950095850c34b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9597777434844ecb90da0cb9cef68826",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8aa50236aaa74bf69eaf0a35190b720d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54b5b9c371794f6582021a0ac7dd2d82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3976b2d501048b9be337008bd67b2cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67bbfa19542b4f20b552b64f04334d62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ae8ae76bfba4bc3bf0ca0ac7e254e2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3cf1d2d538fc48aeba6dfd51db71a997",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16f2ac64636e41dc805fe7ce249dd5c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d3c3afd4c334b0893a756b5198e53ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d9b2ff41b2844fd8d60d63ea9ee8693",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1051d4bf5eb421cabfa5c5f5fbcc9ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38c7e539eb6749b2a1af6c3a4e331811",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68bc59ac88fe4f0f96a5afc088e8dced",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7dc8d1262b61447badab83a9f11bca9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fcc01f2a6bb749c38f41d340d1267021",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c4b6bfac5f64db59e872def20c0a396",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1adc5884979d4791b06c78f5deed6232",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ba5a6bfe32c4cd8b3bd421243dd69ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e05116894ea4ab6bdaf8e13546f3d66",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-04 10:49:55,301 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/pinecone_plugins'])\n",
      "2025-01-04 10:49:55,302 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'upserted_count': 696}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "INDEX_NAME = 'interview-qa2'\n",
    "epub_folder = '/home/bullat/projects/rag/Interview-2.0/data'\n",
    "documents = []\n",
    "for filename in os.listdir(epub_folder):\n",
    "    if filename.endswith('.epub'):\n",
    "        file_path = os.path.join(epub_folder, filename)\n",
    "        text = extract_text_from_epub(file_path)\n",
    "        #TODO использовать name для ссылки на источник\n",
    "        documents.append({'name': filename, 'text': text})\n",
    "\n",
    "text_splitter = CharacterTextSplitter(chunk_size=2000, chunk_overlap=200)\n",
    "texts = []\n",
    "for doc in documents:\n",
    "    chunks = text_splitter.split_text(doc['text'])\n",
    "    for chunk in chunks:\n",
    "        text_id = f\"{doc['name']}_{chunks.index(chunk)}\" \n",
    "        ind_text_dict[text_id] = chunk\n",
    "    # texts.extend(text_splitter.split_text(doc['text']))\n",
    "# print(ind_text_dict[0])\n",
    "\n",
    "embeddings = generate_embeddings(ind_text_dict)\n",
    "# print(embeddings[0])\n",
    "# Create the index if it doesn't exist\n",
    "if INDEX_NAME not in pc.list_indexes().names():\n",
    "    pc.create_index(\n",
    "        name=INDEX_NAME,\n",
    "        dimension=len(embeddings[0]['values']),\n",
    "        metric='cosine',\n",
    "        spec=ServerlessSpec(\n",
    "            cloud='aws',\n",
    "            region='us-east-1'\n",
    "        )\n",
    "    )\n",
    "\n",
    "# Upsert embeddings to the Pinecone index\n",
    "index = pc.Index(INDEX_NAME)\n",
    "index.upsert(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41da32a1b8ef41b8aa87a898ffacac0f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-04 10:50:00,197 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/pinecone_plugins'])\n",
      "2025-01-04 10:50:00,199 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference\n",
      "2025-01-04 10:50:01,134 - __main__ - INFO - Retrieved results: {'matches': [{'id': 'John Mongan - Programming Interviews Exposed_ Coding Your '\n",
      "                    'Way Through the Interview (2018, Wrox Press) - '\n",
      "                    'libgen.li.epub_181',\n",
      "              'score': 0.315634668,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_37',\n",
      "              'score': 0.282967895,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_48',\n",
      "              'score': 0.276279628,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_52',\n",
      "              'score': 0.276162028,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_6',\n",
      "              'score': 0.247066781,\n",
      "              'values': []}],\n",
      " 'namespace': '',\n",
      " 'usage': {'read_units': 6}}\n",
      "2025-01-04 10:50:10,579 - httpx - INFO - HTTP Request: POST https://api.mistral.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "590331b90764400095c4cbcb6a651c5d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-04 10:50:10,619 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/pinecone_plugins'])\n",
      "2025-01-04 10:50:10,621 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference\n",
      "2025-01-04 10:50:11,321 - __main__ - INFO - Retrieved results: {'matches': [{'id': 'John Mongan - Programming Interviews Exposed_ Coding Your '\n",
      "                    'Way Through the Interview (2018, Wrox Press) - '\n",
      "                    'libgen.li.epub_181',\n",
      "              'score': 0.283457965,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_52',\n",
      "              'score': 0.271393955,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_37',\n",
      "              'score': 0.263340652,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_48',\n",
      "              'score': 0.249823749,\n",
      "              'values': []},\n",
      "             {'id': 'John Mongan - Programming Interviews Exposed_ Coding Your '\n",
      "                    'Way Through the Interview (2018, Wrox Press) - '\n",
      "                    'libgen.li.epub_222',\n",
      "              'score': 0.242120966,\n",
      "              'values': []}],\n",
      " 'namespace': '',\n",
      " 'usage': {'read_units': 6}}\n",
      "2025-01-04 10:50:18,645 - httpx - INFO - HTTP Request: POST https://api.mistral.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f83f3ac578e4576b7f988e68f8aa477",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-04 10:50:18,671 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/pinecone_plugins'])\n",
      "2025-01-04 10:50:18,673 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference\n",
      "2025-01-04 10:50:19,346 - __main__ - INFO - Retrieved results: {'matches': [{'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_52',\n",
      "              'score': 0.265813738,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_37',\n",
      "              'score': 0.263616115,\n",
      "              'values': []},\n",
      "             {'id': 'John Mongan - Programming Interviews Exposed_ Coding Your '\n",
      "                    'Way Through the Interview (2018, Wrox Press) - '\n",
      "                    'libgen.li.epub_181',\n",
      "              'score': 0.259607375,\n",
      "              'values': []},\n",
      "             {'id': 'John Mongan - Programming Interviews Exposed_ Coding Your '\n",
      "                    'Way Through the Interview (2018, Wrox Press) - '\n",
      "                    'libgen.li.epub_222',\n",
      "              'score': 0.257264197,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_48',\n",
      "              'score': 0.229598939,\n",
      "              'values': []}],\n",
      " 'namespace': '',\n",
      " 'usage': {'read_units': 6}}\n",
      "2025-01-04 10:50:26,280 - httpx - INFO - HTTP Request: POST https://api.mistral.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "edff45e31a7a4ecc89b886bf2bbcae89",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-04 10:50:26,313 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/pinecone_plugins'])\n",
      "2025-01-04 10:50:26,314 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference\n",
      "2025-01-04 10:50:27,011 - __main__ - INFO - Retrieved results: {'matches': [{'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_37',\n",
      "              'score': 0.263424,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_52',\n",
      "              'score': 0.249376684,\n",
      "              'values': []},\n",
      "             {'id': 'John Mongan - Programming Interviews Exposed_ Coding Your '\n",
      "                    'Way Through the Interview (2018, Wrox Press) - '\n",
      "                    'libgen.li.epub_181',\n",
      "              'score': 0.242394552,\n",
      "              'values': []},\n",
      "             {'id': 'John Mongan - Programming Interviews Exposed_ Coding Your '\n",
      "                    'Way Through the Interview (2018, Wrox Press) - '\n",
      "                    'libgen.li.epub_222',\n",
      "              'score': 0.237621799,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_48',\n",
      "              'score': 0.233924255,\n",
      "              'values': []}],\n",
      " 'namespace': '',\n",
      " 'usage': {'read_units': 6}}\n",
      "2025-01-04 10:50:33,043 - httpx - INFO - HTTP Request: POST https://api.mistral.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b0a76f4cbb14dd49c02bef80bce48fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-04 10:50:33,096 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/pinecone_plugins'])\n",
      "2025-01-04 10:50:33,098 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference\n",
      "2025-01-04 10:50:33,763 - __main__ - INFO - Retrieved results: {'matches': [{'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_37',\n",
      "              'score': 0.252271444,\n",
      "              'values': []},\n",
      "             {'id': 'Narayanan Vishwanathan - SQL and NoSQL Interview '\n",
      "                    'Questions_ Your essential guide to acing SQL and NoSQL '\n",
      "                    'job interviews (English Edition)-BPB Publications '\n",
      "                    '(2023).epub_4',\n",
      "              'score': 0.249290153,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_48',\n",
      "              'score': 0.2476217,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_28',\n",
      "              'score': 0.229124576,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_0',\n",
      "              'score': 0.223165125,\n",
      "              'values': []}],\n",
      " 'namespace': '',\n",
      " 'usage': {'read_units': 6}}\n",
      "2025-01-04 10:50:41,574 - httpx - INFO - HTTP Request: POST https://api.mistral.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4d11d5938754ec9aa78aef94a1856d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-04 10:50:41,607 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/pinecone_plugins'])\n",
      "2025-01-04 10:50:41,608 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference\n",
      "2025-01-04 10:50:42,251 - __main__ - INFO - Retrieved results: {'matches': [{'id': 'John Mongan - Programming Interviews Exposed_ Coding Your '\n",
      "                    'Way Through the Interview (2018, Wrox Press) - '\n",
      "                    'libgen.li.epub_181',\n",
      "              'score': 0.281535089,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_52',\n",
      "              'score': 0.275243282,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_37',\n",
      "              'score': 0.250266701,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_48',\n",
      "              'score': 0.226984143,\n",
      "              'values': []},\n",
      "             {'id': 'John Mongan - Programming Interviews Exposed_ Coding Your '\n",
      "                    'Way Through the Interview (2018, Wrox Press) - '\n",
      "                    'libgen.li.epub_222',\n",
      "              'score': 0.201069236,\n",
      "              'values': []}],\n",
      " 'namespace': '',\n",
      " 'usage': {'read_units': 6}}\n",
      "2025-01-04 10:50:49,940 - httpx - INFO - HTTP Request: POST https://api.mistral.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b7b5f327181487298464f9024a5e8a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-04 10:50:49,966 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/pinecone_plugins'])\n",
      "2025-01-04 10:50:49,967 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference\n",
      "2025-01-04 10:50:50,587 - __main__ - INFO - Retrieved results: {'matches': [{'id': 'John Mongan - Programming Interviews Exposed_ Coding Your '\n",
      "                    'Way Through the Interview (2018, Wrox Press) - '\n",
      "                    'libgen.li.epub_181',\n",
      "              'score': 0.268440485,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_37',\n",
      "              'score': 0.255766809,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_52',\n",
      "              'score': 0.25068441,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_48',\n",
      "              'score': 0.232309654,\n",
      "              'values': []},\n",
      "             {'id': 'Narayanan Vishwanathan - SQL and NoSQL Interview '\n",
      "                    'Questions_ Your essential guide to acing SQL and NoSQL '\n",
      "                    'job interviews (English Edition)-BPB Publications '\n",
      "                    '(2023).epub_4',\n",
      "              'score': 0.222782165,\n",
      "              'values': []}],\n",
      " 'namespace': '',\n",
      " 'usage': {'read_units': 6}}\n",
      "2025-01-04 10:51:00,357 - httpx - INFO - HTTP Request: POST https://api.mistral.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d8a886397f44c1d8cd245c752bcabd9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-04 10:51:00,407 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/pinecone_plugins'])\n",
      "2025-01-04 10:51:00,408 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference\n",
      "2025-01-04 10:51:01,034 - __main__ - INFO - Retrieved results: {'matches': [{'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_52',\n",
      "              'score': 0.284159511,\n",
      "              'values': []},\n",
      "             {'id': 'John Mongan - Programming Interviews Exposed_ Coding Your '\n",
      "                    'Way Through the Interview (2018, Wrox Press) - '\n",
      "                    'libgen.li.epub_181',\n",
      "              'score': 0.259851575,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_37',\n",
      "              'score': 0.254846752,\n",
      "              'values': []},\n",
      "             {'id': 'John Mongan - Programming Interviews Exposed_ Coding Your '\n",
      "                    'Way Through the Interview (2018, Wrox Press) - '\n",
      "                    'libgen.li.epub_222',\n",
      "              'score': 0.230557069,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_0',\n",
      "              'score': 0.218190879,\n",
      "              'values': []}],\n",
      " 'namespace': '',\n",
      " 'usage': {'read_units': 6}}\n",
      "2025-01-04 10:51:11,247 - httpx - INFO - HTTP Request: POST https://api.mistral.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c4b1af98ca94e4496943576ed77db7d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-04 10:51:11,280 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/pinecone_plugins'])\n",
      "2025-01-04 10:51:11,281 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference\n",
      "2025-01-04 10:51:11,975 - __main__ - INFO - Retrieved results: {'matches': [{'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_37',\n",
      "              'score': 0.230281293,\n",
      "              'values': []},\n",
      "             {'id': 'John Mongan - Programming Interviews Exposed_ Coding Your '\n",
      "                    'Way Through the Interview (2018, Wrox Press) - '\n",
      "                    'libgen.li.epub_181',\n",
      "              'score': 0.225543305,\n",
      "              'values': []},\n",
      "             {'id': 'Narayanan Vishwanathan - SQL and NoSQL Interview '\n",
      "                    'Questions_ Your essential guide to acing SQL and NoSQL '\n",
      "                    'job interviews (English Edition)-BPB Publications '\n",
      "                    '(2023).epub_4',\n",
      "              'score': 0.224687412,\n",
      "              'values': []},\n",
      "             {'id': 'John Mongan - Programming Interviews Exposed_ Coding Your '\n",
      "                    'Way Through the Interview (2018, Wrox Press) - '\n",
      "                    'libgen.li.epub_222',\n",
      "              'score': 0.219514564,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_48',\n",
      "              'score': 0.210788757,\n",
      "              'values': []}],\n",
      " 'namespace': '',\n",
      " 'usage': {'read_units': 6}}\n",
      "2025-01-04 10:51:16,960 - httpx - INFO - HTTP Request: POST https://api.mistral.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "828a46efe2754ec58122c1d7ed9cbc25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-04 10:51:16,986 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/pinecone_plugins'])\n",
      "2025-01-04 10:51:16,987 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference\n",
      "2025-01-04 10:51:17,621 - __main__ - INFO - Retrieved results: {'matches': [{'id': 'John Mongan - Programming Interviews Exposed_ Coding Your '\n",
      "                    'Way Through the Interview (2018, Wrox Press) - '\n",
      "                    'libgen.li.epub_181',\n",
      "              'score': 0.306645334,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_7',\n",
      "              'score': 0.303710729,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_0',\n",
      "              'score': 0.289489806,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_52',\n",
      "              'score': 0.264792651,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_179',\n",
      "              'score': 0.255771339,\n",
      "              'values': []}],\n",
      " 'namespace': '',\n",
      " 'usage': {'read_units': 6}}\n",
      "2025-01-04 10:51:29,267 - httpx - INFO - HTTP Request: POST https://api.mistral.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee786139ffee41e2937786fe8c812586",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-04 10:51:29,300 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/pinecone_plugins'])\n",
      "2025-01-04 10:51:29,301 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference\n",
      "2025-01-04 10:51:29,948 - __main__ - INFO - Retrieved results: {'matches': [{'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_52',\n",
      "              'score': 0.259976834,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_37',\n",
      "              'score': 0.253669202,\n",
      "              'values': []},\n",
      "             {'id': 'John Mongan - Programming Interviews Exposed_ Coding Your '\n",
      "                    'Way Through the Interview (2018, Wrox Press) - '\n",
      "                    'libgen.li.epub_222',\n",
      "              'score': 0.24727577,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_48',\n",
      "              'score': 0.240441695,\n",
      "              'values': []},\n",
      "             {'id': 'John Mongan - Programming Interviews Exposed_ Coding Your '\n",
      "                    'Way Through the Interview (2018, Wrox Press) - '\n",
      "                    'libgen.li.epub_181',\n",
      "              'score': 0.238895208,\n",
      "              'values': []}],\n",
      " 'namespace': '',\n",
      " 'usage': {'read_units': 6}}\n",
      "2025-01-04 10:51:38,514 - httpx - INFO - HTTP Request: POST https://api.mistral.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8071c945e4284f9fbef0325b5569cf60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-04 10:51:38,545 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/pinecone_plugins'])\n",
      "2025-01-04 10:51:38,546 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference\n",
      "2025-01-04 10:51:39,158 - __main__ - INFO - Retrieved results: {'matches': [{'id': 'John Mongan - Programming Interviews Exposed_ Coding Your '\n",
      "                    'Way Through the Interview (2018, Wrox Press) - '\n",
      "                    'libgen.li.epub_181',\n",
      "              'score': 0.286523938,\n",
      "              'values': []},\n",
      "             {'id': 'John Mongan - Programming Interviews Exposed_ Coding Your '\n",
      "                    'Way Through the Interview (2018, Wrox Press) - '\n",
      "                    'libgen.li.epub_222',\n",
      "              'score': 0.27295202,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_52',\n",
      "              'score': 0.26908192,\n",
      "              'values': []},\n",
      "             {'id': 'Narayanan Vishwanathan - SQL and NoSQL Interview '\n",
      "                    'Questions_ Your essential guide to acing SQL and NoSQL '\n",
      "                    'job interviews (English Edition)-BPB Publications '\n",
      "                    '(2023).epub_4',\n",
      "              'score': 0.238834202,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_0',\n",
      "              'score': 0.229403257,\n",
      "              'values': []}],\n",
      " 'namespace': '',\n",
      " 'usage': {'read_units': 6}}\n",
      "2025-01-04 10:51:52,071 - httpx - INFO - HTTP Request: POST https://api.mistral.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5942165ffeff4ed8b5327e530aac8efb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-04 10:51:52,098 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/pinecone_plugins'])\n",
      "2025-01-04 10:51:52,099 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference\n",
      "2025-01-04 10:51:52,738 - __main__ - INFO - Retrieved results: {'matches': [{'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_48',\n",
      "              'score': 0.3224819,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_37',\n",
      "              'score': 0.284793794,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_52',\n",
      "              'score': 0.259101689,\n",
      "              'values': []},\n",
      "             {'id': 'John Mongan - Programming Interviews Exposed_ Coding Your '\n",
      "                    'Way Through the Interview (2018, Wrox Press) - '\n",
      "                    'libgen.li.epub_181',\n",
      "              'score': 0.255170316,\n",
      "              'values': []},\n",
      "             {'id': 'Narayanan Vishwanathan - SQL and NoSQL Interview '\n",
      "                    'Questions_ Your essential guide to acing SQL and NoSQL '\n",
      "                    'job interviews (English Edition)-BPB Publications '\n",
      "                    '(2023).epub_4',\n",
      "              'score': 0.243956819,\n",
      "              'values': []}],\n",
      " 'namespace': '',\n",
      " 'usage': {'read_units': 6}}\n",
      "2025-01-04 10:51:58,180 - httpx - INFO - HTTP Request: POST https://api.mistral.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2c3b0e209024acdabed0bd9c1156601",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-04 10:51:58,207 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/pinecone_plugins'])\n",
      "2025-01-04 10:51:58,208 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference\n",
      "2025-01-04 10:51:58,904 - __main__ - INFO - Retrieved results: {'matches': [{'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_52',\n",
      "              'score': 0.296857208,\n",
      "              'values': []},\n",
      "             {'id': 'John Mongan - Programming Interviews Exposed_ Coding Your '\n",
      "                    'Way Through the Interview (2018, Wrox Press) - '\n",
      "                    'libgen.li.epub_181',\n",
      "              'score': 0.254925519,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_37',\n",
      "              'score': 0.240546852,\n",
      "              'values': []},\n",
      "             {'id': 'John Mongan - Programming Interviews Exposed_ Coding Your '\n",
      "                    'Way Through the Interview (2018, Wrox Press) - '\n",
      "                    'libgen.li.epub_222',\n",
      "              'score': 0.231162041,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_179',\n",
      "              'score': 0.225529909,\n",
      "              'values': []}],\n",
      " 'namespace': '',\n",
      " 'usage': {'read_units': 6}}\n",
      "2025-01-04 10:52:11,725 - httpx - INFO - HTTP Request: POST https://api.mistral.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72c3e009c69145e89ea39e22037101a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-04 10:52:11,750 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/pinecone_plugins'])\n",
      "2025-01-04 10:52:11,751 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference\n",
      "2025-01-04 10:52:12,382 - __main__ - INFO - Retrieved results: {'matches': [{'id': 'John Mongan - Programming Interviews Exposed_ Coding Your '\n",
      "                    'Way Through the Interview (2018, Wrox Press) - '\n",
      "                    'libgen.li.epub_181',\n",
      "              'score': 0.298918873,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_37',\n",
      "              'score': 0.275815427,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_48',\n",
      "              'score': 0.258046895,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_52',\n",
      "              'score': 0.242811069,\n",
      "              'values': []},\n",
      "             {'id': 'John Mongan - Programming Interviews Exposed_ Coding Your '\n",
      "                    'Way Through the Interview (2018, Wrox Press) - '\n",
      "                    'libgen.li.epub_222',\n",
      "              'score': 0.221408248,\n",
      "              'values': []}],\n",
      " 'namespace': '',\n",
      " 'usage': {'read_units': 6}}\n",
      "2025-01-04 10:52:22,409 - httpx - INFO - HTTP Request: POST https://api.mistral.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "beeee0dd573d4ccaaf0ec7cab2919899",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-04 10:52:22,435 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/pinecone_plugins'])\n",
      "2025-01-04 10:52:22,436 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference\n",
      "2025-01-04 10:52:23,072 - __main__ - INFO - Retrieved results: {'matches': [{'id': 'John Mongan - Programming Interviews Exposed_ Coding Your '\n",
      "                    'Way Through the Interview (2018, Wrox Press) - '\n",
      "                    'libgen.li.epub_181',\n",
      "              'score': 0.298349589,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_37',\n",
      "              'score': 0.291206658,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_52',\n",
      "              'score': 0.282725066,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_48',\n",
      "              'score': 0.26460132,\n",
      "              'values': []},\n",
      "             {'id': 'John Mongan - Programming Interviews Exposed_ Coding Your '\n",
      "                    'Way Through the Interview (2018, Wrox Press) - '\n",
      "                    'libgen.li.epub_222',\n",
      "              'score': 0.264385283,\n",
      "              'values': []}],\n",
      " 'namespace': '',\n",
      " 'usage': {'read_units': 6}}\n",
      "2025-01-04 10:52:32,596 - httpx - INFO - HTTP Request: POST https://api.mistral.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03fa72caf8b646cdaeb676420ba77bba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-04 10:52:32,628 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/pinecone_plugins'])\n",
      "2025-01-04 10:52:32,630 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference\n",
      "2025-01-04 10:52:33,302 - __main__ - INFO - Retrieved results: {'matches': [{'id': 'John Mongan - Programming Interviews Exposed_ Coding Your '\n",
      "                    'Way Through the Interview (2018, Wrox Press) - '\n",
      "                    'libgen.li.epub_222',\n",
      "              'score': 0.272903144,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_52',\n",
      "              'score': 0.267158419,\n",
      "              'values': []},\n",
      "             {'id': 'John Mongan - Programming Interviews Exposed_ Coding Your '\n",
      "                    'Way Through the Interview (2018, Wrox Press) - '\n",
      "                    'libgen.li.epub_181',\n",
      "              'score': 0.26070556,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_37',\n",
      "              'score': 0.251920372,\n",
      "              'values': []},\n",
      "             {'id': 'Narayanan Vishwanathan - SQL and NoSQL Interview '\n",
      "                    'Questions_ Your essential guide to acing SQL and NoSQL '\n",
      "                    'job interviews (English Edition)-BPB Publications '\n",
      "                    '(2023).epub_4',\n",
      "              'score': 0.244445667,\n",
      "              'values': []}],\n",
      " 'namespace': '',\n",
      " 'usage': {'read_units': 6}}\n",
      "2025-01-04 10:52:39,644 - httpx - INFO - HTTP Request: POST https://api.mistral.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9029d29554440fb82a5705dd606bafd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-04 10:52:39,669 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/pinecone_plugins'])\n",
      "2025-01-04 10:52:39,670 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference\n",
      "2025-01-04 10:52:40,287 - __main__ - INFO - Retrieved results: {'matches': [{'id': 'John Mongan - Programming Interviews Exposed_ Coding Your '\n",
      "                    'Way Through the Interview (2018, Wrox Press) - '\n",
      "                    'libgen.li.epub_181',\n",
      "              'score': 0.25149855,\n",
      "              'values': []},\n",
      "             {'id': 'Narayanan Vishwanathan - SQL and NoSQL Interview '\n",
      "                    'Questions_ Your essential guide to acing SQL and NoSQL '\n",
      "                    'job interviews (English Edition)-BPB Publications '\n",
      "                    '(2023).epub_4',\n",
      "              'score': 0.243961647,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_37',\n",
      "              'score': 0.241372555,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_48',\n",
      "              'score': 0.230153069,\n",
      "              'values': []},\n",
      "             {'id': 'John Mongan - Programming Interviews Exposed_ Coding Your '\n",
      "                    'Way Through the Interview (2018, Wrox Press) - '\n",
      "                    'libgen.li.epub_222',\n",
      "              'score': 0.229636654,\n",
      "              'values': []}],\n",
      " 'namespace': '',\n",
      " 'usage': {'read_units': 6}}\n",
      "2025-01-04 10:52:51,928 - httpx - INFO - HTTP Request: POST https://api.mistral.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d10b7f409d2d4ace9f940e022e8edba5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-04 10:52:51,961 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/pinecone_plugins'])\n",
      "2025-01-04 10:52:51,963 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference\n",
      "2025-01-04 10:52:52,593 - __main__ - INFO - Retrieved results: {'matches': [{'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_48',\n",
      "              'score': 0.31613645,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_37',\n",
      "              'score': 0.311274737,\n",
      "              'values': []},\n",
      "             {'id': 'John Mongan - Programming Interviews Exposed_ Coding Your '\n",
      "                    'Way Through the Interview (2018, Wrox Press) - '\n",
      "                    'libgen.li.epub_181',\n",
      "              'score': 0.305254102,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_52',\n",
      "              'score': 0.283624589,\n",
      "              'values': []},\n",
      "             {'id': 'John Mongan - Programming Interviews Exposed_ Coding Your '\n",
      "                    'Way Through the Interview (2018, Wrox Press) - '\n",
      "                    'libgen.li.epub_222',\n",
      "              'score': 0.231838882,\n",
      "              'values': []}],\n",
      " 'namespace': '',\n",
      " 'usage': {'read_units': 6}}\n",
      "2025-01-04 10:53:00,408 - httpx - INFO - HTTP Request: POST https://api.mistral.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "470078fb6b7f4c84a6298950448a2c0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-04 10:53:00,436 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/pinecone_plugins'])\n",
      "2025-01-04 10:53:00,437 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference\n",
      "2025-01-04 10:53:01,226 - __main__ - INFO - Retrieved results: {'matches': [{'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_37',\n",
      "              'score': 0.232715517,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_48',\n",
      "              'score': 0.22874783,\n",
      "              'values': []},\n",
      "             {'id': 'Narayanan Vishwanathan - SQL and NoSQL Interview '\n",
      "                    'Questions_ Your essential guide to acing SQL and NoSQL '\n",
      "                    'job interviews (English Edition)-BPB Publications '\n",
      "                    '(2023).epub_4',\n",
      "              'score': 0.218591735,\n",
      "              'values': []},\n",
      "             {'id': 'John Mongan - Programming Interviews Exposed_ Coding Your '\n",
      "                    'Way Through the Interview (2018, Wrox Press) - '\n",
      "                    'libgen.li.epub_181',\n",
      "              'score': 0.200412124,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_179',\n",
      "              'score': 0.199679285,\n",
      "              'values': []}],\n",
      " 'namespace': '',\n",
      " 'usage': {'read_units': 6}}\n",
      "2025-01-04 10:53:05,236 - httpx - INFO - HTTP Request: POST https://api.mistral.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "274ab0de241c40cf844202ca36a7d0a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-04 10:53:05,274 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/pinecone_plugins'])\n",
      "2025-01-04 10:53:05,275 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference\n",
      "2025-01-04 10:53:05,948 - __main__ - INFO - Retrieved results: {'matches': [{'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_52',\n",
      "              'score': 0.268253088,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_37',\n",
      "              'score': 0.268057764,\n",
      "              'values': []},\n",
      "             {'id': 'John Mongan - Programming Interviews Exposed_ Coding Your '\n",
      "                    'Way Through the Interview (2018, Wrox Press) - '\n",
      "                    'libgen.li.epub_181',\n",
      "              'score': 0.259692,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_6',\n",
      "              'score': 0.218142748,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_48',\n",
      "              'score': 0.216673225,\n",
      "              'values': []}],\n",
      " 'namespace': '',\n",
      " 'usage': {'read_units': 6}}\n",
      "2025-01-04 10:53:09,829 - httpx - INFO - HTTP Request: POST https://api.mistral.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77435171513d493aa04e6b548a4ba98a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-04 10:53:09,860 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/pinecone_plugins'])\n",
      "2025-01-04 10:53:09,862 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference\n",
      "2025-01-04 10:53:10,640 - __main__ - INFO - Retrieved results: {'matches': [{'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_112',\n",
      "              'score': 0.324085265,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_141',\n",
      "              'score': 0.287549675,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_48',\n",
      "              'score': 0.2800982,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_189',\n",
      "              'score': 0.279964685,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_37',\n",
      "              'score': 0.279394299,\n",
      "              'values': []}],\n",
      " 'namespace': '',\n",
      " 'usage': {'read_units': 6}}\n",
      "2025-01-04 10:53:20,120 - httpx - INFO - HTTP Request: POST https://api.mistral.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85fb0604ee9a4f338dcc8baced066a2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-04 10:53:20,148 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/pinecone_plugins'])\n",
      "2025-01-04 10:53:20,149 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference\n",
      "2025-01-04 10:53:20,793 - __main__ - INFO - Retrieved results: {'matches': [{'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_52',\n",
      "              'score': 0.291153252,\n",
      "              'values': []},\n",
      "             {'id': 'Narayanan Vishwanathan - SQL and NoSQL Interview '\n",
      "                    'Questions_ Your essential guide to acing SQL and NoSQL '\n",
      "                    'job interviews (English Edition)-BPB Publications '\n",
      "                    '(2023).epub_4',\n",
      "              'score': 0.265570283,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_179',\n",
      "              'score': 0.264512271,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_99',\n",
      "              'score': 0.2611444,\n",
      "              'values': []},\n",
      "             {'id': 'John Mongan - Programming Interviews Exposed_ Coding Your '\n",
      "                    'Way Through the Interview (2018, Wrox Press) - '\n",
      "                    'libgen.li.epub_222',\n",
      "              'score': 0.251154453,\n",
      "              'values': []}],\n",
      " 'namespace': '',\n",
      " 'usage': {'read_units': 6}}\n",
      "2025-01-04 10:53:28,283 - httpx - INFO - HTTP Request: POST https://api.mistral.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a5138a860ca418b8d116815fcdde52b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-04 10:53:28,310 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/pinecone_plugins'])\n",
      "2025-01-04 10:53:28,311 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference\n",
      "2025-01-04 10:53:29,117 - __main__ - INFO - Retrieved results: {'matches': [{'id': 'John Mongan - Programming Interviews Exposed_ Coding Your '\n",
      "                    'Way Through the Interview (2018, Wrox Press) - '\n",
      "                    'libgen.li.epub_75',\n",
      "              'score': 0.325372338,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_141',\n",
      "              'score': 0.292265236,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_148',\n",
      "              'score': 0.279181212,\n",
      "              'values': []},\n",
      "             {'id': 'John Mongan - Programming Interviews Exposed_ Coding Your '\n",
      "                    'Way Through the Interview (2018, Wrox Press) - '\n",
      "                    'libgen.li.epub_181',\n",
      "              'score': 0.275000304,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_6',\n",
      "              'score': 0.266727895,\n",
      "              'values': []}],\n",
      " 'namespace': '',\n",
      " 'usage': {'read_units': 6}}\n",
      "2025-01-04 10:53:44,583 - httpx - INFO - HTTP Request: POST https://api.mistral.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d13af5ad36534e6aa4f19099acfb2db6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-04 10:53:44,609 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/pinecone_plugins'])\n",
      "2025-01-04 10:53:44,611 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference\n",
      "2025-01-04 10:53:45,227 - __main__ - INFO - Retrieved results: {'matches': [{'id': 'John Mongan - Programming Interviews Exposed_ Coding Your '\n",
      "                    'Way Through the Interview (2018, Wrox Press) - '\n",
      "                    'libgen.li.epub_181',\n",
      "              'score': 0.324195772,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_52',\n",
      "              'score': 0.258238375,\n",
      "              'values': []},\n",
      "             {'id': 'Narayanan Vishwanathan - SQL and NoSQL Interview '\n",
      "                    'Questions_ Your essential guide to acing SQL and NoSQL '\n",
      "                    'job interviews (English Edition)-BPB Publications '\n",
      "                    '(2023).epub_4',\n",
      "              'score': 0.226562634,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_7',\n",
      "              'score': 0.218683168,\n",
      "              'values': []},\n",
      "             {'id': 'John Mongan - Programming Interviews Exposed_ Coding Your '\n",
      "                    'Way Through the Interview (2018, Wrox Press) - '\n",
      "                    'libgen.li.epub_222',\n",
      "              'score': 0.209943891,\n",
      "              'values': []}],\n",
      " 'namespace': '',\n",
      " 'usage': {'read_units': 6}}\n",
      "2025-01-04 10:53:52,857 - httpx - INFO - HTTP Request: POST https://api.mistral.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4617da0c3ab48d1ad149a54f08f8594",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-04 10:53:52,882 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/pinecone_plugins'])\n",
      "2025-01-04 10:53:52,884 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference\n",
      "2025-01-04 10:53:53,677 - __main__ - INFO - Retrieved results: {'matches': [{'id': 'Narayanan Vishwanathan - SQL and NoSQL Interview '\n",
      "                    'Questions_ Your essential guide to acing SQL and NoSQL '\n",
      "                    'job interviews (English Edition)-BPB Publications '\n",
      "                    '(2023).epub_4',\n",
      "              'score': 0.235818312,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_48',\n",
      "              'score': 0.234484687,\n",
      "              'values': []},\n",
      "             {'id': 'John Mongan - Programming Interviews Exposed_ Coding Your '\n",
      "                    'Way Through the Interview (2018, Wrox Press) - '\n",
      "                    'libgen.li.epub_181',\n",
      "              'score': 0.232513577,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_0',\n",
      "              'score': 0.228299633,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_37',\n",
      "              'score': 0.222052664,\n",
      "              'values': []}],\n",
      " 'namespace': '',\n",
      " 'usage': {'read_units': 6}}\n",
      "2025-01-04 10:53:59,154 - httpx - INFO - HTTP Request: POST https://api.mistral.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f36b0522ba854db39b381529a1079096",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-04 10:53:59,183 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/pinecone_plugins'])\n",
      "2025-01-04 10:53:59,184 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference\n",
      "2025-01-04 10:53:59,967 - __main__ - INFO - Retrieved results: {'matches': [{'id': 'John Mongan - Programming Interviews Exposed_ Coding Your '\n",
      "                    'Way Through the Interview (2018, Wrox Press) - '\n",
      "                    'libgen.li.epub_181',\n",
      "              'score': 0.25756672,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_99',\n",
      "              'score': 0.238736466,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_48',\n",
      "              'score': 0.222472578,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_150',\n",
      "              'score': 0.222290114,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_179',\n",
      "              'score': 0.217392,\n",
      "              'values': []}],\n",
      " 'namespace': '',\n",
      " 'usage': {'read_units': 6}}\n",
      "2025-01-04 10:54:03,703 - httpx - INFO - HTTP Request: POST https://api.mistral.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f1663ad1e4f4aad87d3544335e48843",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-04 10:54:03,731 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/pinecone_plugins'])\n",
      "2025-01-04 10:54:03,732 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference\n",
      "2025-01-04 10:54:04,353 - __main__ - INFO - Retrieved results: {'matches': [{'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_135',\n",
      "              'score': 0.306405783,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_166',\n",
      "              'score': 0.299626648,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_64',\n",
      "              'score': 0.292105347,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_137',\n",
      "              'score': 0.291023016,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_90',\n",
      "              'score': 0.284864,\n",
      "              'values': []}],\n",
      " 'namespace': '',\n",
      " 'usage': {'read_units': 6}}\n",
      "2025-01-04 10:54:09,288 - httpx - INFO - HTTP Request: POST https://api.mistral.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d57ec9984e714e6cbc993743a3314b6a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-04 10:54:09,315 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/pinecone_plugins'])\n",
      "2025-01-04 10:54:09,316 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference\n",
      "2025-01-04 10:54:09,994 - __main__ - INFO - Retrieved results: {'matches': [{'id': 'John Mongan - Programming Interviews Exposed_ Coding Your '\n",
      "                    'Way Through the Interview (2018, Wrox Press) - '\n",
      "                    'libgen.li.epub_181',\n",
      "              'score': 0.291990459,\n",
      "              'values': []},\n",
      "             {'id': 'John Mongan - Programming Interviews Exposed_ Coding Your '\n",
      "                    'Way Through the Interview (2018, Wrox Press) - '\n",
      "                    'libgen.li.epub_222',\n",
      "              'score': 0.261368066,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_52',\n",
      "              'score': 0.245584324,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_37',\n",
      "              'score': 0.245211601,\n",
      "              'values': []},\n",
      "             {'id': 'Narayanan Vishwanathan - SQL and NoSQL Interview '\n",
      "                    'Questions_ Your essential guide to acing SQL and NoSQL '\n",
      "                    'job interviews (English Edition)-BPB Publications '\n",
      "                    '(2023).epub_4',\n",
      "              'score': 0.234642655,\n",
      "              'values': []}],\n",
      " 'namespace': '',\n",
      " 'usage': {'read_units': 6}}\n",
      "2025-01-04 10:54:15,776 - httpx - INFO - HTTP Request: POST https://api.mistral.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14e58487601e42b59ef1d2be936efb23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-04 10:54:15,803 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/pinecone_plugins'])\n",
      "2025-01-04 10:54:15,804 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference\n",
      "2025-01-04 10:54:16,562 - __main__ - INFO - Retrieved results: {'matches': [{'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_52',\n",
      "              'score': 0.265345573,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_37',\n",
      "              'score': 0.253982931,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_48',\n",
      "              'score': 0.249373764,\n",
      "              'values': []},\n",
      "             {'id': 'John Mongan - Programming Interviews Exposed_ Coding Your '\n",
      "                    'Way Through the Interview (2018, Wrox Press) - '\n",
      "                    'libgen.li.epub_181',\n",
      "              'score': 0.248794287,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_0',\n",
      "              'score': 0.231311634,\n",
      "              'values': []}],\n",
      " 'namespace': '',\n",
      " 'usage': {'read_units': 6}}\n",
      "2025-01-04 10:54:21,092 - httpx - INFO - HTTP Request: POST https://api.mistral.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb38cf2d33364529b372a5f8f415fb07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-04 10:54:21,118 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/pinecone_plugins'])\n",
      "2025-01-04 10:54:21,120 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference\n",
      "2025-01-04 10:54:21,990 - __main__ - INFO - Retrieved results: {'matches': [{'id': 'John Mongan - Programming Interviews Exposed_ Coding Your '\n",
      "                    'Way Through the Interview (2018, Wrox Press) - '\n",
      "                    'libgen.li.epub_181',\n",
      "              'score': 0.28613323,\n",
      "              'values': []},\n",
      "             {'id': 'Narayanan Vishwanathan - SQL and NoSQL Interview '\n",
      "                    'Questions_ Your essential guide to acing SQL and NoSQL '\n",
      "                    'job interviews (English Edition)-BPB Publications '\n",
      "                    '(2023).epub_4',\n",
      "              'score': 0.258019835,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_37',\n",
      "              'score': 0.248957485,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_52',\n",
      "              'score': 0.245619804,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_48',\n",
      "              'score': 0.241212398,\n",
      "              'values': []}],\n",
      " 'namespace': '',\n",
      " 'usage': {'read_units': 6}}\n",
      "2025-01-04 10:54:32,688 - httpx - INFO - HTTP Request: POST https://api.mistral.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "725c8e9fc8b74a70a8fbf9e58d5b2424",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-04 10:54:32,714 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/pinecone_plugins'])\n",
      "2025-01-04 10:54:32,716 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference\n",
      "2025-01-04 10:54:33,468 - __main__ - INFO - Retrieved results: {'matches': [{'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_48',\n",
      "              'score': 0.234899819,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_37',\n",
      "              'score': 0.222914785,\n",
      "              'values': []},\n",
      "             {'id': 'John Mongan - Programming Interviews Exposed_ Coding Your '\n",
      "                    'Way Through the Interview (2018, Wrox Press) - '\n",
      "                    'libgen.li.epub_181',\n",
      "              'score': 0.212896317,\n",
      "              'values': []},\n",
      "             {'id': 'Narayanan Vishwanathan - SQL and NoSQL Interview '\n",
      "                    'Questions_ Your essential guide to acing SQL and NoSQL '\n",
      "                    'job interviews (English Edition)-BPB Publications '\n",
      "                    '(2023).epub_4',\n",
      "              'score': 0.205744907,\n",
      "              'values': []},\n",
      "             {'id': 'John Mongan - Programming Interviews Exposed_ Coding Your '\n",
      "                    'Way Through the Interview (2018, Wrox Press) - '\n",
      "                    'libgen.li.epub_222',\n",
      "              'score': 0.199128509,\n",
      "              'values': []}],\n",
      " 'namespace': '',\n",
      " 'usage': {'read_units': 6}}\n",
      "2025-01-04 10:54:38,648 - httpx - INFO - HTTP Request: POST https://api.mistral.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b065f440afa941009872b6bc96b1a34a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-04 10:54:38,675 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/pinecone_plugins'])\n",
      "2025-01-04 10:54:38,677 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference\n",
      "2025-01-04 10:54:39,465 - __main__ - INFO - Retrieved results: {'matches': [{'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_52',\n",
      "              'score': 0.317212522,\n",
      "              'values': []},\n",
      "             {'id': 'John Mongan - Programming Interviews Exposed_ Coding Your '\n",
      "                    'Way Through the Interview (2018, Wrox Press) - '\n",
      "                    'libgen.li.epub_181',\n",
      "              'score': 0.299772978,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_37',\n",
      "              'score': 0.244633883,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_0',\n",
      "              'score': 0.219208121,\n",
      "              'values': []},\n",
      "             {'id': 'John Mongan - Programming Interviews Exposed_ Coding Your '\n",
      "                    'Way Through the Interview (2018, Wrox Press) - '\n",
      "                    'libgen.li.epub_222',\n",
      "              'score': 0.214474499,\n",
      "              'values': []}],\n",
      " 'namespace': '',\n",
      " 'usage': {'read_units': 6}}\n",
      "2025-01-04 10:54:51,515 - httpx - INFO - HTTP Request: POST https://api.mistral.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71e5a61756764603b9c8b765b8548bb4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-04 10:54:51,545 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/pinecone_plugins'])\n",
      "2025-01-04 10:54:51,546 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference\n",
      "2025-01-04 10:54:52,162 - __main__ - INFO - Retrieved results: {'matches': [{'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_109',\n",
      "              'score': 0.418812931,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_101',\n",
      "              'score': 0.400686473,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_11',\n",
      "              'score': 0.312406123,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_78',\n",
      "              'score': 0.280319512,\n",
      "              'values': []},\n",
      "             {'id': 'John Mongan - Programming Interviews Exposed_ Coding Your '\n",
      "                    'Way Through the Interview (2018, Wrox Press) - '\n",
      "                    'libgen.li.epub_181',\n",
      "              'score': 0.277171254,\n",
      "              'values': []}],\n",
      " 'namespace': '',\n",
      " 'usage': {'read_units': 6}}\n",
      "2025-01-04 10:54:59,451 - httpx - INFO - HTTP Request: POST https://api.mistral.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23ba9db2bb8f4521be0530c693aa012b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-04 10:54:59,478 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/pinecone_plugins'])\n",
      "2025-01-04 10:54:59,480 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference\n",
      "2025-01-04 10:55:00,107 - __main__ - INFO - Retrieved results: {'matches': [{'id': 'John Mongan - Programming Interviews Exposed_ Coding Your '\n",
      "                    'Way Through the Interview (2018, Wrox Press) - '\n",
      "                    'libgen.li.epub_181',\n",
      "              'score': 0.290299475,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_37',\n",
      "              'score': 0.246047184,\n",
      "              'values': []},\n",
      "             {'id': 'Narayanan Vishwanathan - SQL and NoSQL Interview '\n",
      "                    'Questions_ Your essential guide to acing SQL and NoSQL '\n",
      "                    'job interviews (English Edition)-BPB Publications '\n",
      "                    '(2023).epub_4',\n",
      "              'score': 0.245066926,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_52',\n",
      "              'score': 0.238940105,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_48',\n",
      "              'score': 0.218876556,\n",
      "              'values': []}],\n",
      " 'namespace': '',\n",
      " 'usage': {'read_units': 6}}\n",
      "2025-01-04 10:55:08,986 - httpx - INFO - HTTP Request: POST https://api.mistral.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5eea85c6dce3486298cfe5d278637ef2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-04 10:55:09,012 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/pinecone_plugins'])\n",
      "2025-01-04 10:55:09,013 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference\n",
      "2025-01-04 10:55:09,683 - __main__ - INFO - Retrieved results: {'matches': [{'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_7',\n",
      "              'score': 0.298514456,\n",
      "              'values': []},\n",
      "             {'id': 'John Mongan - Programming Interviews Exposed_ Coding Your '\n",
      "                    'Way Through the Interview (2018, Wrox Press) - '\n",
      "                    'libgen.li.epub_181',\n",
      "              'score': 0.285708129,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_48',\n",
      "              'score': 0.256853431,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_167',\n",
      "              'score': 0.251374483,\n",
      "              'values': []},\n",
      "             {'id': 'John Mongan - Programming Interviews Exposed_ Coding Your '\n",
      "                    'Way Through the Interview (2018, Wrox Press) - '\n",
      "                    'libgen.li.epub_317',\n",
      "              'score': 0.24653843,\n",
      "              'values': []}],\n",
      " 'namespace': '',\n",
      " 'usage': {'read_units': 6}}\n",
      "2025-01-04 10:55:15,977 - httpx - INFO - HTTP Request: POST https://api.mistral.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7092f1a105a04dee8233cb13be5806da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-04 10:55:16,005 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/pinecone_plugins'])\n",
      "2025-01-04 10:55:16,008 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference\n",
      "2025-01-04 10:55:16,694 - __main__ - INFO - Retrieved results: {'matches': [{'id': 'John Mongan - Programming Interviews Exposed_ Coding Your '\n",
      "                    'Way Through the Interview (2018, Wrox Press) - '\n",
      "                    'libgen.li.epub_181',\n",
      "              'score': 0.333663136,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_44',\n",
      "              'score': 0.329024702,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_48',\n",
      "              'score': 0.323168337,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_136',\n",
      "              'score': 0.321733445,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_161',\n",
      "              'score': 0.302500933,\n",
      "              'values': []}],\n",
      " 'namespace': '',\n",
      " 'usage': {'read_units': 6}}\n",
      "2025-01-04 10:55:24,172 - httpx - INFO - HTTP Request: POST https://api.mistral.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8de94d4e2444fb2905966852f43913e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-04 10:55:24,199 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/pinecone_plugins'])\n",
      "2025-01-04 10:55:24,200 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference\n",
      "2025-01-04 10:55:24,833 - __main__ - INFO - Retrieved results: {'matches': [{'id': 'John Mongan - Programming Interviews Exposed_ Coding Your '\n",
      "                    'Way Through the Interview (2018, Wrox Press) - '\n",
      "                    'libgen.li.epub_181',\n",
      "              'score': 0.299953878,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_52',\n",
      "              'score': 0.274503917,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_37',\n",
      "              'score': 0.252562702,\n",
      "              'values': []},\n",
      "             {'id': 'Narayanan Vishwanathan - SQL and NoSQL Interview '\n",
      "                    'Questions_ Your essential guide to acing SQL and NoSQL '\n",
      "                    'job interviews (English Edition)-BPB Publications '\n",
      "                    '(2023).epub_4',\n",
      "              'score': 0.252410084,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_0',\n",
      "              'score': 0.246245027,\n",
      "              'values': []}],\n",
      " 'namespace': '',\n",
      " 'usage': {'read_units': 6}}\n",
      "2025-01-04 10:55:34,927 - httpx - INFO - HTTP Request: POST https://api.mistral.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a44fd079a9654a4c8196ad9779408f97",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-04 10:55:34,967 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/pinecone_plugins'])\n",
      "2025-01-04 10:55:34,973 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference\n",
      "2025-01-04 10:55:35,636 - __main__ - INFO - Retrieved results: {'matches': [{'id': 'John Mongan - Programming Interviews Exposed_ Coding Your '\n",
      "                    'Way Through the Interview (2018, Wrox Press) - '\n",
      "                    'libgen.li.epub_181',\n",
      "              'score': 0.281829625,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_37',\n",
      "              'score': 0.267004788,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_52',\n",
      "              'score': 0.266520917,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_48',\n",
      "              'score': 0.250588059,\n",
      "              'values': []},\n",
      "             {'id': 'John Mongan - Programming Interviews Exposed_ Coding Your '\n",
      "                    'Way Through the Interview (2018, Wrox Press) - '\n",
      "                    'libgen.li.epub_222',\n",
      "              'score': 0.2400942,\n",
      "              'values': []}],\n",
      " 'namespace': '',\n",
      " 'usage': {'read_units': 6}}\n",
      "2025-01-04 10:55:44,051 - httpx - INFO - HTTP Request: POST https://api.mistral.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8ad0e9da3b749f1886d109b28c3707a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-04 10:55:44,079 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/pinecone_plugins'])\n",
      "2025-01-04 10:55:44,080 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference\n",
      "2025-01-04 10:55:45,018 - __main__ - INFO - Retrieved results: {'matches': [{'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_52',\n",
      "              'score': 0.294229925,\n",
      "              'values': []},\n",
      "             {'id': 'John Mongan - Programming Interviews Exposed_ Coding Your '\n",
      "                    'Way Through the Interview (2018, Wrox Press) - '\n",
      "                    'libgen.li.epub_181',\n",
      "              'score': 0.257864982,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_48',\n",
      "              'score': 0.251392722,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_0',\n",
      "              'score': 0.242465198,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_37',\n",
      "              'score': 0.238301039,\n",
      "              'values': []}],\n",
      " 'namespace': '',\n",
      " 'usage': {'read_units': 6}}\n",
      "2025-01-04 10:55:52,652 - httpx - INFO - HTTP Request: POST https://api.mistral.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4025e68fa4104b90ba6dc91c196ddab4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-04 10:55:52,687 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/pinecone_plugins'])\n",
      "2025-01-04 10:55:52,688 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference\n",
      "2025-01-04 10:55:53,333 - __main__ - INFO - Retrieved results: {'matches': [{'id': 'John Mongan - Programming Interviews Exposed_ Coding Your '\n",
      "                    'Way Through the Interview (2018, Wrox Press) - '\n",
      "                    'libgen.li.epub_181',\n",
      "              'score': 0.28787908,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_52',\n",
      "              'score': 0.262246788,\n",
      "              'values': []},\n",
      "             {'id': 'John Mongan - Programming Interviews Exposed_ Coding Your '\n",
      "                    'Way Through the Interview (2018, Wrox Press) - '\n",
      "                    'libgen.li.epub_222',\n",
      "              'score': 0.261518091,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_37',\n",
      "              'score': 0.233135715,\n",
      "              'values': []},\n",
      "             {'id': 'Narayanan Vishwanathan - SQL and NoSQL Interview '\n",
      "                    'Questions_ Your essential guide to acing SQL and NoSQL '\n",
      "                    'job interviews (English Edition)-BPB Publications '\n",
      "                    '(2023).epub_4',\n",
      "              'score': 0.227601781,\n",
      "              'values': []}],\n",
      " 'namespace': '',\n",
      " 'usage': {'read_units': 6}}\n",
      "2025-01-04 10:56:03,299 - httpx - INFO - HTTP Request: POST https://api.mistral.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7fa32d1a2e4d47b48b229f3fa4cdf9ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-04 10:56:03,327 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/pinecone_plugins'])\n",
      "2025-01-04 10:56:03,328 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference\n",
      "2025-01-04 10:56:03,981 - __main__ - INFO - Retrieved results: {'matches': [{'id': 'John Mongan - Programming Interviews Exposed_ Coding Your '\n",
      "                    'Way Through the Interview (2018, Wrox Press) - '\n",
      "                    'libgen.li.epub_181',\n",
      "              'score': 0.286364406,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_52',\n",
      "              'score': 0.273888618,\n",
      "              'values': []},\n",
      "             {'id': 'John Mongan - Programming Interviews Exposed_ Coding Your '\n",
      "                    'Way Through the Interview (2018, Wrox Press) - '\n",
      "                    'libgen.li.epub_222',\n",
      "              'score': 0.252749652,\n",
      "              'values': []},\n",
      "             {'id': 'Narayanan Vishwanathan - SQL and NoSQL Interview '\n",
      "                    'Questions_ Your essential guide to acing SQL and NoSQL '\n",
      "                    'job interviews (English Edition)-BPB Publications '\n",
      "                    '(2023).epub_4',\n",
      "              'score': 0.230519757,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_37',\n",
      "              'score': 0.224087417,\n",
      "              'values': []}],\n",
      " 'namespace': '',\n",
      " 'usage': {'read_units': 6}}\n",
      "2025-01-04 10:56:08,665 - httpx - INFO - HTTP Request: POST https://api.mistral.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3561f79e3dfa440997e5212311022cf5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-04 10:56:08,691 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/pinecone_plugins'])\n",
      "2025-01-04 10:56:08,693 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference\n",
      "2025-01-04 10:56:09,486 - __main__ - INFO - Retrieved results: {'matches': [{'id': 'John Mongan - Programming Interviews Exposed_ Coding Your '\n",
      "                    'Way Through the Interview (2018, Wrox Press) - '\n",
      "                    'libgen.li.epub_181',\n",
      "              'score': 0.283463031,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_52',\n",
      "              'score': 0.267035484,\n",
      "              'values': []},\n",
      "             {'id': 'John Mongan - Programming Interviews Exposed_ Coding Your '\n",
      "                    'Way Through the Interview (2018, Wrox Press) - '\n",
      "                    'libgen.li.epub_222',\n",
      "              'score': 0.228137285,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_37',\n",
      "              'score': 0.227490842,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_179',\n",
      "              'score': 0.22243996,\n",
      "              'values': []}],\n",
      " 'namespace': '',\n",
      " 'usage': {'read_units': 6}}\n",
      "2025-01-04 10:56:19,054 - httpx - INFO - HTTP Request: POST https://api.mistral.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39bea467e32d42eb859bf81da5b43ea9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-04 10:56:19,083 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/pinecone_plugins'])\n",
      "2025-01-04 10:56:19,084 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference\n",
      "2025-01-04 10:56:19,737 - __main__ - INFO - Retrieved results: {'matches': [{'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_166',\n",
      "              'score': 0.296187967,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_48',\n",
      "              'score': 0.272540152,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_37',\n",
      "              'score': 0.272488475,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_28',\n",
      "              'score': 0.271734506,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_89',\n",
      "              'score': 0.26581046,\n",
      "              'values': []}],\n",
      " 'namespace': '',\n",
      " 'usage': {'read_units': 6}}\n",
      "2025-01-04 10:56:27,924 - httpx - INFO - HTTP Request: POST https://api.mistral.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97abaab3d4f24959bb3260e2e5625a02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-04 10:56:27,957 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/pinecone_plugins'])\n",
      "2025-01-04 10:56:27,959 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference\n",
      "2025-01-04 10:56:28,559 - __main__ - INFO - Retrieved results: {'matches': [{'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_52',\n",
      "              'score': 0.326943576,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_37',\n",
      "              'score': 0.289963633,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_0',\n",
      "              'score': 0.278860122,\n",
      "              'values': []},\n",
      "             {'id': 'John Mongan - Programming Interviews Exposed_ Coding Your '\n",
      "                    'Way Through the Interview (2018, Wrox Press) - '\n",
      "                    'libgen.li.epub_181',\n",
      "              'score': 0.268898964,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_48',\n",
      "              'score': 0.256628096,\n",
      "              'values': []}],\n",
      " 'namespace': '',\n",
      " 'usage': {'read_units': 6}}\n",
      "2025-01-04 10:56:36,243 - httpx - INFO - HTTP Request: POST https://api.mistral.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6d235ddb297499384369b1335d2050d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-04 10:56:36,267 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/pinecone_plugins'])\n",
      "2025-01-04 10:56:36,268 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference\n",
      "2025-01-04 10:56:36,950 - __main__ - INFO - Retrieved results: {'matches': [{'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_48',\n",
      "              'score': 0.304641575,\n",
      "              'values': []},\n",
      "             {'id': 'John Mongan - Programming Interviews Exposed_ Coding Your '\n",
      "                    'Way Through the Interview (2018, Wrox Press) - '\n",
      "                    'libgen.li.epub_181',\n",
      "              'score': 0.282812,\n",
      "              'values': []},\n",
      "             {'id': 'Narayanan Vishwanathan - SQL and NoSQL Interview '\n",
      "                    'Questions_ Your essential guide to acing SQL and NoSQL '\n",
      "                    'job interviews (English Edition)-BPB Publications '\n",
      "                    '(2023).epub_4',\n",
      "              'score': 0.26410073,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_28',\n",
      "              'score': 0.244292945,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_179',\n",
      "              'score': 0.235641,\n",
      "              'values': []}],\n",
      " 'namespace': '',\n",
      " 'usage': {'read_units': 6}}\n",
      "2025-01-04 10:56:42,004 - httpx - INFO - HTTP Request: POST https://api.mistral.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "515ce3e47bef4f4786ac657814635bbd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-04 10:56:42,030 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/pinecone_plugins'])\n",
      "2025-01-04 10:56:42,031 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference\n",
      "2025-01-04 10:56:42,669 - __main__ - INFO - Retrieved results: {'matches': [{'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_7',\n",
      "              'score': 0.314124167,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_48',\n",
      "              'score': 0.3004421,\n",
      "              'values': []},\n",
      "             {'id': 'John Mongan - Programming Interviews Exposed_ Coding Your '\n",
      "                    'Way Through the Interview (2018, Wrox Press) - '\n",
      "                    'libgen.li.epub_181',\n",
      "              'score': 0.262610316,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_37',\n",
      "              'score': 0.262156814,\n",
      "              'values': []},\n",
      "             {'id': 'John Mongan - Programming Interviews Exposed_ Coding Your '\n",
      "                    'Way Through the Interview (2018, Wrox Press) - '\n",
      "                    'libgen.li.epub_287',\n",
      "              'score': 0.251761168,\n",
      "              'values': []}],\n",
      " 'namespace': '',\n",
      " 'usage': {'read_units': 6}}\n",
      "2025-01-04 10:56:52,767 - httpx - INFO - HTTP Request: POST https://api.mistral.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b163ab5ec0ac4794b7d23863a03ce007",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-04 10:56:52,791 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/pinecone_plugins'])\n",
      "2025-01-04 10:56:52,793 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference\n",
      "2025-01-04 10:56:53,425 - __main__ - INFO - Retrieved results: {'matches': [{'id': 'John Mongan - Programming Interviews Exposed_ Coding Your '\n",
      "                    'Way Through the Interview (2018, Wrox Press) - '\n",
      "                    'libgen.li.epub_181',\n",
      "              'score': 0.277388036,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_48',\n",
      "              'score': 0.273377419,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_37',\n",
      "              'score': 0.261703789,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_52',\n",
      "              'score': 0.259345591,\n",
      "              'values': []},\n",
      "             {'id': 'John Mongan - Programming Interviews Exposed_ Coding Your '\n",
      "                    'Way Through the Interview (2018, Wrox Press) - '\n",
      "                    'libgen.li.epub_222',\n",
      "              'score': 0.251933962,\n",
      "              'values': []}],\n",
      " 'namespace': '',\n",
      " 'usage': {'read_units': 6}}\n",
      "2025-01-04 10:57:07,872 - httpx - INFO - HTTP Request: POST https://api.mistral.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "423489bcad534651ae7ce7c7b9cb4b9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-04 10:57:07,906 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/pinecone_plugins'])\n",
      "2025-01-04 10:57:07,907 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference\n",
      "2025-01-04 10:57:08,549 - __main__ - INFO - Retrieved results: {'matches': [{'id': 'John Mongan - Programming Interviews Exposed_ Coding Your '\n",
      "                    'Way Through the Interview (2018, Wrox Press) - '\n",
      "                    'libgen.li.epub_181',\n",
      "              'score': 0.349823356,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_52',\n",
      "              'score': 0.28272149,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_37',\n",
      "              'score': 0.275399476,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_48',\n",
      "              'score': 0.256613582,\n",
      "              'values': []},\n",
      "             {'id': 'Narayanan Vishwanathan - SQL and NoSQL Interview '\n",
      "                    'Questions_ Your essential guide to acing SQL and NoSQL '\n",
      "                    'job interviews (English Edition)-BPB Publications '\n",
      "                    '(2023).epub_4',\n",
      "              'score': 0.239983082,\n",
      "              'values': []}],\n",
      " 'namespace': '',\n",
      " 'usage': {'read_units': 6}}\n",
      "2025-01-04 10:57:18,204 - httpx - INFO - HTTP Request: POST https://api.mistral.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49efad8396c443d4a58a61a573ef276f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-04 10:57:18,231 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/pinecone_plugins'])\n",
      "2025-01-04 10:57:18,232 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference\n",
      "2025-01-04 10:57:18,928 - __main__ - INFO - Retrieved results: {'matches': [{'id': 'Narayanan Vishwanathan - SQL and NoSQL Interview '\n",
      "                    'Questions_ Your essential guide to acing SQL and NoSQL '\n",
      "                    'job interviews (English Edition)-BPB Publications '\n",
      "                    '(2023).epub_4',\n",
      "              'score': 0.273272127,\n",
      "              'values': []},\n",
      "             {'id': 'John Mongan - Programming Interviews Exposed_ Coding Your '\n",
      "                    'Way Through the Interview (2018, Wrox Press) - '\n",
      "                    'libgen.li.epub_181',\n",
      "              'score': 0.262307584,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_52',\n",
      "              'score': 0.253024936,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_0',\n",
      "              'score': 0.227224678,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_48',\n",
      "              'score': 0.224550083,\n",
      "              'values': []}],\n",
      " 'namespace': '',\n",
      " 'usage': {'read_units': 6}}\n",
      "2025-01-04 10:57:21,938 - httpx - INFO - HTTP Request: POST https://api.mistral.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f4065a6357643fe9b173db5c42bfa2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-04 10:57:21,966 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/pinecone_plugins'])\n",
      "2025-01-04 10:57:21,967 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference\n",
      "2025-01-04 10:57:22,942 - __main__ - INFO - Retrieved results: {'matches': [{'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_37',\n",
      "              'score': 0.277405053,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_48',\n",
      "              'score': 0.275306165,\n",
      "              'values': []},\n",
      "             {'id': 'John Mongan - Programming Interviews Exposed_ Coding Your '\n",
      "                    'Way Through the Interview (2018, Wrox Press) - '\n",
      "                    'libgen.li.epub_181',\n",
      "              'score': 0.275160164,\n",
      "              'values': []},\n",
      "             {'id': 'Narayanan Vishwanathan - SQL and NoSQL Interview '\n",
      "                    'Questions_ Your essential guide to acing SQL and NoSQL '\n",
      "                    'job interviews (English Edition)-BPB Publications '\n",
      "                    '(2023).epub_4',\n",
      "              'score': 0.247607455,\n",
      "              'values': []},\n",
      "             {'id': 'John Mongan - Programming Interviews Exposed_ Coding Your '\n",
      "                    'Way Through the Interview (2018, Wrox Press) - '\n",
      "                    'libgen.li.epub_222',\n",
      "              'score': 0.239187911,\n",
      "              'values': []}],\n",
      " 'namespace': '',\n",
      " 'usage': {'read_units': 6}}\n",
      "2025-01-04 10:57:29,833 - httpx - INFO - HTTP Request: POST https://api.mistral.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "506929bd88a943f3930608211217e867",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-04 10:57:29,860 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/pinecone_plugins'])\n",
      "2025-01-04 10:57:29,862 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference\n",
      "2025-01-04 10:57:30,477 - __main__ - INFO - Retrieved results: {'matches': [{'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_52',\n",
      "              'score': 0.260013312,\n",
      "              'values': []},\n",
      "             {'id': 'John Mongan - Programming Interviews Exposed_ Coding Your '\n",
      "                    'Way Through the Interview (2018, Wrox Press) - '\n",
      "                    'libgen.li.epub_181',\n",
      "              'score': 0.247466981,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_37',\n",
      "              'score': 0.238734409,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_48',\n",
      "              'score': 0.23227568,\n",
      "              'values': []},\n",
      "             {'id': 'John Mongan - Programming Interviews Exposed_ Coding Your '\n",
      "                    'Way Through the Interview (2018, Wrox Press) - '\n",
      "                    'libgen.li.epub_222',\n",
      "              'score': 0.222193792,\n",
      "              'values': []}],\n",
      " 'namespace': '',\n",
      " 'usage': {'read_units': 6}}\n",
      "2025-01-04 10:57:37,767 - httpx - INFO - HTTP Request: POST https://api.mistral.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f00532727714598928348539d7feaeb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-04 10:57:37,792 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/pinecone_plugins'])\n",
      "2025-01-04 10:57:37,793 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference\n",
      "2025-01-04 10:57:38,441 - __main__ - INFO - Retrieved results: {'matches': [{'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_7',\n",
      "              'score': 0.292149216,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_48',\n",
      "              'score': 0.284943,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_37',\n",
      "              'score': 0.269664615,\n",
      "              'values': []},\n",
      "             {'id': 'John Mongan - Programming Interviews Exposed_ Coding Your '\n",
      "                    'Way Through the Interview (2018, Wrox Press) - '\n",
      "                    'libgen.li.epub_317',\n",
      "              'score': 0.253210098,\n",
      "              'values': []},\n",
      "             {'id': 'John Mongan - Programming Interviews Exposed_ Coding Your '\n",
      "                    'Way Through the Interview (2018, Wrox Press) - '\n",
      "                    'libgen.li.epub_181',\n",
      "              'score': 0.248427719,\n",
      "              'values': []}],\n",
      " 'namespace': '',\n",
      " 'usage': {'read_units': 6}}\n",
      "2025-01-04 10:57:44,515 - httpx - INFO - HTTP Request: POST https://api.mistral.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a12f7895fcdc4d3193ccb4270b9f1847",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-04 10:57:44,542 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/pinecone_plugins'])\n",
      "2025-01-04 10:57:44,543 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference\n",
      "2025-01-04 10:57:45,208 - __main__ - INFO - Retrieved results: {'matches': [{'id': 'John Mongan - Programming Interviews Exposed_ Coding Your '\n",
      "                    'Way Through the Interview (2018, Wrox Press) - '\n",
      "                    'libgen.li.epub_181',\n",
      "              'score': 0.324158818,\n",
      "              'values': []},\n",
      "             {'id': 'John Mongan - Programming Interviews Exposed_ Coding Your '\n",
      "                    'Way Through the Interview (2018, Wrox Press) - '\n",
      "                    'libgen.li.epub_222',\n",
      "              'score': 0.244371057,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_52',\n",
      "              'score': 0.23594749,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_37',\n",
      "              'score': 0.235508472,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_7',\n",
      "              'score': 0.231052846,\n",
      "              'values': []}],\n",
      " 'namespace': '',\n",
      " 'usage': {'read_units': 6}}\n",
      "2025-01-04 10:57:53,163 - httpx - INFO - HTTP Request: POST https://api.mistral.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ceeada4ce28e495484807ee8248af6f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-04 10:57:53,194 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/pinecone_plugins'])\n",
      "2025-01-04 10:57:53,195 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference\n",
      "2025-01-04 10:57:53,851 - __main__ - INFO - Retrieved results: {'matches': [{'id': 'John Mongan - Programming Interviews Exposed_ Coding Your '\n",
      "                    'Way Through the Interview (2018, Wrox Press) - '\n",
      "                    'libgen.li.epub_181',\n",
      "              'score': 0.286823571,\n",
      "              'values': []},\n",
      "             {'id': 'John Mongan - Programming Interviews Exposed_ Coding Your '\n",
      "                    'Way Through the Interview (2018, Wrox Press) - '\n",
      "                    'libgen.li.epub_222',\n",
      "              'score': 0.252832562,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_37',\n",
      "              'score': 0.239768788,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_52',\n",
      "              'score': 0.232802123,\n",
      "              'values': []},\n",
      "             {'id': 'Narayanan Vishwanathan - SQL and NoSQL Interview '\n",
      "                    'Questions_ Your essential guide to acing SQL and NoSQL '\n",
      "                    'job interviews (English Edition)-BPB Publications '\n",
      "                    '(2023).epub_4',\n",
      "              'score': 0.222159386,\n",
      "              'values': []}],\n",
      " 'namespace': '',\n",
      " 'usage': {'read_units': 6}}\n",
      "2025-01-04 10:57:59,415 - httpx - INFO - HTTP Request: POST https://api.mistral.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71f285410eac441796ace3d27aa49121",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-04 10:57:59,440 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/pinecone_plugins'])\n",
      "2025-01-04 10:57:59,441 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference\n",
      "2025-01-04 10:58:00,068 - __main__ - INFO - Retrieved results: {'matches': [{'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_166',\n",
      "              'score': 0.2810103,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_99',\n",
      "              'score': 0.276640981,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_179',\n",
      "              'score': 0.272053629,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_48',\n",
      "              'score': 0.260253102,\n",
      "              'values': []},\n",
      "             {'id': 'John Mongan - Programming Interviews Exposed_ Coding Your '\n",
      "                    'Way Through the Interview (2018, Wrox Press) - '\n",
      "                    'libgen.li.epub_325',\n",
      "              'score': 0.258440256,\n",
      "              'values': []}],\n",
      " 'namespace': '',\n",
      " 'usage': {'read_units': 6}}\n",
      "2025-01-04 10:58:09,624 - httpx - INFO - HTTP Request: POST https://api.mistral.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "442accf3db5e45e3ac407dde143b5e48",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-04 10:58:09,649 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/pinecone_plugins'])\n",
      "2025-01-04 10:58:09,650 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference\n",
      "2025-01-04 10:58:10,264 - __main__ - INFO - Retrieved results: {'matches': [{'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_52',\n",
      "              'score': 0.300099969,\n",
      "              'values': []},\n",
      "             {'id': 'John Mongan - Programming Interviews Exposed_ Coding Your '\n",
      "                    'Way Through the Interview (2018, Wrox Press) - '\n",
      "                    'libgen.li.epub_181',\n",
      "              'score': 0.289401054,\n",
      "              'values': []},\n",
      "             {'id': 'Narayanan Vishwanathan - SQL and NoSQL Interview '\n",
      "                    'Questions_ Your essential guide to acing SQL and NoSQL '\n",
      "                    'job interviews (English Edition)-BPB Publications '\n",
      "                    '(2023).epub_4',\n",
      "              'score': 0.2598387,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_37',\n",
      "              'score': 0.255283415,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_179',\n",
      "              'score': 0.231203049,\n",
      "              'values': []}],\n",
      " 'namespace': '',\n",
      " 'usage': {'read_units': 6}}\n",
      "2025-01-04 10:58:21,141 - httpx - INFO - HTTP Request: POST https://api.mistral.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47094cf74e0e4356b6828e0c90f898b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-04 10:58:21,166 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/pinecone_plugins'])\n",
      "2025-01-04 10:58:21,167 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference\n",
      "2025-01-04 10:58:21,806 - __main__ - INFO - Retrieved results: {'matches': [{'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_48',\n",
      "              'score': 0.285371482,\n",
      "              'values': []},\n",
      "             {'id': 'John Mongan - Programming Interviews Exposed_ Coding Your '\n",
      "                    'Way Through the Interview (2018, Wrox Press) - '\n",
      "                    'libgen.li.epub_181',\n",
      "              'score': 0.280431688,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_37',\n",
      "              'score': 0.276791781,\n",
      "              'values': []},\n",
      "             {'id': 'John Mongan - Programming Interviews Exposed_ Coding Your '\n",
      "                    'Way Through the Interview (2018, Wrox Press) - '\n",
      "                    'libgen.li.epub_222',\n",
      "              'score': 0.258408248,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_52',\n",
      "              'score': 0.253382117,\n",
      "              'values': []}],\n",
      " 'namespace': '',\n",
      " 'usage': {'read_units': 6}}\n",
      "2025-01-04 10:58:25,986 - httpx - INFO - HTTP Request: POST https://api.mistral.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3bbec4e650a4205a629ea313410db38",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-04 10:58:26,012 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/pinecone_plugins'])\n",
      "2025-01-04 10:58:26,013 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference\n",
      "2025-01-04 10:58:26,672 - __main__ - INFO - Retrieved results: {'matches': [{'id': 'John Mongan - Programming Interviews Exposed_ Coding Your '\n",
      "                    'Way Through the Interview (2018, Wrox Press) - '\n",
      "                    'libgen.li.epub_181',\n",
      "              'score': 0.292211503,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_52',\n",
      "              'score': 0.26211974,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_37',\n",
      "              'score': 0.261454314,\n",
      "              'values': []},\n",
      "             {'id': 'John Mongan - Programming Interviews Exposed_ Coding Your '\n",
      "                    'Way Through the Interview (2018, Wrox Press) - '\n",
      "                    'libgen.li.epub_222',\n",
      "              'score': 0.248256445,\n",
      "              'values': []},\n",
      "             {'id': 'Narayanan Vishwanathan - SQL and NoSQL Interview '\n",
      "                    'Questions_ Your essential guide to acing SQL and NoSQL '\n",
      "                    'job interviews (English Edition)-BPB Publications '\n",
      "                    '(2023).epub_4',\n",
      "              'score': 0.238517284,\n",
      "              'values': []}],\n",
      " 'namespace': '',\n",
      " 'usage': {'read_units': 6}}\n",
      "2025-01-04 10:58:32,075 - httpx - INFO - HTTP Request: POST https://api.mistral.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c4511eb648a441faa14e87dd274b574",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-04 10:58:32,108 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/pinecone_plugins'])\n",
      "2025-01-04 10:58:32,109 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference\n",
      "2025-01-04 10:58:32,736 - __main__ - INFO - Retrieved results: {'matches': [{'id': 'Narayanan Vishwanathan - SQL and NoSQL Interview '\n",
      "                    'Questions_ Your essential guide to acing SQL and NoSQL '\n",
      "                    'job interviews (English Edition)-BPB Publications '\n",
      "                    '(2023).epub_28',\n",
      "              'score': 0.321691751,\n",
      "              'values': []},\n",
      "             {'id': 'John Mongan - Programming Interviews Exposed_ Coding Your '\n",
      "                    'Way Through the Interview (2018, Wrox Press) - '\n",
      "                    'libgen.li.epub_292',\n",
      "              'score': 0.312131971,\n",
      "              'values': []},\n",
      "             {'id': 'John Mongan - Programming Interviews Exposed_ Coding Your '\n",
      "                    'Way Through the Interview (2018, Wrox Press) - '\n",
      "                    'libgen.li.epub_120',\n",
      "              'score': 0.303717077,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_99',\n",
      "              'score': 0.301971257,\n",
      "              'values': []},\n",
      "             {'id': 'John Mongan - Programming Interviews Exposed_ Coding Your '\n",
      "                    'Way Through the Interview (2018, Wrox Press) - '\n",
      "                    'libgen.li.epub_338',\n",
      "              'score': 0.28683573,\n",
      "              'values': []}],\n",
      " 'namespace': '',\n",
      " 'usage': {'read_units': 6}}\n",
      "2025-01-04 10:58:42,400 - httpx - INFO - HTTP Request: POST https://api.mistral.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c06a84c9e2ec4b6aaacc4c7ac637f95d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-04 10:58:42,429 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/pinecone_plugins'])\n",
      "2025-01-04 10:58:42,431 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference\n",
      "2025-01-04 10:58:43,066 - __main__ - INFO - Retrieved results: {'matches': [{'id': 'John Mongan - Programming Interviews Exposed_ Coding Your '\n",
      "                    'Way Through the Interview (2018, Wrox Press) - '\n",
      "                    'libgen.li.epub_181',\n",
      "              'score': 0.30548057,\n",
      "              'values': []},\n",
      "             {'id': 'Narayanan Vishwanathan - SQL and NoSQL Interview '\n",
      "                    'Questions_ Your essential guide to acing SQL and NoSQL '\n",
      "                    'job interviews (English Edition)-BPB Publications '\n",
      "                    '(2023).epub_4',\n",
      "              'score': 0.302054256,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_37',\n",
      "              'score': 0.279734969,\n",
      "              'values': []},\n",
      "             {'id': 'John Mongan - Programming Interviews Exposed_ Coding Your '\n",
      "                    'Way Through the Interview (2018, Wrox Press) - '\n",
      "                    'libgen.li.epub_222',\n",
      "              'score': 0.265095681,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_48',\n",
      "              'score': 0.247248173,\n",
      "              'values': []}],\n",
      " 'namespace': '',\n",
      " 'usage': {'read_units': 6}}\n",
      "2025-01-04 10:58:59,197 - httpx - INFO - HTTP Request: POST https://api.mistral.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "053f488695964c14803c955d9c7494a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-04 10:58:59,223 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/pinecone_plugins'])\n",
      "2025-01-04 10:58:59,225 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference\n",
      "2025-01-04 10:58:59,897 - __main__ - INFO - Retrieved results: {'matches': [{'id': 'John Mongan - Programming Interviews Exposed_ Coding Your '\n",
      "                    'Way Through the Interview (2018, Wrox Press) - '\n",
      "                    'libgen.li.epub_181',\n",
      "              'score': 0.294126868,\n",
      "              'values': []},\n",
      "             {'id': 'John Mongan - Programming Interviews Exposed_ Coding Your '\n",
      "                    'Way Through the Interview (2018, Wrox Press) - '\n",
      "                    'libgen.li.epub_222',\n",
      "              'score': 0.25473389,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_37',\n",
      "              'score': 0.25097844,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_52',\n",
      "              'score': 0.242074415,\n",
      "              'values': []},\n",
      "             {'id': 'Narayanan Vishwanathan - SQL and NoSQL Interview '\n",
      "                    'Questions_ Your essential guide to acing SQL and NoSQL '\n",
      "                    'job interviews (English Edition)-BPB Publications '\n",
      "                    '(2023).epub_4',\n",
      "              'score': 0.234278187,\n",
      "              'values': []}],\n",
      " 'namespace': '',\n",
      " 'usage': {'read_units': 6}}\n",
      "2025-01-04 10:59:05,867 - httpx - INFO - HTTP Request: POST https://api.mistral.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68804f3234954739843efde32a9e8d92",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-04 10:59:05,892 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/pinecone_plugins'])\n",
      "2025-01-04 10:59:05,893 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference\n",
      "2025-01-04 10:59:06,520 - __main__ - INFO - Retrieved results: {'matches': [{'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_37',\n",
      "              'score': 0.290627152,\n",
      "              'values': []},\n",
      "             {'id': 'John Mongan - Programming Interviews Exposed_ Coding Your '\n",
      "                    'Way Through the Interview (2018, Wrox Press) - '\n",
      "                    'libgen.li.epub_181',\n",
      "              'score': 0.282362103,\n",
      "              'values': []},\n",
      "             {'id': 'John Mongan - Programming Interviews Exposed_ Coding Your '\n",
      "                    'Way Through the Interview (2018, Wrox Press) - '\n",
      "                    'libgen.li.epub_195',\n",
      "              'score': 0.278759629,\n",
      "              'values': []},\n",
      "             {'id': 'John Mongan - Programming Interviews Exposed_ Coding Your '\n",
      "                    'Way Through the Interview (2018, Wrox Press) - '\n",
      "                    'libgen.li.epub_188',\n",
      "              'score': 0.26987,\n",
      "              'values': []},\n",
      "             {'id': 'John Mongan - Programming Interviews Exposed_ Coding Your '\n",
      "                    'Way Through the Interview (2018, Wrox Press) - '\n",
      "                    'libgen.li.epub_399',\n",
      "              'score': 0.262482524,\n",
      "              'values': []}],\n",
      " 'namespace': '',\n",
      " 'usage': {'read_units': 6}}\n",
      "2025-01-04 10:59:18,421 - httpx - INFO - HTTP Request: POST https://api.mistral.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1184f87d6ca64db4993c5c9bf016a176",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-04 10:59:18,448 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/pinecone_plugins'])\n",
      "2025-01-04 10:59:18,450 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference\n",
      "2025-01-04 10:59:19,077 - __main__ - INFO - Retrieved results: {'matches': [{'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_52',\n",
      "              'score': 0.276996076,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_48',\n",
      "              'score': 0.267659903,\n",
      "              'values': []},\n",
      "             {'id': 'John Mongan - Programming Interviews Exposed_ Coding Your '\n",
      "                    'Way Through the Interview (2018, Wrox Press) - '\n",
      "                    'libgen.li.epub_181',\n",
      "              'score': 0.254439503,\n",
      "              'values': []},\n",
      "             {'id': 'John Mongan - Programming Interviews Exposed_ Coding Your '\n",
      "                    'Way Through the Interview (2018, Wrox Press) - '\n",
      "                    'libgen.li.epub_69',\n",
      "              'score': 0.229095444,\n",
      "              'values': []},\n",
      "             {'id': 'Narayanan Vishwanathan - SQL and NoSQL Interview '\n",
      "                    'Questions_ Your essential guide to acing SQL and NoSQL '\n",
      "                    'job interviews (English Edition)-BPB Publications '\n",
      "                    '(2023).epub_4',\n",
      "              'score': 0.22800684,\n",
      "              'values': []}],\n",
      " 'namespace': '',\n",
      " 'usage': {'read_units': 6}}\n",
      "2025-01-04 10:59:27,015 - httpx - INFO - HTTP Request: POST https://api.mistral.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a68a4fdfce6d48269a3394648ff5b9c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-04 10:59:27,039 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/pinecone_plugins'])\n",
      "2025-01-04 10:59:27,040 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference\n",
      "2025-01-04 10:59:27,702 - __main__ - INFO - Retrieved results: {'matches': [{'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_0',\n",
      "              'score': 0.241008,\n",
      "              'values': []},\n",
      "             {'id': 'John Mongan - Programming Interviews Exposed_ Coding Your '\n",
      "                    'Way Through the Interview (2018, Wrox Press) - '\n",
      "                    'libgen.li.epub_222',\n",
      "              'score': 0.231490552,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_7',\n",
      "              'score': 0.230072603,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_52',\n",
      "              'score': 0.226709098,\n",
      "              'values': []},\n",
      "             {'id': 'John Mongan - Programming Interviews Exposed_ Coding Your '\n",
      "                    'Way Through the Interview (2018, Wrox Press) - '\n",
      "                    'libgen.li.epub_181',\n",
      "              'score': 0.213150203,\n",
      "              'values': []}],\n",
      " 'namespace': '',\n",
      " 'usage': {'read_units': 6}}\n",
      "2025-01-04 10:59:38,493 - httpx - INFO - HTTP Request: POST https://api.mistral.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8be9bc867b604c50b9961bac5767e1f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-04 10:59:38,522 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/pinecone_plugins'])\n",
      "2025-01-04 10:59:38,524 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference\n",
      "2025-01-04 10:59:39,212 - __main__ - INFO - Retrieved results: {'matches': [{'id': 'John Mongan - Programming Interviews Exposed_ Coding Your '\n",
      "                    'Way Through the Interview (2018, Wrox Press) - '\n",
      "                    'libgen.li.epub_181',\n",
      "              'score': 0.287749529,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_37',\n",
      "              'score': 0.282813281,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_52',\n",
      "              'score': 0.269303441,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_48',\n",
      "              'score': 0.266718268,\n",
      "              'values': []},\n",
      "             {'id': 'Narayanan Vishwanathan - SQL and NoSQL Interview '\n",
      "                    'Questions_ Your essential guide to acing SQL and NoSQL '\n",
      "                    'job interviews (English Edition)-BPB Publications '\n",
      "                    '(2023).epub_4',\n",
      "              'score': 0.244296849,\n",
      "              'values': []}],\n",
      " 'namespace': '',\n",
      " 'usage': {'read_units': 6}}\n",
      "2025-01-04 10:59:46,655 - httpx - INFO - HTTP Request: POST https://api.mistral.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c76cd42b4f31478d80a11460233291a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-04 10:59:46,681 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/pinecone_plugins'])\n",
      "2025-01-04 10:59:46,683 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference\n",
      "2025-01-04 10:59:47,322 - __main__ - INFO - Retrieved results: {'matches': [{'id': 'John Mongan - Programming Interviews Exposed_ Coding Your '\n",
      "                    'Way Through the Interview (2018, Wrox Press) - '\n",
      "                    'libgen.li.epub_181',\n",
      "              'score': 0.271440297,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_52',\n",
      "              'score': 0.26648,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_37',\n",
      "              'score': 0.234081224,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_48',\n",
      "              'score': 0.231471315,\n",
      "              'values': []},\n",
      "             {'id': 'John Mongan - Programming Interviews Exposed_ Coding Your '\n",
      "                    'Way Through the Interview (2018, Wrox Press) - '\n",
      "                    'libgen.li.epub_222',\n",
      "              'score': 0.225782558,\n",
      "              'values': []}],\n",
      " 'namespace': '',\n",
      " 'usage': {'read_units': 6}}\n",
      "2025-01-04 10:59:54,583 - httpx - INFO - HTTP Request: POST https://api.mistral.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1bbb4631217a48f989dfbe489bc937ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-04 10:59:54,608 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/pinecone_plugins'])\n",
      "2025-01-04 10:59:54,609 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference\n",
      "2025-01-04 10:59:55,246 - __main__ - INFO - Retrieved results: {'matches': [{'id': 'John Mongan - Programming Interviews Exposed_ Coding Your '\n",
      "                    'Way Through the Interview (2018, Wrox Press) - '\n",
      "                    'libgen.li.epub_181',\n",
      "              'score': 0.328024983,\n",
      "              'values': []},\n",
      "             {'id': 'John Mongan - Programming Interviews Exposed_ Coding Your '\n",
      "                    'Way Through the Interview (2018, Wrox Press) - '\n",
      "                    'libgen.li.epub_222',\n",
      "              'score': 0.260980397,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_37',\n",
      "              'score': 0.255718082,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_52',\n",
      "              'score': 0.248748034,\n",
      "              'values': []},\n",
      "             {'id': 'Narayanan Vishwanathan - SQL and NoSQL Interview '\n",
      "                    'Questions_ Your essential guide to acing SQL and NoSQL '\n",
      "                    'job interviews (English Edition)-BPB Publications '\n",
      "                    '(2023).epub_4',\n",
      "              'score': 0.237782821,\n",
      "              'values': []}],\n",
      " 'namespace': '',\n",
      " 'usage': {'read_units': 6}}\n",
      "2025-01-04 11:00:02,321 - httpx - INFO - HTTP Request: POST https://api.mistral.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db62038c826145b089aae3d4bbfdf36d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-04 11:00:02,342 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/pinecone_plugins'])\n",
      "2025-01-04 11:00:02,354 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference\n",
      "2025-01-04 11:00:03,377 - __main__ - INFO - Retrieved results: {'matches': [{'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_37',\n",
      "              'score': 0.294479579,\n",
      "              'values': []},\n",
      "             {'id': 'John Mongan - Programming Interviews Exposed_ Coding Your '\n",
      "                    'Way Through the Interview (2018, Wrox Press) - '\n",
      "                    'libgen.li.epub_375',\n",
      "              'score': 0.282921165,\n",
      "              'values': []},\n",
      "             {'id': 'John Mongan - Programming Interviews Exposed_ Coding Your '\n",
      "                    'Way Through the Interview (2018, Wrox Press) - '\n",
      "                    'libgen.li.epub_260',\n",
      "              'score': 0.270358682,\n",
      "              'values': []},\n",
      "             {'id': 'John Mongan - Programming Interviews Exposed_ Coding Your '\n",
      "                    'Way Through the Interview (2018, Wrox Press) - '\n",
      "                    'libgen.li.epub_181',\n",
      "              'score': 0.267140955,\n",
      "              'values': []},\n",
      "             {'id': 'Narayanan Vishwanathan - SQL and NoSQL Interview '\n",
      "                    'Questions_ Your essential guide to acing SQL and NoSQL '\n",
      "                    'job interviews (English Edition)-BPB Publications '\n",
      "                    '(2023).epub_4',\n",
      "              'score': 0.256685942,\n",
      "              'values': []}],\n",
      " 'namespace': '',\n",
      " 'usage': {'read_units': 6}}\n",
      "2025-01-04 11:00:14,251 - httpx - INFO - HTTP Request: POST https://api.mistral.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8acb330f3ee4863928c90f7c741c768",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-04 11:00:14,276 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/pinecone_plugins'])\n",
      "2025-01-04 11:00:14,277 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference\n",
      "2025-01-04 11:00:15,648 - __main__ - INFO - Retrieved results: {'matches': [{'id': 'John Mongan - Programming Interviews Exposed_ Coding Your '\n",
      "                    'Way Through the Interview (2018, Wrox Press) - '\n",
      "                    'libgen.li.epub_181',\n",
      "              'score': 0.292685181,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_52',\n",
      "              'score': 0.291401058,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_48',\n",
      "              'score': 0.255780339,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_99',\n",
      "              'score': 0.251876682,\n",
      "              'values': []},\n",
      "             {'id': 'Narayanan Vishwanathan - SQL and NoSQL Interview '\n",
      "                    'Questions_ Your essential guide to acing SQL and NoSQL '\n",
      "                    'job interviews (English Edition)-BPB Publications '\n",
      "                    '(2023).epub_4',\n",
      "              'score': 0.239222556,\n",
      "              'values': []}],\n",
      " 'namespace': '',\n",
      " 'usage': {'read_units': 6}}\n",
      "2025-01-04 11:00:24,663 - httpx - INFO - HTTP Request: POST https://api.mistral.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f42d1dba751c40529869ae8a81fda9f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-04 11:00:24,687 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/pinecone_plugins'])\n",
      "2025-01-04 11:00:24,688 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference\n",
      "2025-01-04 11:00:25,328 - __main__ - INFO - Retrieved results: {'matches': [{'id': 'John Mongan - Programming Interviews Exposed_ Coding Your '\n",
      "                    'Way Through the Interview (2018, Wrox Press) - '\n",
      "                    'libgen.li.epub_181',\n",
      "              'score': 0.28408736,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_52',\n",
      "              'score': 0.281413406,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_48',\n",
      "              'score': 0.275055677,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_37',\n",
      "              'score': 0.247013077,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_0',\n",
      "              'score': 0.23984012,\n",
      "              'values': []}],\n",
      " 'namespace': '',\n",
      " 'usage': {'read_units': 6}}\n",
      "2025-01-04 11:00:29,077 - httpx - INFO - HTTP Request: POST https://api.mistral.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e999053f184f466bb3711d23ea208760",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-04 11:00:29,105 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/pinecone_plugins'])\n",
      "2025-01-04 11:00:29,106 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference\n",
      "2025-01-04 11:00:29,749 - __main__ - INFO - Retrieved results: {'matches': [{'id': 'John Mongan - Programming Interviews Exposed_ Coding Your '\n",
      "                    'Way Through the Interview (2018, Wrox Press) - '\n",
      "                    'libgen.li.epub_181',\n",
      "              'score': 0.317296982,\n",
      "              'values': []},\n",
      "             {'id': 'Narayanan Vishwanathan - SQL and NoSQL Interview '\n",
      "                    'Questions_ Your essential guide to acing SQL and NoSQL '\n",
      "                    'job interviews (English Edition)-BPB Publications '\n",
      "                    '(2023).epub_4',\n",
      "              'score': 0.260387927,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_52',\n",
      "              'score': 0.254974663,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_7',\n",
      "              'score': 0.250501633,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_48',\n",
      "              'score': 0.242010638,\n",
      "              'values': []}],\n",
      " 'namespace': '',\n",
      " 'usage': {'read_units': 6}}\n",
      "2025-01-04 11:00:39,384 - httpx - INFO - HTTP Request: POST https://api.mistral.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f238f98449694a04b243a77acdee811e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-04 11:00:39,409 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/pinecone_plugins'])\n",
      "2025-01-04 11:00:39,410 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference\n",
      "2025-01-04 11:00:40,384 - __main__ - INFO - Retrieved results: {'matches': [{'id': 'John Mongan - Programming Interviews Exposed_ Coding Your '\n",
      "                    'Way Through the Interview (2018, Wrox Press) - '\n",
      "                    'libgen.li.epub_181',\n",
      "              'score': 0.267123282,\n",
      "              'values': []},\n",
      "             {'id': 'John Mongan - Programming Interviews Exposed_ Coding Your '\n",
      "                    'Way Through the Interview (2018, Wrox Press) - '\n",
      "                    'libgen.li.epub_222',\n",
      "              'score': 0.251824647,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_52',\n",
      "              'score': 0.245113626,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_48',\n",
      "              'score': 0.236920565,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_37',\n",
      "              'score': 0.228835464,\n",
      "              'values': []}],\n",
      " 'namespace': '',\n",
      " 'usage': {'read_units': 6}}\n",
      "2025-01-04 11:00:49,558 - httpx - INFO - HTTP Request: POST https://api.mistral.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cbd01a10832140e6ae8b92f681bb217c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-04 11:00:49,588 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/pinecone_plugins'])\n",
      "2025-01-04 11:00:49,590 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference\n",
      "2025-01-04 11:00:50,269 - __main__ - INFO - Retrieved results: {'matches': [{'id': 'John Mongan - Programming Interviews Exposed_ Coding Your '\n",
      "                    'Way Through the Interview (2018, Wrox Press) - '\n",
      "                    'libgen.li.epub_181',\n",
      "              'score': 0.311074287,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_52',\n",
      "              'score': 0.254956633,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_37',\n",
      "              'score': 0.253498048,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_48',\n",
      "              'score': 0.251823485,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_94',\n",
      "              'score': 0.2501598,\n",
      "              'values': []}],\n",
      " 'namespace': '',\n",
      " 'usage': {'read_units': 6}}\n",
      "2025-01-04 11:00:53,907 - httpx - INFO - HTTP Request: POST https://api.mistral.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47c8851510814f7ca432b2447f547c3c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-04 11:00:53,932 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/pinecone_plugins'])\n",
      "2025-01-04 11:00:53,933 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference\n",
      "2025-01-04 11:00:54,554 - __main__ - INFO - Retrieved results: {'matches': [{'id': 'John Mongan - Programming Interviews Exposed_ Coding Your '\n",
      "                    'Way Through the Interview (2018, Wrox Press) - '\n",
      "                    'libgen.li.epub_181',\n",
      "              'score': 0.27492553,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_48',\n",
      "              'score': 0.252723753,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_37',\n",
      "              'score': 0.246262699,\n",
      "              'values': []},\n",
      "             {'id': 'Narayanan Vishwanathan - SQL and NoSQL Interview '\n",
      "                    'Questions_ Your essential guide to acing SQL and NoSQL '\n",
      "                    'job interviews (English Edition)-BPB Publications '\n",
      "                    '(2023).epub_4',\n",
      "              'score': 0.236164406,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_52',\n",
      "              'score': 0.235876769,\n",
      "              'values': []}],\n",
      " 'namespace': '',\n",
      " 'usage': {'read_units': 6}}\n",
      "2025-01-04 11:01:01,935 - httpx - INFO - HTTP Request: POST https://api.mistral.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72f4aa8bd714443caa8f8724223a8c2a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-04 11:01:01,962 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/pinecone_plugins'])\n",
      "2025-01-04 11:01:01,963 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference\n",
      "2025-01-04 11:01:02,649 - __main__ - INFO - Retrieved results: {'matches': [{'id': 'John Mongan - Programming Interviews Exposed_ Coding Your '\n",
      "                    'Way Through the Interview (2018, Wrox Press) - '\n",
      "                    'libgen.li.epub_181',\n",
      "              'score': 0.332659751,\n",
      "              'values': []},\n",
      "             {'id': 'Narayanan Vishwanathan - SQL and NoSQL Interview '\n",
      "                    'Questions_ Your essential guide to acing SQL and NoSQL '\n",
      "                    'job interviews (English Edition)-BPB Publications '\n",
      "                    '(2023).epub_4',\n",
      "              'score': 0.23411724,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_37',\n",
      "              'score': 0.232524693,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_52',\n",
      "              'score': 0.218199268,\n",
      "              'values': []},\n",
      "             {'id': 'John Mongan - Programming Interviews Exposed_ Coding Your '\n",
      "                    'Way Through the Interview (2018, Wrox Press) - '\n",
      "                    'libgen.li.epub_5',\n",
      "              'score': 0.213396013,\n",
      "              'values': []}],\n",
      " 'namespace': '',\n",
      " 'usage': {'read_units': 6}}\n",
      "2025-01-04 11:01:11,574 - httpx - INFO - HTTP Request: POST https://api.mistral.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37b2c2114eab415fab2ee164914a0293",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-04 11:01:11,598 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/pinecone_plugins'])\n",
      "2025-01-04 11:01:11,599 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference\n",
      "2025-01-04 11:01:12,266 - __main__ - INFO - Retrieved results: {'matches': [{'id': 'John Mongan - Programming Interviews Exposed_ Coding Your '\n",
      "                    'Way Through the Interview (2018, Wrox Press) - '\n",
      "                    'libgen.li.epub_181',\n",
      "              'score': 0.308233738,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_52',\n",
      "              'score': 0.247258,\n",
      "              'values': []},\n",
      "             {'id': 'Narayanan Vishwanathan - SQL and NoSQL Interview '\n",
      "                    'Questions_ Your essential guide to acing SQL and NoSQL '\n",
      "                    'job interviews (English Edition)-BPB Publications '\n",
      "                    '(2023).epub_4',\n",
      "              'score': 0.229907066,\n",
      "              'values': []},\n",
      "             {'id': 'John Mongan - Programming Interviews Exposed_ Coding Your '\n",
      "                    'Way Through the Interview (2018, Wrox Press) - '\n",
      "                    'libgen.li.epub_222',\n",
      "              'score': 0.225609854,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_37',\n",
      "              'score': 0.215428203,\n",
      "              'values': []}],\n",
      " 'namespace': '',\n",
      " 'usage': {'read_units': 6}}\n",
      "2025-01-04 11:01:15,494 - httpx - INFO - HTTP Request: POST https://api.mistral.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec665710441e4f16bf680d1197c63e86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-04 11:01:15,518 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/pinecone_plugins'])\n",
      "2025-01-04 11:01:15,519 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference\n",
      "2025-01-04 11:01:16,172 - __main__ - INFO - Retrieved results: {'matches': [{'id': 'John Mongan - Programming Interviews Exposed_ Coding Your '\n",
      "                    'Way Through the Interview (2018, Wrox Press) - '\n",
      "                    'libgen.li.epub_181',\n",
      "              'score': 0.297357023,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_52',\n",
      "              'score': 0.273246795,\n",
      "              'values': []},\n",
      "             {'id': 'John Mongan - Programming Interviews Exposed_ Coding Your '\n",
      "                    'Way Through the Interview (2018, Wrox Press) - '\n",
      "                    'libgen.li.epub_222',\n",
      "              'score': 0.241941601,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_48',\n",
      "              'score': 0.221677512,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_0',\n",
      "              'score': 0.219416425,\n",
      "              'values': []}],\n",
      " 'namespace': '',\n",
      " 'usage': {'read_units': 6}}\n",
      "2025-01-04 11:01:22,398 - httpx - INFO - HTTP Request: POST https://api.mistral.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14d47026481041359ba2c168ed1f43cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-04 11:01:22,423 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/pinecone_plugins'])\n",
      "2025-01-04 11:01:22,424 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference\n",
      "2025-01-04 11:01:23,041 - __main__ - INFO - Retrieved results: {'matches': [{'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_52',\n",
      "              'score': 0.269951731,\n",
      "              'values': []},\n",
      "             {'id': 'John Mongan - Programming Interviews Exposed_ Coding Your '\n",
      "                    'Way Through the Interview (2018, Wrox Press) - '\n",
      "                    'libgen.li.epub_181',\n",
      "              'score': 0.265077055,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_48',\n",
      "              'score': 0.23029913,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_37',\n",
      "              'score': 0.21318087,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_0',\n",
      "              'score': 0.201809496,\n",
      "              'values': []}],\n",
      " 'namespace': '',\n",
      " 'usage': {'read_units': 6}}\n",
      "2025-01-04 11:01:28,605 - httpx - INFO - HTTP Request: POST https://api.mistral.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c01e0764891a4957b51f7f54bf85c306",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-04 11:01:28,631 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/pinecone_plugins'])\n",
      "2025-01-04 11:01:28,633 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference\n",
      "2025-01-04 11:01:29,334 - __main__ - INFO - Retrieved results: {'matches': [{'id': 'John Mongan - Programming Interviews Exposed_ Coding Your '\n",
      "                    'Way Through the Interview (2018, Wrox Press) - '\n",
      "                    'libgen.li.epub_181',\n",
      "              'score': 0.275387526,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_48',\n",
      "              'score': 0.263747633,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_37',\n",
      "              'score': 0.254312843,\n",
      "              'values': []},\n",
      "             {'id': 'Narayanan Vishwanathan - SQL and NoSQL Interview '\n",
      "                    'Questions_ Your essential guide to acing SQL and NoSQL '\n",
      "                    'job interviews (English Edition)-BPB Publications '\n",
      "                    '(2023).epub_4',\n",
      "              'score': 0.249528736,\n",
      "              'values': []},\n",
      "             {'id': 'John Mongan - Programming Interviews Exposed_ Coding Your '\n",
      "                    'Way Through the Interview (2018, Wrox Press) - '\n",
      "                    'libgen.li.epub_222',\n",
      "              'score': 0.243736401,\n",
      "              'values': []}],\n",
      " 'namespace': '',\n",
      " 'usage': {'read_units': 6}}\n",
      "2025-01-04 11:01:35,028 - httpx - INFO - HTTP Request: POST https://api.mistral.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4dfeec54e314ff88055e60086c50775",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-04 11:01:35,053 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/pinecone_plugins'])\n",
      "2025-01-04 11:01:35,054 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference\n",
      "2025-01-04 11:01:35,691 - __main__ - INFO - Retrieved results: {'matches': [{'id': 'John Mongan - Programming Interviews Exposed_ Coding Your '\n",
      "                    'Way Through the Interview (2018, Wrox Press) - '\n",
      "                    'libgen.li.epub_181',\n",
      "              'score': 0.305018097,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_37',\n",
      "              'score': 0.251329422,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_52',\n",
      "              'score': 0.240639701,\n",
      "              'values': []},\n",
      "             {'id': 'Narayanan Vishwanathan - SQL and NoSQL Interview '\n",
      "                    'Questions_ Your essential guide to acing SQL and NoSQL '\n",
      "                    'job interviews (English Edition)-BPB Publications '\n",
      "                    '(2023).epub_4',\n",
      "              'score': 0.23896803,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_48',\n",
      "              'score': 0.228869706,\n",
      "              'values': []}],\n",
      " 'namespace': '',\n",
      " 'usage': {'read_units': 6}}\n",
      "2025-01-04 11:01:45,189 - httpx - INFO - HTTP Request: POST https://api.mistral.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ccdfb4a9ed804908ae00cff8f9e456f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-04 11:01:45,211 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/pinecone_plugins'])\n",
      "2025-01-04 11:01:45,212 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference\n",
      "2025-01-04 11:01:45,828 - __main__ - INFO - Retrieved results: {'matches': [{'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_99',\n",
      "              'score': 0.296741456,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_76',\n",
      "              'score': 0.273627579,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_52',\n",
      "              'score': 0.270119637,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_179',\n",
      "              'score': 0.260349,\n",
      "              'values': []},\n",
      "             {'id': 'John Mongan - Programming Interviews Exposed_ Coding Your '\n",
      "                    'Way Through the Interview (2018, Wrox Press) - '\n",
      "                    'libgen.li.epub_342',\n",
      "              'score': 0.255220711,\n",
      "              'values': []}],\n",
      " 'namespace': '',\n",
      " 'usage': {'read_units': 6}}\n",
      "2025-01-04 11:01:55,283 - httpx - INFO - HTTP Request: POST https://api.mistral.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4114356ddd23419fbc847cd9e18a48eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-04 11:01:55,307 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/pinecone_plugins'])\n",
      "2025-01-04 11:01:55,308 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference\n",
      "2025-01-04 11:01:55,947 - __main__ - INFO - Retrieved results: {'matches': [{'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_52',\n",
      "              'score': 0.300456673,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_37',\n",
      "              'score': 0.273225754,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_48',\n",
      "              'score': 0.254737735,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_99',\n",
      "              'score': 0.249172747,\n",
      "              'values': []},\n",
      "             {'id': 'John Mongan - Programming Interviews Exposed_ Coding Your '\n",
      "                    'Way Through the Interview (2018, Wrox Press) - '\n",
      "                    'libgen.li.epub_181',\n",
      "              'score': 0.248575136,\n",
      "              'values': []}],\n",
      " 'namespace': '',\n",
      " 'usage': {'read_units': 6}}\n",
      "2025-01-04 11:02:04,303 - httpx - INFO - HTTP Request: POST https://api.mistral.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "464b33a70c9d4877bef76238ef2618e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-04 11:02:04,327 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/pinecone_plugins'])\n",
      "2025-01-04 11:02:04,328 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference\n",
      "2025-01-04 11:02:05,010 - __main__ - INFO - Retrieved results: {'matches': [{'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_52',\n",
      "              'score': 0.280101925,\n",
      "              'values': []},\n",
      "             {'id': 'John Mongan - Programming Interviews Exposed_ Coding Your '\n",
      "                    'Way Through the Interview (2018, Wrox Press) - '\n",
      "                    'libgen.li.epub_181',\n",
      "              'score': 0.238229692,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_37',\n",
      "              'score': 0.222106785,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_48',\n",
      "              'score': 0.214085087,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_6',\n",
      "              'score': 0.190819427,\n",
      "              'values': []}],\n",
      " 'namespace': '',\n",
      " 'usage': {'read_units': 6}}\n",
      "2025-01-04 11:02:14,784 - httpx - INFO - HTTP Request: POST https://api.mistral.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55233eedec654803b4f2fad43d320cc9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-04 11:02:14,807 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/pinecone_plugins'])\n",
      "2025-01-04 11:02:14,808 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference\n",
      "2025-01-04 11:02:20,519 - __main__ - INFO - Retrieved results: {'matches': [{'id': 'John Mongan - Programming Interviews Exposed_ Coding Your '\n",
      "                    'Way Through the Interview (2018, Wrox Press) - '\n",
      "                    'libgen.li.epub_337',\n",
      "              'score': 0.300069332,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_99',\n",
      "              'score': 0.29898,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_48',\n",
      "              'score': 0.284515977,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_179',\n",
      "              'score': 0.269856721,\n",
      "              'values': []},\n",
      "             {'id': 'John Mongan - Programming Interviews Exposed_ Coding Your '\n",
      "                    'Way Through the Interview (2018, Wrox Press) - '\n",
      "                    'libgen.li.epub_317',\n",
      "              'score': 0.266710162,\n",
      "              'values': []}],\n",
      " 'namespace': '',\n",
      " 'usage': {'read_units': 6}}\n",
      "2025-01-04 11:02:38,540 - httpx - INFO - HTTP Request: POST https://api.mistral.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "915b1d4119ae47f982757cc1bc503af0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-04 11:02:38,565 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/pinecone_plugins'])\n",
      "2025-01-04 11:02:38,567 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference\n",
      "2025-01-04 11:02:39,253 - __main__ - INFO - Retrieved results: {'matches': [{'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_139',\n",
      "              'score': 0.270760655,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_141',\n",
      "              'score': 0.259605974,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_179',\n",
      "              'score': 0.25571543,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_150',\n",
      "              'score': 0.239155069,\n",
      "              'values': []},\n",
      "             {'id': 'John Mongan - Programming Interviews Exposed_ Coding Your '\n",
      "                    'Way Through the Interview (2018, Wrox Press) - '\n",
      "                    'libgen.li.epub_351',\n",
      "              'score': 0.229063362,\n",
      "              'values': []}],\n",
      " 'namespace': '',\n",
      " 'usage': {'read_units': 6}}\n",
      "2025-01-04 11:02:43,562 - httpx - INFO - HTTP Request: POST https://api.mistral.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "742ab34d8ffc4303b24f09b8c527e31c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-04 11:02:43,586 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/pinecone_plugins'])\n",
      "2025-01-04 11:02:43,587 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference\n",
      "2025-01-04 11:02:44,272 - __main__ - INFO - Retrieved results: {'matches': [{'id': 'John Mongan - Programming Interviews Exposed_ Coding Your '\n",
      "                    'Way Through the Interview (2018, Wrox Press) - '\n",
      "                    'libgen.li.epub_181',\n",
      "              'score': 0.32985729,\n",
      "              'values': []},\n",
      "             {'id': 'John Mongan - Programming Interviews Exposed_ Coding Your '\n",
      "                    'Way Through the Interview (2018, Wrox Press) - '\n",
      "                    'libgen.li.epub_222',\n",
      "              'score': 0.27311337,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_52',\n",
      "              'score': 0.272930682,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_0',\n",
      "              'score': 0.251365483,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_37',\n",
      "              'score': 0.24751921,\n",
      "              'values': []}],\n",
      " 'namespace': '',\n",
      " 'usage': {'read_units': 6}}\n",
      "2025-01-04 11:13:45,034 - httpx - INFO - HTTP Request: POST https://api.mistral.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "895c035d352c4c2795d65f768f7bd624",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-04 11:13:45,143 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/pinecone_plugins'])\n",
      "2025-01-04 11:13:45,145 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference\n",
      "2025-01-04 11:13:46,056 - __main__ - INFO - Retrieved results: {'matches': [{'id': 'John Mongan - Programming Interviews Exposed_ Coding Your '\n",
      "                    'Way Through the Interview (2018, Wrox Press) - '\n",
      "                    'libgen.li.epub_181',\n",
      "              'score': 0.30542022,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_52',\n",
      "              'score': 0.28920728,\n",
      "              'values': []},\n",
      "             {'id': 'John Mongan - Programming Interviews Exposed_ Coding Your '\n",
      "                    'Way Through the Interview (2018, Wrox Press) - '\n",
      "                    'libgen.li.epub_222',\n",
      "              'score': 0.265515804,\n",
      "              'values': []},\n",
      "             {'id': 'Narayanan Vishwanathan - SQL and NoSQL Interview '\n",
      "                    'Questions_ Your essential guide to acing SQL and NoSQL '\n",
      "                    'job interviews (English Edition)-BPB Publications '\n",
      "                    '(2023).epub_4',\n",
      "              'score': 0.249273881,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_37',\n",
      "              'score': 0.246808946,\n",
      "              'values': []}],\n",
      " 'namespace': '',\n",
      " 'usage': {'read_units': 6}}\n",
      "2025-01-04 11:13:50,026 - httpx - INFO - HTTP Request: POST https://api.mistral.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52d4c346975b4372ab55971d5a4ef178",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-04 11:13:50,051 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/pinecone_plugins'])\n",
      "2025-01-04 11:13:50,052 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference\n",
      "2025-01-04 11:13:50,837 - __main__ - INFO - Retrieved results: {'matches': [{'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_37',\n",
      "              'score': 0.253360063,\n",
      "              'values': []},\n",
      "             {'id': 'John Mongan - Programming Interviews Exposed_ Coding Your '\n",
      "                    'Way Through the Interview (2018, Wrox Press) - '\n",
      "                    'libgen.li.epub_222',\n",
      "              'score': 0.246871546,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_52',\n",
      "              'score': 0.241594315,\n",
      "              'values': []},\n",
      "             {'id': 'John Mongan - Programming Interviews Exposed_ Coding Your '\n",
      "                    'Way Through the Interview (2018, Wrox Press) - '\n",
      "                    'libgen.li.epub_181',\n",
      "              'score': 0.233633861,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_99',\n",
      "              'score': 0.229163587,\n",
      "              'values': []}],\n",
      " 'namespace': '',\n",
      " 'usage': {'read_units': 6}}\n",
      "2025-01-04 11:13:55,515 - httpx - INFO - HTTP Request: POST https://api.mistral.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1c33adf60b44dc4b8431c0473e2efce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-04 11:13:55,541 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/pinecone_plugins'])\n",
      "2025-01-04 11:13:55,542 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference\n",
      "2025-01-04 11:13:56,341 - __main__ - INFO - Retrieved results: {'matches': [{'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_52',\n",
      "              'score': 0.299743354,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_0',\n",
      "              'score': 0.269266874,\n",
      "              'values': []},\n",
      "             {'id': 'John Mongan - Programming Interviews Exposed_ Coding Your '\n",
      "                    'Way Through the Interview (2018, Wrox Press) - '\n",
      "                    'libgen.li.epub_181',\n",
      "              'score': 0.261410981,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_179',\n",
      "              'score': 0.261397511,\n",
      "              'values': []},\n",
      "             {'id': 'John Mongan - Programming Interviews Exposed_ Coding Your '\n",
      "                    'Way Through the Interview (2018, Wrox Press) - '\n",
      "                    'libgen.li.epub_5',\n",
      "              'score': 0.260998964,\n",
      "              'values': []}],\n",
      " 'namespace': '',\n",
      " 'usage': {'read_units': 6}}\n",
      "2025-01-04 11:14:20,547 - httpx - INFO - HTTP Request: POST https://api.mistral.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e449a0a7f17c443ba38196043ae44a25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-04 11:14:20,579 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/pinecone_plugins'])\n",
      "2025-01-04 11:14:20,580 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference\n",
      "2025-01-04 11:14:21,294 - __main__ - INFO - Retrieved results: {'matches': [{'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_7',\n",
      "              'score': 0.347293854,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_82',\n",
      "              'score': 0.276769549,\n",
      "              'values': []},\n",
      "             {'id': 'John Mongan - Programming Interviews Exposed_ Coding Your '\n",
      "                    'Way Through the Interview (2018, Wrox Press) - '\n",
      "                    'libgen.li.epub_5',\n",
      "              'score': 0.25493145,\n",
      "              'values': []},\n",
      "             {'id': 'John Mongan - Programming Interviews Exposed_ Coding Your '\n",
      "                    'Way Through the Interview (2018, Wrox Press) - '\n",
      "                    'libgen.li.epub_298',\n",
      "              'score': 0.239259318,\n",
      "              'values': []},\n",
      "             {'id': 'John Mongan - Programming Interviews Exposed_ Coding Your '\n",
      "                    'Way Through the Interview (2018, Wrox Press) - '\n",
      "                    'libgen.li.epub_6',\n",
      "              'score': 0.22306709,\n",
      "              'values': []}],\n",
      " 'namespace': '',\n",
      " 'usage': {'read_units': 6}}\n",
      "2025-01-04 11:14:29,239 - httpx - INFO - HTTP Request: POST https://api.mistral.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c759b9683fd74d83a9ba3c6b1b95a0bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-04 11:14:29,274 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/pinecone_plugins'])\n",
      "2025-01-04 11:14:29,275 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference\n",
      "2025-01-04 11:14:29,989 - __main__ - INFO - Retrieved results: {'matches': [{'id': 'John Mongan - Programming Interviews Exposed_ Coding Your '\n",
      "                    'Way Through the Interview (2018, Wrox Press) - '\n",
      "                    'libgen.li.epub_181',\n",
      "              'score': 0.225637957,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_37',\n",
      "              'score': 0.225293145,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_48',\n",
      "              'score': 0.218880013,\n",
      "              'values': []},\n",
      "             {'id': 'Narayanan Vishwanathan - SQL and NoSQL Interview '\n",
      "                    'Questions_ Your essential guide to acing SQL and NoSQL '\n",
      "                    'job interviews (English Edition)-BPB Publications '\n",
      "                    '(2023).epub_4',\n",
      "              'score': 0.21693325,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_0',\n",
      "              'score': 0.213306174,\n",
      "              'values': []}],\n",
      " 'namespace': '',\n",
      " 'usage': {'read_units': 6}}\n",
      "2025-01-04 11:14:33,913 - httpx - INFO - HTTP Request: POST https://api.mistral.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63bc2f84e04044458bcd7d4246f9ba4e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-04 11:14:33,940 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/pinecone_plugins'])\n",
      "2025-01-04 11:14:33,942 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference\n",
      "2025-01-04 11:14:34,663 - __main__ - INFO - Retrieved results: {'matches': [{'id': 'John Mongan - Programming Interviews Exposed_ Coding Your '\n",
      "                    'Way Through the Interview (2018, Wrox Press) - '\n",
      "                    'libgen.li.epub_181',\n",
      "              'score': 0.286468446,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_52',\n",
      "              'score': 0.271522701,\n",
      "              'values': []},\n",
      "             {'id': 'John Mongan - Programming Interviews Exposed_ Coding Your '\n",
      "                    'Way Through the Interview (2018, Wrox Press) - '\n",
      "                    'libgen.li.epub_222',\n",
      "              'score': 0.266051471,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_37',\n",
      "              'score': 0.244642496,\n",
      "              'values': []},\n",
      "             {'id': 'Narayanan Vishwanathan - SQL and NoSQL Interview '\n",
      "                    'Questions_ Your essential guide to acing SQL and NoSQL '\n",
      "                    'job interviews (English Edition)-BPB Publications '\n",
      "                    '(2023).epub_4',\n",
      "              'score': 0.234201759,\n",
      "              'values': []}],\n",
      " 'namespace': '',\n",
      " 'usage': {'read_units': 6}}\n",
      "2025-01-04 11:14:45,489 - httpx - INFO - HTTP Request: POST https://api.mistral.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4ddbf44b791427a9caa2cb613ace462",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-04 11:14:45,514 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/pinecone_plugins'])\n",
      "2025-01-04 11:14:45,515 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference\n",
      "2025-01-04 11:14:46,218 - __main__ - INFO - Retrieved results: {'matches': [{'id': 'John Mongan - Programming Interviews Exposed_ Coding Your '\n",
      "                    'Way Through the Interview (2018, Wrox Press) - '\n",
      "                    'libgen.li.epub_239',\n",
      "              'score': 0.315796405,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_99',\n",
      "              'score': 0.303669482,\n",
      "              'values': []},\n",
      "             {'id': 'John Mongan - Programming Interviews Exposed_ Coding Your '\n",
      "                    'Way Through the Interview (2018, Wrox Press) - '\n",
      "                    'libgen.li.epub_5',\n",
      "              'score': 0.301161706,\n",
      "              'values': []},\n",
      "             {'id': 'John Mongan - Programming Interviews Exposed_ Coding Your '\n",
      "                    'Way Through the Interview (2018, Wrox Press) - '\n",
      "                    'libgen.li.epub_337',\n",
      "              'score': 0.301081628,\n",
      "              'values': []},\n",
      "             {'id': 'Narayanan Vishwanathan - SQL and NoSQL Interview '\n",
      "                    'Questions_ Your essential guide to acing SQL and NoSQL '\n",
      "                    'job interviews (English Edition)-BPB Publications '\n",
      "                    '(2023).epub_4',\n",
      "              'score': 0.288959086,\n",
      "              'values': []}],\n",
      " 'namespace': '',\n",
      " 'usage': {'read_units': 6}}\n",
      "2025-01-04 11:14:58,665 - httpx - INFO - HTTP Request: POST https://api.mistral.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9660dc618c114d019ba684d6050205e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-04 11:14:58,697 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/pinecone_plugins'])\n",
      "2025-01-04 11:14:58,698 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference\n",
      "2025-01-04 11:14:59,372 - __main__ - INFO - Retrieved results: {'matches': [{'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_99',\n",
      "              'score': 0.229767829,\n",
      "              'values': []},\n",
      "             {'id': 'John Mongan - Programming Interviews Exposed_ Coding Your '\n",
      "                    'Way Through the Interview (2018, Wrox Press) - '\n",
      "                    'libgen.li.epub_181',\n",
      "              'score': 0.219566941,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_169',\n",
      "              'score': 0.219174668,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_179',\n",
      "              'score': 0.21738252,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_20',\n",
      "              'score': 0.214323163,\n",
      "              'values': []}],\n",
      " 'namespace': '',\n",
      " 'usage': {'read_units': 6}}\n",
      "2025-01-04 11:15:10,376 - httpx - INFO - HTTP Request: POST https://api.mistral.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8501f111bf0748aaa96d2855d0eea2cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-04 11:15:10,404 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/pinecone_plugins'])\n",
      "2025-01-04 11:15:10,405 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference\n",
      "2025-01-04 11:15:11,072 - __main__ - INFO - Retrieved results: {'matches': [{'id': 'John Mongan - Programming Interviews Exposed_ Coding Your '\n",
      "                    'Way Through the Interview (2018, Wrox Press) - '\n",
      "                    'libgen.li.epub_181',\n",
      "              'score': 0.338726044,\n",
      "              'values': []},\n",
      "             {'id': 'John Mongan - Programming Interviews Exposed_ Coding Your '\n",
      "                    'Way Through the Interview (2018, Wrox Press) - '\n",
      "                    'libgen.li.epub_222',\n",
      "              'score': 0.253786623,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_37',\n",
      "              'score': 0.242908761,\n",
      "              'values': []},\n",
      "             {'id': 'Narayanan Vishwanathan - SQL and NoSQL Interview '\n",
      "                    'Questions_ Your essential guide to acing SQL and NoSQL '\n",
      "                    'job interviews (English Edition)-BPB Publications '\n",
      "                    '(2023).epub_4',\n",
      "              'score': 0.235648945,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_52',\n",
      "              'score': 0.232623965,\n",
      "              'values': []}],\n",
      " 'namespace': '',\n",
      " 'usage': {'read_units': 6}}\n",
      "2025-01-04 11:15:17,300 - httpx - INFO - HTTP Request: POST https://api.mistral.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2a42a14f0a54bf9bdb974dbefcce0c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-04 11:15:17,324 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/pinecone_plugins'])\n",
      "2025-01-04 11:15:17,325 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference\n",
      "2025-01-04 11:15:17,981 - __main__ - INFO - Retrieved results: {'matches': [{'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_48',\n",
      "              'score': 0.24254714,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_37',\n",
      "              'score': 0.232763305,\n",
      "              'values': []},\n",
      "             {'id': 'Narayanan Vishwanathan - SQL and NoSQL Interview '\n",
      "                    'Questions_ Your essential guide to acing SQL and NoSQL '\n",
      "                    'job interviews (English Edition)-BPB Publications '\n",
      "                    '(2023).epub_4',\n",
      "              'score': 0.210799202,\n",
      "              'values': []},\n",
      "             {'id': 'John Mongan - Programming Interviews Exposed_ Coding Your '\n",
      "                    'Way Through the Interview (2018, Wrox Press) - '\n",
      "                    'libgen.li.epub_222',\n",
      "              'score': 0.209570304,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_179',\n",
      "              'score': 0.198449522,\n",
      "              'values': []}],\n",
      " 'namespace': '',\n",
      " 'usage': {'read_units': 6}}\n",
      "2025-01-04 11:15:28,858 - httpx - INFO - HTTP Request: POST https://api.mistral.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "abf009e6d21644e0881fd735f51ce439",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-04 11:15:28,883 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/pinecone_plugins'])\n",
      "2025-01-04 11:15:28,885 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference\n",
      "2025-01-04 11:15:29,595 - __main__ - INFO - Retrieved results: {'matches': [{'id': 'John Mongan - Programming Interviews Exposed_ Coding Your '\n",
      "                    'Way Through the Interview (2018, Wrox Press) - '\n",
      "                    'libgen.li.epub_181',\n",
      "              'score': 0.326951474,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_37',\n",
      "              'score': 0.279266417,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_52',\n",
      "              'score': 0.278153151,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_48',\n",
      "              'score': 0.247268111,\n",
      "              'values': []},\n",
      "             {'id': 'John Mongan - Programming Interviews Exposed_ Coding Your '\n",
      "                    'Way Through the Interview (2018, Wrox Press) - '\n",
      "                    'libgen.li.epub_222',\n",
      "              'score': 0.225803226,\n",
      "              'values': []}],\n",
      " 'namespace': '',\n",
      " 'usage': {'read_units': 6}}\n",
      "2025-01-04 11:15:39,568 - httpx - INFO - HTTP Request: POST https://api.mistral.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2eb627b68a6b437ab40e6ee190a30ca3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-04 11:15:39,593 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/pinecone_plugins'])\n",
      "2025-01-04 11:15:39,594 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference\n",
      "2025-01-04 11:15:40,285 - __main__ - INFO - Retrieved results: {'matches': [{'id': 'John Mongan - Programming Interviews Exposed_ Coding Your '\n",
      "                    'Way Through the Interview (2018, Wrox Press) - '\n",
      "                    'libgen.li.epub_181',\n",
      "              'score': 0.296679169,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_37',\n",
      "              'score': 0.265440583,\n",
      "              'values': []},\n",
      "             {'id': 'John Mongan - Programming Interviews Exposed_ Coding Your '\n",
      "                    'Way Through the Interview (2018, Wrox Press) - '\n",
      "                    'libgen.li.epub_222',\n",
      "              'score': 0.261389196,\n",
      "              'values': []},\n",
      "             {'id': 'Narayanan Vishwanathan - SQL and NoSQL Interview '\n",
      "                    'Questions_ Your essential guide to acing SQL and NoSQL '\n",
      "                    'job interviews (English Edition)-BPB Publications '\n",
      "                    '(2023).epub_4',\n",
      "              'score': 0.239475504,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_6',\n",
      "              'score': 0.225782365,\n",
      "              'values': []}],\n",
      " 'namespace': '',\n",
      " 'usage': {'read_units': 6}}\n",
      "2025-01-04 11:15:46,012 - httpx - INFO - HTTP Request: POST https://api.mistral.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76fb3ea790eb40b99a66394e1da473a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-04 11:15:46,050 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/pinecone_plugins'])\n",
      "2025-01-04 11:15:46,052 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference\n",
      "2025-01-04 11:15:46,731 - __main__ - INFO - Retrieved results: {'matches': [{'id': 'John Mongan - Programming Interviews Exposed_ Coding Your '\n",
      "                    'Way Through the Interview (2018, Wrox Press) - '\n",
      "                    'libgen.li.epub_181',\n",
      "              'score': 0.291864961,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_37',\n",
      "              'score': 0.280926913,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_52',\n",
      "              'score': 0.269448191,\n",
      "              'values': []},\n",
      "             {'id': 'Narayanan Vishwanathan - SQL and NoSQL Interview '\n",
      "                    'Questions_ Your essential guide to acing SQL and NoSQL '\n",
      "                    'job interviews (English Edition)-BPB Publications '\n",
      "                    '(2023).epub_4',\n",
      "              'score': 0.249617338,\n",
      "              'values': []},\n",
      "             {'id': 'John Mongan - Programming Interviews Exposed_ Coding Your '\n",
      "                    'Way Through the Interview (2018, Wrox Press) - '\n",
      "                    'libgen.li.epub_222',\n",
      "              'score': 0.2483114,\n",
      "              'values': []}],\n",
      " 'namespace': '',\n",
      " 'usage': {'read_units': 6}}\n",
      "2025-01-04 11:16:00,955 - httpx - INFO - HTTP Request: POST https://api.mistral.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Function to load questions from JSON file\n",
    "def load_questions(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        return json.load(file)\n",
    "\n",
    "# Function to save answers to JSON file\n",
    "def save_answers(answers, file_path):\n",
    "    with open(file_path, 'w', encoding='utf-8') as file:\n",
    "        json.dump(answers, file, ensure_ascii=False, indent=4)\n",
    "\n",
    "# Function to get answers from RAG\n",
    "def get_answers(questions):\n",
    "    answers = {}\n",
    "    for q_id, question in questions.items():\n",
    "        # Step 1: Retrieve relevant documents from the vector database\n",
    "        retrieved_docs = retrieve_documents(question)\n",
    "\n",
    "        # Step 2: Generate a response using Mistral API\n",
    "        answer = generate_response(question, retrieved_docs)\n",
    "\n",
    "        answers[q_id] = answer\n",
    "    return answers\n",
    "\n",
    "# Load questions from file\n",
    "questions_file_path = '/home/bullat/projects/rag/Interview-2.0/question_for_test.json'\n",
    "questions = load_questions(questions_file_path)\n",
    "\n",
    "# Get answers from RAG\n",
    "answers = get_answers(questions)\n",
    "\n",
    "# Save answers to file\n",
    "answers_file_path = '/home/bullat/projects/rag/Interview-2.0/answers.json'\n",
    "save_answers(answers, answers_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-04 11:16:01,006 - sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: cpu\n",
      "2025-01-04 11:16:01,006 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: paraphrase-MiniLM-L6-v2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b65c36f96234472a5aba4c67f8131d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4d0193f49d444c28f70499227d2177a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question ID: 0\n",
      "Generated Answer: Алгоритм бинарного поиска — это эффективный алгоритм поиска, который используется для нахождения элемента в отсортированном списке. Он основан на принципе деления пополам: в каждом шаге алгоритм проверяет средний элемент списка и определяет, находится ли искомое значение слева, справа или же оно является средним элементом. Затем алгоритм продолжает поиск в соответствующей половине списка, и так далее, пока элемент не будет найден или список не станет пустым.\n",
      "\n",
      "Бинарный поиск имеет логарифмическую сложность O(log n), что делает его намного более эффективным, чем линейный поиск, особенно для больших списков.\n",
      "\n",
      "Пример кода на Python:\n",
      "```\n",
      "def binary_search(arr, low, high, x):\n",
      "  if high >= low:\n",
      "    mid = (high + low) // 2\n",
      "    if arr[mid] == x:\n",
      "      return mid\n",
      "    elif arr[mid] > x:\n",
      "      return binary_search(arr, low, mid - 1, x)\n",
      "    else:\n",
      "      return binary_search(arr, mid + 1, high, x)\n",
      "  else:\n",
      "    return -1\n",
      "```\n",
      "В этом коде `arr` — отсортированный список, `low` и `high` — индексы начала и конца подмассива, в котором осуществляется поиск, а `x` — искомое значение. Функция возвращает индекс найденного элемента или `-1`, если элемент не найден.\n",
      "Reference Answer: Алгоритм бинарного поиска - это метод поиска элемента в отсортированном массиве, который делит массив пополам и проверяет центральный элемент, повторяя процесс с левой или правой частью массива до нахождения элемента.\n",
      "Cosine Similarity: 0.9706306457519531\n",
      "BLEU Score: 8.284408557044559e-79\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7fac7e5b41b48c8842a2f9a7e92460a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d65ee94d3194b29bee8fd443bec3469",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question ID: 1\n",
      "Generated Answer: Графовые нейронные сети (ГНС) - это тип искусственных нейронных сетей, которые могут эффективно обрабатывать структурированные данные в виде графов. В отличие от традиционных нейронных сетей, которые работают с фиксированным размером входных данных, ГНС могут обрабатывать входные данные разного размера и структуры.\n",
      "\n",
      "ГНС представляют собой набор узлов (вершин) и ребер (связей) между ними. Каждая вершина представляет собой узел нейронной сети, а каждое ребро имеет связанное с ним весовое значение. Везовые значения ребер могут быть обучены с помощью различных алгоритмов машинного обучения.\n",
      "\n",
      "ГНС могут применяться в различных задачах, таких как классификация графов, рекомендательные системы, поиск кратчайшего пути и т.д. Они также находят широкое применение в таких областях, как биоинформатика, химия и социальные сети.\n",
      "\n",
      "В целом, ГНС могут эффективно решать задачи, в которых данные имеют сложную структуру и не поддаются обработке с помощью традиционных нейронных сетей.\n",
      "Reference Answer: Графовые нейронные сети (GNN) - это разновидность нейронных сетей, разработанных для обработки данных, представленных в виде графов. Они применяются для задач, где связи между объектами так же важны, как и сами объекты, например, в социальных сетях или молекулярных структурах.\n",
      "Cosine Similarity: 0.8983469605445862\n",
      "BLEU Score: 1.1674470660650275e-78\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6bda1617693147258a60f4a4adcecbfe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50a7b8554281458487d9d6a4523e4107",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question ID: 2\n",
      "Generated Answer: Машинное обучение - это подход в области искусственного интеллекта, который позволяет компьютерам автоматически обучаться и улучшать свои способности к выполнению определенных задач, анализируя данные. В контексте анализа данных машинное обучение используется для создания моделей, которые могут предсказывать результаты или обнаруживать уклонения на основе исторических данных. Это может быть полезно в различных сферах, таких как прогнозирование продаж, оптимизация рекламы, обнаружение мошенничества и многое другое. Кроме того, машинное обучение может помочь в выявлении важных особенностей и закономерностей в больших наборах данных, которые могут быть трудно обнаружить вручную.\n",
      "\n",
      "Translation:\n",
      "Machine learning is an approach in the field of artificial intelligence that enables computers to automatically learn and improve their abilities to perform certain tasks by analyzing data. In the context of data analysis, machine learning is used to create models that can predict outcomes or detect anomalies based on historical data. This can be useful in various fields, such as sales forecasting, ad optimization, fraud detection, and much more. In addition, machine learning can help identify important features and patterns in large datasets that can be difficult to detect manually.\n",
      "Reference Answer: Машинное обучение - это область искусственного интеллекта, которая фокусируется на разработке алгоритмов, которые позволяют компьютерам обучаться на данных. Оно применяется в анализе данных для прогнозирования, кластеризации, классификации и поиска скрытых закономерностей.\n",
      "Cosine Similarity: 0.9838210344314575\n",
      "BLEU Score: 0.018859362302973106\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb6dc6c4b3374f389b8951e971d7809c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5527a88b1cc64f45afceaabcefa962a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question ID: 3\n",
      "Generated Answer: Обучение с учителем (supervised learning) и обучение без учителя (unsupervised learning) - два основных подхода в машинном обучении.\n",
      "\n",
      "Обучение с учителем происходит, когда алгоритм обучается на наборе данных, сопровождаемых правильными ответами (метаданными). В этом случае задача алгоритма состоит в том, чтобы найти закономерность в данных и предсказать правильный ответ для новых данных. Например, классификация электронных писем как спам или неспам на основе их содержимого - типичная задача обучения с учителем.\n",
      "\n",
      "Обучение без учителя происходит, когда алгоритм обучается на наборе данных без каких-либо метаданных. В этом случае задача алгоритма состоит в том, чтобы найти внутреннюю структуру или закономерности в данных. Например, кластеризация клиентов на основании их покупательского поведения - типичная задача обучения без учителя.\n",
      "Reference Answer: Обучение с учителем предполагает наличие размеченных данных для тренировки модели, где каждому входному сигналу соответствует целевой выход. Обучение без учителя не использует размеченные данные и направлено на выявление скрытых структур в данных, таких как кластеры или ассоциации.\n",
      "Cosine Similarity: 0.6917515993118286\n",
      "BLEU Score: 1.1540795680165678e-78\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12a37290972e4305bc986261b64d0708",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3dd876808452418886075db620a1f22f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question ID: 4\n",
      "Generated Answer: Регрессия - это статистический метод, используемый для моделирования зависимости одной переменной от одной или нескольких других переменных. Существует несколько типов регрессии:\n",
      "\n",
      "1. Линейная регрессия: Этот тип регрессии используется для моделирования линейной зависимости между одной зависимой переменной и одной или несколькими независимыми переменными.\n",
      "2. Логистическая регрессия: Этот тип регрессии используется для моделирования зависимости категориальной переменной от одной или нескольких независимых переменных.\n",
      "3. Полиномиальная регрессия: Этот тип регрессии используется для моделирования нелинейной зависимости между одной зависимой переменной и одной или несколькими независимыми переменными.\n",
      "4. Ранговая регрессия: Этот тип регрессии используется для моделирования зависимости переменной, лишь ранжированной по величине, от одной или нескольких независимых переменных.\n",
      "5. Полиномиальная логарифмическая регрессия: Этот тип регрессии используется для моделирования логарифмической зависимости одной переменной от одной или нескольких независимых переменных.\n",
      "\n",
      "Это лишь несколько примеров типов регрессии, существуют и другие.\n",
      "Reference Answer: Регрессия - это метод моделирования зависимостей между переменными. Основные типы регрессии включают линейную регрессию, полиномиальную регрессию, логистическую регрессию и регрессию по методу наименьших квадратов.\n",
      "Cosine Similarity: 0.9089060425758362\n",
      "BLEU Score: 6.534361309179912e-79\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "685ea0f5517742c4a3ee3addaf3ddc34",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d53c9a34b044b02a6cea527f6c7009e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question ID: 5\n",
      "Generated Answer: To evaluate the accuracy of a machine learning model, you can use various metrics, depending on the type of problem you are solving. For classification tasks, common metrics include accuracy, precision, recall, F1-score, and area under the ROC curve (AUC-ROC). For regression tasks, common metrics include mean absolute error (MAE), mean squared error (MSE), root mean squared error (RMSE), and R-squared. Additionally, you can use cross-validation techniques, such as k-fold cross-validation, to get a more robust estimate of your model's performance.\n",
      "\n",
      "In Russian:\n",
      "\n",
      "Для оценки точности модели машинного обучения можно использовать различные метрики, в зависимости от типа решаемой задачи. Для задач классификации распространенными метриками являются точность, точность, полнота, показатель F1 и площадь под кривой ROC (AUC-ROC). Для задач регрессии распространенными метриками являются средняя абсолютная ошибка (MAE), среднеквадратическая ошибка (MSE), корневая среднеквадратическая ошибка (RMSE) и коэффициент детерминации R-квадрат. Кроме того, вы можете использовать методы кросс-валидации, такие как k-fold кросс-валидация, чтобы получить более надежную оценку производительности модели.\n",
      "Reference Answer: Точность модели машинного обучения оценивается с помощью различных метрик, таких как точность (accuracy), полнота (recall), F-мера, среднеквадратическая ошибка (MSE) и коэффициент детерминации (R²).\n",
      "Cosine Similarity: 0.15677806735038757\n",
      "BLEU Score: 8.605196120522377e-79\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31695921d9734bffbcd1d75ef6432521",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6fca238873e348f6b17e28e1f15542e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question ID: 6\n",
      "Generated Answer: Переобучение (overfitting) происходит, когда модель машинного обучения становится слишком сложной и начинает учиться не только на важных признаках, но и на шуме в данных. Это приводит к тому, что модель хорошо работает на обучающей выборке, но плохо генеральзируется на новые данные.\n",
      "\n",
      "Чтобы избежать переобучения, можно использовать различные техники регуляризации, такие как L1 или L2 регуляризация, которые добавляют штраф за сложность модели. Также можно использовать раннее завершение обучения (early stopping), когда обучение модели прерывается, когда она перестает улучшать свои показатели на валидационной выборке. Ещё одним способом является увеличение размера обучающей выборки.\n",
      "\n",
      "Другой подход заключается в использовании методов регуляризации, таких как Dropout или DropConnect, которые случайно отключают нейроны в сети во время обучения, чтобы предотвратить переобучение. Кроме того, можно использовать техники предобработки данных, такие как нормализация или уменьшение размерности, чтобы уменьшить шум и улучшить качество данных.\n",
      "\n",
      "Наконец, можно использовать методы ensemble learning, такие как bagging или boosting, которые комбинируют несколько простых моделей, чтобы создать более сложную и точную модель. Эти методы могут помочь снизить риск переобучения, поскольку они основаны на нескольких независимых моделях, которые учитывают различные аспекты данных.\n",
      "Reference Answer: Переобучение происходит, когда модель слишком точно подстраивается под обучающие данные, теряя способность обобщать новые данные. Чтобы избежать переобучения, используют методы регуляризации, кросс-валидацию и увеличение объема тренировочных данных.\n",
      "Cosine Similarity: 0.9251230955123901\n",
      "BLEU Score: 0.029685653035431844\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5212482bfdf4d829f970090dda24807",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7fe18d131926400cab89e753b1441326",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question ID: 7\n",
      "Generated Answer: Отложенная выборка (англ. deferred selection) в машинном обучении - это техника, при которой мы откладываем выбор лучшей модели до тех пор, пока не будет доступен полный набор данных. Например, мы можем использовать различные модельные архитектуры или гиперпараметры для обучения модели на тренировочном наборе данных, а затем выбрать наилучшую модель на основе ее производительности на тестовом наборе данных. Это помогает избежать переобучения и получить более точные прогнозы на новых данных.\n",
      "\n",
      "Конкретно, в машинном обучении это часто используется в контексте кросс-валидации, когда набор данных разбивается на несколько подмножеств, и модель обучается и тестируется на каждом из них по очереди. Затем производительность модели оценивается на основе среднего значения метрики качества, вычисленной на всех тестовых подмножествах. Затем мы можем выбрать модель, которая показала лучшую производительность на тестовых подмножествах, и использовать ее для прогнозирования на новых данных.\n",
      "\n",
      "Особое значение отложенная выборка имеет в случае небольшого размера обучающей выборки, когда риск переобучения особенно высок. В этом случае отложенная выборка помогает уменьшить эффект случайности и получить более надежные результаты.\n",
      "\n",
      "В целом, отложенная выборка является полезной техникой, которая помогает улучшить качество прогнозов и избежать переобучения в машинном обучении.\n",
      "\n",
      "(Note: The knowledge base provided does not contain information on deferred selection in machine learning. The response was generated based on general knowledge of the topic.)\n",
      "Reference Answer: Отложенная выборка - это часть данных, которая используется для проверки модели после тренировки, но не участвует в процессе обучения, позволяя оценить её способность к обобщению на новые данные.\n",
      "Cosine Similarity: 0.778693675994873\n",
      "BLEU Score: 2.303136912149078e-155\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e546cd9db9ca476bb496a4af82e0718b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a826f75fc3b4951af1be4022f80ffd1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question ID: 8\n",
      "Generated Answer: Нормализация данных - это процесс организации данных в базах данных, чтобы минимизировать избыточность и зависимости между таблицами. Это делается для улучшения эффективности, уменьшения риска ошибок и облегчения управления данными. Нормализация включает в себя несколько уровней, каждый из которых имеет определенные правила и ограничения. Наиболее часто используемые уровни нормализации - это 1NF, 2NF, 3NF и BCNF. Нормализация данных помогает избежать ряда проблем, таких как избыточность, несогласованность и ограниченная гибкость. Она также способствует более простому проектированию и обслуживанию базы данных.\n",
      "Reference Answer: Нормализация данных - это процесс преобразования данных к единому масштабу для улучшения сходимости алгоритмов машинного обучения и повышения точности моделей.\n",
      "Cosine Similarity: 0.9842214584350586\n",
      "BLEU Score: 0.05299390161904921\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07f956bd5ae94fe694fda0d51a343ca1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64898ebc767845d7809c8f9099fcbb56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question ID: 9\n",
      "Generated Answer: Метод k-NN (k ближайших соседей) — это алгоритм машинного обучения, который используется для классификации и регрессии. В основе этого алгоритма лежит предположение, что объекты, находящиеся близко друг к другу в пространстве объектов, имеют схожие характеристики.\n",
      "\n",
      "В процессе обучения алгоритм k-NN не делает никаких предположений о распределении данных и не строит модели. Вместо этого он сохраняет всю обучающую выборку в памяти. При предсказании метки для нового объекта он находит k ближайших соседей этого объекта в обучающей выборке и производит предсказание на основе меток этих соседей.\n",
      "\n",
      "В случае классификации предсказание делается путем голосования: каждый из k ближайших соседей голосует за класс, к которому он принадлежит, и в качестве предсказания выбирается класс, набравший наибольшее число голосов. В случае регрессии предсказание делается путем вычисления среднего значения меток k ближайших соседей.\n",
      "\n",
      "Важным параметром алгоритма k-NN является выбор числа k ближайших соседей. Чем больше значение k, тем более гладкой будет граница разделения между классами, но при этом алгоритм станет менее чувствительным к локальным особенностям данных. Наоборот, при малых значениях k алгоритм будет более точным в локальных областях, но будет более подвержен шуму и выбросам в данных.\n",
      "\n",
      "В целом, метод k-NN является простым и эффективным алгоритмом машинного обучения, который может давать хорошие результаты в задачах классификации и регрессии, особенно когда размеры обучающей выборки небольшие. Однако его основным недостатком является то, что он может быть медленным и требовательным к памяти на больших выборках.\n",
      "Reference Answer: Метод ближайших соседей (k-NN) классифицирует объекты по их ближайшим соседям в пространстве признаков. Классу объекта присваивается тот, к которому относится большинство из k ближайших соседей.\n",
      "Cosine Similarity: 0.9574257731437683\n",
      "BLEU Score: 7.307063492030966e-79\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a765c15bf94547528d86a64a6d15b878",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac620f0aa7254b409c2a16354045b832",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question ID: 10\n",
      "Generated Answer: Решающее дерево (Decision Tree) - это модель машинного обучения, которая используется для классификации и регрессии. Оно представляет собой иерархическую структуру, где каждый узел соответствует одному условию, а каждый лист соответствует классу или значению целевой переменной.\n",
      "\n",
      "Решающее дерево строится путем выбора наиболее важных признаков и разделения данных на подмножества на основе этих признаков. Этот процесс повторяется рекурсивно для каждого подмножества, пока все данные не будут правильно классифицированы или достигнут определенный предел.\n",
      "\n",
      "Решающее дерево широко используется в задачах классификации, где оно может эффективно обнаруживать взаимосвязи между входными переменными и целевым классом. Оно также легко интерпретируется и может быть использовано для объяснения принятия решений моделью машинного обучения.\n",
      "\n",
      "В качестве примера можно рассмотреть задачу классификации покупателей на сайте электронной коммерции на основе их демографических данных и историю их покупок. Решающее дерево может использоваться для определения наиболее важных факторов, влияющих на решение покупателя о покупке, и для предсказания вероятности того, что определенный покупатель сделает покупку в будущем.\n",
      "Reference Answer: Решающее дерево - это модель машинного обучения, которая представляет собой дерево решений и используется для задач классификации и регрессии. Оно состоит из узлов, которые представляют признаки, и ветвей, которые представляют условия разделения данных.\n",
      "Cosine Similarity: 0.6646038889884949\n",
      "BLEU Score: 0.05733651465496025\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a268f51db9e14a45b41492a92fc8282d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4370b3b5f7e8415caf96bdb04b2abadf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question ID: 11\n",
      "Generated Answer: В зависимости от конкретной задачи и характеристик данных, могут быть использованы различные алгоритмы кластеризации. Например,algorithmdict['k-means'], algorithmdict['hierarchical clustering'], algorithmdict['DBSCAN'], algorithmdict['Gaussian mixture models'], и др.\n",
      "\n",
      "* k-means - один из самых популярных и широко используемых алгоритмов кластеризации. Он делит данные на k кластеров, каждый из которых представляет собой совокупность точек, близких к центру масс кластера (centroid). Алгоритм итеративно пересчитывает центроиды и перераспределяет точки между кластерами, пока критерии остановки не будут достигнуты.\n",
      "* Hierarchical clustering - алгоритм, который строит иерархическую структуру кластеров (dendrogram). Существует два основных подхода к иерархической кластеризации: агломеративный (bottom-up) и делительный (top-down). Агломеративный подход начинается с каждой точки как отдельного кластера и постепенно объединяет близкие кластеры, в то время как делительный подход начинается с одного большого кластера, содержащего все точки, и постепенно разделяет его на более мелкие кластеры.\n",
      "* DBSCAN (Density-Based Spatial Clustering of Applications with Noise) - алгоритм, который определяет кластеры как области высокой плотности, окруженные области низкой плотности. Он не требует предварительного определения числа кластеров и может найти кластеры произвольной формы.\n",
      "* Gaussian mixture models - модель, которая представляет данные как смесь гауссовских распределений. Алгоритм вычисляет параметры этих распределений и использует их для кластеризации данных.\n",
      "\n",
      "Важно отметить, что для успешной кластеризации данных необходимо предварительно провести их нормализацию и выбрать подходящие метрики расстояния. Кроме того, выбор алгоритма кластеризации и его параметров может сильно зависеть от конкретной задачи и характеристик данных.\n",
      "Reference Answer: Для кластеризации данных используются алгоритмы, такие как k-средние (k-means), иерархическая кластеризация, DBSCAN и спектральная кластеризация.\n",
      "Cosine Similarity: 0.5737051963806152\n",
      "BLEU Score: 1.5021419618459875e-155\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "309d523f5bd049bc8f2876d3b93400c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a5bbd9955614bbb963a12d094b1eae7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question ID: 12\n",
      "Generated Answer: Метрика MSE (Mean Squared Error) представляет собой среднее квадратичное отклонение предсказанных значений от реальных значений. Она используется для оценки качества моделей машинного обучения, особенно в задачах регрессии. MSE вычисляется как среднее значение квадратов разницы между предсказанными и реальными значениями. Чем меньше значение MSE, тем лучше модель машинного обучения. MSE широко используется в прогнозировании, обработке изображений и других приложениях машинного обучения. Например, в задачах прогнозирования она помогает определить, насколько хорошо модель предсказывает будущие значения на основе исторических данных. В обработке изображений MSE может использоваться для оценки качества восстановления изображения после сжатия или искажения.\n",
      "Reference Answer: Метрика MSE (Mean Squared Error) измеряет среднеквадратическую ошибку предсказаний модели и используется для оценки моделей регрессии.\n",
      "Cosine Similarity: 0.9808957576751709\n",
      "BLEU Score: 0.0529715946034933\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8737445e57324f8986e5cd7af23720ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0003b85c5c145b889851bbd6a7bc255",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question ID: 13\n",
      "Generated Answer: Сдвиг данных (байас) — это systematic ошибка, возникающая при оценке статистических параметров или моделей, когда средние значения обучающей и тестовой выборки не совпадают. Это может привести к неточностям в модели, поскольку она будет слишком оптимистична или пессимистична в зависимости от направления сдвига.\n",
      "\n",
      "Для борьбы с сдвигом данных можно использовать различные подходы:\n",
      "\n",
      "1. Обработка данных: можно применить методы нормализации или стандартизации данных, чтобы привести их к одному масштабу и уменьшить влияние выбросов.\n",
      "2. Учет сдвига во время обучения: можно использовать методы, которые учитывают возможность сдвига данных во время обучения модели. Например, техника \"оценка сдвига байаса\" (bias correction) заключается в оценке среднего значения тестовой выборки и использовании его для корректировки предсказаний модели.\n",
      "3. Коллективное обучение (ensemble learning): можно использовать несколько моделей, обученных на разных подмножествах данных, и комбинировать их предсказания. Это может помочь уменьшить влияние сдвига данных, поскольку разные модели могут иметь разные систематические ошибки.\n",
      "4. Обработка данных на стадии пост-обработки: можно использовать методы пост-обработки, такие как срезка (clipping) или регуляризация, чтобы уменьшить влияние сдвига данных на предсказания модели.\n",
      "\n",
      "В качестве примера, рассмотрим задачу классификации, где модель должна предсказать, является ли объект картинки кошкой или собакой. Если среднее значение пикселей в обучающей выборке отличается от среднего значения в тестовой выборке, то модель может сделать неверные предсказания. В этом случае можно использовать метод нормализации данных, например, вычесть среднее значение пикселей из каждой картинки, чтобы уменьшить влияние сдвига данных.\n",
      "Reference Answer: Сдвиг данных - это изменение распределения данных во времени. Для борьбы с ним используют адаптивные модели и регулярные обновления данных, используемых для обучения модели.\n",
      "Cosine Similarity: 0.8367639780044556\n",
      "BLEU Score: 6.101361650094348e-79\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c049189113ce457399e06903cc467f6c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb5193b0115e4e4d81ab4f443b11115a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question ID: 14\n",
      "Generated Answer: Методы ансамблевого обучения (ensemble learning methods) — это подход в машинном обучении, который заключается в объединении прогнозов нескольких моделей для получения более точного результата. Такой подход позволяет улучшить точность прогноза по сравнению с использованием отдельной модели. Ансамблевое обучение включает в себя методы, такие как bagging, boosting и stacking. Например, в методе bagging создается несколько моделей, обученных на разных подвыборках данных, а затем их прогнозы комбинируются с помощью среднего или голосования. В методе boosting создается последовательность моделей, каждая из которых пытается улучшить предсказания предыдущей модели. В методе stacking используется комбинация моделей, каждая из которых обучена на разных признаках или использует разные алгоритмы. В результате получается более сложная модель, которая может лучше адаптироваться к данным и улучшить точность прогноза.\n",
      "\n",
      "Translation:\n",
      "Ensemble learning methods are an approach in machine learning that involves combining the predictions of several models to obtain a more accurate result. This approach can improve the accuracy of the prediction compared to using a single model. Ensemble learning includes methods such as bagging, boosting, and stacking. For example, in the bagging method, several models are created, each trained on different subsets of the data, and their predictions are then combined using averaging or voting. In the boosting method, a sequence of models is created, each of which tries to improve the predictions of the previous model. In the stacking method, a combination of models is used, each of which is trained on different features or uses different algorithms. As a result, a more complex model is obtained, which can better adapt to the data and improve the accuracy of the prediction.\n",
      "Reference Answer: Методы ансамблевого обучения объединяют несколько моделей для улучшения их точности и устойчивости. Основные методы включают bagging, boosting и stacking.\n",
      "Cosine Similarity: 0.5584397315979004\n",
      "BLEU Score: 0.014773388081818738\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c417aa938714b05ae5fcd235f5f771b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5211554ec2d648d691697885130ac02a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question ID: 15\n",
      "Generated Answer: Код базы знаний не содержит информации о работе алгоритма случайного леса. Однако, я могу предоставить вам общий обзор этого алгоритма.\n",
      "\n",
      "Алгоритм случайного леса (Random Forest) является одним из методов машинного обучения, который используется для решения задач классификации и регрессии. Он основан на концепции \"ensemble learning\", которая заключается в объединении нескольких моделей для получения более точного прогноза.\n",
      "\n",
      "Случайный лес состоит из множества деревьев решений (дерево решений - это модель машинного обучения, которая используется для классификации или регрессии). Каждое дерево обучается на разных подмножествах данных и features, выбранных случайным образом. В результате, каждое дерево дает свой собственный прогноз. Затем, все прогнозы комбинируются путем голосования (для задач классификации) или среднего арифметического (для задач регрессии).\n",
      "\n",
      "Один из основных преимуществ алгоритма случайного леса заключается в том, что он является очень мощным и может работать с необработанными данными, не требуя сложного предварительного анализа. Кроме того, он имеет способность избегать переобучения, что делает его очень эффективным для работы с большими данными.\n",
      "\n",
      "Надеюсь, это поможет вам лучше понять алгоритм случайного леса. Если у вас будут дополнительные вопросы, не стесняйтесь спрашивать.\n",
      "Reference Answer: Алгоритм случайного леса использует множество решающих деревьев для создания ансамбля, где каждое дерево обучается на случайной выборке данных с заменой, а предсказания дерева объединяются для получения окончательного результата.\n",
      "Cosine Similarity: 0.9614774584770203\n",
      "BLEU Score: 9.127963352290968e-79\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c59efde7295648ec8dba0519cab4c5ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85bca66f643b42168d8a0c6d48851b49",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question ID: 16\n",
      "Generated Answer: Нейронные сети - это математические модели, которые имитируют работу человеческого мозга. Они используются в анализе данных для решения различных задач, таких как классификация, регрессия и распознавание образов. Нейронные сети могут обучаться на больших объемах данных и обнаруживать сложные зависимости между переменными. Они широко используются в машинном обучении и искусственном интеллекте. Например, нейронные сети могут использоваться для распознавания речи, обнаружения объектов на изображениях, прогнозирования финансовых рынков и многого другого.\n",
      "\n",
      "Translation:\n",
      "Neural networks are mathematical models that simulate the work of the human brain. They are used in data analysis to solve various tasks, such as classification, regression, and image recognition. Neural networks can learn from large amounts of data and detect complex dependencies between variables. They are widely used in machine learning and artificial intelligence. For example, neural networks can be used for speech recognition, object detection in images, predicting financial markets, and much more.\n",
      "Reference Answer: Нейронные сети - это модели, вдохновленные биологическими нейронами, которые используются для обработки и анализа сложных данных. Они применяются в задачах, таких как распознавание изображений, обработка естественного языка и предсказание временных рядов.\n",
      "Cosine Similarity: 0.9738264083862305\n",
      "BLEU Score: 0.023227037166257007\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "afe3570aa5c54443b05080232379d6b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21dbd8ca60d14fd7875f2d019b5f1045",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question ID: 17\n",
      "Generated Answer: Я знаю несколько типов активационных функций, которые используются в машинном обучении. Вот некоторые из них:\n",
      "\n",
      "1. Сигмоидная функция (sigmoid function): эта функция имеет S-образную форму и ограничена между 0 и 1. Она часто используется в нейронных сетях для моделирования вероятностей.\n",
      "2. Функция прямого линейного единичного усиления (ReLU - Rectified Linear Unit): это простая функция, которая возвращает максимум из входного значения и 0. Она часто используется в нейронных сетях из-за своей простоты и эффективности.\n",
      "3. Функция гиперболического тангенса (tanh function): это функция, похожая на сигмоидную функцию, но она ограничена между -1 и 1. Она часто используется в нейронных сетях для моделирования симметричных данных.\n",
      "4. Софтмакс-функция (softmax function): это функция, которая используется для нормирования векторов, чтобы они суммировались до 1. Она часто используется в последнем слое нейронных сетей для классификации.\n",
      "5. Функция левых и правых уточнений ( Leaky ReLU and Parametric ReLU): это модификации функции ReLU, которые позволяют избежать проблемы \"мёртвого ребра\" путем введения небольшого склона для отрицательных входных значений.\n",
      "6. Функция максимальной видимости (Swish function): это недавно предложенная функция активации, которая сочетает в себе преимущества ReLU и sigmoid-функции. Она имеет более гладкую форму, чем ReLU, и может помочь улучшить обучение нейронных сетей.\n",
      "\n",
      "Вот несколько из них. Выберите наиболее подходящую функцию активации в зависимости от типа задачи и архитектуры нейронной сети.\n",
      "Reference Answer: Типы активационных функций включают сигмоидную функцию, гиперболический тангенс (tanh), функцию ReLU (Rectified Linear Unit), Leaky ReLU и функцию Softmax.\n",
      "Cosine Similarity: 0.6617639660835266\n",
      "BLEU Score: 2.3548364604928044e-155\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43f3cb7f462c4df7957e16df5af63325",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef8d6dd73ef34bd088be239b1322d6a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question ID: 18\n",
      "Generated Answer: Алгоритм градиентного спуска используется для оптимизации функции, находя минимум или максимум. Он основывается на вычислении градиента функции в текущей точке и изменении значения параметров в направлении, противоположном направлению градиента. Это позволяет сделать функцию более плоской (с минимальным значением) в каждой итерации алгоритма, постепенно приближаясь к оптимальному решению. Математически это может быть записано как:\n",
      "\n",
      "θ = θ - η \\* ∇J(θ)\n",
      "\n",
      "где θ - вектор параметров, η - скорость обучения (step size), ∇J(θ) - градиент функции стоимости (cost function) в точке θ. Скорость обучения определяет величину шага на каждой итерации алгоритма, и должно быть выбрано таким образом, чтобы алгоритм не сходился слишком медленно или слишком быстро (то есть, чтобы избежать переобучения или недообучения).\n",
      "\n",
      "В общем, алгоритм градиентного спуска является одним из основных методов оптимизации в машинном обучении и широко используется для обучения моделей, таких как линейная регрессия, логистическая регрессия и нейронные сети.\n",
      "Reference Answer: Алгоритм градиентного спуска оптимизирует параметры модели, уменьшая ошибку путем итеративного обновления параметров в направлении, противоположном градиенту функции потерь.\n",
      "Cosine Similarity: 0.9656826257705688\n",
      "BLEU Score: 0.02372657509246532\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26fbc286f44b49e4a5c63519c8af2936",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20c249c2baee4043a72153271c971f95",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question ID: 19\n",
      "Generated Answer: Функция потерь (или функция ошибки) - это мера разницы между предсказанным результатом и фактическим результатом. Она используется для оценки качества модели машинного обучения. Функция потерь помогает оптимизатору найти лучшие параметры модели, минимизируя сумму потерь на обучающей выборке. В зависимости от конкретной задачи машинного обучения можно использовать различные функции потерь, такие как функция мейнкаудового риска, функция среднеквадратичной ошибки или функция кросс-энтропии.\n",
      "Reference Answer: Функция потерь измеряет, насколько точны предсказания модели. Она используется для оптимизации модели путем минимизации потерь, например, среднеквадратическая ошибка (MSE) или кросс-энтропия.\n",
      "Cosine Similarity: 0.9592201709747314\n",
      "BLEU Score: 1.2699338644622464e-78\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a156ca0f4134293825d7f018763d252",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "587991f7b9f1484c8db5e7cce2b22f22",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question ID: 20\n",
      "Generated Answer: Глубокое обучение (deep learning) - это подход к машинному обучению, который основан на искусственных нейронных сетях с большим числом скрытых слоев. Основное отличие глубокого обучения от традиционного машинного обучения заключается в том, что глубокое обучение способно автоматически извлекать признаки из данных, не требуя ручного их определения. Кроме того, глубокое обучение лучше подходит для обработки крупных объемов данных и может достичь более высокой точности в задачах классификации, регрессии и обработки естественного языка.\n",
      "Reference Answer: Глубокое обучение - это подмножество машинного обучения, которое использует многослойные нейронные сети для обработки и анализа данных. Оно отличается от машинного обучения большей сложностью моделей и способностью извлекать сложные признаки из данных.\n",
      "Cosine Similarity: 0.6965371370315552\n",
      "BLEU Score: 5.1387516415983556e-155\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29f8adec526b4ff4ba074969324ad65d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ffc15777685f4b218b51936d573d5c01",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question ID: 21\n",
      "Generated Answer: Сверточная нейронная сеть (CNN) - это тип искусственных нейронных сетей, которые специально используются для обработки двумерных данных, таких как изображения. Они состоят из нескольких слоев, включая сверточный слой, пулинговый слой и полносвязный слой.\n",
      "\n",
      "Сверточный слой применяет convolution operation к входному изображению, используя фильтры или ядра. Эти фильтры перемещаются по всему изображению, и в каждой позиции производится операция свёртки, чтобы выделить особенности изображения, такие как края, углы и текстуры.\n",
      "\n",
      "После сверточного слоя следует пулинговый слой, который уменьшает размер изображения, сохраняя при этом важные особенности. Существует два основных типа пулинга: максимальное пулинг и среднее пулинг. Максимальное пулинг выбирает максимальное значение в каждом пулинговом окне, в то время как среднее пулинг вычисляет среднее значение в каждом окне.\n",
      "\n",
      "Наконец, полносвязный слой используется для классификации выделенных особенностей. Он связывает все нейроны предыдущего слоя с каждым нейроном в следующем слое.\n",
      "\n",
      "C помощью CNN можно достичь высокой точности в задачах классификации изображений, таких как распознавание лиц, видов животных и других объектов. Кроме того, CNN можно использовать для других задач, таких как объектное обнаружение и сегментация изображений.\n",
      "Reference Answer: Сверточная нейронная сеть (CNN) использует сверточные слои для извлечения признаков из данных, особенно из изображений. Она применяется в задачах распознавания образов, классификации изображений и сегментации.\n",
      "Cosine Similarity: 0.9743748307228088\n",
      "BLEU Score: 0.018687993392454586\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2723da9e003049efb6f0378b7a1dc677",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1a44033679144bc89ead45bdf6a5de1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question ID: 22\n",
      "Generated Answer: Рекуррентная нейронная сеть (RNN) - это вид искусственных нейронных сетей, которые могут использовать информацию о предыдущих входах для предсказания текущего выхода. Это делает их особенно полезными для обработки последовательностей данных, таких как речь или текст. RNN используются в различных приложениях, включая распознавание речи, машинный перевод, генерацию текста и прогнозирование временных рядов. Например, при разработке систему распознавания речи RNN может использоваться для анализа звуковых волн и определения соответствующих слов или фраз. В области машинного перевода RNN может использоваться для анализа входного текста на одном языке и генерации соответствующего текста на другом языке. В области генерации текста RNN может использоваться для создания убедительных и когерентных текстовых ответов в чатах или других текстовых интерфейсах. В области прогнозирования временных рядов RNN может использоваться для предсказания будущих значений на основе прошлых данных. Например, RNN может быть использована для прогнозирования цен на акции или погодных условий.\n",
      "Reference Answer: Рекуррентная нейронная сеть (RNN) учитывает временную последовательность данных и используется для задач, связанных с временными рядами, например, предсказание временных рядов и обработка последовательностей.\n",
      "Cosine Similarity: 0.9424678087234497\n",
      "BLEU Score: 0.021032819835498432\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6494ec3fef94757bf9013a7bfd2c048",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "623683a675954710beed7d1bf7fa0c1f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question ID: 23\n",
      "Generated Answer: Long Short-Term Memory (LSTM) сеть является разновидностью рекуррентных нейронных сетей (RNN), которая лучше всего подходит для работы с последовательностями данных. Основная задача LSTM сети заключается в сохранении памяти о предыдущих входах и использовании этой памяти для предсказания следующего элемента последовательности.\n",
      "\n",
      "LSTM сеть состоит из нескольких блоков, каждый из которых содержит три основных компонента: забывающую вороту (forget gate), входную вороту (input gate) и выходную вороту (output gate). Эти ворота определяют, какие данные будут сохраняться в состоянии памяти LSTM сети и какие данные будут игнорироваться.\n",
      "\n",
      "Забывающая вороту определяет, какую информацию необходимо сохранить из предыдущего состояния памяти. Она использует сигмоидную функцию для оценки значения от 0 до 1 для каждого элемента в предыдущем состоянии памяти. Значения близкие к 1 означают, что элемент должен быть сохранен, а значения близкие к 0 означают, что элемент должен быть забыт.\n",
      "\n",
      "Входная вороту определяет, какие новые данные должны быть добавлены в состояние памяти. Она также использует сигмоидную функцию для оценки значения от 0 до 1 для каждого элемента в текущем входе. Значения близкие к 1 означают, что элемент должен быть добавлен в состояние памяти, а значения близкие к 0 означают, что элемент должен быть проигнорирован.\n",
      "\n",
      "Выходная вороту определяет, какая информация должна быть выведена из состояния памяти LSTM сети. Она использует тангенсиальную функцию для преобразования состояния памяти в диапазон от -1 до 1, а затем использует сигмоидную функцию для определения значения от 0 до 1, указывающего, какая часть преобразованного состояния памяти должна быть выведена.\n",
      "\n",
      "LSTM сеть может быть использована для решения многих задач, таких как распознавание речи, генерация текста и предсказание временных рядов. Она также широко используется в области машинного обучения для решения задач с последовательными данными, таких как классификация текста и голосового ввода.\n",
      "\n",
      "В целом, LSTM сеть является мощным инструментом для работы с последовательностями данных, поскольку она может сохранять информацию о предыдущих входах и использовать эту информацию для предсказания следующего элемента последовательности.\n",
      "Reference Answer: LSTM (Long Short-Term Memory) нейронные сети - это разновидность RNN, которая может хранить долгосрочные зависимости в данных. Они используются для задач, где важны длительные зависимости, например, в обработке текста.\n",
      "Cosine Similarity: 0.9551708102226257\n",
      "BLEU Score: 7.758717293614723e-232\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "611f8ee1838b4e63ae9d719d7c462276",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f30c1760d784398bd053dde398ee551",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question ID: 24\n",
      "Generated Answer: Гиперпараметры - это параметры машинного обучения, которые определяются перед началом обучения модели. Они отличаются от параметров модели, которые обновляются во время обучения. Примерами гиперпараметров могут служитьlearning rate, количество слоев в нейронной сети, количество узлов в каждом слое и т.д.\n",
      "\n",
      "Оптимизация гиперпараметров - это процесс нахождения лучшего набора гиперпараметров для конкретной модели и данных. Этот процесс может быть выполнен различными способами, такими как Grid Search, Random Search и Bayesian Optimization.\n",
      "\n",
      "Grid Search заключается в том, что мы пробегаемся по всевозможным комбинациям гиперпараметров и выбираем лучшую комбинацию на основе метрики качества. Random Search аналогичен Grid Search, но вместо того, чтобы просматривать все возможные комбинации, мы выбираем случайные комбинации гиперпараметров и оцениваем их. Bayesian Optimization использует байесовский подход для определения следующей комбинации гиперпараметров, которая должна быть проверена. Это позволяет найти лучшие гиперпараметры с меньшим количеством экспериментов, чем Grid Search или Random Search.\n",
      "Reference Answer: Гиперпараметры - это параметры модели, которые задаются до обучения и не изменяются во время обучения, такие как скорость обучения и количество слоев. Их оптимизация осуществляется с помощью методов, таких как сеточный поиск и байесовская оптимизация.\n",
      "Cosine Similarity: 0.9807822108268738\n",
      "BLEU Score: 0.02586673745882532\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b80bf51fef04bc0a41bded39ea32a6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3bf1d77b1f9a43159051a66ac3ba2717",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question ID: 25\n",
      "Generated Answer: Кросс-валидация (англ. cross-validation) — это метод оценки модели машинного обучения, который позволяет избежать переобучения и получить более точную оценку ее качества. Основная идея заключается в разделении выборки данных на несколько подвыборок (как правило, их число составляет от 5 до 10), для каждой из которых поочередно строится модель и проводится ее обучение. Затем модель тестируется на оставшейся части данных, и получается оценка ее качества. Этот процесс повторяется для каждой подвыборки, и в итоге получается средняя оценка качества модели. Таким образом, кросс-валидация позволяет получить более объективную оценку модели и избежать завышения ее качества в силу случайных особенностей выборки данных.\n",
      "Reference Answer: Кросс-валидация - это метод оценки модели, при котором данные делятся на несколько подвыборок. Модель обучается на одной подвыборке и проверяется на другой, позволяя оценить её обобщающую способность.\n",
      "Cosine Similarity: 0.7229681015014648\n",
      "BLEU Score: 8.81449174005902e-79\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1e9d3a7d4884f228e8e77ecf034125e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5190f2408c3d4db8b331e81b86a8d4f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question ID: 26\n",
      "Generated Answer: Методы уменьшения размерности, такие как PCA (приincipal component analysis), используются для преобразования высокоразмерных данных в низкоразмерное пространство, сохраняя при этом максимум информации. PCA выполняет это, находя основные компоненты данных и преобразуя их в новую систему координат, где первые несколько компонентов содержат большую часть вариации данных. Это позволяет уменьшить размерность данных, удалив ненужные или повторяющиеся компоненты, и улучшить их представление для последующего анализа.\n",
      "Reference Answer: Методы уменьшения размерности, такие как PCA (Principal Component Analysis), уменьшают количество признаков в данных, сохраняя при этом как можно больше информации. Они используются для визуализации и ускорения работы моделей.\n",
      "Cosine Similarity: 0.9773015379905701\n",
      "BLEU Score: 0.10768046681752602\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72c34ee0c98b40d4862ac1d516bbc32b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "978deae883bf4789918349d0e6ff0233",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question ID: 27\n",
      "Generated Answer: Гиперплоскость в контексте SVM (Support Vector Machine) является линией (для двумерного пространства), плоскостью (для трехмерного пространства) или, обобщенно, гиперплоскостью (для пространства с большим количеством измерений), которая разделяет два класса данных максимально эффективно. Она определяется как множество точек, находящихся на одинаковом расстоянии до ближайших точек из разных классов. Идея SVM заключается в нахождении такой гиперплоскости, которая максимизирует расстояние (маرжин) между ней и ближайшими точками из каждого класса. Эти ближайшие точки известны как Support Vectors.\n",
      "Reference Answer: Гиперплоскость в контексте SVM (Support Vector Machine) - это плоскость, разделяющая данные на разные классы, обеспечивая максимальное расстояние между классами для улучшения точности классификации.\n",
      "Cosine Similarity: 0.9790389537811279\n",
      "BLEU Score: 0.08232701615158478\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77ace86c902c4aaca0a60bb39b67368b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd6d54a815a34b9a81a7ea49f9e217f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question ID: 28\n",
      "Generated Answer: Мы можем обрабатывать пропущенные данные в наборе данных несколькими способами. Во-первых, мы можем удалить строки или столбцы, содержащие пропущенные данные, если их количество незначительно и не влияет на общую точность модели. Во-вторых, мы можем заполнить пропущенные данные средними значениями, медианами или другими статистическими мерами, если мы можем предположить, что пропущенные данные распределены случайно. В-третьих, мы можем использовать более сложные методы импутации, такие как множественное импутирование или машинное обучение, чтобы предсказать значения пропущенных данных на основе других данных в наборе. Важно отметить, что метод обработки пропущенных данных должен быть выбран в зависимости от конкретной задачи и характеристик данных.\n",
      "Reference Answer: Для работы с пропущенными данными применяются методы, такие как удаление пропущенных значений, замена на среднее или медианное значение, и использование моделей для предсказания пропущенных значений.\n",
      "Cosine Similarity: 0.9658080339431763\n",
      "BLEU Score: 2.46993761371609e-155\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2162cddf88634613ab865ab96c13799f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47aadf05e46e4f14a217c2f80073acd0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question ID: 29\n",
      "Generated Answer: Свертка (convolution) в нейронных сетях - это операция, которая используется для извлечения локальных особенностей из входного изображения или сигнала. Она выполняется путем согласования фильтра (ядра) определенного размера с различными частями входного изображения и вычисления суммы элементов, умноженных на соответствующие значения фильтра. Результатом является карта особенностей, которая сохраняет позиционную информацию о локальных структурах входного изображения. Свертка широко используется в сетях глубинного обучения, особенно в задачах компьютерного зрения, таких как обнаружение объектов и сегментация изображений.\n",
      "Reference Answer: Свертка в нейронных сетях - это операция, применяемая в сверточных слоях для извлечения локальных признаков из данных, таких как изображения. Она используется для создания карт признаков.\n",
      "Cosine Similarity: 0.952592134475708\n",
      "BLEU Score: 0.09681501925037285\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b187815f8a4c48b6999a0a1781b322f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67b50f1c35354182bcd348ce9f627852",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question ID: 30\n",
      "Generated Answer: Метод опорных векторов (SVM) - это алгоритм машинного обучения, используемый для классификации и регрессии. Алгоритм строит гиперплоскость, которая максимизирует расстояние (маржину) между двумя классами. Опорные векторы - это точки данных, которые лежат в непосредственной близости от гиперплоскости и определяют её положение и ориентацию. В случае линейно неразделимых данных, алгоритм SVM может использовать ядро (kernel function) для преобразования данных в более высокую размерность, где они становятся линейно разделимыми. Затем алгоритм строит гиперплоскость в этом пространстве и использует её для классификации новых данных.\n",
      "\n",
      "Основное преимущество SVM заключается в том, что он минимизирует эмпирическую ошибку классификации и одновременно максимизирует маржину, обеспечивая хорошую обобщающую способность на новых данных. Кроме того, SVM обладает хорошей устойчивостью к шуму и выбросам в данных.\n",
      "\n",
      "SVM может использоваться для решения задач многоклассовой классификации с помощью различных методов, таких как one-vs-one или one-vs-all. Для задач регрессии SVM может быть расширен до метода опорных векторов для регрессии (SVR), который строит гиперплоскость, минимизирующую сумму отклонений от гиперплоскости.\n",
      "\n",
      "В целом, SVM является эффективным и широко используемым методом машинного обучения, особенно в случаях, когда количество измерений (размерность) больше количества объектов (выборок).\n",
      "Reference Answer: Метод опорных векторов (SVM) - это алгоритм классификации, который ищет гиперплоскость, максимально разделяющую данные на классы. Он эффективен для задач классификации и регрессии.\n",
      "Cosine Similarity: 0.9404264688491821\n",
      "BLEU Score: 0.041742630555556326\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93944444627f4f5a9f260e224684087b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c1a664fa72a4bb0a35f508afd68db38",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question ID: 31\n",
      "Generated Answer: Регуляризация - это техника машинного обучения, которая используется для предотвращения переобучения модели на тренировочных данных. Она добавляет штраф к функции потерь модели, чтобы снизить веса некоторых параметров и таким образом уменьшить их влияние на предсказания. Регуляризация помогает модели лучше обобщать на новых данных, улучшая ее точность и устойчивость к шуму и ошибкам в данных.\n",
      "\n",
      "Translation:\n",
      "Regularization is a machine learning technique used to prevent overfitting of the model on training data. It adds a penalty to the model's loss function to reduce the weights of some parameters and thus decrease their influence on predictions. Regularization helps the model to generalize better to new data, improving its accuracy and robustness to noise and errors in the data.\n",
      "Reference Answer: Регуляризация - это метод, используемый для предотвращения переобучения модели путем добавления штрафных значений к функции потерь, что ограничивает сложность модели. Виды регуляризации включают L1 и L2.\n",
      "Cosine Similarity: 0.981987476348877\n",
      "BLEU Score: 0.03199140730621607\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ebb1ee35504e426998d940bb064bcc93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9cffc3c1d6a04f2e948677ffdbbac3ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question ID: 32\n",
      "Generated Answer: Я использую такие библиотеки машинного обучения, как TensorFlow, PyTorch, Scikit-learn и Keras.\n",
      "\n",
      "TensorFlow - это открытая библиотека с открытым исходным кодом для выполнения вычислений с помощью тензоров. Она была разработана компанией Google Brain Team для решения задач машинного обучения иdeep learning. Я использую TensorFlow для тренировки нейронных сетей, т.к. он имеет хорошую поддержку GPU и TPU, а также предоставляет инструменты для создания моделей машинного обучения.\n",
      "\n",
      "PyTorch - это ещё одна популярная библиотека машинного обучения с открытым исходным кодом, разработанная компанией Facebook. Она отличается простотой использования и удобством отладки, что делает её идеальным выбором для экспериментов и быстрой прототипизации. Я использую PyTorch для решения задач машинного обучения, которые требуют максимальной гибкости и производительности.\n",
      "\n",
      "Scikit-learn - это библиотека машинного обучения с открытым исходным кодом на Python, которая включает в себя алгоритмы для регрессии, классификации, кластеризации и других задач машинного обучения. Я использую Scikit-learn для быстрого прототипирования и тестирования моделей машинного обучения, а также для создания pipeline-ов для машинного обучения.\n",
      "\n",
      "Keras - это высокоуровневая библиотека машинного обучения с открытым исходным кодом, которая может работать поверх TensorFlow или Theano. Она обеспечивает простой и интуитивно понятный интерфейс для создания нейронных сетей, что делает её идеальным выбором для обучающихся и исследователей. Я использую Keras для создания простых нейронных сетей и прототипирования моделей машинного обучения.\n",
      "\n",
      "В целом, я выбираю библиотеки машинного обучения в зависимости от конкретной задачи, требований к производительности и сложности модели.\n",
      "Reference Answer: Библиотеки для машинного обучения, такие как TensorFlow, PyTorch, scikit-learn и Keras, используются из-за их эффективности, гибкости и поддержки широкого спектра алгоритмов и инструментов.\n",
      "Cosine Similarity: 0.9744168519973755\n",
      "BLEU Score: 5.725218109470878e-79\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2d11d4abbe44e8ab1a9496eeebd4635",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf3cba3b6b2c41d6b871923693829f7e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question ID: 33\n",
      "Generated Answer: Баггинг (Bagging) и бустинг (Boosting) являются двумя популярными методами ensemble learning (объединения моделей) в машинном обучении.\n",
      "\n",
      "Баггинг является методом уменьшения дисперсии (variance reduction) в модели машинного обучения. Он основан на идее создания нескольких моделей, обученных на разных подмножествах данных, и комбинирования их прогнозов путем средневзвешенного среднего, голосования или других методов. Это позволяет уменьшить дисперсию оценок и улучшить общую точность модели.\n",
      "\n",
      "Бустинг, с другой стороны, является методом уменьшения смещения (bias reduction) в модели машинного обучения. Он основан на идее обучения последовательности моделей, каждая из которых пытается исправить ошибки предыдущей. Каждая модель дает больший вес ошибкам предыдущей модели, и в результате получается комбинированная модель, которая лучше адаптируется к данным. Бустинг может быть реализован с помощью различных алгоритмов, таких как AdaBoost, Gradient Boosting и XGBoost.\n",
      "Reference Answer: Bagging и boosting - это методы ансамблевого обучения. Bagging уменьшает вариацию модели, комбинируя результаты нескольких моделей, обученных на случайных подвыборках данных. Boosting улучшает точность модели, последовательно обучая модели на ошибках предыдущих моделей.\n",
      "Cosine Similarity: 0.8159072399139404\n",
      "BLEU Score: 0.023654710200815762\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be88a0b7f10441a7a06b03d58634d673",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63ec413d473a4739ba4be6e7d2fa1221",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question ID: 34\n",
      "Generated Answer: В модели машинного обучения важность признаков можно определить различными способами, например:\n",
      "\n",
      "1. Коэффициенты регрессии: в линейной или логистической регрессии коэффициенты модели представляют собой веса, присваиваемые каждому признаку, и их величина указывает на силу влияния признака на результат.\n",
      "2. Метод перемешивания признаков: это техника, при которой значения одного или нескольких признаков случайным образом перемешиваются, и затем измеряется изменение качества модели. Если значения признака важны, то их перемешивание должно привести к значительному ухудшению модели.\n",
      "3. Метод пермутаций: похож на метод перемешивания, но вместо случайного перемешивания значений признака, значения одного признака замещаются значениями другого признака.\n",
      "4. Метод глобальной чувствительности: этот метод оценивает влияние каждого признака на модель, изменяя значения признака на всей области значений и измеряя изменение качества модели.\n",
      "5. Метод локальной чувствительности: это метод, который оценивает влияние изменения значения признака вблизи текущей точки данных на результат модели.\n",
      "\n",
      "Важно отметить, что не все методы применимы к каждой модели, и выбор метода зависит от типа модели и характеристик данных.\n",
      "Reference Answer: Для определения важности признаков используются методы, такие как случайные леса, методы отбора признаков на основе статистических тестов и методы оценки вклада признаков в производительность модели.\n",
      "Cosine Similarity: 0.9630206823348999\n",
      "BLEU Score: 8.398464852179726e-232\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ad8f0813d684991a05c2f1578b7de6a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3cc92dfe528b4a8180464658e7c02413",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question ID: 35\n",
      "Generated Answer: ROC-кривая (Receiver Operating Characteristic curve) - это график, показывающий производительность бинарного классификатора. Она позволяет проверить отношение чувствительности и специфичности классификатора. Чувствительность (true positive rate) измеряет долю правильно классифицированных положительных примеров, а специфичность (true negative rate) - долю правильно классифицированных отрицательных примеров. На графике обычно отображается зависимость чувствительности от фальшивой чувствительности (false positive rate), которая равна 1 минус специфичность. Рокуровская характеристика классификатора демонстрирует его производительность как компромисс между селективностью и чувствительностью. Её интерпретация заключается в следующем: чем ближе AUC (площадь под ROC-кривой) к 1, тем лучше производительность классификатора, а если AUC равна 0,5, то классификатор работает как случайный предсказатель.\n",
      "Reference Answer: ROC-кривая (Receiver Operating Characteristic) показывает зависимость между долей верно предсказанных положительных примеров и долей неверно предсказанных отрицательных примеров. Она используется для оценки качества бинарных классификаторов.\n",
      "Cosine Similarity: 0.9356119632720947\n",
      "BLEU Score: 9.248028528169543e-79\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8f1d684b1ff4de59d47e558b85377fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e77d906c30ee479db211d4492744ef4a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question ID: 36\n",
      "Generated Answer: F-score - это метрика качества бинарной классификации, которая комбинирует показатели точности (precision) и полноты (recall) в одну величину. Он рассчитывается по следующей формуле:\n",
      "\n",
      "F-score = 2 \\* (точность \\* полнота) / (точность + полнота)\n",
      "\n",
      "Где:\n",
      "\n",
      "* Точность (precision) - это отношение количества истинно положительных классификаций к общему количеству положительных классификаций.\n",
      "* Полнота (recall) - это отношение количества истинно положительных классификаций к общему количеству наблюдений, которые относятся к положительному классу.\n",
      "\n",
      "F-score принимает значения от 0 до 1, где 1 соответствует идеальной классификации, а 0 - полному отсутствию классификации.\n",
      "\n",
      "F-score также известен как F1-score, поскольку он является частным случаем более общего семейства метрик F-score, которые могут быть вычислены с помощью различных весовых коэффициентов для точности и полноты. Ф1-score соответствует случаю, когда эти весовые коэффициенты равны 1.\n",
      "Reference Answer: F-score - это метрика, объединяющая точность (precision) и полноту (recall). Она рассчитывается как гармоническое среднее между точностью и полнотой, позволяя оценить эффективность модели при наличии несбалансированных классов.\n",
      "Cosine Similarity: 0.9807647466659546\n",
      "BLEU Score: 7.319261461334884e-79\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "030f8d236afa444fbe626fe9435c020f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97d2a06c1a3a495db41f800178b44be1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question ID: 37\n",
      "Generated Answer: Дисбаланс классов - это ситуация, когда в наборе данных для машинного обучения один класс значительно преобладает над другим. Это может привести к тому, что модель будет неточно предсказывать редкий класс, поскольку она будет склонна предпочитать более распространенный класс.\n",
      "\n",
      "Существует несколько способов борьбы с дисбалансом классов:\n",
      "\n",
      "1. Увеличение веса редкого класса: можно увеличить вес rare класса при обучении модели, чтобы сделать его более значимым для алгоритма.\n",
      "2. Уменьшение веса распространенного класса: аналогично, можно уменьшить вес преобладающего класса, чтобы уравновесить влияние классов.\n",
      "3. Обучение с повторениями: можно повторять rare класс several times, чтобы увеличить его представительность в обучающем наборе данных.\n",
      "4. Синтетическое увеличение данных: можно генерировать синтетические данные для rare класса с помощью методов, таких как SMOTE (Synthetic Minority Over-sampling Technique), для увеличения его представительности.\n",
      "5. Использование метрик, устойчивых к дисбалансу классов: вместо классических метрик, таких как точность и F1-мерa, можно использовать метрики, которые лучше отражают качество модели на rare классе, например, precision, recall, F-beta score и AUC-ROC.\n",
      "\n",
      "Все эти методы могут помочь улучшить качество предсказаний модели на rare классе и обеспечить более сбалансированные результаты.\n",
      "Reference Answer: Дисбаланс классов - это ситуация, когда один класс данных существенно преобладает над другим. Это может повлиять на работу моделей машинного обучения, поскольку модель будет склонна к предсказаниям преобладающего класса. Для борьбы с этим применяются методы балансировки данных, такие как синтетическое увеличение меньшего класса (SMOTE), взвешивание классов и использование ансамблевых методов.\n",
      "Cosine Similarity: 0.9828498959541321\n",
      "BLEU Score: 0.06249531381682246\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "993662aac6534eca97e096eddc9c7c5f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a585ae4a0434aba824235368470b368",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question ID: 38\n",
      "Generated Answer: Точность (precision) и полнота (recall) - это два важных показателя качества модели машинного обучения.\n",
      "\n",
      "Точность измеряет долю верно классифицированных положительных примеров среди всех предсказанных положительных примеров. То есть, если модель предсказала, что объект является позитивным, то точность показывает, насколько часто эта модель прав. Формула для расчета точности:\n",
      "\n",
      "precision = true positives / (true positives + false positives)\n",
      "\n",
      "Полнота измеряет долю верно классифицированных положительных примеров среди всех действительных положительных примеров. То есть, из всех объектов, которые на самом деле являются положительными, полнота показывает, насколько часто модель это правильно определяет. Формула для расчета полноты:\n",
      "\n",
      "recall = true positives / (true positives + false negatives)\n",
      "\n",
      "Точность и полнота часто используются вместе для оценки качества модели, потому что они дают разные сведения о модели и могут помочь найти оптимальную модель для конкретной задачи. Например, если мы хотим минимизировать число ложноположительных результатов, мы можем предпочесть модель с высокой точностью. Если же нам важно найти как можно больше положительных примеров, то мы можем предпочесть модель с высокой полнотой.\n",
      "Reference Answer: Точность (precision) измеряет долю истинно положительных предсказаний среди всех положительных предсказаний модели. Полнота (recall) измеряет долю истинно положительных предсказаний среди всех реальных положительных примеров. Высокая точность означает, что модель редко ошибается в своих положительных предсказаниях, а высокая полнота означает, что модель выявляет почти все реальные положительные случаи.\n",
      "Cosine Similarity: 0.9488844275474548\n",
      "BLEU Score: 4.066095887895611e-155\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89cd517b19bc46eba0eb5b6c51b846ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d6b60d6aa1a4616a3b69bb4e60716b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question ID: 39\n",
      "Generated Answer: Кросс-энтропия (англ. cross-entropy) — это мера расстояния между двумя вероятностными распределениями. Она используется в машинном обучении и информационной теории для оценки качества модели предсказания. Кросс-энтропия применяется в алгоритмах обучения с учителем (supervised learning), таких как метод максимального правдоподобия (maximum likelihood estimation), алгоритм обратного распространения ошибки (backpropagation) и т.д. Например, кросс-энтропия используется в нейронных сетях для измерения разницы между предсказанным и реальным выходом на каждой итерации обучения, что позволяет оптимизировать веса нейронной сети и улучшить качество предсказаний.\n",
      "\n",
      "Translation:\n",
      "\n",
      "Кросс-энтропия (англ. cross-entropy) is a measure of the distance between two probability distributions. It is used in machine learning and information theory to assess the quality of a prediction model. Cross-entropy is used in supervised learning algorithms (supervised learning), such as maximum likelihood estimation, backpropagation algorithm, etc. For example, cross-entropy is used in neural networks to measure the difference between the predicted and actual output on each iteration of training, which allows you to optimize the weights of the neural network and improve the accuracy of predictions.\n",
      "Reference Answer: Кросс-энтропия - это функция потерь, используемая в задачах классификации. Она измеряет расхождение между истинным распределением меток и предсказанным распределением вероятностей модели. Используется для оптимизации моделей, таких как логистическая регрессия и нейронные сети.\n",
      "Cosine Similarity: 0.6952495574951172\n",
      "BLEU Score: 2.124528316404656e-155\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56fc476c54a04ca993f92d8087dc0af3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54ea78c2445849cb89df92fe3f4e8c73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question ID: 40\n",
      "Generated Answer: Модель можно объяснить коллегам или заинтересованным сторонам следующим образом:\n",
      "\n",
      "Когда мы говорим о модели в контексте машинного обучения, мы имеем в виду математическую функцию, которая позволяет нам предсказывать значения одной переменной на основе значений других переменных. Эта функция обучается на наборе данных и пытается найти закономерности в них.\n",
      "\n",
      "Модель может быть представлена в виде уравнения, графика или матрицы коэффициентов. Модель может быть очень простой, например, линейная регрессия, или очень сложной, например, глубокая искусственная нейронная сеть.\n",
      "\n",
      "Когда мы используем модель для предсказаний, мы вводим в нее значения входных переменных, и модель выдает нам предсказанное значение выходной переменной. Например, если мы используем модель для предсказания цены дома, мы вводим в нее размер дома, его возраст, расположение и другие характеристики, и модель выдает нам предсказанную цену.\n",
      "\n",
      "Модель может быть очень полезной для предсказания результатов, прогнозирования трендов, принятия решений и улучшения бизнес-процессов. Но делать это нужно осторожно, так как модель может быть неточной или давать ложные предсказания, если она не была должным образом обучена или если входные данные не соответствуют данным, на которых она была обучена.\n",
      "\n",
      "В целом, модель - это математическая функция, которая позволяет нам делать предсказания на основе данных, и она может быть очень полезной для решения различных задач.\n",
      "Reference Answer: Для объяснения модели коллегам или заинтересованным сторонам важно использовать понятный язык, визуализации и примеры. Можно начать с общей концепции модели, объяснив, какие данные использовались, какие были выбраны признаки и какова цель модели. Затем можно продемонстрировать результаты моделей с помощью графиков и метрик, таких как точность, полнота и ROC-кривые.\n",
      "Cosine Similarity: 0.9807084798812866\n",
      "BLEU Score: 0.014900246885894416\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb8f34ab9948404ca4e5beef30f74b5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f10d66095187413d944e252a0266a6b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question ID: 41\n",
      "Generated Answer: Я использую различные подходы для визуализации данных в зависимости от конкретной задачи и набора данных. Наиболее часто используемые методы включают в себя гистограммы, диаграммы рассеяния, графики зависимости, дендрограммы, карты плотности и т.д. Также я могу использовать библиотеки Python, такие как Matplotlib, Seaborn и Plotly, для создания более сложных и интерактивных визуализаций.\n",
      "\n",
      "(Translation: I use various approaches for data visualization depending on the specific task and dataset. The most commonly used methods include histograms, scatter plots, dependency graphs, dendrograms, density maps, etc. I can also use Python libraries such as Matplotlib, Seaborn, and Plotly to create more complex and interactive visualizations.)\n",
      "Reference Answer: Для визуализации данных используются различные подходы, включая гистограммы, диаграммы рассеяния, тепловые карты и boxplot. Эти визуализации помогают выявить тенденции, аномалии и зависимости в данных, а также объяснить результаты анализа и моделей машинного обучения.\n",
      "Cosine Similarity: 0.9675973653793335\n",
      "BLEU Score: 9.532271762555308e-79\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d01aa845d82c4deebb97d89f72953360",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da40e26b446d4a19b8dbf0b35f162e39",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question ID: 42\n",
      "Generated Answer: Бутстрепинг и кросс-валидация - это две разные техники, используемые для оценки качества моделей машинного обучения.\n",
      "\n",
      "Бутстрепинг (Bootstrapping) - это метод, при котором создаются несколько моделей путем выборки данных с возвратом. Это означает, что при каждой итерации выборки некоторые наблюдения могут быть выбраны несколько раз, а другие вообще не будут выбраны. Затем каждая модель обучается на этих выборках и используется для предсказания на тестовой выборке. Результаты всех моделей объединяются для получения окончательного предсказания.\n",
      "\n",
      "Кросс-валидация (Cross-validation) - это метод, при котором данные разделяются на несколько подмножеств, обычно называемых \"фолдами\". Затем модель обучается на одном или нескольких фолдах и используется для предсказания на остальных фолдах. Этот процесс повторяется несколько раз, каждый раз используя разные фолды для обучения и тестирования. Результаты всех итераций объединяются для получения окончательного предсказания.\n",
      "\n",
      "Основное различие между бутстрепингом и кросс-валидацией заключается в том, что бутстрепинг использует выборку с возвратом, в то время как кросс-валидация использует разделение данных на фолды без возврата. Кроме того, бутстрепинг обычно используется для оценки точности модели, а кросс-валидация - для выбора параметров модели и оценки ее общей способности к генерализации.\n",
      "Reference Answer: Бутстрепинг - это метод оценки статистической точности, который заключается в многократном выборке с заменой из исходного набора данных и построении оценок на основе этих выборок. Кросс-валидация - это метод оценки модели, при котором данные делятся на несколько подвыборок, модель обучается на одной подвыборке и проверяется на другой.\n",
      "Cosine Similarity: 0.9041194319725037\n",
      "BLEU Score: 1.156321207604462e-78\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "540411d9d1e6478d9bdea277ce26a09d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "594e8a99723543d6a078a62ac5227691",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question ID: 43\n",
      "Generated Answer: t-SNE (t-Distributed Stochastic Neighbor Embedding) - это алгоритм визуализации высокоразмерных данных, который позволяет представлять их в низкоразмерном пространстве (например, в двумерном или трёхмерном). Он используется для того, чтобы обнаруживать и представлять структуры и закономерности в данных, которые невозможно увидеть при простойprojекции высокоразмерных данных на низкоразмерное пространство. Алгоритм t-SNE основан на идее сохранения локальных отношений между точками в высокоразмерном пространстве при их переходе в низкоразмерное пространство. Благодаря этому, он может эффективно отделять разные кластеры данных и обнаруживать нелинейные структуры. Например, t-SNE часто используется для визуализации результатов обработки естественного языка, таких как вложенные представления слов или документов.\n",
      "\n",
      "Примечание: знания об алгоритме t-SNE могут быть полезны при подготовке к собеседованию на должность машинного обучения. Возможно, вы будете спрашивать о том, как использовать t-SNE для анализа данных, или как интерпретировать результаты визуализации, полученные с помощью этого алгоритма.\n",
      "Reference Answer: t-SNE (t-Distributed Stochastic Neighbor Embedding) - это метод уменьшения размерности, который используется для визуализации многомерных данных в двумерном или трехмерном пространстве. Он сохраняет локальные структуры данных, что позволяет лучше понимать взаимосвязи между объектами.\n",
      "Cosine Similarity: 0.9892662167549133\n",
      "BLEU Score: 0.0657865257842591\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "167e730cd32f4f92b3ccf9a3b6c4ec5c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7ece55f55b24316b6a78149cacc8786",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question ID: 44\n",
      "Generated Answer: В области обработки естественного языка решаются различные типы задач. Некоторые из них включают:\n",
      "\n",
      "1. Разрешение кореференции (определение, когда несколько упоминаний в тексте относятся к одному и тому же предмету)\n",
      "2. Назначение именованных сущностей (различение упоминаний лиц, организаций, локаций и т.д.)\n",
      "3. Обработка поисковых запросов (понимание намерений пользователя и предоставление соответствующих результатов)\n",
      "4. Машинный перевод (перевод текста с одного языка на другой)\n",
      "5. Анализ настроений (определение эмоционального тона текста)\n",
      "6. Понимание речи (преобразование речи в текст)\n",
      "7. Генерация текста (создание автоматически сгенерированного текста, например, ответов на вопросы или суммарных текстов)\n",
      "8. Классификация текста (отнесение текста к определенной категории или категориям)\n",
      "9. Извлечение информации (выделение важной информации из текста)\n",
      "10. Оптимизация контента (улучшение контента для удовлетворения поисковых запросов и увеличения трафика)\n",
      "\n",
      "(Note: This information is based on general knowledge and not specific citations from the provided knowledge base.)\n",
      "Reference Answer: С помощью NLP (обработка естественного языка) решаются такие задачи, как классификация текстов, анализ тональности, извлечение информации, машинный перевод, генерация текста и диалоговые системы. Эти задачи помогают анализировать и обрабатывать большие объемы текстовых данных.\n",
      "Cosine Similarity: 0.9194413423538208\n",
      "BLEU Score: 7.977486860467955e-232\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a19097957be04c8eae8636d7432a08e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91a7c3bffad1409cbb0151180dc7c537",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question ID: 45\n",
      "Generated Answer: Токенизация в обработке естественного языка (NLP) – это процесс разбиения текста на более мелкие компоненты, известные как токены. Это может быть слов, словосочетаний, символов или даже звуков. Токенизация является важным шагом в NLP, поскольку позволяет машине легко анализировать и интерпретировать текст. Она используется во многих приложениях, таких как поиск информации, автоматическая классификация текста и перевод языков. В некоторых случаях токенизация может быть выполнена простой разбивкой текста по пробелам, но в более сложных случаях может потребоваться использовать более продвинутые алгоритмы, которые могут учесть грамматику и синтаксис текста.\n",
      "Reference Answer: Токенизация в NLP - это процесс разбиения текста на более мелкие элементы, такие как слова или символы. Эти элементы, называемые токенами, используются в дальнейшей обработке и анализе текста.\n",
      "Cosine Similarity: 0.9624428153038025\n",
      "BLEU Score: 0.08011911341833446\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d184ae82d92a45b4834c051b656ac8af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4f075ecb7474e4493523fbc3e5dc4c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question ID: 46\n",
      "Generated Answer: Метод TF-IDF (Term Frequency-Inverse Document Frequency) является алгоритмом, используемым для определения важности термина в конкретном документе в коллекции документов или корпусе. Он состоит из двух частей: частоты термина (TF) и обратной частоты документа (IDF).\n",
      "\n",
      "Частота термина (TF) отражает, насколько часто термин встречается в одном документе. Обычно это представлено в виде числа или в виде отношения числа вхождений термина к общему числу слов в документе.\n",
      "\n",
      "Обратная частота документа (IDF) является мерой важности термина во всем корпусе документов. Он определяется как логарифм отношения общего числа документов к числу документов, в которых встречается данный термин. Это показывает, насколько редким является термин во всем корпусе.\n",
      "\n",
      "TF-IDF представляет собой произведение TF и IDF, которое дает меру важности термина в конкретном документе относительно всего корпуса. Чем выше TF-IDF, тем более важным является термин. Этот метод часто используется в обработке естественного языка, например, для поиска информации и классификации текстов.\n",
      "\n",
      "Подробнее о TF-IDF можно прочитать в разделе \"2 Пробирный гвоздь\" в книге \"Машинное обучение и глубокое обучение на примерах\", в главе \"II Предварительная подготовка данных и их визуализация\", разделе \"3.2 Поиск по тексту\".\n",
      "\n",
      "Нота: В данном случае я не нашёл информацию о TF-IDF в предоставленной базе знаний, поэтому я использовал дополнительные источники, чтобы ответить на ваш вопрос.\n",
      "Reference Answer: Метод TF-IDF (Term Frequency-Inverse Document Frequency) измеряет важность термина в документе относительно всего корпуса документов. Он состоит из двух компонентов: частоты термина (TF), которая измеряет, как часто термин встречается в документе, и обратной частоты документа (IDF), которая уменьшает вес часто встречающихся терминов в корпусе. Этот метод используется для преобразования текста в числовые векторы для анализа.\n",
      "Cosine Similarity: 0.9873765110969543\n",
      "BLEU Score: 0.07475822253163363\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71779339d7514a8ea81d385fd83fe35a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce24e0c4ec7c43aea9b46319fe0e24f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question ID: 47\n",
      "Generated Answer: Word2Vec - это алгоритм обработки естественного языка, разработанный командой исследователей Google в 2013 году. Он используется для создания векторных представлений слов на основе их контекста в тексте. Word2Vec строит модель, учитывающую семантические и грамматические связи между словами, что позволяет компьютеру понимать смысл и значение слов. Алгоритм Word2Vec может быть использован для различных приложений, таких как анализ текстов, классификация документов, рекомендательные системы и машинный перевод.\n",
      "\n",
      "Word2Vec работает по следующему принципу: сначала он проходит через большой корпус текстов и строит словарь всех встречающихся слов. Затем для каждого слова он определяет контекст - соседние слова, встречающиеся в определенном окне вокруг него. На основе контекста слова Word2Vec создает векторное представление слова в многомерном пространстве. Размерность этого пространства выбирается заранее и обычно составляет несколько сотен или тысяч измерений. Векторное представление слова является его \"смыслом\" в данном пространстве, и оно может быть использовано для различных задач, таких как поиск синонимов, определение отношений между словами и кластеризация слов по смыслу.\n",
      "\n",
      "В качестве примера использования Word2Vec можно привести следующий код на языке Python:\n",
      "```\n",
      "from gensim.models import Word2Vec\n",
      "\n",
      "# Загружаем текстовый корпус\n",
      "texts = [['apple', 'banana', 'cherry'], ['dog', 'cat', 'mouse'], ['Paris', 'London', 'New York']]\n",
      "\n",
      "# Создаем модель Word2Vec\n",
      "model = Word2Vec(texts, size=10, window=5, min_count=1)\n",
      "\n",
      "# Получаем векторное представление слова \"apple\"\n",
      "vector = model.wv['apple']\n",
      "\n",
      "# Находим ближайшие слова к \"apple\" по векторному представлению\n",
      "similar_words = model.wv.most_similar('apple')\n",
      "```\n",
      "В этом примере мы создаем модель Word2Vec на основе текстового корпуса, состоящего из трех предложений. Размерность векторного пространства устанавливается в 10 измерений, окно контекста - в 5 слов, а минимальное количество вхождений слова в корпусе - в 1. Затем мы получаем векторное представление слова \"apple\" и находим слова, близкие к нему по векторному представлению.\n",
      "Reference Answer: Word2Vec - это метод представления слов в виде векторов плотности, который учитывает контекст слов в тексте. Он используется для построения моделей, способных понимать семантические отношения между словами и улучшать качество задач обработки естественного языка, таких как классификация текстов и машинный перевод.\n",
      "Cosine Similarity: 0.9772846698760986\n",
      "BLEU Score: 1.1835317098563934e-78\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "829584cfcd754b30993d362d3f651e7a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2987472c186c4279a56fc821f6f6307b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question ID: 48\n",
      "Generated Answer: Для оценки качества классификатора в задаче NLP существует несколько метрик, таких как:\n",
      "\n",
      "1. Точность (Accuracy): соотношение правильно классифицированных экземпляров к общему числу экземпляров.\n",
      "\n",
      "2. Точность для каждого класса (Precision): соотношение правильно классифицированных экземпляров для данного класса к общему числу экземпляров, классифицированных как данный класс.\n",
      "\n",
      "3. Заброс (Recall): соотношение правильно классифицированных экземпляров для данного класса к общему числу экземпляров данного класса.\n",
      "\n",
      "4. F1-мера (F1-score): среднее гармоническое точности и заброса.\n",
      "\n",
      "5. Матрица ошибок (Confusion matrix): таблица, показывающая число правильных и неправильных классификаций для каждого класса.\n",
      "\n",
      "6. ROC-кривая (Receiver Operating Characteristic curve): график, показывающий зависимость точности от заброса для различных пороговых значений классификации.\n",
      "\n",
      "7. AUC (Area Under Curve): площадь под ROC-кривой, которая показывает общую эффективность классификатора.\n",
      "\n",
      "Выбор метрики зависит от конкретной задачи и требований к классификатору. Например, если ложные положительные классификации являются более критичными, чем ложные отрицательные, то следует использовать метрику, которая лучше отражает это, например, заброс или F1-меру.\n",
      "Reference Answer: Качество классификатора в задаче NLP оценивается с помощью метрик, таких как точность (accuracy), точность (precision), полнота (recall), F-мера и AUC-ROC. Эти метрики позволяют оценить, насколько хорошо модель классифицирует текстовые данные.\n",
      "Cosine Similarity: 0.9371957778930664\n",
      "BLEU Score: 0.020159431335582723\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17d6f8d760b74fb5bc0d0c7ade496e9c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89a2ff0f64bd4080b7dfe6bfca52a73f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question ID: 49\n",
      "Generated Answer: Энтропия в контексте информационной теории - это мера неопределенности или случайности в данных. Она измеряется в битах и определяется как ожидаемое значение логарифмической функции вероятности символов в сообщении. Энтропия является важным понятием в информационной теории, поскольку она позволяет определить максимальную эффективность передачи данных по каналу связи.\n",
      "Reference Answer: Энтропия в контексте теории информации - это мера неопределенности или случайности в системе. Она используется для оценки количества информации, необходимой для описания состояния системы, и применяется в задачах, таких как построение решающих деревьев и выбор признаков.\n",
      "Cosine Similarity: 0.9564481973648071\n",
      "BLEU Score: 0.1646740825602667\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f72d87c443db4704b4b223d27d2a107f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46b90c4b947b4762917fa46142bbd28d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question ID: 50\n",
      "Generated Answer: Для анализа временных рядов можно использовать различные методы, такие как декомпозиция исходного ряда на три компонента: тренд, сезонность и шум. Тренд отражает общие тенденции в данных, сезонность отражает повторяющиеся циклы в данных, а шум представляет собой случайные отклонения от тренда и сезонности. После декомпозиции временного ряда на эти компоненты можно применять различные статистические методы для прогнозирования будущих значений. Кроме того, можно использовать методы машинного обучения, такие как ARIMA или LSTM, для прогнозирования временных рядов.\n",
      "\n",
      "Translation:\n",
      "\n",
      "To analyze time series, various methods can be used, such as decomposing the original series into three components: trend, seasonality, and noise. The trend reflects the overall trends in the data, seasonality reflects repeating cycles in the data, and noise represents random deviations from the trend and seasonality. After decomposing a time series into these components, various statistical methods can be applied to predict future values. In addition, machine learning methods such as ARIMA or LSTM can be used to forecast time series.\n",
      "Reference Answer: Для анализа временных рядов используются методы, такие как скользящее среднее, автокорреляция, сезонная декомпозиция и модели ARIMA. Эти методы позволяют выявлять тенденции, сезонные колебания и зависимости во временных рядах.\n",
      "Cosine Similarity: 0.9624755382537842\n",
      "BLEU Score: 0.02340533530984286\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c25af4ed50734a33b383492f782a83db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c3c19c7855d4569b433a5479265db65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question ID: 51\n",
      "Generated Answer: Скользящее среднее (moving average) - это метод сглаживания временных рядов, состоящий в вычислении среднего значения для определенного числа наблюдений, движущегося по времени. Оно используется для выделения основной тенденции временного ряда и отфильтровки шума.\n",
      "\n",
      "Например, если у вас есть временной ряд из цен акций за каждый день, то вы можете использовать скользящее среднее, чтобы увидеть общее направление цены акций на протяжении времени. Это может помочь в прогнозировании будущих цен акций или в принятии решений о покупке или продаже акций.\n",
      "\n",
      "Скользящее среднее может быть вычислено для различных периодов времени, таких как 7, 14 или 30 дней. Чем длиннее период времени, тем меньше реагирует скользящее среднее на короткосрочные колебания цен.\n",
      "\n",
      "В машинном обучении скользящее среднее может использоваться для нормализации временных рядов и уменьшения влияния шума на модель. Оно также может быть использовано для обнаружения аномалий в данных, например, для определения аномальных транзакций в финансовых системах.\n",
      "Reference Answer: Скользящее среднее - это метод сглаживания временного ряда путем усреднения значений за определенный период. Оно используется для устранения шума и выявления долгосрочных тенденций в данных.\n",
      "Cosine Similarity: 0.6721351742744446\n",
      "BLEU Score: 0.029985760313443667\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c48a1d9704fe4dfe96d3bbcc3aa06fec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c822ab3118424f6f9a8eb7fce362e300",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question ID: 52\n",
      "Generated Answer: ARIMA-модель - это авторегрессионная интегрированная движущаяся средняя модель, которая используется для прогнозирования временных рядов. Она широко применяется в экономике, финансах, маркетинге и других областях, где необходимо проанализировать и предсказать тенденции временных рядов. ARIMA-модель состоит из трех основных компонентов: авторегрессионного (AR), интегрированного (I) и движущейся средней (MA) частей. Эта модель может быть эффективной для прогнозирования нестационарных временных рядов, которые могут иметь тренды или сезонность. ARIMA-модель может быть использована для короткосрочного и среднесрочного прогнозирования. Более подробную информацию о ARIMA-модели и ее применении можно найти в книгах и онлайн-ресурсах, посвященных временным рядам и прогнозированию.\n",
      "Reference Answer: ARIMA-модель (Autoregressive Integrated Moving Average) используется для анализа и прогнозирования временных рядов. Она состоит из трех компонентов: авторегрессии (AR), интегрирования (I) и скользящего среднего (MA), которые позволяют моделировать различные типы временных зависимостей.\n",
      "Cosine Similarity: 0.6498816013336182\n",
      "BLEU Score: 0.04857109661636975\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48f39c919c13402cb65f9469fc475612",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85c447e0801346ed95a4e937d7dd4183",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question ID: 53\n",
      "Generated Answer: К сожалению, в вашем вопросе нет конкретики, какие именно большие данные имеются в виду и в каком контексте. Однако, я могу дать общий ответ на этот вопрос.\n",
      "\n",
      "Когда речь идет о работе с большими данными, важными факторами являются эффективность и масштабируемость. Одним из подходов к работе с большими данными является использование распределенных систем обработки данных, таких как Apache Hadoop и Apache Spark. Эти системы позволяют параллельно обрабатывать большие объемы данных на нескольких узлах, что существенно ускоряет процесс.\n",
      "\n",
      "Другим подходом является использование алгоритмов машинного обучения, которые способны эффективно работать с большими объемами данных. Например, алгоритмы градиентного бустинга, такие как XGBoost и LightGBM, способны обрабатывать большие объемы данных и достигать высокой точности модели.\n",
      "\n",
      "Также при работе с большими данными важно учитывать вопросы безопасности и конфиденциальности данных.\n",
      "\n",
      "Надеюсь, это помогло вам получить общее представление о работе с большими данными. Если у вас есть более конкретные вопросы, не стесняйтесь спрашивать.\n",
      "Reference Answer: Работа с большими данными включает использование распределенных систем хранения и обработки данных, таких как Hadoop и Spark. Эти системы позволяют эффективно обрабатывать большие объемы данных, обеспечивая масштабируемость и высокую производительность.\n",
      "Cosine Similarity: 0.8916705846786499\n",
      "BLEU Score: 0.055051438333867615\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "addd4bbe51ba4f12830da9db7532b9e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63d1c0dc970b49dcabd4e62500b752e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question ID: 54\n",
      "Generated Answer: Я знаю несколько инструментов для работы с большими данными, таких как Apache Hadoop, Apache Spark, Apache Flink и Apache Hive. Hadoop используется для хранения и обработки больших объемов неструктурированных данных, Spark специально разработан для обработки данных в реальном времени, Flink используется для обработки потоковых данных, а Hive является системой управления базами данных, работающей поверх Hadoop для анализа больших объемов данных.\n",
      "\n",
      "Translation:\n",
      "I know several tools for working with big data, such as Apache Hadoop, Apache Spark, Apache Flink, and Apache Hive. Hadoop is used for storing and processing large amounts of unstructured data, Spark is specifically designed for real-time data processing, Flink is used for processing stream data, and Hive is a database management system that runs on top of Hadoop for analyzing large volumes of data.\n",
      "Reference Answer: Для работы с большими данными используются инструменты, такие как Apache Hadoop, Apache Spark, Apache Flink, и базы данных, такие как Apache Cassandra, MongoDB и HDFS. Эти инструменты обеспечивают распределенную обработку и хранение данных.\n",
      "Cosine Similarity: 0.9062728881835938\n",
      "BLEU Score: 0.058374292627490366\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3130e4ce3356453789b8b53534e79204",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9660e99688a4bcda290919fc0b12fd4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question ID: 55\n",
      "Generated Answer: Hadoop и Spark - это две популярные платформы для обработки больших данных. Главное различие между ними заключается в их архитектуре и подходе к обработке данных.\n",
      "\n",
      "Hadoop использует модель MapReduce для обработки больших объемов данных. MapReduce разбивает задачу на две части: Map и Reduce. Map-функция отвечает за обработку входных данных и создание ключей/значений, а Reduce-функция объединяет все значения для каждого ключа, выполняя определенную операцию над ними. Hadoop хранит данные в HDFS (Hadoop Distributed File System), распределенной файловой системе, которая обеспечивает отказоустойчивость и масштабируемость.\n",
      "\n",
      "Spark, с другой стороны, основан на концепции RDD (Resilient Distributed Datasets). RDD представляет собой неизменяемую коллекцию данных, разделенную на партии и распределенную между узлами в кластере. Spark может выполнять различные операции над RDD, такие как преобразования, фильтрация и агрегация. Spark также поддерживает возможность обработки данных в реальном времени и машинного обучения. Spark использует собственную память для хранения intermediate данных, что позволяет ему работать быстрее, чем Hadoop.\n",
      "\n",
      "В целом, можно сказать, что Hadoop предназначен для обработки больших объемов данных в батчевом режиме, тогда как Spark более универсален и может работать как в батчевом режиме, так и в режиме реального времени.\n",
      "Reference Answer: Hadoop и Spark - это платформы для обработки больших данных. Hadoop использует модель MapReduce для распределенной обработки данных, а Spark предлагает более быструю и гибкую обработку данных в памяти, что делает его подходящим для сложных аналитических задач.\n",
      "Cosine Similarity: 0.9786785840988159\n",
      "BLEU Score: 0.071054474463768\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b506ab04c1044508bb0ed523b7ae813a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b271d12ba114a28af660299dd19bd77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question ID: 56\n",
      "Generated Answer: При проектировании архитектуры ETL-процесса, следует учесть несколько важных аспектов:\n",
      "\n",
      "1. Источники данных: определите все источники данных, которые необходимо интегрировать в ETL-процесс. Это могут быть реляционные базы данных, файлы CSV, API и т.д.\n",
      "2. Преобразование данных: определите необходимые операции преобразования данных, такие как очистка, форматирование, агрегация и нормализация.\n",
      "3. Загрузка данных: определите целевые системы хранения данных, такие как реляционные базы данных, хранилища данных NoSQL, дата-сленты или дата-уорехаусы.\n",
      "4. Выполняемость: определите требования к производительности ETL-процесса, включая частоту загрузки данных, объемы данных и время выполнения.\n",
      "5. Мониторинг и обработка ошибок: определите механизмы мониторинга и обработки ошибок ETL-процесса, включая системы оповещения и журналы ошибок.\n",
      "6. Масштабируемость: определите возможности масштабирования ETL-процесса для обработки больших объемов данных и увеличения числа источников данных.\n",
      "7. Безопасность: определите механизмы защиты данных, включая шифрование, авторизацию и аутентификацию.\n",
      "\n",
      "Архитектура ETL-процесса может включать в себя несколько компонентов, таких как ETL-инструменты, сервера баз данных, хранилища данных и средства мониторинга. При проектировании архитектуры следует учитывать требования к производительности, масштабируемости, безопасности и обработке ошибок.\n",
      "Reference Answer: Архитектура ETL (Extract, Transform, Load) процесса включает извлечение данных из источников, их преобразование в требуемый формат и загрузку в целевую систему. Она проектируется с учетом требований к качеству данных, производительности и масштабируемости.\n",
      "Cosine Similarity: 0.6850461959838867\n",
      "BLEU Score: 8.886273379203676e-232\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48b4ba51ae51464fb4111cf17cca41f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8eec8116b804526a9afebe0e5c82e1d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question ID: 57\n",
      "Generated Answer: Потоковая обработка данных (stream processing) — это метод обработки больших объемов данных, при котором информация обрабатывается по мере ее поступления, без необходимости хранить все данные в памяти или на диске. Это позволяет обрабатывать данные в реальном времени или близком к реальному времени, что критично для некоторых приложений, таких как мониторинг сети, обработка транзакций в финансовой сфере или обработка потоковых медиа-данных. Потоковая обработка данных может быть реализована с использованием различных технологий, таких как Apache Kafka, Apache Flink, Apache Spark Streaming и др.\n",
      "Reference Answer: Потоковая обработка данных - это процесс обработки данных в реальном времени по мере их поступления. Она используется для задач, где важна оперативная обработка данных, таких как мониторинг, анализ событий и обработка потоков данных.\n",
      "Cosine Similarity: 0.7040963172912598\n",
      "BLEU Score: 1.7504472241389895e-78\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94095c3f83ea487b9e198953c184a358",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6955a1bafcdd4f3280a6329253a16f38",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question ID: 58\n",
      "Generated Answer: Я не нахожу информацию о использовании облачных технологий в анализе данных в базе знаний. Однако, я могу сказать, что облачные технологии широко используются в анализе данных для хранения и обработки больших объемов данных. Они предоставляют эластичность, масштабируемость и безопасность для аналитических работ. Кроме того, облачные технологии позволяют аналитикам использовать мощные инструменты машинного обучения и искусственного интеллекта для обработки данных.\n",
      "\n",
      "Translation:\n",
      "I cannot find information about the use of cloud technologies in data analysis in the knowledge base. However, I can say that cloud technologies are widely used in data analysis to store and process large volumes of data. They provide elasticity, scalability, and security for analytical work. In addition, cloud technologies allow analysts to use powerful tools of machine learning and artificial intelligence for data processing.\n",
      "Reference Answer: Облачные технологии используются для хранения, обработки и анализа данных, предоставляя гибкость, масштабируемость и доступность ресурсов. Популярные облачные платформы включают Amazon Web Services (AWS), Microsoft Azure и Google Cloud Platform.\n",
      "Cosine Similarity: 0.9181514382362366\n",
      "BLEU Score: 2.30628356173731e-155\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73fb804aab0a496a9e4db2317852ccce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44d22c5d796c4dd5a66122c9adecc5dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question ID: 59\n",
      "Generated Answer: Data lake - это центральное хранилище данных в их исходной форме, которое может хранить большие объемы неструктурированных, полуструктурированных и структурированных данных. Он используется для хранения данных из различных источников, таких как социальные сети, веб-сайты, устройства Интернета вещей (IoT) и другие.\n",
      "\n",
      "Data lake необходим для поддержки современных аналитических операций, таких как машинное обучение, искусственный интеллект и биг-дата-аналитика. Он позволяет компаниям хранить и анализировать большие объемы данных в реальном времени, что помогает им принимать более информированные решения и обнаруживать новые возможности.\n",
      "\n",
      "Кроме того, data lake обеспечивает более гибкую архитектуру хранения данных, чем традиционные системы хранения данных, такие как реляционные базы данных. Он позволяет компаниям легко интегрировать данные из разных источников, независимо от их формата, и легко добавлять новые источники данных в будущем.\n",
      "\n",
      "В целом, data lake является ключевым компонентом современной аналитической инфраструктуры и играет важную роль в поддержке цифровой трансформации компаний.\n",
      "Reference Answer: Data lake - это хранилище, которое позволяет хранить большие объемы необработанных данных в их исходном формате. Оно необходимо для интеграции и анализа различных типов данных, таких как структурированные, полуструктурированные и неструктурированные данные.\n",
      "Cosine Similarity: 0.9837849140167236\n",
      "BLEU Score: 0.0361149946010914\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "775d5082cafd41ec8c015c57e7be91eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27c3be1779224bb5803268dea5fe4a29",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question ID: 60\n",
      "Generated Answer: Я могу помочь вам подготовиться к интервью на позицию машинного инженера, отвечая на вопросы о NoSQL базах данных. Но ведь вы спрашиваете, как я работаю с NoSQL базами данных. Как AI-ассистент, у меня нет возможности напрямую работать с базами данных или выполнять код. Моя основная задача - предоставлять информацию и советы на основе запрошенной тематики, в данном случае - NoSQL баз данных.\n",
      "\n",
      "Что касается работы с NoSQL базами данных, то их основное отличие от реляционных заключается в отказе от табличной модели и поддержке неструктурированных данных. Существует несколько категорий NoSQL баз данных, таких как документо-ориентированные, ключ-значение, ширококолоночные и графовые базы данных, каждая из которых имеет свои преимущества и особенности. При работе с ними важно понимать их функциональность и использовать те базы данных, которые лучше всего подходят для конкретной задачи.\n",
      "\n",
      "Например, MongoDB - это документо-ориентированная NoSQL база данных, которая использует JSON-подобные документы для хранения данных. Она позволяет легко масштабировать систему, добавляя новые узлы, и обеспечивает высокую производительность за счет отказа от некоторых функций реляционных баз данных, таких как поддержка ACID-транзакций и схемы данных.\n",
      "\n",
      "Cassandra - это ширококолоночная NoSQL база данных, которая оптимизирована для работы с большими объемами данных и обеспечивает высокую доступность и масштабируемость. Она использует архитектуру без единого точка отказа и позволяет легко добавлять новые узлы в систему.\n",
      "\n",
      "Redis - это база данных ключ-значение, которая оптимизирована для работы с операциями в памяти и обеспечивает очень высокую скорость доступа к данным. Она также поддерживает различные типы данных, такие как строки, хеши, списки и множества, и позволяет выполнять операции над ними прямо на сервере.\n",
      "\n",
      "HBase - это распределенная база данных, которая построена поверх Hadoop и оптимизирована для работы с большими объемами неструктурированных данных. Она использует архитектуру с колонками и позволяет выполнять операции поиска и сортировки по любой колонке.\n",
      "\n",
      "Надеюсь, эта информация поможет вам лучше понять NoSQL базы данных и их особенности. Если у вас есть конкретные вопросы или задачи, я готов помочь вам их решить.\n",
      "Reference Answer: Работа с NoSQL базами данных, такими как MongoDB, Cassandra и Redis, включает хранение и обработку больших объемов данных с гибкой схемой. Эти базы данных обеспечивают высокую производительность и масштабируемость для работы с разнообразными типами данных.\n",
      "Cosine Similarity: 0.8152387738227844\n",
      "BLEU Score: 0.014394097325756982\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3d3976e944e4f11a269521048694f47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af5c14f702de4721a281b232f9480e0f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question ID: 61\n",
      "Generated Answer: Графовые базы данных - это тип баз данных, которые хранят и обрабатывают данные в виде графа, где каждая запись представляет собой узел, а отношения между записями представлены ребрами. Они используются в различных приложениях, таких как социальные сети, recommendation engines, fraud detection и других областях, где требуется анализ сложных связей между объектами. Например, в социальных сетях графовые базы данных могут быть использованы для хранения информации о пользователях и их взаимосвязях, а также для анализа сетей и обнаружения паттернов. В recommendation engines они могут быть использованы для хранения информации о товарах и их связях, а также для генерации рекомендаций на основе этих связей. В области fraud detection графовые базы данных могут быть использованы для обнаружения мошеннических схем путем анализа сложных связей между субъектами.\n",
      "Reference Answer: Графовые базы данных, такие как Neo4j и Amazon Neptune, используются для хранения и обработки данных, представленных в виде графов. Они применяются в задачах, где важны связи между объектами, таких как социальные сети, рекомендации и анализ связей.\n",
      "Cosine Similarity: 0.624115526676178\n",
      "BLEU Score: 0.03334273639438118\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17c1330103884f3f94608240809d0fbd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3e3361027db4c6f9f3f33bf225608aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question ID: 62\n",
      "Generated Answer: Мне недоступна информация о работе алгоритма PageRank в моей базе знаний. Однако я могу предоставить общий обзор алгоритма в соответствии с общедоступными источниками.\n",
      "\n",
      "PageRank - это алгоритм ранжирования веб-страниц, разработанный компанией Google. Алгоритм определяет относительную важность веб-страницы, основываясь на количестве и качестве ссылок, указывающих на нее. Он использует математическую модель для представления Веб-графа, где каждая веб-страница представлена узлом, а ссылки между ними - ребрами.\n",
      "\n",
      "Алгоритм PageRank работает следующим образом:\n",
      "\n",
      "1. Начальные значения: Каждой веб-странице присваивается начальное значение PageRank. Обычно все страницы имеют одинаковые начальные значения.\n",
      "2. Распределение весов: Для каждой веб-страницы рассчитывается вес, который будет передан ссылающимся страницам. Этот вес рассчитывается как отношение количества исходящих ссылок на общее количество ссылок на странице.\n",
      "3. Перераспределение весов: Веса, рассчитанные на предыдущем шаге, перераспределяются между ссылаемыми страницами. Это делается путем умножения веса исходной страницы на отношение количества ссылок на нее к общему количеству исходящих ссылок с исходной страницы.\n",
      "4. Нормализация: Значения PageRank нормализуются, чтобы их сумма была равна единице. Это гарантирует, что PageRank представляет собой вероятностную распределенную величину.\n",
      "5. Итеративное повторение: Шаги 2-4 повторяются до тех пор, пока значения PageRank не станут стабильными или не будет достигнуто заданное количество итераций.\n",
      "\n",
      "PageRank используется для ранжирования результатов поиска в Google, чтобы обеспечить наиболее актуальные и полезные результаты для пользователей.\n",
      "Reference Answer: Алгоритм PageRank используется для оценки важности веб-страниц на основе их ссылочной структуры. Он работает путем итеративного обновления значений PageRank для каждой страницы на основе ссылок, полученных от других страниц.\n",
      "Cosine Similarity: 0.93668532371521\n",
      "BLEU Score: 6.320544986279898e-79\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9214a252b6764900a890cb8975b89112",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3e1e37750014b12b127b6b65ad6cd3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question ID: 63\n",
      "Generated Answer: BigQuery - это сервис Google Cloud Platform для обработки больших данных и выполнения аналитики. Он позволяет выполнять запросы к большим данным с использованием языка SQL и получать результаты в реальном времени. BigQuery может обрабатывать терабайты данных за секунды и является хорошим выбором для выполнения сложных запросов к большим данным. Он также интегрирован с другими сервисами Google Cloud Platform, такими как Google Cloud Storage и Google Drive, что позволяет легко загружать данные и получать к ним доступ.\n",
      "\n",
      "BigQuery используется для различных целей, таких как выполнение ад-хок запросов к данным, создание отчетов и дашбордов, выполнение машинного обучения и другие задачи аналитики. Он также может использоваться для выполнения ETL-процессов, таких как экспорт данных из одного источника в другой или преобразование данных для последующего анализа. BigQuery также поддерживает возможность создавать и управлять виртуальными схемами, что позволяет создавать единую схему для нескольких источников данных и получать к ним единый доступ.\n",
      "\n",
      "В целом, BigQuery является мощным и гибким сервисом для обработки больших данных, который может использоваться для выполнения различных задач аналитики и обработки данных.\n",
      "Reference Answer: BigQuery - это облачный сервис для анализа больших данных, предоставляемый Google. Он используется для быстрого выполнения запросов на больших объемах данных и интеграции с другими инструментами для обработки и визуализации данных.\n",
      "Cosine Similarity: 0.6885114908218384\n",
      "BLEU Score: 9.154444189244545e-79\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "023c0be7aec242b98a266dcedcc73a46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34285046a7b24ed29d85aecb7f558da9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question ID: 64\n",
      "Generated Answer: Извините, но в вашем вопросе не упоминается ничего о машинном обучении или подготовке к собеседованию на позицию инженера по машинному обучению. Тем не менее, я могу попробовать ответить на ваш вопрос о том, как использовать инструменты бизнес-аналитики (BI).\n",
      "\n",
      "BI-инструменты используются для сбора, анализа и визуализации данных с целью обеспечить лучшее принятие решений в организациях. Вот несколько способов, как можно использовать эти инструменты:\n",
      "\n",
      "1. Создание отчетов и дашбордов: BI-инструменты позволяют создавать отчеты и дашборды, которые обеспечивают быстрый обзор ключевых показателей эффективности (KPI) и других важных данных.\n",
      "2. Анализ данных: BI-инструменты могут использоваться для проведения детального анализа данных, чтобы получить более глубокие эвристические знания и обнаружить закономерности.\n",
      "3. Прогнозирование: некоторые BI-инструменты включают функции прогнозирования, которые позволяют пользователям создавать прогнозы на основе исторических данных.\n",
      "4. Коллаборация: многие BI-инструменты включают функции коллаборации, которые позволяют пользователям совместно работать над анализом данных и обмениваться своими наблюдениями и идеями.\n",
      "5. Интеграция с другими системами: BI-инструменты могут интегрироваться с другими системами, такими как CRM или ERP, чтобы обеспечить единый источник истины для данных организации.\n",
      "\n",
      "Надеюсь, это поможет вам лучше понять, как можно использовать инструменты бизнес-аналитики.\n",
      "Reference Answer: Инструменты BI (бизнес-аналитики), такие как Tableau, Power BI и QlikView, используются для визуализации данных, создания отчетов и проведения анализа. Они помогают преобразовывать данные в понятные и полезные инсайты для бизнеса.\n",
      "Cosine Similarity: 0.7631889581680298\n",
      "BLEU Score: 2.4851553523457504e-155\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45b55da001ee4bfe91adaeb02448368b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47f21f0d42df4d169b2586271d425f1e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question ID: 65\n",
      "Generated Answer: Мы можем использовать различные методы машинного обучения для предсказания оттока клиентов, например:\n",
      "\n",
      "1. Регрессионные модели, такие как линейная регрессия, логистическая регрессия и случайные леса.\n",
      "2. Алгоритмы классификации, такие какSupport Vector Machines (SVM), K-nearest neighbors (KNN) и gradient boosting.\n",
      "3. Некоторые специализированные модели, такие как модели уelinga (churn model) и модели выживаемости (survival analysis model).\n",
      "\n",
      "Выбор метода зависит от конкретной ситуации и характеристик данных. Важно также провести подробный анализ данных и feature engineering, чтобы улучшить точность предсказаний.\n",
      "\n",
      "[Translation: We can use various machine learning methods to predict customer churn, such as:\n",
      "\n",
      "1. Regression models, such as linear regression, logistic regression, and random forests.\n",
      "2. Classification algorithms, such as Support Vector Machines (SVM), K-nearest neighbors (KNN), and gradient boosting.\n",
      "3. Some specialized models, such as churn models and survival analysis models.\n",
      "\n",
      "The choice of method depends on the specific situation and characteristics of the data. It is also important to conduct a thorough data analysis and feature engineering to improve prediction accuracy.]\n",
      "Reference Answer: Методы предсказания оттока клиентов включают анализ поведения клиентов, создание прогнозных моделей с использованием машинного обучения и использование метрик, таких как коэффициент оттока (churn rate) и жизненная ценность клиента (CLV).\n",
      "Cosine Similarity: 0.9749807119369507\n",
      "BLEU Score: 2.497758455744859e-155\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "209a8c058ba74aacb1b08bcb60c9845e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "507a7782660348bd990b2f48eba0f1e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question ID: 66\n",
      "Generated Answer: Модель Маркова - это математическая модель, которая описывает случайный процесс, в котором будущее состояние системы зависит только от текущего состояния, а не от предыдущих состояний. В других словах, это модель без памяти.\n",
      "\n",
      "Модель Маркова широко используется в различных областях, таких как финансы, экономика, лингвистика, компьютерные науки и другие. В частности, она применяется в задачах классификации, фильтрации, предсказания и распознавания речи. Например, в обработке естественного языка модель Маркова используется для построения моделей языка, которые могут генерировать или распознавать речь последовательностей символов или слов. В финансах модель Маркова используется для моделирования временных рядов, таких как курсы акций, чтобы предсказать их будущие значения.\n",
      "\n",
      "В компьютерных науках модель Маркова используется в алгоритме пакетной компрессии данных, алгоритме поиска по графу, алгоритме распознавания рукописного ввода и других алгоритмах.\n",
      "\n",
      "В целом, модель Маркова является важным инструментом в области машинного обучения и искусственного интеллекта.\n",
      "Reference Answer: Модель Маркова - это статистическая модель, описывающая вероятностные переходы между состояниями в системе. Она используется в задачах, таких как предсказание последовательностей, анализ временных рядов и моделирование систем с дискретными состояниями.\n",
      "Cosine Similarity: 0.9853280782699585\n",
      "BLEU Score: 0.024608663767121754\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "146d5e144e9945069e3123d409c7e5e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71ebb187028c4b72b3a3fb3b9675aff6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question ID: 67\n",
      "Generated Answer: Для обработки аномалий в данных существует несколько подходов. Мы можем использовать различные алгоритмы машинного обучения, такие как кластерный анализ, регрессию, классификацию, метод главных компонент и т.д., для обнаружения аномальных точек. Еще один подход заключается в использовании статистических методов, таких как метод трех сигм, для определения аномальных значений. Также мы можем использовать методы основанные на соседях, например алгоритм локальной плотности (LOF), для обнаружения аномалий. Важно отметить, что выбор метода зависит от конкретной задачи и характеристик данных.\n",
      "\n",
      "To process anomalies in data, several approaches can be used. We can use various machine learning algorithms, such as cluster analysis, regression, classification, principal component method, etc., to detect anomalous points. Another approach is to use statistical methods, such as the three sigma method, to determine anomalous values. In addition, we can use neighbor-based methods, such as the local density algorithm (LOF), to detect anomalies. It is important to note that the choice of method depends on the specific task and the characteristics of the data.\n",
      "Reference Answer: Для обработки аномалий в данных используются методы, такие как контрольные карты, методы кластеризации, алгоритмы машинного обучения и статистические тесты. Эти методы позволяют выявлять и анализировать необычные и непредсказуемые данные.\n",
      "Cosine Similarity: 0.9865726828575134\n",
      "BLEU Score: 0.028583862838738355\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c21a841f4da345b1aea3f144689b4939",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4b39393f4e946218f72737d9bdb5266",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question ID: 68\n",
      "Generated Answer: DBSCAN (Density-Based Spatial Clustering of Applications with Noise) - это алгоритм кластеризации, основанный на плотности. Он используется для выявления групп объектов с высокой плотностью, окруженных области с низкой плотностью.\n",
      "\n",
      "DBSCAN определяет кластеры следующим образом:\n",
      "\n",
      "1. Для каждого объекта в наборе данных считается число объектов, находящихся в пределах заданного радиуса ε (ε-соседство).\n",
      "2. Если число объектов в ε-соседстве объекта больше или равно заданному пороговому значению минимального количества объектов (minPts), то этот объект считается ядром кластера.\n",
      "3. Затем алгоритм находит все объекты, которые находятся в ε-соседстве ядра кластера, и добавляет их в кластер.\n",
      "4. Если у объекта есть ε-соседи, но их число меньше minPts, то этот объект считается шумом и не отнесен к кластеру.\n",
      "5. Алгоритм повторяет шаги 3 и 4 для всех объектов, пока не будут найдены все кластеры.\n",
      "\n",
      "DBSCAN имеет некоторые преимущества по сравнению с другими алгоритмами кластеризации, такими как K-means. Например, DBSCAN может найти кластеры произвольной формы, в то время как K-means требует, чтобы кластеры были сферическими и имели примерно одинаковый размер. Кроме того, DBSCAN не требует заранее известного числа кластеров, в отличие от K-means.\n",
      "\n",
      "However, DBSCAN may not perform well with large datasets, as the computation time and memory requirements increase rapidly with the size of the dataset. Additionally, the choice of ε and minPts can greatly affect the results of the clustering, and finding the optimal parameters can be a challenge.\n",
      "Reference Answer: Алгоритм DBSCAN (Density-Based Spatial Clustering of Applications with Noise) - это алгоритм кластеризации, который группирует объекты на основе плотности их распределения в пространстве. Он определяет кластеры как плотные области объектов, разделенные областями с низкой плотностью. DBSCAN не требует заранее задавать количество кластеров и может эффективно выявлять кластеры любой формы.\n",
      "Cosine Similarity: 0.9797060489654541\n",
      "BLEU Score: 0.07756419127793457\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ba20cca091c436d996f6cc7b9a8b604",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7d834386d9d4e0ca8185ef866109905",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question ID: 69\n",
      "Generated Answer: Метод k-средних (или k-means clustering) — это алгоритм кластеризации, используемый для разделения данных на группы (кластеры) на основе их сходства. Алгоритм работает следующим образом:\n",
      "\n",
      "1. Выбираются k начальных центроидов (точек, представляющих центры кластеров). Обычно эти точки выбираются случайным образом.\n",
      "2. Каждая точка данных отнесена к кластеру, центроид которого находится ближе всего к этой точке.\n",
      "3. Новые центроиды вычисляются как средние значения координат всех точек в кластере.\n",
      "4. Шаги 2 и 3 повторяются до тех пор, пока центроиды не меняются или не достигнуто максимальное количество итераций.\n",
      "\n",
      "Метод k-средних используется для разделения данных на группы без предварительного знания о классах. Он широко используется в машинном обучении, обработке изображений, биоинформатике и других областях.\n",
      "\n",
      "Однако, метод k-средних имеет ряд ограничений, таких как чувствительность к начальным условиям, неспособность обрабатывать неопределенные данные и плохая производительность на больших наборах данных. Для решения этих проблем были разработаны различные модификации и варианты алгоритма, такие как k-medians, k-medoids и др.\n",
      "Reference Answer: Метод k-средних - это алгоритм кластеризации, который разделяет данные на k кластеров, минимизируя сумму квадратов расстояний между объектами и центроидами кластеров. Центроиды и кластеры обновляются итеративно до сходимости алгоритма. Метод используется для анализа данных и сегментации.\n",
      "Cosine Similarity: 0.7378417253494263\n",
      "BLEU Score: 8.100210231534884e-79\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b38c5cdc17f488bb49d595c52dc76c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9d5c38193074bc7b0bbae0aaca82ba5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question ID: 70\n",
      "Generated Answer: Байесовская классификация - это метод машинного обучения, основанный на теореме Байеса и используемый для решения задач классификации. Он позволяет определить вероятность принадлежности объекта к определенному классу на основе известной вероятности появления этого класса и условной вероятности появления объекта, принадлежащего этому классу. Байесовская классификация широко используется в области искусственного интеллекта, например, в распознавании речи, обработке естественного языка, биоинформатике и других областях.\n",
      "Reference Answer: Байесовская классификация - это метод классификации, основанный на теореме Байеса, которая описывает вероятностные отношения между признаками и классами. Модели байесовской классификации, такие как наивный байесовский классификатор, используются для задач классификации текста, спама и анализа тональности.\n",
      "Cosine Similarity: 0.9902681112289429\n",
      "BLEU Score: 0.08375853894238805\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46903a90d9c749709d1d1c8fcede8f4e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2878d19f39b3400485a27179321b4dad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question ID: 71\n",
      "Generated Answer: Для проведения экспериментов с A/B тестированием следует выполнить следующие шаги:\n",
      "\n",
      "1. Определите цель и гипотезу: перед началом тестирования необходимо определить, что вы хотите проверить или оптимизировать. Например, гипотеза может звучать так: \"Увеличение размера кнопки приведет к увеличению конверсии\".\n",
      "2. Разделите пользователей на две группы: одна группа будет видить исходный вариант (контрольная группа), а другая группа будет видить измененный вариант (экспериментальная группа).\n",
      "3. Создайте измененный вариант: в зависимости от вашей гипотезы создайте измененную версию вашей страницы или функции.\n",
      "4. Проанализируйте данные: после того, как пользователи будут взаимодействовать с вашим продуктом, соберите и проанализируйте данные. Это поможет вам определить, влияет ли ваш измененный вариант на целевую метрику.\n",
      "5. Вывод и рекомендации: на основе анализа данных сделайте вывод о том, подтверждает ли ваша гипотеза или нет. Если гипотеза подтверждается, рекомендуется внедрить изменения. Если гипотеза не подтверждается, необходимо продолжить тестирование и исследование.\n",
      "\n",
      "Важно также учитывать размер выборки, время тестирования и статистическую значимость результатов.\n",
      "Reference Answer: Эксперименты с A/B тестированием включают разделение пользователей на две группы, A и B, где группа A получает текущую версию продукта, а группа B - измененную версию. Результаты эксперимента сравниваются для оценки влияния изменений на ключевые метрики, такие как конверсия или удержание пользователей.\n",
      "Cosine Similarity: 0.9375976920127869\n",
      "BLEU Score: 9.526647362834152e-79\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7992e9c905394e97bbbfd53568d26506",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "102fc8a6169349d2b46eafb7cfe23b8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question ID: 72\n",
      "Generated Answer: Гипотезы в машинном обучении - это предположения о распределении данных или о том, как модель должна учиться от них. Они могут быть проверены с помощью статистических тестов, которые позволяют определить, насколько вероятно, что наблюдаемые данные могли быть получены случайно, если гипотеза верна. Например, один из распространенных тестов - тест t-Student, который используется для сравнения средних значений двух выборок. Если p-value (вероятность получения наблюдаемых данных при верной нулевой гипотезе) меньше заданного уровня значимости (например, 0,05), то гипотеза отвергается, и считается, что обнаруженная разница статистически значима. Если p-value больше уровня значимости, то гипотеза не отвергается, и считается, что разница может быть объяснена случайностью.\n",
      "\n",
      "Translation:\n",
      "Hypotheses in machine learning are assumptions about the distribution of data or how a model should learn from them. They can be tested using statistical tests, which allow to determine how likely it is that the observed data could have been obtained by chance if the hypothesis is true. For example, one of the commonly used tests is the t-test, which is used to compare the mean values of two samples. If the p-value (probability of obtaining the observed data if the null hypothesis is true) is less than a given significance level (e.g., 0.05), then the hypothesis is rejected, and it is considered that the detected difference is statistically significant. If the p-value is greater than the level of significance, then the hypothesis is not rejected, and it is considered that the difference may be explained by chance.\n",
      "Reference Answer: Гипотезы - это предположения, которые проверяются в процессе исследования. Проверка гипотез включает формулирование нулевой и альтернативной гипотез, сбор данных и применение статистических тестов для оценки значимости результатов и принятия решения о принятии или отклонении гипотезы.\n",
      "Cosine Similarity: 0.9669711589813232\n",
      "BLEU Score: 1.892944842163126e-155\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf9c95c2bca74606b5389972054cdb77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50326f74518941be99ea3189c0d71902",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question ID: 73\n",
      "Generated Answer: В моей работе я использую различные статистические тесты, такие как t-тест, хи-квадратное тестирование, ANOVA, регрессионный анализ и другие, в зависимости от конкретной задачи и типа данных.\n",
      "\n",
      "Translation: In my work, I use various statistical tests, such as the t-test, chi-square testing, ANOVA, regression analysis, and others, depending on the specific task and type of data.\n",
      "\n",
      "Note: The provided knowledge base does not seem to contain information relevant to the user's question. Therefore, I have provided a general answer based on common statistical tests used in machine learning engineering.\n",
      "Reference Answer: В своей работе я использую различные статистические тесты, такие как t-тест, ANOVA, хи-квадрат тест и тесты на нормальность распределения. Эти тесты помогают оценить значимость различий между группами, зависимости и распределения данных.\n",
      "Cosine Similarity: 0.9634597301483154\n",
      "BLEU Score: 0.09741544274063611\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c81b511b8a67418680136ef3a6d913d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d7774c93a3d446e90fe600334df4132",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question ID: 74\n",
      "Generated Answer: P-значение (p-value) - это вероятность того, что результат исследования может быть получен случайно, если нулевая гипотеза является истинной. Обычно используется для тестирования статистических гипотез. P-значение интерпретируется следующим образом: если оно меньше уровня значимости (обычно 0,05), то считается, что результат значим и нулевая гипотеза отвергается. Если же p-значение больше уровня значимости, то результат незначим и нулевая гипотеза не отвергается. Важно помнить, что отсутствие статистической значимости не означает отсутствия практической значимости.\n",
      "\n",
      "Translation:\n",
      "\n",
      "P-значение (p-value) is the probability that the research result can be obtained by chance if the null hypothesis is true. It is commonly used for testing statistical hypotheses. The p-value is interpreted as follows: if it is less than the significance level (usually 0.05), it is considered that the result is significant and the null hypothesis is rejected. If the p-value is greater than the significance level, the result is not significant and the null hypothesis is not rejected. It is important to remember that the absence of statistical significance does not mean the absence of practical significance.\n",
      "Reference Answer: p-значение - это вероятность получения результатов, равных или более экстремальных, чем наблюдаемые, при условии, что нулевая гипотеза верна. Низкое p-значение указывает на значимые различия, что позволяет отвергнуть нулевую гипотезу.\n",
      "Cosine Similarity: 0.806908130645752\n",
      "BLEU Score: 5.819095143359225e-79\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "599bd9aaf08d434dac7bc2273ff82d5c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0540621a5c614c2692067890724545ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question ID: 75\n",
      "Generated Answer: Для построения доверительных интервалов обычно используются статистические методы. Например, один из распространенных подходов - это использование теоремы центральной предельной теоремы (ЦПТ) для определения границ доверительного интервала.\n",
      "\n",
      "Согласно ЦПТ, если у нас есть независимые и одинаково распределенные случайные величины с математическим ожиданием μ и дисперсией σ², то стандартизированная сумма этих величин будет стремиться к нормальному распределению с математическим ожиданием 0 и дисперсией 1, когда количество величин стремится к бесконечности.\n",
      "\n",
      "Используя этот факт, мы можем построить доверительный интервал для математического ожидания μ следующим образом:\n",
      "\n",
      "1. Выберем уровень значимости α (например, α = 0,05).\n",
      "2. Найдем критическое значение t-распределения t\\_α/2 с n-1 степенями свободы, где n - количество наблюдений.\n",
      "3. Рассчитаем среднее значение x и стандартное отклонение s на основе наших наблюдений.\n",
      "4. Построим доверительный интервал для μ следующим образом: x ± t\\_α/2 \\* s/√n\n",
      "\n",
      "Этот интервал будет содержать математическое ожидание μ с вероятностью 1 - α.\n",
      "\n",
      "Надеюсь, это поможет!\n",
      "Reference Answer: Для построения доверительных интервалов я использую статистические методы, такие как бутстрепинг и стандартная ошибка выборки. Доверительный интервал показывает диапазон значений, в котором с заданной вероятностью находится истинное значение параметра.\n",
      "Cosine Similarity: 0.9898701310157776\n",
      "BLEU Score: 0.019128796253251788\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d04177c6275d49fc9833c308fe5bc08b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d813f11a5d664463865fddb065f21a67",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question ID: 76\n",
      "Generated Answer: Я использую различные методы визуализации данных, такие как гистограммы, диаграммы рассеяния, графики линий, графики баров, дерево решений, тепловые карты и т.д. Зависит от типа данных и того, что нужно продемонстрировать.\n",
      "\n",
      "(I use various data visualization methods, such as histograms, scatter plots, line charts, bar charts, decision trees, heatmaps, etc. It depends on the type of data and what needs to be demonstrated.)\n",
      "Reference Answer: Для визуализации данных я использую методы, такие как гистограммы, диаграммы рассеяния, тепловые карты, boxplot и линейные графики. Эти методы помогают визуально представлять распределения данных, взаимосвязи и тренды.\n",
      "Cosine Similarity: 0.9684140682220459\n",
      "BLEU Score: 0.06947962277500036\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf9a84a1f53b4a4da7c4e21288da1c7e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95c4bd9bda934cdfbf8c4f7d3e25e680",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question ID: 77\n",
      "Generated Answer: Гистограмма - это графическое представление данных, которые могут быть представлены в виде набора категорий. Она состоит из столбцов, каждый из которых соответствует определенной категории, и высота столбца показывает частоту или количество элементов в этой категории.\n",
      "\n",
      "Гистограммы часто используются для визуализации распределения данных, например, для отображения распределения возрастов людей в определенной популяции. Они также могут быть полезны для обнаружения аномалий или выбросов в данных, а также для сравнения распределений между двумя или более группами.\n",
      "\n",
      "В машинном обучении гистограммы часто используются для визуализации распределений признаков в данных, чтобы лучше понять, как они влияют на модель и как их можно преобразовать для улучшения ее производительности. Например, гистограмма может показать, что распределение значений признака сильно смещено влево или вправо, что может указывать на необходимость нормализации данных.\n",
      "Reference Answer: Гистограмма - это график, представляющий распределение данных. Она используется для визуализации частоты значений в наборе данных и позволяет выявлять тенденции, аномалии и распределения.\n",
      "Cosine Similarity: 0.979467511177063\n",
      "BLEU Score: 8.200307182094573e-79\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06a98f1281cc4080bccc0cc9033eeb78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b9d7d7b94b743778a38f0141b333df5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question ID: 78\n",
      "Generated Answer: Диаграмма рассеяния (scatter plot) - это график, на котором каждая точка соответствует одному объекту с двумя измеряемыми характеристиками. Она используется для визуализации взаимосвязи между двумя переменными. На оси X обычно откладывается одна переменная, а на оси Y - вторая. Примеры использования диаграмм рассеяния включают в себя исследование зависимости между ростом и весом людей, температурой и давлением, или любыми другими парами переменных.\n",
      "\n",
      "Translation:\n",
      "\n",
      "A scatter plot (диаграмма рассеяния) is a graph where each point corresponds to an object with two measured characteristics. It is used to visualize the correlation between two variables. One variable is usually plotted on the X-axis and the other on the Y-axis. Examples of scatter plot use include studying the dependence between people's height and weight, temperature and pressure, or any other pair of variables.\n",
      "Reference Answer: Диаграмма рассеяния отображает взаимосвязь между двумя переменными. По её точкам можно определить корреляцию, выявить тренды и аномалии, а также понять характер связи между переменными.\n",
      "Cosine Similarity: 0.781991720199585\n",
      "BLEU Score: 7.145668412690912e-79\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8495597cf6548b6a5868a774ea8c0fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64d4bf6966364d6b93206894d6021fb5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question ID: 79\n",
      "Generated Answer: Корреляционный анализ - это статистический метод, который используется для определения степени связи или зависимости между двумя или более переменными. Он помогает определить, существует ли взаимосвязь между переменными, и если да, то какого рода она. Корреляционный анализ не позволяет определить причинно-следственную связь между переменными, он только показывает, насколько они связаны. Один из распространенных показателей корреляции - коэффициент корреляции Пирсона. Он может принимать значения от -1 до 1. Значение 1 означает совершенную положительную корреляцию, значение -1 - совершенную отрицательную корреляцию, а значение 0 означает отсутствие корреляции. Корреляционный анализ широко используется в различных областях, таких как экономика, психология, медицина и т.д.\n",
      "Reference Answer: Корреляционный анализ оценивает степень взаимосвязи между переменными. Коэффициент корреляции показывает, насколько сильно и в каком направлении связаны переменные, помогая выявлять зависимые и независимые факторы.\n",
      "Cosine Similarity: 0.9820346832275391\n",
      "BLEU Score: 3.1947013268637067e-155\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "410ee5d271d74f6ab169e80cd540e1f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8be36410019e46c7bbbcbf2ea0c6c96f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question ID: 80\n",
      "Generated Answer: Когда вы строите тепловые карты, вы представляете данные в виде графического изображения, где различные цвета или оттенки используются для обозначения различных уровней интенсивности или плотности данных. Они могут показывать распределение температур, плотность населения, уровень осадков, частоту использования слов в тексте и многое другое. Тепловые карты могут быть полезны для визуализации больших объемов данных и обнаружения паттернов или тенденций.\n",
      "\n",
      "To build heatmaps, you represent data in a graphical image where different colors or shades are used to denote different levels of intensity or density of data. They can show temperature distribution, population density, rainfall levels, word frequency in text, and much more. Heatmaps can be useful for visualizing large amounts of data and detecting patterns or trends.\n",
      "\n",
      "Translation:\n",
      "Когда вы строите тепловые карты, вы представляете данные графически с помощью различных цветов или оттенков для обозначения различных уровней интенсивности или плотности данных. Тепловые карты могут показать распределение температур, плотность населения, уровень осадков, частоту использования слов в тексте и т.д. Они полезны для визуализации больших объемов данных и обнаружения паттернов или тенденций.\n",
      "\n",
      "Note: The provided knowledge base does not contain information about building heatmaps or what they show. The response is based on general knowledge.\n",
      "Reference Answer: Тепловые карты представляют данные в виде цветовых шкал, показывая интенсивность значений. Они используются для визуализации корреляций, матриц данных и распределений, помогая выявлять взаимосвязи и аномалии.\n",
      "Cosine Similarity: 0.9206869602203369\n",
      "BLEU Score: 6.924639722988986e-79\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a056c3cd23b4a96beaa51ebfcef12a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51a18cd381f84136ae4587d8262524c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question ID: 81\n",
      "Generated Answer: Boxplot, также известный как диаграмма Tukey'a или диаграмма коробки с усами, является графическим средством представления статистических данных, которое отображает пять числовых суммарных показателей: минимальное значение, первый квартиль (Q1), медиану (Q2), третий квартиль (Q3) и максимальное значение.\n",
      "\n",
      "Интерпретация boxplot'а происходит следующим образом:\n",
      "1. Вертикальная линия в середине диаграммы представляет медиану (Q2) или значение, разделяющее данные на две равные части.\n",
      "2. Прямоугольник, или \"коробка\", ограничивает интервал между первым (Q1) и третьим (Q3) квартилями. Этот интервал называется интерквартильным размахом (IQR) и отображает middle 50% значений.\n",
      "3. Линии, или \"усы\", которые распространяются от коробки, представляют минимальные и максимальные значения данных, за исключением аномальных значений. Они распространяются на 1,5 IQR от границ коробки.\n",
      "4. Отдельные точки за пределами усов представляют аномальные значения или выбросы. Они определяются как значения, которые находятся за пределами 1,5 IQR от границ коробки.\n",
      "\n",
      "В целом, boxplot помогает быстро определять центральную тенденцию, разброс, асимметрию и наличие выбросов в данных.\n",
      "Reference Answer: Boxplot (коробчатая диаграмма) - это график, который визуализирует распределение данных через их квартили. Он показывает медиану, интерквартильный размах, выбросы и симметричность распределения, помогая анализировать и сравнивать наборы данных.\n",
      "Cosine Similarity: 0.9470080733299255\n",
      "BLEU Score: 6.885877678021066e-232\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0b3e8b4be1f45d3b218c8dd419a9305",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88fb9bb017714fab8f42bae4b6aed55a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question ID: 82\n",
      "Generated Answer: Matplotlib - это популярная библиотека Python для построения графиков и визуализации данных. Чтобы использовать Matplotlib для построения графиков, следуйте этим шагам:\n",
      "\n",
      "1. Установите Matplotlib, если вы еще этого не сделали. Вы можете сделать это, используя pip:\n",
      "```\n",
      "pip install matplotlib\n",
      "```\n",
      "2. Импортируйте Matplotlib в ваш скрипт Python:\n",
      "```python\n",
      "import matplotlib.pyplot as plt\n",
      "```\n",
      "3. Создайте данные для графика. Например, создайте два списка: один для значений по оси X, другой для значений по оси Y:\n",
      "```python\n",
      "x = [1, 2, 3, 4, 5]\n",
      "y = [2, 3, 5, 7, 11]\n",
      "```\n",
      "4. Построите график, используя функцию `plot()`. Она принимает значения по оси X и Y в качестве аргументов:\n",
      "```python\n",
      "plt.plot(x, y)\n",
      "```\n",
      "5. Отобразите график с помощью функции `show()`:\n",
      "```python\n",
      "plt.show()\n",
      "```\n",
      "\n",
      "Это создаст простой линейный график для данных из примера. Вы также можете настроить различные аспекты графика, такие как цвет, тип линий, легенды и т.д., используя различные функции и параметры Matplotlib.\n",
      "Reference Answer: Для построения графиков с помощью matplotlib я использую функции этой библиотеки для создания гистограмм, линейных графиков, диаграмм рассеяния и других видов визуализаций. Matplotlib позволяет настроить внешний вид графиков и добавить аннотации.\n",
      "Cosine Similarity: 0.7468698620796204\n",
      "BLEU Score: 2.968538645416938e-155\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af2da830a1374a2d92a631a53e6cc992",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25a3b7e95ee44cc8a82d23156a6dc094",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question ID: 83\n",
      "Generated Answer: Seaborn - это библиотека Python для статистического анализа и визуализации данных. Она построена на основе Matplotlib и Pandas и предоставляет высокоуровневые инструменты для создания профессионально выглядящих графиков. Преимущества Seaborn включают:\n",
      "\n",
      "1. Простота использования: Seaborn имеет интуитивно понятный синтаксис и предлагает множество встроенных стилей и тематических картов, что позволяет быстро создавать привлекательные графики.\n",
      "2. Встроенные тематические карты: Seaborn предлагает различные встроенные стили для графиков, что помогает создавать консистентный внешний вид в презентациях и отчетах.\n",
      "3. Поддержка работы с данными Pandas: Seaborn интегрируется с Pandas DataFrames и сериями, что упрощает манипулирование данными и их визуализацией.\n",
      "4. Удобство визуализации распределений данных: Seaborn предоставляет функции для простой визуализации распределений данных, такие как гистограммы, кумулятивные гистограммы, плотности и графики рассеивания.\n",
      "5. Встроенные средства для визуализации корреляций: Seaborn предлагает инструменты для простой визуализации корреляций между переменными, такие как матрицы корреляции и графики рассеивания с наложенными линиями регрессии.\n",
      "\n",
      "В целом, Seaborn является мощным и удобным инструментом для статистического анализа и визуализации данных в Python.\n",
      "Reference Answer: Seaborn - это библиотека для визуализации данных, построенная на основе matplotlib. Она предоставляет высокоуровневый интерфейс для создания привлекательных и информативных графиков, таких как тепловые карты, boxplot и pairplot, с меньшим количеством кода.\n",
      "Cosine Similarity: 0.7844053506851196\n",
      "BLEU Score: 0.024654390492649968\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f848b1e0f3384d658a9e761168b9ccf4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da081cd304384f9da4b6702ebfe42ab9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question ID: 84\n",
      "Generated Answer: К сожалению, в вашем вопросе не упоминается графическая задача или обработка данных, поэтому я не могу применить информацию из базы знаний. Тем не менее, я могу попробовать ответить на ваш вопрос о библиотеке Plotly.\n",
      "\n",
      "Plotly - это библиотека для визуализации данных в Python, которая предоставляет простой и интуитивно понятный интерфейс для создания различных типов графиков, диаграмм и картографических представлений. Она основана на JavaScript-библиотеке Plotly.js и может экспортировать результаты в несколько форматов, включая HTML, PDF, PNG и SVG.\n",
      "\n",
      "Вот несколько основных функций и возможностей библиотеки Plotly:\n",
      "\n",
      "* Поддержка различных типов графиков: линейные диаграммы, столбчатые диаграммы, гистограммы, отображение рассеяния, точечные диаграммы,Area charts, heatmaps, 3D-графики и др.\n",
      "* Интерактивные графики: пользователи могут масштабировать, перетаскивать и кликать на элементы графика, чтобы увидеть дополнительную информацию.\n",
      "* Создание сложных графиков: Plotly позволяет комбинировать различные типы графиков на одной диаграмме и добавлять различные элементы, такие как легенды, заголовки и подписи осей.\n",
      "* Экспорт графиков: результаты могут быть экспортированы в несколько форматов, включая HTML, PDF, PNG, SVG, EPS и JSON.\n",
      "* Встроенная поддержка машинного обучения: Plotly может визуализировать результаты алгоритмов машинного обучения, таких как решения регрессии, кластеризации и классификации.\n",
      "\n",
      "Чтобы использовать Plotly в Python, вам нужно установить библиотеку, используя команду pip install plotly. Затем вы можете импортировать библиотеку в ваш скрипт и создавать графики, используя простой и интуитивно понятный синтаксис. Например, вот как создать линейный график:\n",
      "```python\n",
      "import plotly.graph_objects as go\n",
      "\n",
      "# Создаем данные\n",
      "x = [1, 2, 3, 4, 5]\n",
      "y = [2, 3, 5, 7, 11]\n",
      "\n",
      "# Создаем график\n",
      "fig = go.Figure()\n",
      "fig.add_trace(go.Scatter(x=x, y=y, mode='lines'))\n",
      "\n",
      "# Отображаем график\n",
      "fig.show()\n",
      "```\n",
      "Этот код создает линейный график с точками и линиями, соединяющими их. Вы также можете добавить заголовок, подписи осей и другие элементы, чтобы улучшить визуализацию.\n",
      "\n",
      "Надеюсь, этот ответ поможет вам лучше понять библиотеку Plotly. Если у вас есть дополнительные вопросы, не стесняйтесь спрашивать.\n",
      "Reference Answer: Библиотека Plotly используется для создания интерактивных графиков и визуализаций. Она позволяет создавать динамичные и настраиваемые визуализации, такие как линейные графики, гистограммы и тепловые карты, которые можно взаимодействовать и анализировать в режиме реального времени.\n",
      "Cosine Similarity: 0.8042299151420593\n",
      "BLEU Score: 2.063864963831942e-155\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16d7d67953994964ada6986dfa0f2bc9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4719624a264442deb0f4aa3a32c361bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question ID: 85\n",
      "Generated Answer: Pandas — это библиотека Python для анализа и манипуляции данными. Она предоставляет инструменты для работы с данными в формате таблиц (DataFrame) и серий (Series). Pandas часто используется для импорта, экспорта, преобразования, очистки, слияния и визуализации данных. Она также обеспечивает эффективную работу с большими объёмами данных и интеграцию с другими библиотеками Python, такими как NumPy и Matplotlib. Кроме того, Pandas предоставляет возможности для работы с временными рядами (time series) и повышает производительность при выполнении операций с данными.\n",
      "Reference Answer: Pandas - это библиотека для обработки и анализа данных в Python. Она предоставляет структуры данных, такие как DataFrame и Series, и функции для чтения, фильтрации, агрегирования и манипуляции данными, что делает её незаменимой для анализа данных.\n",
      "Cosine Similarity: 0.974032998085022\n",
      "BLEU Score: 5.000767067879822e-155\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0772af9948c4096847e36e6fb352918",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ff70804f085463e8cb30a9139cd002b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question ID: 86\n",
      "Generated Answer: Мы можем работать с массивами данных в NumPy следующим образом:\n",
      "\n",
      "1. Создание массива:\n",
      "```\n",
      "import numpy as np\n",
      "array = np.array([1, 2, 3, 4, 5])\n",
      "```\n",
      "2. Операции с массивами:\n",
      "* Сложение: `array1 + array2`\n",
      "* Вычитание: `array1 - array2`\n",
      "* Умножение: `array1 * array2`\n",
      "* Деление: `array1 / array2`\n",
      "* Возведение в степень: `array1 ** array2`\n",
      "* Нахождение модуля: `np.abs(array)`\n",
      "* Нахождение квадратного корня: `np.sqrt(array)`\n",
      "3. Индексация и срезы:\n",
      "```\n",
      "# Получение первого элемента\n",
      "array[0]\n",
      "\n",
      "# Получение последнего элемента\n",
      "array[-1]\n",
      "\n",
      "# Получение среза массива от первого до третьего элемента\n",
      "array[0:3]\n",
      "```\n",
      "4. Изменение размерности массива:\n",
      "```\n",
      "# Добавление новой оси к массиву\n",
      "array = np.expand_dims(array, axis=0)\n",
      "\n",
      "# Удаление оси из массива\n",
      "array = np.squeeze(array, axis=0)\n",
      "```\n",
      "5. Создание многомерных массивов:\n",
      "```\n",
      "# Создание матрицы 2x3\n",
      "matrix = np.array([[1, 2, 3], [4, 5, 6]])\n",
      "\n",
      "# Создание тензора 2x3x4\n",
      "tensor = np.array([[[1, 2, 3, 4], [5, 6, 7, 8], [9, 10, 11, 12]], [[13, 14, 15, 16], [17, 18, 19, 20], [21, 22, 23, 24]]])\n",
      "```\n",
      "6. Преобразование типа данных в массиве:\n",
      "```\n",
      "# Преобразование типа данных в массиве в int\n",
      "array = array.astype(int)\n",
      "\n",
      "# Преобразование типа данных в массиве в float\n",
      "array = array.astype(float)\n",
      "```\n",
      "7. Создание массивов со случайными значениями:\n",
      "```\n",
      "# Создание массива размером (3, 3) со случайными значениями от 0 до 1\n",
      "array = np.random.rand(3, 3)\n",
      "\n",
      "# Создание массива размером (3, 3) со случайными целыми значениями от 0 до 10\n",
      "array = np.random.randint(0, 10, size=(3, 3))\n",
      "```\n",
      "8. Нахождение максимального и минимального значения в массиве:\n",
      "```\n",
      "# Нахождение максимального значения в массиве\n",
      "max_value = np.max(array)\n",
      "\n",
      "# Нахождение минимального значения в массиве\n",
      "min_value = np.min(array)\n",
      "```\n",
      "9. Нахождение индекса максимального и минимального значения в массиве:\n",
      "```\n",
      "# Нахождение индекса максимального значения в массиве\n",
      "max_index = np.argmax(array)\n",
      "\n",
      "# Нахождение индекса минимального значения в массиве\n",
      "min_index = np.argmin(array)\n",
      "```\n",
      "10. Сортировка массива:\n",
      "```\n",
      "# Сортировка массива по возрастанию\n",
      "sorted_array = np.sort(array)\n",
      "\n",
      "# Сортировка массива по убыванию\n",
      "sorted_array = np.sort(array)[::-1]\n",
      "```\n",
      "11. Нахождение уникальных значений в массиве:\n",
      "```\n",
      "# Нахождение уникальных значений в массиве\n",
      "unique_values = np.unique(array)\n",
      "```\n",
      "12. Нахождение частоты встречаемости значений в массиве:\n",
      "```\n",
      "# Нахождение частоты встречаемости значений в массиве\n",
      "frequency = np.bincount(array)\n",
      "```\n",
      "13. Проверка, является ли массив массивом одного изданных чисел:\n",
      "```\n",
      "# Проверка, является ли массив массивом одного изданных чисел\n",
      "is_single_value_array = np.all(array == array[0])\n",
      "```\n",
      "14. Проверка, является ли массив отсортированным:\n",
      "```\n",
      "# Проверка, является ли массив отсортированным\n",
      "is_sorted = np.all(np.diff(array) >= 0)\n",
      "```\n",
      "15. Преобразование массива в массив логических значений:\n",
      "```\n",
      "# Преобразование массива в массив логических значений\n",
      "bool_array = np.array([True, False, True, True], dtype=bool)\n",
      "```\n",
      "16. Нахождение суммы элементов массива:\n",
      "```\n",
      "# Нахождение суммы элементов массива\n",
      "sum_of_elements = np.sum(array)\n",
      "```\n",
      "17. Нахождение среднего значения элементов массива:\n",
      "```\n",
      "# Нахождение среднего значения элементов массива\n",
      "mean_of_elements = np.mean(array)\n",
      "```\n",
      "18. Нахождение среднеквадратичного отклонения элементов массива:\n",
      "```\n",
      "# Нахождение среднеквадратичного отклонения элементов массива\n",
      "standard_deviation = np.std(array)\n",
      "```\n",
      "19. Нахождение дисперсии элементов массива:\n",
      "```\n",
      "# Нахождение дисперсии элементов массива\n",
      "variance = np.var(array)\n",
      "```\n",
      "20. Нахождение коэффициента корреляции Пирсона между двумя массивами:\n",
      "```\n",
      "# Нахождение коэффициента корреляции Пирсона между двумя массивами\n",
      "correlation = np.corrcoef(array1, array2)[0, 1]\n",
      "```\n",
      "21. Нахождение коэффициента детерминации между двумя массивами:\n",
      "```\n",
      "# Нахождение коэффициента детерминации между двумя массивами\n",
      "coefficient_of_determination = np.square(np.corrcoef(array1, array2)[0, 1])\n",
      "```\n",
      "22. Нахождение матрицы корреляции между несколькими массивами:\n",
      "```\n",
      "# Нахождение матрицы корреляции между несколькими массивами\n",
      "correlation_matrix = np.corrcoef(array1, array2, array3)\n",
      "```\n",
      "23. Нахождение матрицы ковариации между несколькими массивами:\n",
      "```\n",
      "# Нахождение матрицы ковариации между несколькими массивами\n",
      "covariance_matrix = np.cov(array1, array2, array3)\n",
      "```\n",
      "24. Преобразование массива в одномерный массив:\n",
      "```\n",
      "# Преобразование массива в одномерный массив\n",
      "flattened_array = array.flatten()\n",
      "```\n",
      "25. Преобразование массива в многомерный массив:\n",
      "```\n",
      "# Преобразование массива в многомерный массив\n",
      "reshaped_array = array.reshape((3, 3))\n",
      "```\n",
      "26. Транспонирование массива:\n",
      "```\n",
      "# Транспонирование массива\n",
      "transposed_array = array.transpose()\n",
      "```\n",
      "27. Нахождение количества элементов в массиве:\n",
      "```\n",
      "# Нахождение количества элементов в массиве\n",
      "number_of_elements = np.size(array)\n",
      "```\n",
      "28. Нахождение размерности массива:\n",
      "```\n",
      "# Нахождение размерности массива\n",
      "shape = np.shape(array)\n",
      "```\n",
      "29. Нахождение размера массива в байтах:\n",
      "```\n",
      "# Нахождение размера массива в байтах\n",
      "size_in_bytes = np.nbytes(array)\n",
      "```\n",
      "30. Нахождение типа данных в массиве:\n",
      "```\n",
      "# Нахождение типа данных в массиве\n",
      "data_type = array.dtype\n",
      "```\n",
      "31. Создание массива с заданным числом элементов и заданным значением по умолчанию:\n",
      "```\n",
      "# Создание массива размером (3, 3) с заданным значением по умолчанию 0\n",
      "array = np.zeros((3, 3))\n",
      "\n",
      "# Создание массива размером (3, 3) с заданным значением по умолчанию 1\n",
      "array = np.ones((3, 3))\n",
      "\n",
      "# Создание массива размером (3, 3) с заданным значением по умолчанию -1\n",
      "array = np.full((3, 3), -1)\n",
      "\n",
      "# Создание массива размером (3, 3) с заполнением элементов последовательностью\n",
      "array = np.arange(9).reshape((3, 3))\n",
      "```\n",
      "32. Создание массива с заданным шагом:\n",
      "```\n",
      "# Создание массива со значениями от 0 до 9 с шагом 2\n",
      "array = np.arange(0, 10, 2)\n",
      "```\n",
      "33. Создание массива с заданным диапазоном значений:\n",
      "```\n",
      "# Создание массива со значениями от 10 до 20\n",
      "array = np.linspace(10, 20, 11)\n",
      "```\n",
      "34. Создание массива с заданным числом элементов и заданным интервалом между ними:\n",
      "```\n",
      "# Создание массива с 5 элементами и интервалом 0.5 между ними\n",
      "array = np.linspace(0, 2, 5)\n",
      "```\n",
      "35. Создание массива с заданным числом элементов и заданным интервалом между ними, включая конечные значения:\n",
      "```\n",
      "# Создание массива с 5 элементами и интервалом 0.5 между ними, включая конечные значения\n",
      "array = np.linspace(0, 2, 6)\n",
      "```\n",
      "36. Создание массива с заданным числом строк и заданным числом столбцов:\n",
      "```\n",
      "# Создание массива размером (3, 3)\n",
      "array = np.empty((3, 3))\n",
      "```\n",
      "37. Создание массива с заданным числом строк и заданным числом столбцов, заполненного случайными значениями:\n",
      "```\n",
      "# Создание массива размером (3, 3) заполненного случайными значениями\n",
      "array = np.random.rand(3, 3)\n",
      "```\n",
      "38. Создание массива с заданным числом строк и заданным числом столбцов, заполненного случайными целыми значениями:\n",
      "```\n",
      "# Создание массива размером (3, 3) заполненного случайными целыми значениями\n",
      "array = np.random.randint(10, size=(3, 3))\n",
      "```\n",
      "39. Поворот массива на заданный угол:\n",
      "```\n",
      "# Поворот массива на 90 градусов\n",
      "array = np.rot90(array)\n",
      "```\n",
      "40. Отражение массива относительно заданной оси:\n",
      "```\n",
      "# Отражение массива относительно оси y\n",
      "array = np.flipud(array)\n",
      "\n",
      "# Отражение массива относительно оси x\n",
      "array = np.fliplr(array)\n",
      "```\n",
      "41. Замена отрицательных значений в массиве на заданное значение:\n",
      "```\n",
      "# Замена отрицательных значений в массиве на 0\n",
      "array = np.maximum(array, 0)\n",
      "```\n",
      "42. Замена положительных значений в массиве на заданное значение:\n",
      "```\n",
      "# Замена положительных значений в массиве на 0\n",
      "array = np.minimum(array, 0)\n",
      "```\n",
      "43. Замена нулевых значений в массиве на заданное значение:\n",
      "```\n",
      "# Замена нулевых значений в массиве на 1\n",
      "array = np.where(array == 0, 1, array)\n",
      "```\n",
      "44. Нахождение индексов элементов массива, удовлетворяющих заданному условию:\n",
      "```\n",
      "# Нахождение индексов элементов массива, равных 0\n",
      "indices = np.where(array == 0)\n",
      "```\n",
      "45. Нахождение значений элементов массива, удовлетворяющих заданному условию:\n",
      "```\n",
      "# Нахождение значений элементов массива, больших 0\n",
      "values = array[array > 0]\n",
      "```\n",
      "46. Удаление элементов массива, удовлетворяющих заданному условию:\n",
      "```\n",
      "# Удаление элементов массива, равных 0\n",
      "array = np.delete(array, np.where(array == 0))\n",
      "```\n",
      "47. Добавление новой оси к массиву:\n",
      "```\n",
      "# Добавление новой оси к массиву\n",
      "array = np.expand_dims(array, axis=0)\n",
      "```\n",
      "48. Удаление оси из массива:\n",
      "```\n",
      "# Удаление оси из массива\n",
      "array = np.squeeze(array, axis=0)\n",
      "```\n",
      "49. Объединение двух массивов по заданной оси:\n",
      "```\n",
      "# Объединение двух массивов по оси 0\n",
      "array = np.concatenate([array1, array2], axis=0)\n",
      "\n",
      "# Объединение двух массивов по оси 1\n",
      "array = np.concatenate([array1, array2], axis=1)\n",
      "```\n",
      "50. Разбиение массива на несколько массивов по заданному числу элементов:\n",
      "```\n",
      "# Разбиение массива на несколько массивов по 3 элемента\n",
      "arrays = np.array_split(array, 3)\n",
      "```\n",
      "51. Разбиение массива на несколько массивов по заданному интервалу:\n",
      "```\n",
      "# Разбиение массива на несколько массивов с интервалом 3\n",
      "arrays = np.split(array, 3)\n",
      "```\n",
      "52. Нахождение индексов максимального и минимального значения в массиве:\n",
      "```\n",
      "# Нахождение индекса максимального значения в массиве\n",
      "max_index = np.argmax(array)\n",
      "\n",
      "# Нахождение индекса минимального значения в массиве\n",
      "min_index = np.argmin(array)\n",
      "```\n",
      "53. Нахождение индексов элементов массива, удовлетворяющих заданному условию:\n",
      "```\n",
      "# Нахождение индексов элементов массива, больших 0\n",
      "indices = np.where(array > 0)\n",
      "```\n",
      "54. Нахождение значений элементов массива, удовлетворяющих заданному условию:\n",
      "```\n",
      "# Нахождение значений элементов массива, больших 0\n",
      "values = array[array > 0]\n",
      "```\n",
      "55. Удаление элементов массива, удовлетворяющих заданному условию:\n",
      "```\n",
      "# Удаление элементов массива, равных 0\n",
      "array = np.delete(array, np.where(array == 0))\n",
      "```\n",
      "56. Замена значений элементов массива, удовлетворяющих заданному условию:\n",
      "```\n",
      "# Замена значений элементов массива, меньших 0, на 0\n",
      "array[array < 0] = 0\n",
      "```\n",
      "57. Поиск значения в массиве:\n",
      "```\n",
      "# Поиск значения 5 в массиве\n",
      "index = np.where(array == 5)\n",
      "```\n",
      "58. Поиск всех вхождений значения в массиве:\n",
      "```\n",
      "# Поиск всех вхождений значения 5 в массиве\n",
      "indices = np.where(array == 5)\n",
      "```\n",
      "59. Нахождение индекса первого вхождения значения в массиве:\n",
      "```\n",
      "# Нахождение индекса первого вхождения значения 5 в массиве\n",
      "index = np.where(array == 5)[0][0]\n",
      "```\n",
      "60. Нахождение индекса последнего вхождения значения в массиве:\n",
      "```\n",
      "# Нахождение индекса последнего вхождения значения 5 в массиве\n",
      "index = np.where(array == 5)[0][-1]\n",
      "```\n",
      "61. Нахождение индексов элементов массива, удовлетворяющих заданному условию:\n",
      "```\n",
      "# Нахождение индексов элементов массива, больших 0\n",
      "indices = np.where(array > 0)\n",
      "```\n",
      "62. Нахождение значений элементов массива, удовлетворяющих заданному условию:\n",
      "```\n",
      "# Нахождение значений элементов массива, больших 0\n",
      "values = array[array > 0]\n",
      "```\n",
      "63. Удаление элементов массива, удовлетворяющих заданному условию:\n",
      "```\n",
      "# Удаление элементов массива, равных 0\n",
      "array = np.delete(array, np.where(array == 0))\n",
      "```\n",
      "64. Замена значений элементов массива, удовлетворяющих заданному условию:\n",
      "```\n",
      "# Замена значений элементов массива, меньших 0, на 0\n",
      "array[array < 0] = 0\n",
      "```\n",
      "65. Преобразование массива в массив логических значений:\n",
      "```\n",
      "# Преобразование массива в массив логических значений\n",
      "bool_array = np.array([True, False, True], dtype=bool)\n",
      "```\n",
      "66. Преобразование массива логических значений в массив чисел:\n",
      "```\n",
      "# Преобразование массива логических значений в массив чисел\n",
      "number_array = bool_array.astype(int)\n",
      "```\n",
      "67. Преобразование массива в одномерный массив:\n",
      "```\n",
      "# Преобразование массива в одномерный массив\n",
      "flattened_array = array.flatten()\n",
      "```\n",
      "68. Преобразование массива в многомерный массив:\n",
      "```\n",
      "# Преобразование массива в многомерный массив\n",
      "reshaped_array = array.reshape((3, 3))\n",
      "```\n",
      "69. Транспонирование массива:\n",
      "```\n",
      "# Транспонирование массива\n",
      "transposed_array = array.transpose()\n",
      "```\n",
      "70. Нахождение количества элементов в массиве:\n",
      "```\n",
      "# Нахождение количества элементов в массиве\n",
      "number_of_elements = np.size(array)\n",
      "```\n",
      "71. Нахождение размерности массива:\n",
      "```\n",
      "# Нахождение размерности массива\n",
      "shape = np.shape(array)\n",
      "```\n",
      "72. Нахождение размера массива в байтах:\n",
      "```\n",
      "# Нахождение размера массива в байтах\n",
      "size_in_bytes = np.nbytes(array)\n",
      "```\n",
      "73. Нахождение типа данных в массиве:\n",
      "```\n",
      "# Нахождение типа данных в массиве\n",
      "data_type = array.dtype\n",
      "```\n",
      "74. Преобразование массива в массив с заданным типом данных:\n",
      "```\n",
      "# Преобразование массива в массив с типом данных float\n",
      "array = array.astype(float)\n",
      "```\n",
      "75. Нахождение максимального значения в массиве:\n",
      "```\n",
      "# Нахождение максимального значения в массиве\n",
      "max_value = np.max(array)\n",
      "```\n",
      "76. Нахождение минимального значения в массиве:\n",
      "```\n",
      "# Нахождение минимального значения в массиве\n",
      "min_value = np.min(array)\n",
      "```\n",
      "77. Нахождение среднего значения элементов массива:\n",
      "```\n",
      "# Нахождение среднего значения элементов массива\n",
      "mean_value = np.mean(array)\n",
      "```\n",
      "78. Нахождение медианы элементов массива:\n",
      "```\n",
      "# Нахождение медианы элементов массива\n",
      "median_value = np.median(array)\n",
      "```\n",
      "79. Нахождение моды элементов массива:\n",
      "```\n",
      "# Нахождение моды элементов массива\n",
      "mode_value = np.mode(array)\n",
      "```\n",
      "80. Нахождение стандартного отклонения элементов массива:\n",
      "```\n",
      "# Нахождение стандартного отклонения элементов массива\n",
      "standard_deviation = np.std(array)\n",
      "```\n",
      "81. Нахождение вариации элементов массива:\n",
      "```\n",
      "# Нахождение вариации элементов массива\n",
      "variance = np.var(array)\n",
      "```\n",
      "82. Нахождение корреляции между двумя массивами:\n",
      "```\n",
      "# Нахождение корреляции между двумя массивами\n",
      "correlation = np.corrcoef(array1, array2)[0, 1]\n",
      "```\n",
      "83. Нахождение коэффициента детерминации между двумя массивами:\n",
      "```\n",
      "# Нахождение коэффициента детерминации между двумя массивами\n",
      "coefficient_of_determination = np.square(np.corrcoef(array1, array2)[0, 1])\n",
      "```\n",
      "84. Нахождение матрицы корреляции между несколькими массивами:\n",
      "```\n",
      "# Нахождение матрицы корреляции между несколькими массивами\n",
      "correlation_matrix = np.corrcoef(array1, array2, array3)\n",
      "```\n",
      "85. Нахождение матрицы ковариации между несколькими массивами:\n",
      "```\n",
      "# Нахождение матрицы ковариации между несколькими массивами\n",
      "covariance_matrix = np.cov(array1, array2, array3)\n",
      "```\n",
      "86. Нахождение производной функции в заданных точках:\n",
      "```\n",
      "# Нахождение производной функции в заданных точках\n",
      "derivative = np.gradient(array)\n",
      "```\n",
      "87. Нахождение интеграла функции в заданных точках:\n",
      "```\n",
      "# Нахождение интеграла функции в заданных точках\n",
      "integral = np.trapz(array, x)\n",
      "```\n",
      "88. Нахождение суммы элементов массива:\n",
      "```\n",
      "# Нахождение суммы элементов массива\n",
      "sum_of_elements = np.sum(array)\n",
      "```\n",
      "89. Нахождение произведения элементов массива:\n",
      "```\n",
      "# Нахождение произведения элементов массива\n",
      "product_of_elements = np.prod(array)\n",
      "```\n",
      "90. Нахождение минимальной размерности массива:\n",
      "```\n",
      "# Нахождение минимальной размерности массива\n",
      "min_dimension = np.min(np.shape(array))\n",
      "```\n",
      "91. Нахождение максимальной размерности массива:\n",
      "```\n",
      "# Нахождение максимальной размерности массива\n",
      "max_dimension = np.max(np.shape(array))\n",
      "```\n",
      "92. Нахождение количества не нулевых элементов в массиве:\n",
      "```\n",
      "# Нахождение количества не нулевых элементов в массиве\n",
      "number_of_nonzero_elements = np.count_nonzero(array)\n",
      "```\n",
      "93. Нахождение количества уникальных элементов в массиве:\n",
      "```\n",
      "# Нахождение количества уникальных элементов в массиве\n",
      "number_of_unique_elements = np.unique(array).size\n",
      "```\n",
      "94. Нахождение максимального элемента в каждом столбце массива:\n",
      "```\n",
      "# Нахождение максимального элемента в каждом столбце массива\n",
      "max_element_in_each_column = np.max(array, axis=0)\n",
      "```\n",
      "95. Нахождение минимального элемента в каждом столбце массива:\n",
      "```\n",
      "# Нахождение минимального элемента в каждом столбце массива\n",
      "min_element_in_each_column = np.min(array, axis=0)\n",
      "```\n",
      "96. Нахождение среднего элемента в каждом столбце массива:\n",
      "```\n",
      "# Нахождение среднего элемента в каждом столбце массива\n",
      "mean_element_in_each_column = np.mean(array, axis=0)\n",
      "```\n",
      "97. Нахождение суммы элементов в каждом столбце массива:\n",
      "```\n",
      "# Нахождение суммы элементов в каждом столбце массива\n",
      "sum_of_elements_in_each_column = np.sum(array, axis=0)\n",
      "```\n",
      "98. Нахождение произведения элементов в каждом столбце массива:\n",
      "```\n",
      "# Нахождение произведения элементов в каждом столбце массива\n",
      "product_of_elements_in_each_column = np.prod(array, axis=0)\n",
      "```\n",
      "99. Нахождение количества не нулевых элементов в каждом столбце массива:\n",
      "```\n",
      "# Нахождение количества не нулевых элементов в каждом столбце массива\n",
      "number_of_nonzero_elements_in_each_column = np.count_nonzero(array, axis=0)\n",
      "```\n",
      "100. Нахождение максимального элемента в каждой строке массива:\n",
      "```\n",
      "# Нахождение максимального элемента в каждой строке массива\n",
      "max_element_in_each_row = np.max(array, axis=1)\n",
      "```\n",
      "101. Нахождение минимального элемента в каждой строке массива:\n",
      "```\n",
      "# Нахождение минимального элемента в каждой строке массива\n",
      "min_element_in_each_row = np.min(array, axis=1)\n",
      "```\n",
      "102. Нахождение среднего элемента в каждой строке массива:\n",
      "```\n",
      "# Нахождение среднего элемента в каждой строке массива\n",
      "mean_element_in_each_row = np.mean(array, axis=1)\n",
      "```\n",
      "103. Нахождение суммы элементов в каждой строке массива:\n",
      "```\n",
      "# Нахождение суммы элементов в каждой строке массива\n",
      "sum_of_elements_in_each_row = np.sum(array, axis=1)\n",
      "```\n",
      "104. Нахождение произведения элементов в каждой строке массива:\n",
      "```\n",
      "# Нахождение произведения элементов в каждой строке массива\n",
      "product_of_elements_in_each_row = np.prod(array, axis=1)\n",
      "```\n",
      "105. Нахождение количества не нулевых элементов в каждой строке массива:\n",
      "```\n",
      "# Нахождение количества не нулевых элементов в каждой строке массива\n",
      "number_of_nonzero_elements_in_each_row = np.count_nonzero(array, axis=1)\n",
      "```\n",
      "106. Нахождение индексов максимального элемента в каждой строке массива:\n",
      "```\n",
      "# Нахождение индексов максимального элемента в каждой строке массива\n",
      "indices_of_max_element_in_each_row = np.argmax(array, axis=1)\n",
      "```\n",
      "107. Нахождение индексов минимального элемента в каждой строке массива:\n",
      "```\n",
      "# Нахождение индексов минимального элемента в каждой строке массива\n",
      "indices_of_min_element_in_each_row = np.argmin(array, axis=1)\n",
      "```\n",
      "108. Нахождение индексов элементов массива, удовлетворяющих заданному условию, в каждой строке:\n",
      "```\n",
      "# Нахождение индексов элементов массива, больших 0, в каждой строке\n",
      "indices = np.argwhere(array > 0)\n",
      "```\n",
      "109. Нахождение значений элементов массива, удовлетворяющих заданному условию, в каждой строке:\n",
      "```\n",
      "# Нахождение значений элементов массива, больших 0, в каждой строке\n",
      "values = array[array > 0]\n",
      "```\n",
      "110. Удаление элементов массива, удовлетворяющих заданному условию, в каждой строке:\n",
      "```\n",
      "# Удаление элементов массива, равных 0, в каждой строке\n",
      "array = np.delete(array, np.where(array == 0), axis=1)\n",
      "```\n",
      "111. Замена значений элементов массива, удовлетворяющих заданному условию, в каждой строке:\n",
      "```\n",
      "# Замена значений элементов массива, меньших 0, на 0 в каждой строке\n",
      "array[array < 0] = 0\n",
      "```\n",
      "112. Поворот массива на заданный угол:\n",
      "```\n",
      "# Поворот массива на 90 градусов\n",
      "array = np.rot90(array)\n",
      "```\n",
      "113. Отражение массива относительно заданной оси:\n",
      "```\n",
      "# Отражение массива относительно оси y\n",
      "array = np.flipud(array)\n",
      "\n",
      "# Отражение массива относительно оси x\n",
      "array = np.fliplr(array)\n",
      "```\n",
      "114. Замена отрицательных значений в массиве на заданное значение:\n",
      "```\n",
      "# Замена отрицательных значений в массиве на 0\n",
      "array = np.maximum(array, 0)\n",
      "```\n",
      "115. Замена положительных значений в массиве на заданное значение:\n",
      "```\n",
      "# Замена положительных значений в массиве на 0\n",
      "array = np.minimum(array, 0)\n",
      "```\n",
      "116. Замена нолевых значений в массиве на заданное значение:\n",
      "```\n",
      "# Замена нолевых значений в массиве на 1\n",
      "array = np.where(array == 0, 1, array)\n",
      "```\n",
      "117. Сортировка элементов массива:\n",
      "```\n",
      "# Сортировка элементов массива по возрастанию\n",
      "sorted_array = np.sort(array)\n",
      "\n",
      "# Сортировка элементов массива по убыванию\n",
      "sorted_array = np.sort(array)[::-1]\n",
      "```\n",
      "118. Нахождение уникальных значений в массиве:\n",
      "```\n",
      "# Нахождение уникальных значений в массиве\n",
      "unique_values = np.unique(array)\n",
      "```\n",
      "119. Нахождение частоты встречаемости значений в массиве:\n",
      "```\n",
      "# Нахождение частоты встречаемости значений в массиве\n",
      "frequency = np.bincount(array)\n",
      "```\n",
      "120. Проверка, является ли массив массивом одного изданных чисел:\n",
      "```\n",
      "# Проверка, является ли массив массивом одного изданных чисел\n",
      "is_single_value_array = np.all(array == array[0])\n",
      "```\n",
      "121. Проверка, является ли массив отсортированным:\n",
      "```\n",
      "# Проверка, является ли массив отсортированным\n",
      "is_sorted = np.all(np.diff(array) >= 0)\n",
      "```\n",
      "122. Преобразование массива в массив логических значений:\n",
      "```\n",
      "# Преобразование массива в массив логических значений\n",
      "bool_array = np.array([True, False, True], dtype=bool)\n",
      "```\n",
      "123. Преобразование массива логических значений в массив чисел:\n",
      "```\n",
      "# Преобразование массива логических значений в массив чисел\n",
      "number_array = bool_array.astype(int)\n",
      "```\n",
      "124. Преобразование массива в одномерный массив:\n",
      "```\n",
      "# Преобразование массива в одномерный массив\n",
      "flattened_array = array.flatten()\n",
      "```\n",
      "125. Преобразование массива в многомерный массив:\n",
      "```\n",
      "# Преобразование массива в многомерный массив\n",
      "reshaped_array = array.reshape((3, 3))\n",
      "```\n",
      "126. Транспонирование массива:\n",
      "```\n",
      "# Транспонирование массива\n",
      "transposed_array = array.transpose()\n",
      "```\n",
      "127. Нахождение количества элементов в массиве:\n",
      "```\n",
      "# Нахождение количества элементов в массиве\n",
      "number_of_elements = np.size(array)\n",
      "```\n",
      "128. Нахождение размерности массива:\n",
      "```\n",
      "# Нахождение размерности массива\n",
      "shape = np.shape(array)\n",
      "```\n",
      "129. Нахождение размера массива в байтах:\n",
      "```\n",
      "# Нахождение размера массива в байтах\n",
      "size_in_bytes = np.nbytes(array)\n",
      "```\n",
      "130. Нахождение типа данных в массиве:\n",
      "```\n",
      "# Нахождение типа данных в массиве\n",
      "data_type = array.dtype\n",
      "```\n",
      "131. Преобразование массива в массив с заданным типом данных:\n",
      "```\n",
      "# Преобразование массива в массив с типом данных float\n",
      "array = array.astype(float)\n",
      "```\n",
      "132. Нахождение максимального значения в массиве:\n",
      "```\n",
      "# Нахождение максимального значения в массиве\n",
      "max_value = np.max(array)\n",
      "```\n",
      "133. Нахождение минимального значения в массиве:\n",
      "```\n",
      "# Нахождение минимального значения в массиве\n",
      "min_value = np.min(array)\n",
      "```\n",
      "134. Нахождение среднего значения элементов массива:\n",
      "```\n",
      "# Нахождение среднего значения элементов массива\n",
      "mean_value = np.mean(array)\n",
      "```\n",
      "135. Нахождение медианы элементов массива:\n",
      "```\n",
      "# Нахождение медианы элементов массива\n",
      "median_value = np.median(array)\n",
      "```\n",
      "136. Нахождение моды элементов массива:\n",
      "```\n",
      "# Нахождение моды элементов массива\n",
      "mode_value = np.mode(array)\n",
      "```\n",
      "137. Нахождение стандартного отклонения элементов массива:\n",
      "```\n",
      "# Нахождение стандартного отклонения элементов массива\n",
      "standard_deviation = np.std(array)\n",
      "```\n",
      "138. Нахождение вариации элементов массива:\n",
      "```\n",
      "# Нахождение вариации элементов массива\n",
      "variance = np.var(array)\n",
      "```\n",
      "139. Нахождение корреляции между двумя массивами:\n",
      "```\n",
      "# Нахождение корреляции между двумя массивами\n",
      "correlation = np.corrcoef(array1, array2)[0, 1]\n",
      "```\n",
      "140. Нахождение коэффициента детерминации между двумя массивами:\n",
      "```\n",
      "# Нахождение коэффициента детерминации между двумя массивами\n",
      "coefficient_of_determination = np.square(np.corrcoef(array1, array2)[0, 1])\n",
      "```\n",
      "141. Нахождение матрицы корреляции между несколькими массивами:\n",
      "```\n",
      "# Нахождение матрицы корреляции между несколькими массивами\n",
      "correlation_matrix = np.corrcoef(array1, array2, array3)\n",
      "```\n",
      "142. Нахождение матрицы ковариации между несколькими массивами:\n",
      "```\n",
      "# Нахождение матрицы ковариации между несколькими массивами\n",
      "covariance_matrix = np.cov(array1, array2, array3)\n",
      "```\n",
      "143. Нахождение производной функции в заданных точках:\n",
      "```\n",
      "# Нахождение производной функции в заданных точках\n",
      "derivative = np.gradient(array)\n",
      "```\n",
      "144. Нахождение интеграла функции в заданных точках:\n",
      "```\n",
      "# Нахождение интеграла функции в заданных точках\n",
      "integral = np.trapz(array, x)\n",
      "```\n",
      "145. Нахождение суммы элементов массива:\n",
      "```\n",
      "# Нахождение суммы элементов массива\n",
      "sum_of_elements = np.sum(array)\n",
      "```\n",
      "146. Нахождение произведения элементов массива:\n",
      "```\n",
      "# Нахождение произведения элементов массива\n",
      "product_of_elements = np.prod(array)\n",
      "```\n",
      "147. Нахождение минимальной размерности массива:\n",
      "```\n",
      "# Нахождение минимальной размерности массива\n",
      "min_dimension = np.min(np.shape(array))\n",
      "```\n",
      "148. Нахождение максимальной размерности массива:\n",
      "```\n",
      "# Нахождение максимальной размерности массива\n",
      "max_dimension = np.max(np.shape(array))\n",
      "```\n",
      "149. Нахождение количества не нулевых элементов в массиве:\n",
      "```\n",
      "# Нахождение количества не нулевых элементов в массиве\n",
      "number_of_nonzero_elements = np.count_nonzero(array)\n",
      "```\n",
      "150. Нахождение количества уникальных элементов в массиве:\n",
      "```\n",
      "# Нахождение количества уникальных элементов в массиве\n",
      "number_of_unique_elements = np.unique(array).size\n",
      "```\n",
      "151. Нахождение максимального элемента в каждом столбце массива:\n",
      "```\n",
      "# Нахождение максимального элемента в каждом столбце массива\n",
      "max_element_in_each_column = np.max(array, axis=0)\n",
      "```\n",
      "152. Нахождение минимального элемента в каждом столбце массива:\n",
      "```\n",
      "# Нахождение минимального элемента в каждом столбце массива\n",
      "min_element_in_each_column = np.min(array, axis=0)\n",
      "```\n",
      "153. Нахождение среднего элемента в каждом столбце массива:\n",
      "```\n",
      "# Нахождение среднего элемента в каждом столбце массива\n",
      "mean_element_in_each_column = np.mean(array, axis=0)\n",
      "```\n",
      "154. Нахождение суммы элементов в каждом столбце массива:\n",
      "```\n",
      "# Нахождение суммы элементов в каждом столбце массива\n",
      "sum_of_elements_in_each_column = np.sum(array, axis=0)\n",
      "```\n",
      "155. Нахождение произведения элементов в каждом столбце массива:\n",
      "```\n",
      "# Нахождение произведения элементов в каждом столбце массива\n",
      "product_of_elements_in_each_column = np.prod(array, axis=0)\n",
      "```\n",
      "156. Нахождение количества не нулевых элементов в каждом столбце массива:\n",
      "```\n",
      "# Нахождение количества не нулевых элементов в каждом столбце массива\n",
      "number_of_nonzero_elements_in_each_column = np.count_nonzero(array, axis=0)\n",
      "```\n",
      "157. Нахождение максимального элемента в каждой строке массива:\n",
      "```\n",
      "# Нахождение максимального элемента в каждой строке массива\n",
      "max_element_in_each_row = np.max(array, axis=1)\n",
      "```\n",
      "158. Нахождение минимального элемента в каждой строке массива:\n",
      "```\n",
      "# Нахождение минимального элемента в каждой строке массива\n",
      "min_element_in_each_row = np.min(array, axis=1)\n",
      "```\n",
      "159. Нахождение среднего элемента в каждой строке массива:\n",
      "```\n",
      "# Нахождение среднего элемента в каждой строке массива\n",
      "mean_element_in_each_row = np.mean(array, axis=1)\n",
      "```\n",
      "160. Нахождение суммы элементов в каждой строке массива:\n",
      "```\n",
      "# Нахождение суммы элементов в каждой строке массива\n",
      "sum_of_elements_in_each_row = np.sum(array, axis=1)\n",
      "```\n",
      "161. Нахождение произведения элементов в каждой строке массива:\n",
      "```\n",
      "# Нахождение произведения элементов в каждой строке массива\n",
      "product_of_elements_in_each_row = np.prod(array, axis=1)\n",
      "```\n",
      "162. Нахождение количества не нулевых элементов в каждой строке массива:\n",
      "```\n",
      "# Нахождение количества не нулевых элементов в каждой строке массива\n",
      "number_of_nonzero_elements_in_each_row = np.count_nonzero(array, axis=1)\n",
      "```\n",
      "163. Нахождение индексов максимального элемента в каждой строке массива:\n",
      "```\n",
      "# Нахождение индексов максимального элемента в каждой строке массива\n",
      "indices_of_max_element_in_each_row = np.argmax(array, axis=1)\n",
      "```\n",
      "164. Нахождение индексов минимального элемента в каждой строке массива:\n",
      "```\n",
      "# Нахождение индексов минимального элемента в каждой строке массива\n",
      "indices_of_min_element_in_each_row = np.argmin(array, axis=1)\n",
      "```\n",
      "165. Нахождение индексов элементов массива, удовлетворяющих заданному условию, в каждой строке:\n",
      "```\n",
      "# Нахождение индексов элементов массива, больших 0, в каждой строке\n",
      "indices = np.argwhere(array > 0)\n",
      "```\n",
      "166. Нахождение значений элементов массива, удовлетворяющих заданному условию, в каждой строке:\n",
      "```\n",
      "# Нахождение значений элементов массива, больших 0, в каждой строке\n",
      "values = array[array > 0]\n",
      "```\n",
      "167. Удаление элементов массива, удовлетворяющих заданному условию, в каждой строке:\n",
      "```\n",
      "# Удаление элементов массива, равных 0, в каждой строке\n",
      "array = np.delete(array, np.where(array == 0), axis=1)\n",
      "```\n",
      "168. Замена значений элементов массива, удовлетворяющих заданному условию, в каждой строке:\n",
      "```\n",
      "# Замена значений элементов массива, меньших 0, на 0 в каждой строке\n",
      "array[array < 0] = 0\n",
      "```\n",
      "169. Поворот массива на заданный угол:\n",
      "```\n",
      "# Поворот массива на 90 градусов\n",
      "array = np.rot90(array)\n",
      "```\n",
      "170. Отражение массива относительно заданной оси:\n",
      "```\n",
      "# Отражение массива относительно оси y\n",
      "array = np.flipud(array)\n",
      "\n",
      "# Отражение массива относительно оси x\n",
      "array = np.fliplr(array)\n",
      "```\n",
      "171. Замена отрицательных значений в массиве на заданное значение:\n",
      "```\n",
      "# Замена отрицательных значений в массиве на 0\n",
      "array = np.maximum(array, 0)\n",
      "```\n",
      "172. Замена положительных значений в массиве на заданное значение:\n",
      "```\n",
      "# Замена положительных значений в массиве на 0\n",
      "array = np.minimum(array, 0)\n",
      "```\n",
      "173. Замена нолевых значений в массиве на заданное значение:\n",
      "```\n",
      "# Замена нолевых значений в массиве на 1\n",
      "array = np.where(array == 0, 1, array)\n",
      "```\n",
      "174. Сортировка элементов массива:\n",
      "```\n",
      "# Сортировка элементов массива по возрастанию\n",
      "sorted_array = np.sort(array)\n",
      "\n",
      "# Сортировка элементов массива по убыванию\n",
      "sorted_array = np.sort(array)[::-1]\n",
      "```\n",
      "175. Нахождение уникальных значений в массиве:\n",
      "```\n",
      "# Нахождение уникальных значений в массиве\n",
      "unique_values = np.unique(array)\n",
      "```\n",
      "176. Нахождение частоты встречаемости значений в массиве:\n",
      "```\n",
      "# Нахождение частоты встречаемости значений в массиве\n",
      "frequency = np.bincount(array)\n",
      "```\n",
      "177. Проверка, является ли массив массивом одного изданных чисел:\n",
      "```\n",
      "# Проверка, является ли массив массивом одного изданных чисел\n",
      "is_single_value_array = np.all(array == array[0])\n",
      "```\n",
      "178. Проверка, является ли массив отсортированным:\n",
      "```\n",
      "# Проверка, является ли массив отсортированным\n",
      "is_sorted = np.all(np.diff(array) >= 0)\n",
      "```\n",
      "179. Преобразование массива в массив логических значений:\n",
      "```\n",
      "# Преобразование массива в массив логических значений\n",
      "bool_array = np.array([True, False, True], dtype=bool)\n",
      "```\n",
      "180. Преобразование массива логических значений в массив чисел:\n",
      "```\n",
      "# Преобразование массива логических значений в массив чисел\n",
      "number_array = bool_array.astype(int)\n",
      "```\n",
      "181. Преобразование массива в одномерный массив:\n",
      "```\n",
      "# Преобразование массива в одномерный массив\n",
      "flattened_array = array.flatten()\n",
      "```\n",
      "182. Преобразование массива в многомерный массив:\n",
      "```\n",
      "# Преобразование массива в многомерный массив\n",
      "reshaped_array = array.reshape((3, 3))\n",
      "```\n",
      "183. Транспонирование массива:\n",
      "```\n",
      "# Транспонирование массива\n",
      "transposed_array = array.transpose()\n",
      "```\n",
      "184. Нахождение количества элементов в массиве:\n",
      "```\n",
      "# Нахождение количества элементов в массиве\n",
      "number_of_elements = np.size(array)\n",
      "```\n",
      "185. Нахождение размерности массива:\n",
      "```\n",
      "# Нахождение размерности массива\n",
      "shape = np.shape(array)\n",
      "```\n",
      "186. Нахождение размера массива в байтах:\n",
      "```\n",
      "# Нахождение размера массива в байтах\n",
      "size_in_bytes = np.nbytes(array)\n",
      "```\n",
      "187. Нахождение типа данных в массиве:\n",
      "```\n",
      "# Нахождение типа данных в массиве\n",
      "data_type = array.dtype\n",
      "```\n",
      "188. Преобразование массива в массив с заданным типом данных:\n",
      "```\n",
      "# Преобразование массива в массив с типом данных float\n",
      "array = array.astype(float)\n",
      "```\n",
      "189. Нахождение максимального значения в массиве:\n",
      "```\n",
      "# Нахождение максимального значения в массиве\n",
      "max_value = np.max(array)\n",
      "```\n",
      "190. Нахождение минимального значения в массиве:\n",
      "```\n",
      "# Нахождение минимального значения в массиве\n",
      "min_value = np.min(array)\n",
      "```\n",
      "191. Нахождение среднего значения элементов массива:\n",
      "```\n",
      "# Нахождение среднего значения элементов массива\n",
      "mean_value = np.mean(array)\n",
      "```\n",
      "192. Нахождение медианы элементов массива:\n",
      "```\n",
      "# Нахождение медианы элементов массива\n",
      "median_value = np.median(array)\n",
      "```\n",
      "193. Нахождение моды элементов массива:\n",
      "```\n",
      "# Нахождение моды элементов массива\n",
      "mode_value = np.mode(array)\n",
      "```\n",
      "194. Нахождение стандартного отклонения элементов массива:\n",
      "```\n",
      "# Нахождение стандартного отклонения элементов массива\n",
      "standard_deviation = np.std(array)\n",
      "```\n",
      "195. Нахождение вариации элементов массива:\n",
      "```\n",
      "# Нахождение вариации элементов массива\n",
      "variance = np.var(array)\n",
      "```\n",
      "196. Нахождение корреляции между двумя массивами:\n",
      "```\n",
      "# Нахождение корреляции между двумя массивами\n",
      "correlation = np.corrcoef(array1, array2)[0, 1]\n",
      "```\n",
      "197. Нахождение коэффициента детерминации между двумя массивами:\n",
      "```\n",
      "# Нахождение коэффициента детерминации между двумя массивами\n",
      "coefficient_of_determination = np.square(np.corrcoef(array1, array2)[0, 1])\n",
      "```\n",
      "198. Нахождение матрицы корреляции между несколькими массивами:\n",
      "```\n",
      "# Нахождение матрицы корреляции между несколькими массивами\n",
      "correlation_matrix = np.corrcoef(array1, array2, array3)\n",
      "```\n",
      "199. Нахождение матрицы ковариации между несколькими массивами:\n",
      "```\n",
      "# Нахождение матрицы ковариации между несколькими массивами\n",
      "covariance_matrix = np.cov(array1, array2, array3)\n",
      "```\n",
      "200. Нахождение производной функции в заданных точках:\n",
      "```\n",
      "# Нахождение производной функции в заданных точках\n",
      "derivative = np.gradient(array)\n",
      "```\n",
      "201. Нахождение интеграла функции в заданных точках:\n",
      "```\n",
      "# Нахождение интеграла функции в заданных точках\n",
      "integral = np.trapz(array, x)\n",
      "```\n",
      "202. Нахождение суммы элементов массива:\n",
      "```\n",
      "# Нахождение суммы элементов массива\n",
      "sum_of_elements = np.sum(array)\n",
      "```\n",
      "203. Нахождение произведения элементов массива:\n",
      "```\n",
      "# Нахождение произведения элементов массива\n",
      "product_of_elements = np.prod(array)\n",
      "```\n",
      "204. Нахождение минимальной размерности массива:\n",
      "```\n",
      "# Нахождение минимальной размерности массива\n",
      "min_dimension = np.min(np.shape(array))\n",
      "```\n",
      "205. Нахождение максимальной размерности массива:\n",
      "```\n",
      "# Нахождение максимальной размерности массива\n",
      "max_dimension = np.max(np.shape(array))\n",
      "```\n",
      "206. Нахождение количества не нулевых элементов в массиве:\n",
      "```\n",
      "# Нахождение количества не нулевых элементов в массиве\n",
      "number_of_nonzero_elements = np.count_nonzero(array)\n",
      "```\n",
      "207. Нахождение количества уникальных элементов в массиве:\n",
      "```\n",
      "# Нахождение количества уникальных элементов в массиве\n",
      "number_of_unique_elements = np.unique(array).size\n",
      "```\n",
      "208. Нахождение максимального элемента в каждом столбце массива:\n",
      "```\n",
      "# Нахождение максимального элемента в каждом столбце массива\n",
      "max_element_in_each_column = np.max(array, axis=0)\n",
      "```\n",
      "209. Нахождение минимального элемента в каждом столбце массива:\n",
      "```\n",
      "# Нахождение минимального элемента в каждом столбце массива\n",
      "min_element_in_each_column = np.min(array, axis=0)\n",
      "```\n",
      "210. Нахождение среднего элемента в каждом столбце массива:\n",
      "```\n",
      "# Нахождение среднего элемента в каждом столбце массива\n",
      "mean_element_in_each_column = np.mean(array, axis=0)\n",
      "```\n",
      "211. Нахождение суммы элементов в каждом столбце массива:\n",
      "```\n",
      "# Нахождение суммы элементов в каждом столбце массива\n",
      "sum_of_elements_in_each_column = np.sum(array, axis=0)\n",
      "```\n",
      "212. Нахождение произведения элементов в каждом столбце массива:\n",
      "```\n",
      "# Нахождение произведения элементов в каждом столбце массива\n",
      "product_of_elements_in_each_column = np.prod(array, axis=0)\n",
      "```\n",
      "213. Нахождение количества не нулевых элементов в каждом столбце массива:\n",
      "```\n",
      "# Нахождение количества не нулевых элементов в каждом столбце массива\n",
      "number_of_nonzero_elements_in_each_column = np.count_nonzero(array, axis=0)\n",
      "```\n",
      "214. Нахождение максимального элемента в каждой строке массива:\n",
      "```\n",
      "# Нахождение максимального элемента в каждой строке массива\n",
      "max_element_in_each_row = np.max(array, axis=1)\n",
      "```\n",
      "215. Нахождение минимального элемента в каждой строке массива:\n",
      "```\n",
      "# Нахождение минимального элемента в каждой строке массива\n",
      "min_element_in_each_row = np.min(array, axis=1)\n",
      "```\n",
      "216. Нахождение среднего элемента в каждой строке массива:\n",
      "```\n",
      "# Нахождение среднего элемента в каждой строке массива\n",
      "mean_element_in_each_row = np.mean(array, axis=1)\n",
      "```\n",
      "217. Нахождение суммы элементов в каждой строке массива:\n",
      "```\n",
      "# Нахождение суммы элементов в каждой строке массива\n",
      "sum_of_elements_in_each_row = np.sum(array, axis=1)\n",
      "```\n",
      "218. Нахождение произведения элементов в каждой строке массива:\n",
      "```\n",
      "# Нахождение произведения элементов в каждой строке массива\n",
      "product_of_elements_in_each_row = np.prod(array, axis=1)\n",
      "```\n",
      "219. Нахождение количества не нулевых элементов в каждой строке массива:\n",
      "```\n",
      "# Нахождение количества не нулевых элементов в каждой строке массива\n",
      "number_of_nonzero_elements_in_each_row = np.count_nonzero(array, axis=1)\n",
      "```\n",
      "220. Нахождение индексов максимального элемента в каждой строке массива:\n",
      "```\n",
      "# Нахождение индексов максимального элемента в каждой строке массива\n",
      "indices_of_max_element_in_each_row = np.argmax(array, axis=1)\n",
      "```\n",
      "221. Нахождение индексов минимального элемента в каждой строке массива:\n",
      "```\n",
      "# Нахождение индексов минимального элемента в каждой строке массива\n",
      "indices_of_min_element_in_each_row = np.argmin(array, axis=1)\n",
      "```\n",
      "222. Нахождение индексов элементов массива, удовлетворяющих заданному условию, в каждой строке:\n",
      "```\n",
      "# Нахождение индексов элементов массива, больших 0, в каждой строке\n",
      "indices = np.argwhere(array > 0)\n",
      "```\n",
      "223. Нахождение значений элементов массива, удовлетворяющих заданному условию, в каждой строке:\n",
      "```\n",
      "# Нахождение значений элементов массива, больших 0, в каждой строке\n",
      "values = array[array > 0]\n",
      "```\n",
      "224. Удаление элементов массива, удовлетворяющих заданному условию, в каждой строке:\n",
      "```\n",
      "# Удаление элементов массива, равных 0, в каждой строке\n",
      "array = np.delete(array, np.where(array == 0), axis=1)\n",
      "```\n",
      "225. Замена значений элементов массива, удовлетворяющих заданному условию, в каждой строке:\n",
      "```\n",
      "# Замена значений элементов массива, меньших 0, на 0 в каждой строке\n",
      "array[array < 0] = 0\n",
      "```\n",
      "226. Поворот массива на заданный угол:\n",
      "```\n",
      "# Поворот массива на 90 градусов\n",
      "array = np.rot90(array)\n",
      "```\n",
      "227. Отражение массива относительно заданной оси:\n",
      "```\n",
      "# Отражение массива относительно оси y\n",
      "array = np.flipud(array)\n",
      "\n",
      "# Отражение массива относительно оси x\n",
      "array = np.fliplr(array)\n",
      "```\n",
      "228. Замена отрицательных значений в массиве на заданное значение:\n",
      "```\n",
      "# Замена отрицательных значений в массиве на 0\n",
      "array = np.maximum(array, 0)\n",
      "```\n",
      "229. Замена положительных значений в массиве на заданное значение:\n",
      "```\n",
      "# Замена положительных значений в массиве на 0\n",
      "array = np.minimum(array, 0)\n",
      "```\n",
      "230. Замена нолевых значений в массиве на заданное значение:\n",
      "```\n",
      "# Замена нолевых значений в массиве на 1\n",
      "array = np.where(array == 0, 1, array)\n",
      "```\n",
      "231. Сортировка элементов массива:\n",
      "```\n",
      "# Сортировка элементов массива по возрастанию\n",
      "sorted_array = np.sort(array)\n",
      "\n",
      "# Сортировка элементов массива по убыванию\n",
      "sorted_array = np.sort(array)[::-1]\n",
      "```\n",
      "232. Нахождение уникальных значений в массиве:\n",
      "```\n",
      "# Нахождение уникальных значений в массиве\n",
      "unique_values = np.unique(array)\n",
      "```\n",
      "233. Нахождение частоты встречаемости значений в массиве:\n",
      "```\n",
      "# Нахождение частоты встречаемости значений в массиве\n",
      "frequency = np.bincount(array)\n",
      "```\n",
      "234. Проверка, является ли массив массивом одного изданных чисел:\n",
      "```\n",
      "# Проверка, является ли массив массивом одного изданных чисел\n",
      "is_single_value_array = np.all(array == array[0])\n",
      "```\n",
      "235. Проверка, является ли массив отсортированным:\n",
      "```\n",
      "# Проверка, является ли массив отсортированным\n",
      "is_sorted = np.all(np.diff(array) >= 0)\n",
      "```\n",
      "236. Преобразование массива в массив логических значений:\n",
      "```\n",
      "# Преобразование массива в массив логических значений\n",
      "bool_array = np.array([True, False, True], dtype=bool)\n",
      "```\n",
      "237. Преобразование массива логических значений в массив чисел:\n",
      "```\n",
      "# Преобразование массива логических значений в массив чисел\n",
      "number_array = bool_array.astype(int)\n",
      "```\n",
      "238. Преобразование массива в одномерный массив:\n",
      "```\n",
      "# Преобразование массива в одномерный массив\n",
      "flattened_array = array.flatten()\n",
      "```\n",
      "239. Преобразование массива в многомерный массив:\n",
      "```\n",
      "# Преобразование массива в многомерный массив\n",
      "reshaped_array = array.reshape((3, 3))\n",
      "```\n",
      "240. Транспонирование массива:\n",
      "```\n",
      "# Транспонирование массива\n",
      "transposed_array = array.transpose()\n",
      "```\n",
      "241. Нахождение количества элементов в массиве:\n",
      "```\n",
      "# Нахождение количества элементов в массиве\n",
      "number_of_elements = np.size(array)\n",
      "```\n",
      "242. Нахождение размерности массива:\n",
      "```\n",
      "# Нахождение размерности массива\n",
      "shape = np.shape(array)\n",
      "```\n",
      "243. Нахождение размера массива в байтах:\n",
      "```\n",
      "# Нахождение размера массива в байтах\n",
      "size_in_bytes = np.nbytes(array)\n",
      "```\n",
      "244. Нахождение типа данных в массиве:\n",
      "```\n",
      "# Нахождение типа данных в массиве\n",
      "data_type = array.dtype\n",
      "```\n",
      "245. Преобразование массива в массив с заданным типом данных:\n",
      "```\n",
      "# Преобразование массива в массив с типом данных float\n",
      "array = array.astype(float)\n",
      "```\n",
      "246. Нахождение максимального значения в массиве:\n",
      "```\n",
      "# Нахождение максимального значения в массиве\n",
      "max_value = np.max(array)\n",
      "```\n",
      "247. Нахождение минимального значения в массиве:\n",
      "```\n",
      "# Нахождение минимального значения в массиве\n",
      "min_value = np.min(array)\n",
      "```\n",
      "248. Нахождение среднего значения элементов массива:\n",
      "```\n",
      "# Нахождение среднего значения элементов массива\n",
      "mean_value = np.mean(array)\n",
      "```\n",
      "249. Нахождение медианы элементов массива:\n",
      "```\n",
      "# Нахождение медианы элементов массива\n",
      "median_value = np.median(array)\n",
      "```\n",
      "250. Нахождение моды элементов массива:\n",
      "```\n",
      "# Нахождение моды элементов массива\n",
      "mode_value = np.mode(array)\n",
      "```\n",
      "251. Нахождение стандартного отклонения элементов массива:\n",
      "```\n",
      "# Нахождение стандартного отклонения элементов массива\n",
      "standard_deviation = np.std(array)\n",
      "```\n",
      "252. Нахождение вариации элементов массива:\n",
      "```\n",
      "# Нахождение вариации элементов массива\n",
      "variance = np.var(array)\n",
      "```\n",
      "253. Нахождение корреляции между двумя массивами:\n",
      "```\n",
      "# Нахождение корреляции между двумя массивами\n",
      "correlation = np.corrcoef(array1, array2)[0, 1]\n",
      "```\n",
      "254. Нахождение коэффициента детерминации между двумя массивами:\n",
      "```\n",
      "# Нахождение коэффициента детерминации между двумя массивами\n",
      "coefficient_of_determination = np.square(np.corrcoef(array1, array2)[0, 1])\n",
      "```\n",
      "255. Нахождение матрицы корреляции между несколькими массивами:\n",
      "```\n",
      "# Нахождение матрицы корреляции между несколькими массивами\n",
      "correlation_matrix = np.corrcoef(array1, array2, array3)\n",
      "```\n",
      "256. Нахождение матрицы ковариации между несколькими массивами:\n",
      "```\n",
      "# Нахождение матрицы ковариации между несколькими массивами\n",
      "covariance_matrix = np.cov(array1, array2, array3)\n",
      "```\n",
      "257. Нахождение производной функции в заданных точках:\n",
      "```\n",
      "# Нахождение производной функции в заданных точках\n",
      "derivative = np.gradient(array)\n",
      "```\n",
      "258. Нахождение интеграла функции в заданных точках:\n",
      "```\n",
      "# Нахождение интеграла функции в заданных точках\n",
      "integral = np.trapz(array, x)\n",
      "```\n",
      "259. Нахождение суммы элементов массива:\n",
      "```\n",
      "# Нахождение суммы элементов массива\n",
      "sum_of_elements = np.sum(array)\n",
      "```\n",
      "260. Нахождение произведения элементов массива:\n",
      "```\n",
      "# Нахождение произведения элементов массива\n",
      "product_of_elements = np.prod(array)\n",
      "```\n",
      "261. Нахождение минимальной размерности массива:\n",
      "```\n",
      "# Нахождение минимальной размерности массива\n",
      "min_dimension = np.min(np.shape(array))\n",
      "```\n",
      "262. Нахождение максимальной размерности массива:\n",
      "```\n",
      "# Нахождение максимальной размерности массива\n",
      "max_dimension = np.max(np.shape(array))\n",
      "```\n",
      "263. Нахождение количества не нулевых элементов в массиве:\n",
      "```\n",
      "# Нахождение количества не нулевых элементов в массиве\n",
      "number_of_nonzero_elements = np.count_nonzero(array)\n",
      "```\n",
      "264. Нахождение количества уникальных элементов в массиве:\n",
      "```\n",
      "# Нахождение количества уникальных элементов в массиве\n",
      "number_of_unique_elements = np.unique(array).size\n",
      "```\n",
      "265. Нахождение максимального элемента в каждом столбце массива:\n",
      "```\n",
      "# Нахождение максимального элемента в каждом столбце массива\n",
      "max_element_in_each_column = np.max(array, axis=0)\n",
      "```\n",
      "266. Нахождение минимального элемента в каждом столбце массива:\n",
      "```\n",
      "# Нахождение минимального элемента в каждом столбце массива\n",
      "min_element_in_each_column = np.min(array, axis=0)\n",
      "```\n",
      "267. Нахождение среднего элемента в каждом столбце массива:\n",
      "```\n",
      "# Нахождение среднего элемента в каждом столбце массива\n",
      "mean_element_in_each_column = np.mean(array, axis=0)\n",
      "```\n",
      "268. Нахождение суммы элементов в каждом столбце массива:\n",
      "```\n",
      "# Нахождение суммы элементов в каждом столбце массива\n",
      "sum_of_elements_in_each_column = np.sum(array, axis=0)\n",
      "```\n",
      "269. Нахождение произведения элементов в каждом столбце массива:\n",
      "```\n",
      "# Нахождение произведения элементов в каждом столбце массива\n",
      "product_of_elements_in_each_column = np.prod(array, axis=0)\n",
      "```\n",
      "270. Нахождение количества не нулевых элементов в каждом столбце массива:\n",
      "```\n",
      "# Нахождение количества не нулевых элементов в каждом столбце массива\n",
      "number_of_nonzero_elements_in_each_column = np.count_nonzero(array, axis=0)\n",
      "```\n",
      "271. Нахождение максимального элемента в каждой строке массива:\n",
      "```\n",
      "# Нахождение максимального элемента в каждой строке массива\n",
      "max_element_in_each_row = np.max(array, axis=1)\n",
      "```\n",
      "272. Нахождение минимального элемента в каждой строке массива:\n",
      "```\n",
      "# Нахождение минимального элемента в каждой строке массива\n",
      "min_element_in_each_row = np.min(array, axis=1)\n",
      "```\n",
      "273. Нахождение среднего элемента в каждой строке массива:\n",
      "```\n",
      "# Нахождение среднего элемента в каждой строке массива\n",
      "mean_element_in_each_row = np.mean(array, axis=1)\n",
      "```\n",
      "274. Нахождение суммы элементов в каждой строке массива:\n",
      "```\n",
      "# Нахождение суммы элементов в каждой строке массива\n",
      "sum_of_elements_in_each_row = np.sum(array, axis=1)\n",
      "```\n",
      "275. Нахождение произведения элементов в каждой строке массива:\n",
      "```\n",
      "# Нахождение произведения элементов в каждой строке массива\n",
      "product_of_elements_in_each_row = np.prod(array, axis=1)\n",
      "```\n",
      "276. Нахождение количества не нулевых элементов в каждой строке массива:\n",
      "```\n",
      "# Нахождение количества не нулевых элементов в каждой строке массива\n",
      "number_of_nonzero_elements_in_each_row = np.count_nonzero(array, axis=1)\n",
      "```\n",
      "277. Нахождение индексов максимального элемента в каждой строке массива:\n",
      "```\n",
      "# Нахождение индексов максимального элемента в каждой строке массива\n",
      "indices_of_max_element_in_each_row = np.argmax(array, axis=1)\n",
      "```\n",
      "278. Нахождение индексов минимального элемента в каждой строке массива:\n",
      "```\n",
      "# Нахождение индексов минимального элемента в каждой строке массива\n",
      "indices_of_min_element_in_each_row = np.argmin(array, axis=1)\n",
      "```\n",
      "279. Нахождение индексов элементов массива, удовлетворяющих заданному условию, в каждой строке:\n",
      "```\n",
      "# Нахождение индексов элементов массива, больших 0, в каждой строке\n",
      "indices = np.argwhere(array > 0)\n",
      "```\n",
      "280. Нахождение значений элементов массива, удовлетворяющих заданному условию, в каждой строке:\n",
      "```\n",
      "# Нахождение значений элементов массива, больших 0, в каждой строке\n",
      "values = array[array > 0]\n",
      "```\n",
      "281. Удаление элементов массива, удовлетворяющих заданному условию, в каждой строке:\n",
      "```\n",
      "# Удаление элементов массива, равных 0, в каждой строке\n",
      "array = np.delete(array, np.where(array == 0), axis=1)\n",
      "```\n",
      "282. Замена значений элементов массива, удовлетворяющих заданному условию, в каждой строке:\n",
      "```\n",
      "# Замена значений элементов массива, меньших 0, на 0 в каждой строке\n",
      "array[array < 0] = 0\n",
      "```\n",
      "283. Поворот массива на заданный угол:\n",
      "```\n",
      "# Поворот массива на 90 градусов\n",
      "array = np.rot90(array)\n",
      "```\n",
      "284. Отражение массива относительно заданной оси:\n",
      "```\n",
      "# Отражение массива относительно оси y\n",
      "array = np.flipud(array)\n",
      "\n",
      "# Отражение массива относительно оси x\n",
      "array = np.fliplr(array)\n",
      "```\n",
      "285. Замена отрицательных значений в массиве на заданное значение:\n",
      "```\n",
      "# Замена отрицательных значений в массиве на 0\n",
      "array = np.maximum(array, 0)\n",
      "```\n",
      "286. Замена положительных значений в массиве на заданное значение:\n",
      "```\n",
      "# Замена положительных значений в массиве на 0\n",
      "array = np.minimum(array, 0)\n",
      "```\n",
      "287. Замена нолевых значений в массиве на заданное значение:\n",
      "```\n",
      "# Замена нолевых значений в массиве на 1\n",
      "array = np.where(array == 0, 1, array)\n",
      "```\n",
      "288. Сортировка элементов массива:\n",
      "```\n",
      "# Сортировка элементов массива по возрастанию\n",
      "sorted_array = np.sort(array)\n",
      "\n",
      "# Сортировка элементов массива по убыванию\n",
      "sorted_array = np.sort(array)[::-1]\n",
      "```\n",
      "289. Нахождение уникальных значений в массиве:\n",
      "```\n",
      "# Нахождение уникальных значений в массиве\n",
      "unique_values = np.unique(array)\n",
      "```\n",
      "290. Нахождение частоты встречаемости значений в массиве:\n",
      "```\n",
      "# Нахождение частоты встречаемости значений в массиве\n",
      "frequency = np.bincount(array)\n",
      "```\n",
      "291. Проверка, является ли массив массивом одного изданных чисел:\n",
      "```\n",
      "# Проверка, является ли массив массивом одного изданных чисел\n",
      "is_single_value_array = np.all(array == array[0])\n",
      "```\n",
      "292. Проверка, является ли массив отсортированным:\n",
      "```\n",
      "# Проверка, является ли массив отсортированным\n",
      "is_sorted = np.all(np.diff(array) >= 0)\n",
      "```\n",
      "293. Преобразование массива в массив логических значений:\n",
      "```\n",
      "# Преобразование массива в массив логических значений\n",
      "bool_array = np.array([True, False, True], dtype=bool)\n",
      "```\n",
      "294. Преобразование массива логических значений в массив чисел:\n",
      "```\n",
      "# Преобразование массива логических значений в массив чисел\n",
      "number_array = bool_array.astype(int)\n",
      "```\n",
      "295. Преобразование массива в одномерный массив:\n",
      "```\n",
      "# Преобразование массива в одномерный массив\n",
      "flattened_array = array.flatten()\n",
      "```\n",
      "296. Преобразование массива в многомерный массив:\n",
      "```\n",
      "# Преобразование массива в многомерный массив\n",
      "reshaped_array = array.reshape((3, 3))\n",
      "```\n",
      "297. Транспонирование массива:\n",
      "```\n",
      "# Транспонирование массива\n",
      "transposed_array = array.transpose()\n",
      "```\n",
      "298. Нахождение количества элементов в массиве:\n",
      "```\n",
      "# Нахождение количества элементов в массиве\n",
      "number_of_elements = np.size(array)\n",
      "```\n",
      "299. Нахождение размерности массива:\n",
      "```\n",
      "# Нахождение размерности массива\n",
      "shape = np.shape(array)\n",
      "```\n",
      "300. Нахождение размера массива в байтах:\n",
      "```\n",
      "# Нахождение размера массива в байтах\n",
      "size_in_bytes = np.nbytes(array)\n",
      "```\n",
      "301. Нахождение типа данных в массиве:\n",
      "```\n",
      "# Нахождение типа данных в массиве\n",
      "data_type = array.dtype\n",
      "```\n",
      "302. Преобразование массива в массив с заданным типом данных:\n",
      "```\n",
      "# Преобразование массива в массив с типом данных float\n",
      "array = array.astype(float)\n",
      "```\n",
      "303. Нахождение максимального значения в массиве:\n",
      "```\n",
      "# Нахождение максимального значения в массиве\n",
      "max_value = np.max(array)\n",
      "```\n",
      "304. Нахождение минимального значения в массиве:\n",
      "```\n",
      "# Нахождение минимального значения в массиве\n",
      "min_value = np.min(array)\n",
      "```\n",
      "305. Нахождение среднего значения элементов массива:\n",
      "```\n",
      "# Нахождение среднего значения элементов массива\n",
      "mean_value = np.mean(array)\n",
      "```\n",
      "306. Нахождение медианы элементов массива:\n",
      "```\n",
      "# Нахождение медианы элементов массива\n",
      "median_value = np.median(array)\n",
      "```\n",
      "307. Нахождение моды элементов массива:\n",
      "```\n",
      "# Нахождение моды элементов массива\n",
      "mode_value = np.mode(array)\n",
      "```\n",
      "308. Нахождение стандартного отклонения элементов массива:\n",
      "```\n",
      "# Нахождение стандартного отклонения элементов массива\n",
      "standard_deviation = np.std(array)\n",
      "```\n",
      "309. Нахождение вариации элементов массива:\n",
      "```\n",
      "# Нахождение вариации элементов массива\n",
      "variance = np.var(array)\n",
      "```\n",
      "310. Нахождение корреляции между двумя массивами:\n",
      "```\n",
      "# Нахождение корреляции между двумя массивами\n",
      "correlation = np.corrcoef(array1, array2)[0, 1]\n",
      "```\n",
      "311. Нахождение коэффициента детерминации между двумя массивами:\n",
      "```\n",
      "# Нахождение коэффициента детерминации между двумя массивами\n",
      "coefficient_of_determination = np.square(np.corrcoef(array1, array2)[0, 1])\n",
      "```\n",
      "312. Нахождение матрицы корреляции между несколькими массивами:\n",
      "```\n",
      "# Нахождение матрицы корреляции между несколькими массивами\n",
      "correlation_matrix = np.corrcoef(array1, array2, array3)\n",
      "```\n",
      "313. Нахождение матрицы ковариации между несколькими массивами:\n",
      "```\n",
      "# Нахождение матрицы ковариации между несколькими массивами\n",
      "covariance_matrix = np.cov(array1, array2, array3)\n",
      "```\n",
      "314. Нахождение производной функции в заданных точках:\n",
      "```\n",
      "# Нахождение производной функции в заданных точках\n",
      "derivative = np.gradient(array)\n",
      "```\n",
      "315. Нахождение интеграла функции в заданных точках:\n",
      "```\n",
      "# Нахождение интеграла функции в заданных точках\n",
      "integral = np.trapz(array, x)\n",
      "```\n",
      "316. Нахождение суммы элементов массива:\n",
      "```\n",
      "# Нахождение суммы элементов массива\n",
      "sum_of_elements = np.sum(array)\n",
      "```\n",
      "317. Нахождение произведения элементов массива:\n",
      "```\n",
      "# Нахождение произведения элементов массива\n",
      "product_of_elements = np.prod(array)\n",
      "```\n",
      "318. Нахождение минимальной размерности массива:\n",
      "```\n",
      "# Нахождение минимальной размерности массива\n",
      "min_dimension = np.min(np.shape(array))\n",
      "```\n",
      "319. Нахождение максимальной размерности массива:\n",
      "```\n",
      "# Нахождение максимальной размерности массива\n",
      "max_dimension = np.max(np.shape(array))\n",
      "```\n",
      "320. Нахождение количества не нулевых элементов в массиве:\n",
      "```\n",
      "# Нахождение количества не нулевых элементов в массиве\n",
      "number_of_nonzero_elements = np.count_nonzero(array)\n",
      "```\n",
      "321. Нахождение количества уникальных элементов в массиве:\n",
      "```\n",
      "# Нахождение количества уникальных элементов в массиве\n",
      "number_of_unique_elements = np.unique(array).size\n",
      "```\n",
      "322. Нахождение максимального элемента в каждом столбце массива:\n",
      "```\n",
      "# Нахождение максимального элемента в каждом столбце массива\n",
      "max_element_in_each_column = np.max(array, axis=0)\n",
      "```\n",
      "323. Нахождение минимального элемента в каждом столбце массива:\n",
      "```\n",
      "# Нахождение минимального элемента в каждом столбце массива\n",
      "min_element_in_each_column = np.min(array, axis=0)\n",
      "```\n",
      "324. Нахождение среднего элемента в каждом столбце массива:\n",
      "```\n",
      "# Нахождение среднего элемента в каждом столбце массива\n",
      "mean_element_in_each_column = np.mean(array, axis=0)\n",
      "```\n",
      "325. Нахождение суммы элементов в каждом столбце массива:\n",
      "```\n",
      "# Нахождение суммы элементов в каждом столбце массива\n",
      "sum_of_elements_in_each_column = np.sum(array, axis=0)\n",
      "```\n",
      "326. Нахождение произведения элементов в каждом столбце массива:\n",
      "```\n",
      "# Нахождение произведения элементов в каждом столбце массива\n",
      "product_of_elements_in_each_column = np.prod(array, axis=0)\n",
      "```\n",
      "327. Нахождение количества не нулевых элементов в каждом столбце массива:\n",
      "```\n",
      "# Нахождение количества не нулевых элементов в каждом столбце массива\n",
      "number_of_nonzero_elements_in_each_column = np.count_nonzero(array, axis=0)\n",
      "```\n",
      "328. Нахождение максимального элемента в каждой строке массива:\n",
      "```\n",
      "# Нахождение максимального элемента в каждой строке массива\n",
      "max_element_in_each_row = np.max(array, axis=1)\n",
      "```\n",
      "329. Нахождение минимального элемента в каждой строке массива:\n",
      "```\n",
      "# Нахождение минимального элемента в каждой строке массива\n",
      "min_element_in_each_row = np.min(array, axis=1)\n",
      "```\n",
      "330. Нахождение среднего элемента в каждой строке массива:\n",
      "```\n",
      "# Нахождение среднего элемента в каждой строке массива\n",
      "mean_element_in_each_row = np.mean(array, axis=1)\n",
      "```\n",
      "331. Нахождение суммы элементов в каждой строке массива:\n",
      "```\n",
      "# Нахождение суммы элементов в каждой строке массива\n",
      "sum_of_elements_in_each_row = np.sum(array, axis=1)\n",
      "```\n",
      "332. Нахождение произведения элементов в каждой строке массива:\n",
      "```\n",
      "# Нахождение произведения элементов в каждой строке массива\n",
      "product_of_elements_in_each_row = np.prod(array, axis=1)\n",
      "```\n",
      "333. Нахождение количества не нулевых элементов в каждой строке массива:\n",
      "```\n",
      "# Нахождение количества не нулевых элементов в каждой строке массива\n",
      "number_of_nonzero_elements_in_each_row = np.count_nonzero(array, axis=1)\n",
      "```\n",
      "334. Нахождение индексов максимального элемента в каждой строке массива:\n",
      "```\n",
      "# Нахождение индексов максимального элемента в каждой строке массива\n",
      "indices_of_max_element_in_each_row = np.argmax(array, axis=1)\n",
      "```\n",
      "335. Нахождение индексов минимального элемента в каждой строке массива:\n",
      "```\n",
      "# Нахождение индексов минимального элемента в каждой строке массива\n",
      "indices_of_min_element_in_each_row = np.argmin(array, axis=1)\n",
      "```\n",
      "336. Нахождение индексов элементов массива, удовлетворяющих заданному условию, в каждой строке:\n",
      "```\n",
      "# Нахождение индексов элементов массива, больших 0, в каждой строке\n",
      "indices = np.argwhere(array > 0)\n",
      "```\n",
      "337. Нахождение значений элементов массива, удовлетворяющих заданному условию, в каждой строке:\n",
      "```\n",
      "# Нахождение значений элементов массива, больших 0, в каждой строке\n",
      "values = array[array > 0]\n",
      "```\n",
      "338. Удаление элементов массива, удовлетворяющих заданному условию, в каждой строке:\n",
      "```\n",
      "# Удаление элементов массива, равных 0, в каждой строке\n",
      "array = np.delete(array, np.where(array == 0), axis=1)\n",
      "```\n",
      "339. Замена значений элементов массива, удовлетворяющих заданному условию, в каждой строке:\n",
      "```\n",
      "# Замена значений элементов массива, меньших 0, на 0 в каждой строке\n",
      "array[array < 0] = 0\n",
      "```\n",
      "340. Поворот массива на заданный угол:\n",
      "```\n",
      "# Поворот массива на 90 градусов\n",
      "array = np.rot90(array)\n",
      "```\n",
      "341. Отражение массива относительно заданной оси:\n",
      "```\n",
      "# Отражение массива относительно оси y\n",
      "array = np.flipud(array)\n",
      "\n",
      "# Отражение массива относительно оси x\n",
      "array = np.fliplr(array)\n",
      "```\n",
      "342. Замена отрицательных значений в массиве на заданное значение:\n",
      "```\n",
      "# Замена отрицательных значений в массиве на 0\n",
      "array = np.maximum(array, 0)\n",
      "```\n",
      "343. Замена положительных значений в массиве на заданное значение:\n",
      "```\n",
      "# Замена положительных значений в массиве на 0\n",
      "array = np.minimum(array, 0)\n",
      "```\n",
      "344. Замена нолевых значений в массиве на заданное значение:\n",
      "```\n",
      "# Замена нолевых значений в массиве на 1\n",
      "array = np.where(array == 0, 1, array)\n",
      "```\n",
      "345. Сортировка элементов массива:\n",
      "```\n",
      "# Сортировка элементов массива по возрастанию\n",
      "sorted_array = np.sort(array)\n",
      "\n",
      "# Сортировка элементов массива по убыванию\n",
      "sorted_array = np.sort(array)[::-1]\n",
      "```\n",
      "346. Нахождение уникальных значений в массиве:\n",
      "```\n",
      "# Нахождение уникальных значений в массиве\n",
      "unique_values = np.unique(array)\n",
      "```\n",
      "347. Нахождение частоты встречаемости значений в массиве:\n",
      "```\n",
      "# Нахождение частоты встречаемости значений в массиве\n",
      "frequency = np.bincount(array)\n",
      "```\n",
      "348. Проверка, является ли массив массивом одного изданных чисел:\n",
      "```\n",
      "# Проверка, является ли массив массивом одного изданных чисел\n",
      "is_single_value_array = np.all(array == array[0])\n",
      "```\n",
      "349. Проверка, является ли массив отсортированным:\n",
      "```\n",
      "# Проверка, является ли массив отсортированным\n",
      "is_sorted = np.all(np.diff(array) >= 0)\n",
      "```\n",
      "350. Преобразование массива в массив логических значений:\n",
      "```\n",
      "# Преобразование массива в массив логических значений\n",
      "bool_array = np.array([True, False, True], dtype=bool)\n",
      "```\n",
      "351. Преобразование массива логических значений в массив чисел:\n",
      "```\n",
      "# Преобразование массива логических значений в массив чисел\n",
      "number_array = bool_array.astype(int)\n",
      "```\n",
      "352. Преобразование массива в одномерный массив:\n",
      "```\n",
      "# Преобразование массива в одномерный массив\n",
      "flattened_array = array.flatten()\n",
      "```\n",
      "353. Преобразование массива в многомерный массив:\n",
      "```\n",
      "# Преобразование массива в многомерный массив\n",
      "reshaped_array = array.reshape((3, 3))\n",
      "```\n",
      "354. Транспонирование массива:\n",
      "```\n",
      "# Транспонирование массива\n",
      "transposed_array = array.transpose()\n",
      "```\n",
      "355. Нахождение количества элементов в массиве:\n",
      "```\n",
      "# Нахождение количества элементов в массиве\n",
      "number_of_elements = np.size(array)\n",
      "```\n",
      "356. Нахождение размерности массива:\n",
      "```\n",
      "# Нахождение размерности массива\n",
      "shape = np.shape(array)\n",
      "```\n",
      "357. Нахождение размера массива в байтах:\n",
      "```\n",
      "# Нахождение размера массива в байтах\n",
      "size_in_bytes = np.nbytes(array)\n",
      "```\n",
      "358. Нахождение типа данных в массиве:\n",
      "```\n",
      "# Нахождение типа данных в массиве\n",
      "data_type = array.dtype\n",
      "```\n",
      "359. Преобразование массива в массив с заданным типом данных:\n",
      "```\n",
      "# Преобразование массива в массив с типом данных float\n",
      "array = array.astype(float)\n",
      "```\n",
      "360. Нахождение максимального значения в массиве:\n",
      "```\n",
      "# Нахождение максимального значения в массиве\n",
      "max_value = np.max(array)\n",
      "```\n",
      "361. Нахождение минимального значения в массиве:\n",
      "```\n",
      "# Нахождение минимального значения в массиве\n",
      "min_value = np.min(array)\n",
      "```\n",
      "362. Нахождение среднего значения элементов массива:\n",
      "```\n",
      "# Нахождение среднего значения элементов массива\n",
      "mean_value = np.mean(array)\n",
      "```\n",
      "363. Нахождение медианы элементов массива:\n",
      "```\n",
      "# Нахождение медианы элементов массива\n",
      "median_value = np.median(array)\n",
      "```\n",
      "364. Нахождение моды элементов массива:\n",
      "```\n",
      "# Нахождение моды элементов массива\n",
      "mode_value = np.mode(array)\n",
      "```\n",
      "365. Нахождение стандартного отклонения элементов массива:\n",
      "```\n",
      "# Нахождение стандартного отклонения элементов массива\n",
      "standard_deviation = np.std(array)\n",
      "```\n",
      "366. Нахождение вариации элементов массива:\n",
      "```\n",
      "# Нахождение вариации элементов массива\n",
      "variance = np.var(array)\n",
      "```\n",
      "367. Нахождение корреляции между двумя массивами:\n",
      "```\n",
      "# Нахождение корреляции между двумя массивами\n",
      "correlation = np.corrcoef(array1, array2)[0, 1]\n",
      "```\n",
      "368. Нахождение коэффициента детерминации между двумя массивами:\n",
      "```\n",
      "# Нахождение коэффициента детерминации между двумя массивами\n",
      "coefficient_of_determination = np.square(np.corrcoef(array1, array2)[0, 1])\n",
      "```\n",
      "369. Нахождение матрицы корреляции между несколькими массивами:\n",
      "```\n",
      "# Нахождение матрицы корреляции между несколькими массивами\n",
      "correlation_matrix = np.corrcoef(array1, array2, array3)\n",
      "```\n",
      "370. Нахождение матрицы ковариации между несколькими массивами:\n",
      "```\n",
      "# Нахождение матрицы ковариации между несколькими массивами\n",
      "covariance_matrix = np.cov(array1, array2, array3)\n",
      "```\n",
      "371. Нахождение производной функции в заданных точках:\n",
      "```\n",
      "# Нахождение производной функции в заданных точках\n",
      "derivative = np.gradient(array)\n",
      "```\n",
      "372. Нахождение интеграла функции в заданных точках:\n",
      "```\n",
      "# Нахождение интеграла функции в заданных точках\n",
      "integral = np.trapz(array, x)\n",
      "```\n",
      "373. Нахождение суммы элементов массива:\n",
      "```\n",
      "# Нахождение суммы элементов массива\n",
      "sum_of_elements = np.sum(array)\n",
      "```\n",
      "374. Нахождение произведения элементов массива:\n",
      "```\n",
      "# Нахождение произведения элементов массива\n",
      "product_of_elements = np.prod(array)\n",
      "```\n",
      "375. Нахождение минимальной размерности массива:\n",
      "```\n",
      "# Нахождение минимальной размерности массива\n",
      "min_dimension = np.min(np.shape(array))\n",
      "```\n",
      "376. Нахождение максимальной размерности массива:\n",
      "```\n",
      "# Нахождение максимальной размерности массива\n",
      "max_dimension = np.max(np.shape(array))\n",
      "```\n",
      "377. Нахождение количества не нулевых элементов в массиве:\n",
      "```\n",
      "# Нахождение количества не нулевых элементов в массиве\n",
      "number_of_nonzero_elements = np.count_nonzero(array)\n",
      "```\n",
      "378. Нахождение количества уникальных элементов в массиве:\n",
      "```\n",
      "# Нахождение количества уникальных элементов в массиве\n",
      "number_of_unique_elements = np.unique(array).size\n",
      "```\n",
      "379. Нахождение максимального элемента в каждом столбце массива:\n",
      "```\n",
      "# Нахождение максимального элемента в каждом столбце массива\n",
      "max_element_in_each_column = np.max(array, axis=0)\n",
      "```\n",
      "380. Нахождение минимального элемента в каждом столбце массива:\n",
      "```\n",
      "# Нахождение минимального элемента в каждом столбце массива\n",
      "min_element_in_each_column = np.min(array, axis=0)\n",
      "```\n",
      "381. Нахождение среднего элемента в каждом столбце массива:\n",
      "```\n",
      "# Нахождение среднего элемента в каждом столбце массива\n",
      "mean_element_in_each_column = np.mean(array, axis=0)\n",
      "```\n",
      "382. Нахождение суммы элементов в каждом столбце массива:\n",
      "```\n",
      "# Нахождение суммы элементов в каждом столбце массива\n",
      "sum_of_elements_in_each_column = np.sum(array, axis=0)\n",
      "```\n",
      "383. Нахождение произведения элементов в каждом столбце массива:\n",
      "```\n",
      "# Нахождение произведения элементов в каждом столбце массива\n",
      "product_of_elements_in_each_column = np.prod(array, axis=0)\n",
      "```\n",
      "384. Нахождение количества не нулевых элементов в каждом столбце массива:\n",
      "```\n",
      "# Нахождение количества не нулевых элементов в каждом столбце массива\n",
      "number_of_nonzero_elements_in_each_column = np.count_nonzero(array, axis=0)\n",
      "```\n",
      "385. Нахождение максимального элемента в каждой строке массива:\n",
      "```\n",
      "# Нахождение максимального элемента в каждой строке массива\n",
      "max_element_in_each_row = np.max(array, axis=1)\n",
      "```\n",
      "386. Нахождение минимального элемента в каждой строке массива:\n",
      "```\n",
      "# Нахождение минимального элемента в каждой строке массива\n",
      "min_element_in_each_row = np.min(array, axis=1)\n",
      "```\n",
      "387. Нахождение среднего элемента в каждой строке массива:\n",
      "```\n",
      "# Нахождение среднего элемента в каждой строке массива\n",
      "mean_element_in_each_row = np.mean(array, axis=1)\n",
      "```\n",
      "388. Нахождение суммы элементов в каждой строке массива:\n",
      "```\n",
      "# Нахождение суммы элементов в каждой строке массива\n",
      "sum_of_elements_in_each_row = np.sum(array, axis=1)\n",
      "```\n",
      "389. Нахождение произведения элементов в каждой строке массива:\n",
      "```\n",
      "# Нахождение произведения элементов в каждой строке массива\n",
      "product_of_elements_in_each_row = np.prod(array, axis=1)\n",
      "```\n",
      "390. Нахождение количества не нулевых элементов в каждой строке массива:\n",
      "```\n",
      "# Нахождение количества не нулевых элементов в каждой строке массива\n",
      "number_of_nonzero_elements_in_each_row = np.count_nonzero(array, axis=1)\n",
      "```\n",
      "391. Нахождение индексов максимального элемента в каждой строке массива:\n",
      "```\n",
      "# Нахождение индексов максимального элемента в каждой строке массива\n",
      "indices_of_max_element_in_each_row = np.argmax(array, axis=1)\n",
      "```\n",
      "392. Нахождение индексов минимального элемента в каждой строке массива:\n",
      "```\n",
      "# Нахождение индексов минимального элемента в каждой строке массива\n",
      "indices_of_min_element_in_each_row = np.argmin(array, axis=1)\n",
      "```\n",
      "393. Нахождение индексов элементов массива, удовлетворяющих заданному условию, в каждой строке:\n",
      "```\n",
      "# Нахождение индексов элементов массива, больших 0, в каждой строке\n",
      "indices = np.argwhere(array > 0)\n",
      "```\n",
      "394. Нахождение значений элементов массива, удовлетворяющих заданному условию, в каждой строке:\n",
      "```\n",
      "# Нахождение значений элементов массива, больших 0, в каждой строке\n",
      "values = array[array > 0]\n",
      "```\n",
      "395. Удаление элементов массива, удовлетворяющих заданному условию, в каждой строке:\n",
      "```\n",
      "# Удаление элементов массива, равных 0, в каждой строке\n",
      "array = np.delete(array, np.where(array == 0), axis=1)\n",
      "```\n",
      "396. Замена значений элементов массива, удовлетворяющих заданному условию, в каждой строке:\n",
      "```\n",
      "# Замена значений элементов массива, меньших 0, на 0 в каждой строке\n",
      "array[array < 0] = 0\n",
      "```\n",
      "397. Поворот массива на заданный угол:\n",
      "```\n",
      "# Поворот массива на 90 градусов\n",
      "array = np.rot90(array)\n",
      "```\n",
      "398. Отражение массива относительно заданной оси:\n",
      "```\n",
      "# Отражение массива относительно оси y\n",
      "array = np.flipud(array)\n",
      "\n",
      "# Отражение массива относительно оси x\n",
      "array = np.fliplr(array)\n",
      "```\n",
      "399. Замена отрицательных значений в массиве на заданное значение:\n",
      "```\n",
      "# Замена отрицательных значений в массиве на 0\n",
      "array = np.maximum(array, 0)\n",
      "```\n",
      "400. Замена положительных значений в массиве на заданное значение:\n",
      "```\n",
      "# Замена положительных значений в массиве на 0\n",
      "array = np.minimum(array, 0)\n",
      "```\n",
      "401. Замена нолевых значений в массиве на заданное значение:\n",
      "```\n",
      "# Замена нолевых значений в массиве на 1\n",
      "array = np.where(array == 0, 1, array)\n",
      "```\n",
      "402. Сортировка элементов массива:\n",
      "```\n",
      "# Сортировка элементов массива по возрастанию\n",
      "sorted_array = np.sort(array)\n",
      "\n",
      "# Сортировка элементов массива по убыванию\n",
      "sorted_array = np.sort(array)[::-1]\n",
      "```\n",
      "403. Нахождение уникальных значений в массиве:\n",
      "```\n",
      "# Нахождение уникальных значений в массиве\n",
      "unique_values = np.unique(array)\n",
      "```\n",
      "404. Нахождение частоты встречаемости значений в массиве:\n",
      "```\n",
      "# Нахождение частоты встречаемости значений в массиве\n",
      "frequency = np.bincount(array)\n",
      "```\n",
      "405. Проверка, является ли массив массивом одного изданных чисел:\n",
      "```\n",
      "# Проверка, является ли массив массивом одного изданных чисел\n",
      "is_single_value_array = np.all(array == array[0])\n",
      "```\n",
      "406. Проверка, является ли массив отсортированным:\n",
      "```\n",
      "# Проверка, является ли массив отсортированным\n",
      "is_sorted = np.all(np.diff(array) >= 0)\n",
      "```\n",
      "407. Преобразование массива в массив логических значений:\n",
      "```\n",
      "# Преобразование массива в массив логических значений\n",
      "bool_array = np.array([True, False, True], dtype=bool)\n",
      "```\n",
      "408. Преобразование массива логических значений в массив чисел:\n",
      "```\n",
      "# Преобразование массива логических значений в массив чисел\n",
      "number_array = bool_array.astype(int)\n",
      "```\n",
      "409. Преобразование массива в одномерный массив:\n",
      "```\n",
      "# Преобразование массива в одномерный массив\n",
      "flattened_array = array.flatten()\n",
      "```\n",
      "410. Преобразование массива в многомерный массив:\n",
      "```\n",
      "# Преобразование массива в многомерный массив\n",
      "reshaped_array = array.reshape((3, 3))\n",
      "```\n",
      "411. Транспонирование массива:\n",
      "```\n",
      "# Транспонирование массива\n",
      "transposed_array = array.transpose()\n",
      "```\n",
      "412. Нахождение количества элементов в массиве:\n",
      "```\n",
      "# Нахождение количества элементов в массиве\n",
      "number_of_elements = np.size(array)\n",
      "```\n",
      "413. Нахождение размерности массива:\n",
      "```\n",
      "# Нахождение размерности массива\n",
      "shape = np.shape(array)\n",
      "```\n",
      "414. Нахождение размера массива в байтах:\n",
      "```\n",
      "# Нахождение размера массива в байтах\n",
      "size_in_bytes = np.nbytes(array)\n",
      "```\n",
      "415. Нахождение типа данных в массиве:\n",
      "```\n",
      "# Нахождение типа данных в массиве\n",
      "data_type = array.dtype\n",
      "```\n",
      "416. Преобразование массива в массив с заданным типом данных:\n",
      "```\n",
      "# Преобразование массива в массив с типом данных float\n",
      "array = array.astype(float)\n",
      "```\n",
      "417. Нахождение максимального значения в массиве:\n",
      "```\n",
      "# Нахождение максимального значения в массиве\n",
      "max_value = np.max(array)\n",
      "```\n",
      "418. Нахождение минимального значения в массиве:\n",
      "```\n",
      "# Нахождение минимального значения в массиве\n",
      "min_value = np.min(array)\n",
      "```\n",
      "419. Нахождение среднего значения элементов массива:\n",
      "```\n",
      "# Нахождение среднего значения элементов массива\n",
      "mean_value = np.mean(array)\n",
      "```\n",
      "420. Нахождение медианы элементов массива:\n",
      "```\n",
      "# Нахождение медианы элементов массива\n",
      "median_value = np.median(array)\n",
      "```\n",
      "421. Нахождение моды элементов массива:\n",
      "```\n",
      "# Нахождение моды элементов массива\n",
      "mode_value = np.mode(array)\n",
      "```\n",
      "422. Нахождение стандартного отклонения элементов массива:\n",
      "```\n",
      "# Нахождение стандартного отклонения элементов массива\n",
      "standard_deviation = np.std(array)\n",
      "```\n",
      "423. Нахождение вариации элементов массива:\n",
      "```\n",
      "# Нахождение вариации элементов массива\n",
      "variance = np.var(array)\n",
      "```\n",
      "424. Нахождение корреляции между двумя массивами:\n",
      "```\n",
      "# Нахождение корреляции между двумя массивами\n",
      "correlation = np.corrcoef(array1, array2)[0, 1]\n",
      "```\n",
      "425. Нахождение коэффициента детерминации между двумя массивами:\n",
      "```\n",
      "# Нахождение коэффициента детерминации между двумя массивами\n",
      "coefficient_of_determination = np.square(np.corrcoef(array1, array2)[0, 1])\n",
      "```\n",
      "426. Нахождение матрицы корреляции между несколькими массивами:\n",
      "```\n",
      "# Нахождение матрицы корреляции между несколькими массивами\n",
      "correlation_matrix = np.corrcoef(array1, array2, array3)\n",
      "```\n",
      "427. Нахождение матрицы ковариации между несколькими массивами:\n",
      "```\n",
      "# Нахождение матрицы ковариации между несколькими массивами\n",
      "covariance_matrix = np.cov(array1, array2, array3)\n",
      "```\n",
      "428. Нахождение производной функции в заданных точках:\n",
      "```\n",
      "# Нахождение производной функции в заданных точках\n",
      "derivative = np.gradient(array)\n",
      "```\n",
      "429. Нахождение интеграла функции в заданных точках:\n",
      "```\n",
      "# Нахождение интеграла функции в заданных точках\n",
      "integral = np.trapz(array, x)\n",
      "```\n",
      "430. Нахождение суммы элементов массива:\n",
      "```\n",
      "# Нахождение суммы элементов массива\n",
      "sum_of_elements = np.sum(array)\n",
      "```\n",
      "431. Нахождение произведения элементов массива:\n",
      "```\n",
      "# Нахождение произведения элементов массива\n",
      "product_of_elements = np.prod(array)\n",
      "```\n",
      "432. Нахождение минимальной размерности массива:\n",
      "```\n",
      "# Нахождение минимальной размерности массива\n",
      "min_dimension = np.min(np.shape(array))\n",
      "```\n",
      "433. Нахождение максимальной размерности массива:\n",
      "```\n",
      "# Нахождение максимальной размерности массива\n",
      "max_dimension = np.max(np.shape(array))\n",
      "```\n",
      "434. Нахождение количества не нулевых элементов в массиве:\n",
      "```\n",
      "# Нахождение количества не нулевых элементов в массиве\n",
      "number_of_nonzero_elements = np.count_nonzero(array)\n",
      "```\n",
      "435. Нахождение количества уникальных элементов в массиве:\n",
      "```\n",
      "# Нахождение количества уникальных элементов в массиве\n",
      "number_of_unique_elements = np.unique(array).size\n",
      "```\n",
      "436. Нахождение максимального элемента в каждом столбце массива:\n",
      "```\n",
      "# Нахождение максимального элемента в каждом столбце массива\n",
      "max_element_in_each_column = np.max(array, axis=0)\n",
      "```\n",
      "437. Нахождение минимального элемента в каждом столбце массива:\n",
      "```\n",
      "# Нахождение минимального элемента в каждом столбце массива\n",
      "min_element_in_each_column = np.min(array, axis=0)\n",
      "```\n",
      "438. Нахождение среднего элемента в каждом столбце массива:\n",
      "```\n",
      "# Нахождение среднего элемента в каждом столбце массива\n",
      "mean_element_in_each_column = np.mean(array, axis=0)\n",
      "```\n",
      "439. Нахождение суммы элементов в каждом столбце массива:\n",
      "```\n",
      "# Нахождение суммы элементов в каждом столбце массива\n",
      "sum_of_elements_in_each_column = np.sum(array, axis=0)\n",
      "```\n",
      "440. Нахождение произведения элементов в каждом столбце массива:\n",
      "```\n",
      "# Нахождение произведения элементов в каждом столбце массива\n",
      "product_of_elements_in_each_column = np.prod(array, axis=0)\n",
      "```\n",
      "441. Нахождение количества не нулевых элементов в каждом столбце массива:\n",
      "```\n",
      "# Нахождение количества не нулевых элементов в каждом столбце массива\n",
      "number_of_nonzero_elements_in_each_column = np.count_nonzero(array, axis=0)\n",
      "```\n",
      "442. Нахождение максимального элемента в каждой строке массива:\n",
      "```\n",
      "# Нахождение максимального элемента в каждой строке массива\n",
      "max_element_in_each_row = np.max(array, axis=1)\n",
      "```\n",
      "443. Нахождение минимального элемента в каждой строке массива:\n",
      "```\n",
      "# Нахождение минимального элемента в каждой строке массива\n",
      "min_element_in_each_row = np.min(array, axis=1)\n",
      "```\n",
      "444. Нахождение среднего элемента в каждой строке массива:\n",
      "```\n",
      "# Нахождение среднего элемента в каждой строке массива\n",
      "mean_element_in_each_row = np.mean(array, axis=1)\n",
      "```\n",
      "445. Нахождение суммы элементов в каждой строке массива:\n",
      "```\n",
      "# Нахождение суммы элементов в каждой строке массива\n",
      "sum_of_elements_in_each_row = np.sum(array, axis=1)\n",
      "```\n",
      "446. Нахождение произведения элементов в каждой строке массива:\n",
      "```\n",
      "# Нахождение произведения элементов в каждой строке массива\n",
      "product_of_elements_in_each_row = np.prod(array, axis=1)\n",
      "```\n",
      "447. Нахождение количества не нулевых элементов в каждой строке массива:\n",
      "```\n",
      "# Нахождение количества не нулевых элементов в каждой строке массива\n",
      "number_of_nonzero_elements_in_each_row = np.count_nonzero(array, axis=1)\n",
      "```\n",
      "448. Нахождение индексов максимального элемента в каждой строке массива:\n",
      "```\n",
      "# Нахождение индексов максимального элемента в каждой строке массива\n",
      "indices_of_max_element_in_each_row = np.argmax(array, axis=1)\n",
      "```\n",
      "449. Нахождение индексов минимального элемента в каждой строке массива:\n",
      "```\n",
      "# Нахождение индексов минимального элемента в каждой строке массива\n",
      "indices_of_min_element_in_each_row = np.argmin(array, axis=1)\n",
      "```\n",
      "450. Нахождение индексов элементов массива, удовлетворяющих заданному условию, в каждой строке:\n",
      "```\n",
      "# Нахождение индексов элементов массива, больших 0, в каждой строке\n",
      "indices = np.argwhere(array > 0)\n",
      "```\n",
      "451. Нахождение значений элементов массива, удовлетворяющих заданному условию, в каждой строке:\n",
      "```\n",
      "# Нахождение значений элементов массива, больших 0, в каждой строке\n",
      "values = array[array > 0]\n",
      "```\n",
      "452. Удаление элементов массива, удовлетворяющих заданному условию, в каждой строке:\n",
      "```\n",
      "# Удаление элементов массива, равных 0, в каждой строке\n",
      "array = np.delete(array, np.where(array == 0), axis=1)\n",
      "```\n",
      "453. Замена значений элементов массива, удовлетворяющих заданному условию, в каждой строке:\n",
      "```\n",
      "# Замена значений элементов массива, меньших 0, на 0 в каждой строке\n",
      "array[array < 0] = 0\n",
      "```\n",
      "454. Поворот массива на заданный угол:\n",
      "```\n",
      "# Поворот массива на 90 градусов\n",
      "array = np.rot90(array)\n",
      "```\n",
      "455. Отражение массива относительно заданной оси:\n",
      "```\n",
      "# Отражение массива относительно оси y\n",
      "array = np.flipud(array)\n",
      "\n",
      "# Отражение массива относительно оси x\n",
      "array = np.fliplr(array)\n",
      "```\n",
      "456. Замена отрицательных значений в массиве на заданное значение:\n",
      "```\n",
      "# Замена отрицательных значений в массиве на 0\n",
      "array = np.maximum(array, 0)\n",
      "```\n",
      "457. Замена положительных значений в массиве на заданное значение:\n",
      "```\n",
      "# Замена положительных значений в массиве на 0\n",
      "array = np.minimum(array, 0)\n",
      "```\n",
      "458. Замена нолевых значений в массиве на заданное значение:\n",
      "```\n",
      "# Замена нолевых значений в массиве на 1\n",
      "array = np.where(array == 0, 1, array)\n",
      "```\n",
      "459. Сортировка элементов массива:\n",
      "```\n",
      "# Сортировка элементов массива по возрастанию\n",
      "sorted_array = np.sort(array)\n",
      "\n",
      "# Сортировка элементов массива по убыванию\n",
      "sorted_array = np.sort(array)[::-1]\n",
      "```\n",
      "460. Нахождение уникальных значений в массиве:\n",
      "```\n",
      "# Нахождение уникальных значений в массиве\n",
      "unique_values = np.unique(array)\n",
      "```\n",
      "461. Нахождение частоты встречаемости значений в массиве:\n",
      "```\n",
      "# Нахождение частоты встречаемости значений в массиве\n",
      "frequency = np.bincount(array)\n",
      "```\n",
      "462. Проверка, является ли массив массивом одного изданных чисел:\n",
      "```\n",
      "# Проверка, является ли массив массивом одного изданных чисел\n",
      "is_single_value_array = np.all(array == array[0])\n",
      "```\n",
      "463. Проверка, является ли массив отсортированным:\n",
      "```\n",
      "# Проверка, является ли массив отсортированным\n",
      "is_sorted = np.all(np.diff(array) >= 0)\n",
      "```\n",
      "464. Преобразование массива в массив логических значений:\n",
      "```\n",
      "# Преобразование массива в массив логических значений\n",
      "bool_array = np.array([True, False, True], dtype=bool)\n",
      "```\n",
      "465. Преобразование массива логических значений в массив чисел:\n",
      "```\n",
      "# Преобразование массива логических значений в массив чисел\n",
      "number_array = bool_array.astype(int)\n",
      "```\n",
      "466. Преобразование массива в одномерный массив:\n",
      "```\n",
      "# Преобразование массива в одномерный массив\n",
      "flattened_array = array.flatten()\n",
      "```\n",
      "467. Преобразование массива в многомерный массив:\n",
      "```\n",
      "# Преобразование массива в многомерный массив\n",
      "reshaped_array = array.reshape((3, 3))\n",
      "```\n",
      "468. Транспонирование массива:\n",
      "```\n",
      "# Транспонирование массива\n",
      "transposed_array = array.transpose()\n",
      "```\n",
      "469. Нахождение количества элементов в массиве:\n",
      "```\n",
      "# Нахождение количества элементов в массиве\n",
      "number_of_elements = np.size(array)\n",
      "```\n",
      "470. Нахо\n",
      "Reference Answer: Для работы с массивами данных в NumPy я использую функции для создания, манипуляции и анализа массивов. NumPy предоставляет эффективные операции и методы для работы с многомерными массивами, позволяя выполнять математические и статистические вычисления.\n",
      "Cosine Similarity: 0.473150372505188\n",
      "BLEU Score: 0.00040169203124487414\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d91bd4ba14554330a33894e421dd693c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4cea48dc99e2447196c620b6d5c6e00f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question ID: 87\n",
      "Generated Answer: Я использую различные методы для обработки текстовых данных, включая токенезацию, лемматизацию, удаление стоп-слов, удаление знаков препинания, нормализацию текста и применение методов машинного обучения, таких какTF-IDF, Word2Vec и BERT, для выделения ключевых фраз и извлечения признаков.\n",
      "\n",
      "Translation:\n",
      "I use various methods for processing text data, including tokenization, lemmatization, stop words removal, punctuation removal, text normalization, and application of machine learning methods such as TF-IDF, Word2Vec, and BERT to extract key phrases and features.\n",
      "Reference Answer: Для обработки текстовых данных я использую методы, такие как токенизация, удаление стоп-слов, стемминг и лемматизация. Эти методы позволяют преобразовать текст в числовую форму для дальнейшего анализа и моделирования.\n",
      "Cosine Similarity: 0.9739539623260498\n",
      "BLEU Score: 3.6336461326078003e-155\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7b786975a084b08997e406688f3481d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "645836dd18684620b0202c11228f1abd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question ID: 88\n",
      "Generated Answer: Препроцессинг данных - это процесс подготовки данных к дальнейшей обработке и анализу. Он включает в себя различные операции, такие как очистка данных, нормализация, стандартизация, подстановка пропусков, объединение и преобразование данных. Препроцессинг данных необходим для того, чтобы сделать данные более полезными, удобными для анализа и улучшить точность моделей машинного обучения. Он помогает избавиться от шумов и ошибок в данных, уменьшить размерность данных и улучшить их качество. Препроцессинг данных является одним из ключевых этапов в работе data scientist'а или машинного обучения инженера.\n",
      "Reference Answer: Препроцессинг данных - это этап подготовки данных перед их анализом. Он включает очистку данных, нормализацию, удаление выбросов и преобразование признаков, что необходимо для улучшения качества и производительности моделей машинного обучения.\n",
      "Cosine Similarity: 0.9814635515213013\n",
      "BLEU Score: 0.05725843046720262\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8fc892cd57444c96a9fbaacb334036dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c720afee733845bb813043cee1435ccb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question ID: 89\n",
      "Generated Answer: Scikit-learn - это популярная библиотека машинного обучения на Python. Она предоставляет множество инструментов для моделирования данных, включая алгоритмы классификации, регрессии, кластеризации, рекомендательных систем и др.\n",
      "\n",
      "Вот общая схема использования Scikit-learn для моделирования данных:\n",
      "\n",
      "1. Загрузка данных: Scikit-learn предоставляет функцию `load_dataset()` для загрузки встроенных наборов данных. Также можно загружать данные из файлов или баз данных с помощью функций `pandas.read_csv()`, `numpy.load()` и др.\n",
      "2. Предварительная обработка данных: перед моделированием данных необходимо провести их предварительную обработку, включая очистку данных, нормализацию,feature engineering и др. В Scikit-learn предоставляются различные инструменты для этой цели, такие как `StandardScaler()`, `OneHotEncoder()`, `PCA()` и др.\n",
      "3. Разделение данных на обучающую и тестовую выборки: для оценки качества модели необходимо разделить данные на обучающую и тестовую выборки. В Scikit-learn предоставляется функция `train_test_split()`, которая позволяет разделить данные на две части.\n",
      "4. Подбор параметров модели: Scikit-learn предоставляет различные алгоритмы машинного обучения, каждый из которых имеет свои параметры. Для подбора оптимальных параметров можно использовать методы градиентного спуска, решающие методы, кросс-валидацию и др.\n",
      "5. Обучение модели: после подбора параметров можно обучить модель на обучающей выборке данных с помощью метода `fit()`.\n",
      "6. Оценка модели: для оценки качества модели можно использовать различные метрики, такие как точность, лосс-функция, ROC-кривая, F1-мер и др. В Scikit-learn предоставляются функции `accuracy_score()`, `mean_squared_error()`, `roc_auc_score()` и др.\n",
      "7. Применение модели: после оценки модели можно применить ее к новым данным для предсказания. В Scikit-learn предоставляется метод `predict()`, который позволяет сделать предсказание на основе модели.\n",
      "\n",
      "Вот пример использования Scikit-learn для моделирования данных:\n",
      "```python\n",
      "from sklearn.datasets import load_iris\n",
      "from sklearn.model_selection import train_test_split\n",
      "from sklearn.preprocessing import StandardScaler\n",
      "from sklearn.linear_model import LogisticRegression\n",
      "from sklearn.metrics import accuracy_score\n",
      "\n",
      "# Загрузка данных\n",
      "iris = load_iris()\n",
      "X = iris.data\n",
      "y = iris.target\n",
      "\n",
      "# Разделение данных на обучающую и тестовую выборки\n",
      "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
      "\n",
      "# Нормализация данных\n",
      "scaler = StandardScaler()\n",
      "X_train = scaler.fit_transform(X_train)\n",
      "X_test = scaler.transform(X_test)\n",
      "\n",
      "# Обучение модели\n",
      "model = LogisticRegression()\n",
      "model.fit(X_train, y_train)\n",
      "\n",
      "# Оценка модели\n",
      "y_pred = model.predict(X_test)\n",
      "accuracy = accuracy_score(y_test, y_pred)\n",
      "print(\"Точность модели:\", accuracy)\n",
      "\n",
      "# Применение модели\n",
      "new_data = [[5.1, 3.5, 1.4, 0.2], [6.3, 2.9, 5.6, 1.8]]\n",
      "new_data = scaler.transform(new_data)\n",
      "y_pred = model.predict(new_data)\n",
      "print(\"Предсказание:\", iris.target_names[y_pred])\n",
      "```\n",
      "В этом примере мы загружаем встроенный набор данных Iris, разделяем его на обучающую и тестовую выборки, нормализуем данные, обучаем модель логистической регрессии, оцениваем ее точность и применяем модель к новым данным для предсказания.\n",
      "Reference Answer: Для моделирования данных с помощью scikit-learn я использую функции библиотеки для создания, обучения и оценки моделей машинного обучения. Scikit-learn предоставляет широкий набор алгоритмов и инструментов для классификации, регрессии и кластеризации.\n",
      "Cosine Similarity: 0.8549582958221436\n",
      "BLEU Score: 4.257288538842767e-79\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b028a8142de4450b6f24b573c9a9028",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60a82a46696b475dba543918a547c7f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question ID: 90\n",
      "Generated Answer: Разведывательный анализ данных (EDA) является процессом исследования данных для понимания их основных характеристик, структуры, выявления аномалий и зависимостей. Я выполняю EDA с помощью следующих шагов:\n",
      "\n",
      "1. Подготовка данных: очистка и преобразование данных для последующего анализа.\n",
      "2. Визуализация данных: создание гистограмм, диаграмм рассеяния, боксплотов и других графиков для визуального представления данных.\n",
      "3. Анализ выборки: оценка средних значений, дисперсий, коэффициентов корреляции и других статистических показателей.\n",
      "4. Оценка распределения: определение типа распределения данных (нормальное, экспоненциальное и т.д.).\n",
      "5. Поиск зависимостей: определение зависимостей между переменными с помощью методов регрессии, корреляции и других статистических моделей.\n",
      "6. Идентификация аномалий: обнаружение выбросов и выявление несоответствий в данных.\n",
      "\n",
      "В процессе EDA я часто использую библиотеки Python, такие как pandas, NumPy, Matplotlib и Seaborn, которые предоставляют мощные средства для обработки данных и визуализации результатов.\n",
      "Reference Answer: Разведывательный анализ данных (EDA) включает предварительное исследование данных для выявления их основных характеристик. Я использую визуализации, такие как гистограммы и диаграммы рассеяния, и статистические методы для понимания структуры данных и выявления закономерностей.\n",
      "Cosine Similarity: 0.9834147095680237\n",
      "BLEU Score: 0.034248246015729795\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5bcf16514ac43c69b3cb9acef4a0dd8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b551478b16a7412d80ba230ab4434f59",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question ID: 91\n",
      "Generated Answer: Визуализация данных - это представление данных в графической или визуальной форме, такой как диаграммы, графики, карты и др. Этот процесс помогает лучше понять и интерпретировать данные, обнаружить тенденции и закономерности, сделать выводы и принять решения. Визуализация данных также улучшает коммуникацию и обмен информацией между людьми, поскольку она позволяет легко понять сложные данные и передать их другим. Визуализация данных является важным этапом в process of data analysis and decision making.\n",
      "Reference Answer: Визуализация данных - это процесс представления данных в графическом или визуальном формате. Она помогает лучше понять распределения, взаимосвязи и тренды в данных, облегчая интерпретацию результатов анализа.\n",
      "Cosine Similarity: 0.9673706293106079\n",
      "BLEU Score: 0.05795084580022091\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "997b3afc3c2d4759a43810834be0c4d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1cefea027b914f5881183c82abb0efb0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question ID: 92\n",
      "Generated Answer: Для очистки данных можно использовать различные методы. Вот несколько примеров:\n",
      "\n",
      "1. Удаление пропущенных значений (англ. Removing missing values) - это процесс удаления строк или столбцов, содержащих пропущенные значения. Это может быть полезно, если пропущенные значения составляют малую часть данных и их удаление не сильно повлияет на общую статистику.\n",
      "2. Замена пропущенных значений (англ. Imputing missing values) - это процесс замены пропущенных значений на определенные значения, такие как среднее, медиана или мода. Это может быть полезно, если пропущенные значения составляют большую часть данных и их удаление приведет к потере важной информации.\n",
      "3. Нормализация данных (англ. Data normalization) - это процесс преобразования данных в формат, который легче анализировать и интерпретировать. Это может включать в себя преобразование нечисловых данных в числовые, линейную нормализацию или стандартизацию.\n",
      "4. Очистка данных от аномалий (англ. Cleaning data anomalies) - это процесс удаления или исправления некорректных или неожиданных значений в данных. Это может быть полезно, если такие значения могут ввести в заблуждение алгоритмы машинного обучения.\n",
      "5. Обработка выбросов (англ. Outlier treatment) - это процесс удаления или уменьшения влияния выбросов в данных. Выбросы - это значения, которые значительно отличаются от других значений в данных и могут влиять на статистические показатели.\n",
      "\n",
      "Выбор метода очистки данных зависит от контекста и целей анализа. В некоторых случаях может потребоваться использовать несколько методов в комбинации.\n",
      "Reference Answer: Для очистки данных я использую методы, такие как удаление пропущенных значений, исправление ошибок, нормализация и кодирование категориальных признаков. Эти методы улучшают качество данных и повышают точность моделей.\n",
      "Cosine Similarity: 0.7944931983947754\n",
      "BLEU Score: 5.567870127471284e-79\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25da11a6eca2424baebb578718448223",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "614857a76d42440086b1580edb2b8729",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question ID: 93\n",
      "Generated Answer: Feature engineering - это процесс создания новых функциональных признаков из существующих данных с целью улучшения модели машинного обучения. Это включает в себя различные операции, такие как нормализация, стандартизация, выделение функций, агрегацию и преобразование функций.\n",
      "\n",
      "Процесс feature engineering обычно включает в себя следующие шаги:\n",
      "\n",
      "1. Понимание проблемы и данных: необходимо хорошо понимать проблему и данные, с которыми работаете, чтобы определить, какие функции могут быть полезны для модели машинного обучения.\n",
      "2. Выбор функций: необходимо выбрать функции, которые будут использоваться в модели машинного обучения. Это может включать в себя использование доменного знания, статистических методов и методов машинного обучения для выбора функций.\n",
      "3. Преобразование функций: после выбора функций их необходимо преобразовать в форму, пригодную для модели машинного обучения. Это может включать в себя нормализацию, стандартизацию, выделение функций, агрегацию и преобразование функций.\n",
      "4. Отбор функций: после преобразования функций необходимо отсортировать их и выбрать те, которые будут использоваться в модели машинного обучения. Это может быть сделано с помощью различных методов, таких как регуляризация, выборка на основе значений и методы машинного обучения.\n",
      "5. Оценка функций: после выбора функций необходимо оценить их качество и определить, какие функции лучше всего подходят для модели машинного обучения. Это может быть сделано с помощью различных методов, таких как кросс-валидация, графики и статистические тесты.\n",
      "\n",
      "В целом, feature engineering является важным процессом для создания эффективной модели машинного обучения. Он может значительно повысить качество модели, но требует значительного времени и усилий. Для успешного feature engineering необходимо хорошо понимать данные и проблему, а также иметь опыт в области машинного обучения и статистики.\n",
      "Reference Answer: Feature engineering - это процесс создания новых признаков из исходных данных. Он включает выбор значимых признаков, преобразование существующих и создание новых на основе знаний о данных, что помогает улучшить производительность моделей.\n",
      "Cosine Similarity: 0.9854376316070557\n",
      "BLEU Score: 0.029092809853437325\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd03c557c80b4bb582e455acb439565f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39d246709fa941e2bc97bbee5faef2b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question ID: 94\n",
      "Generated Answer: Метод главных компонент (PCA) - это алгоритм линейного преобразования данных, который используется для уменьшения размерности данных, сохраняя при этом максимум информации. Он основан на идее проектирования данных на новую систему координат, где первые несколько осей соответствуют направлениям максимального разброса данных.\n",
      "\n",
      "PCA работает следующим образом:\n",
      "\n",
      "1. Центрирование данных: сначала вычитается среднее значение из каждого измерения, чтобы избежать смещения данных.\n",
      "2. Вычисление ковариационной матрицы: ковариационная матрица представляет собой матрицу, элементы которой соответствуют ковариации между парами измерений.\n",
      "3. Нахождение собственных векторов и собственных значений ковариационной матрицы: собственные векторы представляют собой направления, вдоль которых данные имеют максимальную вариацию, а собственные значения соответствуют разбросу данных вдоль этих направлений.\n",
      "4. Выбор главных компонент: главные компоненты - это линейная комбинация измерений, которые соответствуют максимальному разбросу данных. В качестве главных компонент выбираются первые k собственных векторов, соответствующих k наибольшим собственным значениям.\n",
      "5. Преобразование данных: данные проектируются на новую систему координат, образованную главными компонентами. Каждая точка данных представляется в виде k-мерного вектора, где k - количество выбранных главных компонент.\n",
      "\n",
      "PCA широко используется в машинном обучении, особенно в задачах, где число измерений исходных данных очень велико, и требуется уменьшить размерность данных для улучшения производительности и уменьшения риска переобучения модели.\n",
      "Reference Answer: Метод главных компонент (PCA) - это метод уменьшения размерности, который преобразует данные в новое пространство признаков, сохраняя как можно больше информации. Он используется для визуализации данных и ускорения работы моделей.\n",
      "Cosine Similarity: 0.9801183342933655\n",
      "BLEU Score: 0.03278600500276399\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7957fc3ba6ff4d42b981ce0422ad0008",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a864215e507342c99377e0aa8589656d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question ID: 95\n",
      "Generated Answer: Для обработки выбросов в данных существует несколько подходов. Вот некоторые из них:\n",
      "\n",
      "1. Удаление выбросов - это простое решение, но оно может привести к потере важной информации.\n",
      "2. Замена выбросов средним значением или медианой - это более сохраняющее информацию решение, чем удаление, но оно может привести к смещению данных.\n",
      "3. Использование robustных методов оценки, таких как оценка M-смотрителя, которая менее чувствительна к выбросам, чем обычное среднее.\n",
      "4. Использование методов уменьшения размерности, таких как главные компоненты анализа (ПКА), для удаления выбросов, которые могут быть вызваны измерениями, содержащими ошибки.\n",
      "\n",
      "Выбор подхода зависит от контекста и характера данных. Рекомендуется изучить различные методы и выбрать наиболее подходящий для конкретной задачи.\n",
      "Reference Answer: Для обработки выбросов в данных я использую методы, такие как удаление выбросов, логарифмическое преобразование и применение робастных методов оценки. Эти методы помогают улучшить качество данных и точность моделей.\n",
      "Cosine Similarity: 0.9426164627075195\n",
      "BLEU Score: 0.038575321084566655\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "826ab35035aa4efd810ed33d7af1159f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df591ab5788a40b7bf3155ee0b73274a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question ID: 96\n",
      "Generated Answer: Дискретизация - это процесс преобразования непрерывного сигнала в дискретный, то есть представление его в виде последовательности отдельных отрезков или точек. Это необходимо для того, чтобы можно было хранить, обрабатывать и передавать сигнал с помощью цифровой техники. В машинном обучении дискретизация используется для преобразования непрерывных переменных в категориальные, например, для преобразования возраста человека в возрастные группы. Это позволяет использовать более простые модели машинного обучения, такие как линейная регрессия и логистическая регрессия, которые работают только с категориальными переменными.\n",
      "\n",
      "Translation:\n",
      "\n",
      "Дискретизация - это процесс преобразования непрерывного сигнала в дискретный, то есть представление его в виде последовательности отдельных отрезков или точек. Это необходимо для того, чтобы можно было хранить, обрабатывать и передавать сигнал с помощью цифровой техники. В машинном обучении дискретизация используется для преобразования непрерывных переменных в категориальные, например, для преобразования возраста человека в возрастные группы. Это позволяет использовать более простые модели машинного обучения, такие как линейная регрессия и логистическая регрессия, которые работают только с категориальными переменными.\n",
      "\n",
      "Translation in English:\n",
      "\n",
      "Discretization is the process of converting a continuous signal into a discrete one, i.e. representing it as a sequence of separate segments or points. This is necessary in order to be able to store, process and transmit the signal using digital technology. In machine learning, discretization is used to convert continuous variables into categorical ones, for example, to convert a person's age into age groups. This allows you to use simpler machine learning models, such as linear regression and logistic regression, which only work with categorical variables.\n",
      "Reference Answer: Дискретизация - это процесс преобразования непрерывных данных в категориальные. Она используется для упрощения анализа данных и моделей, а также для улучшения интерпретации результатов.\n",
      "Cosine Similarity: 0.9749170541763306\n",
      "BLEU Score: 0.018471889226723846\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da7542d5d97c4fd8a8545ae95c2311b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e7b062035bb426cb95b8baf4032d2a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question ID: 97\n",
      "Generated Answer: Градиентный бустинг (Gradient Boosting) — это алгоритм машинного обучения, который строит модель в виде последовательности слабых классификаторов, обычно решающих задачу регрессии или классификации. Каждый следующий классификатор стремится исправить ошибки предыдущего.\n",
      "\n",
      "Алгоритм градиентного бустинга работает следующим образом:\n",
      "\n",
      "1. Начинаем с простой модели, которая предсказывает среднее значение целевой переменной для регрессии или частоту класса для классификации.\n",
      "2. Вычисляем ошибки предсказаний (резидуальные ошибки) для каждой точки в обучающей выборке.\n",
      "3. Строим новый классификатор, который предназначен для предсказания резидуальных ошибок предыдущей модели. В процессе обучения этого классификатора минимизируется функция потерь, например, среднеквадратическое отклонение для регрессии или функция потерь биномиального распределения для классификации.\n",
      "4. Обновляем модель, добавляя новый классификатор, умноженный на некоторый коэффициент (шаг обучения или learning rate), к существующей модели.\n",
      "5. Повторяем шаги 2-4 несколько раз, до тех пор, пока не будет достигнуто необходимое качество модели или не будет выполнено предельное число итераций.\n",
      "\n",
      "В результате получаем модель, которая представляет собой линейную комбинацию слабых классификаторов, каждый из которых помогает улучшить качество предсказаний предыдущей модели.\n",
      "Reference Answer: Алгоритм градиентного бустинга использует ансамбль слабых моделей, таких как решающие деревья, которые последовательно обучаются на ошибках предыдущих моделей. Он эффективно улучшает точность предсказаний путем уменьшения ошибки на каждом этапе обучения.\n",
      "Cosine Similarity: 0.69395911693573\n",
      "BLEU Score: 5.3012666666889136e-79\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1767676e63ad4b9dbf670c681a6431be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa6acb50c8f04b8dae135b165ba36ef5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question ID: 98\n",
      "Generated Answer: Ансамблевые методы в машинном обучении - это техники, которые комбинируют несколько моделей машинного обучения для улучшения точности прогнозов. Они основаны на идее, что ensemble (\"ансамбль\") из нескольких моделей может быть более точным, чем каждая модель отдельно. Существует несколько разных типов ансамблевых методов, таких как метод баггинга, метод бостонской шкалы и метод gradient boosting. Эти методы используются для решения задач классификации, регрессии и прогнозирования. Например, метод gradient boosting часто используется для решения задач регрессии и прогнозирования, поскольку он может эффективно моделировать сложные взаимосвязи между переменными. Ансамблевые методы широко используются в машинном обучении, поскольку они могут значительно улучшить точность моделей.\n",
      "Reference Answer: Ансамблевые методы в машинном обучении объединяют несколько моделей для улучшения их точности и устойчивости. Основные методы включают bagging, boosting и stacking, которые помогают уменьшить переобучение и улучшить обобщающую способность моделей.\n",
      "Cosine Similarity: 0.7630688548088074\n",
      "BLEU Score: 0.052287224510505534\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dbccc3f9d0f7445a918b9d852c6fc2bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd15492a120e409095096ae52668b013",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question ID: 99\n",
      "Generated Answer: Когда вы оцениваете качество модели машинного обучения на тестовых данных, вы можете использовать различные метрики, такие как точность, recall, F1-мерa, log-потерю, ROC-карту и AUC-значение, зависящие от конкретной задачи. Вы можете также использовать кросс-валидацию для улучшения оценки качества модели. Кроме того, важно сравнивать результаты с базовыми моделями и моделями сопоставимого качества. Наконец, важно не надметать моделью, проверяя ее на данных, которые использовались для обучения модели. Это может привести к завышенной оценке качества модели.\n",
      "\n",
      "Translation:\n",
      "\n",
      "Когда вы оцениваете качество модели машинного обучения на тестовых данных, вы можете использовать различные метрики, такие как точность, полнота, F1-мерa, log-потеря, ROC-кривая и AUC-значение, в зависимости от конкретной задачи. Вы также можете использовать кросс-валидацию для улучшения оценки качества модели. Кроме того, важно сравнивать результаты с базовыми моделями и моделями сравнимого качества. Наконец, важно не переоценивать модель, проверяя ее на данных, которые использовались для обучения модели. Это может привести к завышенной оценке качества модели.\n",
      "\n",
      "Transliteration:\n",
      "\n",
      "Kogda vy otsenivayete kachestvo modeli mashinnoogo obucheniya na testovykh dannykh, vy mozhete ispol'zovat' razlichnye metriki, takie kak tochnost', polnota, F1-mera, log-poterya, ROC-krivaya i AUC-znachenie, v zavisimosti ot konkretnoi zadachi. Vy takzhe mozhete ispol'zovat' kross-validatsiyu dlya uluchsheniya otsenki kachestva modeli. Krome togo, vazhno sravnivat' rezul'taty s bazovymi modeliami i modeliami sravnimo kachestva. Nakonec, vazhno ne pereotsenivat' model', proveryaya ee na dannykh, kotoryye ispol'zovalis' dlya obucheniya modeli. Eto mozhet privesti k zavyshennoi otsenke kachestva modeli.\n",
      "Reference Answer: Для оценки качества модели на тестовых данных я использую метрики, такие как точность (accuracy), полнота (recall), F-мера и AUC-ROC. Эти метрики позволяют оценить, насколько хорошо модель справляется с задачей классификации или регрессии на новых данных.\n",
      "Cosine Similarity: 0.7610799670219421\n",
      "BLEU Score: 5.525460195308765e-79\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Load your data\n",
    "with open('/home/bullat/projects/rag/Interview-2.0/answers.json', 'r', encoding='utf-8') as f:\n",
    "    generated_answers = json.load(f)\n",
    "\n",
    "with open('/home/bullat/projects/rag/Interview-2.0/Answer_fact.json', 'r', encoding='utf-8') as f:\n",
    "    reference_answers = json.load(f)\n",
    "\n",
    "# Initialize the SentenceTransformer model\n",
    "model = SentenceTransformer('paraphrase-MiniLM-L6-v2')\n",
    "\n",
    "# Define function to calculate Cosine Similarity\n",
    "def calculate_cosine_similarity(generated, reference):\n",
    "    generated_vector = model.encode([generated])\n",
    "    reference_vector = model.encode([reference])\n",
    "    return cosine_similarity(generated_vector, reference_vector)[0][0]\n",
    "\n",
    "# Define function to calculate BLEU Score\n",
    "def calculate_bleu_score(generated, reference):\n",
    "    reference_tokens = [reference.split()]\n",
    "    generated_tokens = generated.split()\n",
    "    return sentence_bleu(reference_tokens, generated_tokens)\n",
    "\n",
    "# Calculate and print metrics\n",
    "for key in generated_answers.keys():\n",
    "    generated = generated_answers[key]\n",
    "    reference = reference_answers[key]\n",
    "    \n",
    "    cosine_sim = calculate_cosine_similarity(generated, reference)\n",
    "    bleu_score = calculate_bleu_score(generated, reference)\n",
    "    \n",
    "    print(f\"Question ID: {key}\")\n",
    "    print(f\"Generated Answer: {generated}\")\n",
    "    print(f\"Reference Answer: {reference}\")\n",
    "    print(f\"Cosine Similarity: {cosine_sim}\")\n",
    "    print(f\"BLEU Score: {bleu_score}\")\n",
    "    print()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/bullat/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "2025-01-04 11:16:11,609 - absl - INFO - Using default tokenizer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation Metrics:\n",
      "ROUGE-1: 0.1352\n",
      "ROUGE-2: 0.0675\n",
      "ROUGE-L: 0.1337\n",
      "BLEU: 0.0322\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from rouge_score import rouge_scorer\n",
    "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
    "import numpy as np\n",
    "import nltk\n",
    "\n",
    "# Download required NLTK data\n",
    "nltk.download('punkt')\n",
    "\n",
    "def load_json(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        return json.load(f)\n",
    "\n",
    "def simple_tokenize(text):\n",
    "    # Simple whitespace tokenization with punctuation handling\n",
    "    return [word.strip('.,!?()[]{}:;\"\\'') for word in text.split()]\n",
    "\n",
    "def calculate_metrics(pred_answers, true_answers):\n",
    "    scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=False)\n",
    "    smooth = SmoothingFunction()\n",
    "    metrics = {}\n",
    "    \n",
    "    rouge_scores = {'rouge1': [], 'rouge2': [], 'rougeL': []}\n",
    "    bleu_scores = []\n",
    "    \n",
    "    for key in pred_answers:\n",
    "        if key in true_answers:\n",
    "            rouge = scorer.score(true_answers[key], pred_answers[key])\n",
    "            for metric in rouge_scores:\n",
    "                rouge_scores[metric].append(rouge[metric].fmeasure)\n",
    "            \n",
    "            reference = [simple_tokenize(true_answers[key].lower())]\n",
    "            candidate = simple_tokenize(pred_answers[key].lower())\n",
    "            \n",
    "            if reference[0] and candidate:  # Check if tokens exist\n",
    "                bleu = sentence_bleu(reference, candidate, \n",
    "                                   smoothing_function=smooth.method1)\n",
    "                bleu_scores.append(bleu)\n",
    "    \n",
    "    # Calculate averages\n",
    "    metrics['rouge1'] = np.mean(rouge_scores['rouge1']) if rouge_scores['rouge1'] else 0\n",
    "    metrics['rouge2'] = np.mean(rouge_scores['rouge2']) if rouge_scores['rouge2'] else 0\n",
    "    metrics['rougeL'] = np.mean(rouge_scores['rougeL']) if rouge_scores['rougeL'] else 0\n",
    "    metrics['bleu'] = np.mean(bleu_scores) if bleu_scores else 0\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "# Load and evaluate\n",
    "pred_answers = load_json('/home/bullat/projects/rag/Interview-2.0/answers.json')\n",
    "true_answers = load_json('/home/bullat/projects/rag/Interview-2.0/Answer_fact.json')\n",
    "metrics = calculate_metrics(pred_answers, true_answers)\n",
    "\n",
    "print(\"\\nEvaluation Metrics:\")\n",
    "print(f\"ROUGE-1: {metrics['rouge1']:.4f}\")\n",
    "print(f\"ROUGE-2: {metrics['rouge2']:.4f}\")\n",
    "print(f\"ROUGE-L: {metrics['rougeL']:.4f}\")\n",
    "print(f\"BLEU: {metrics['bleu']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/bullat/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "2025-01-04 11:40:37,655 - sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: cpu\n",
      "2025-01-04 11:40:37,656 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: paraphrase-MiniLM-L6-v2\n",
      "2025-01-04 11:40:40,860 - absl - INFO - Using default tokenizer.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e70e96afe914e3f99bc8b1a9f2fd52e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3062ba152394458a87531180059aac0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dcac92394fef4e53ae13f23be6fd9d10",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02c4cf7f880b4190be70bc07df27bd82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0b213da29b54fe594938949d5fe281f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87269e2e6bbc4152972710724af2e8dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9d53ff6b41e449e92e33f49abd1c6f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55bf406ff7514b17ad0710e06cc67d15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f8fc5fec95e4394a061b7160824591e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d5501d1207c412bbbc5cef76e4c033f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd1728682d224930a14bbed5421bab0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2351d8f6b1e49a49462cce3288c5dde",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0436e26d4b1a4ff0a36177ac4efc46d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ce9236ec38e46bc82130451c5b5deef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8119da4ae93c4a6c8597ccc8b145566c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5abd9765fc24505a9ed9ed169c0d4c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ae61c008978433290aa85ee2c886dc6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2fca11597cf54ecfa38ff2b02d6521c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a6683e31ce34ff89e0b4250ec3d7581",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73e5e2d4d3be471c82f5dc014eb91f4a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5fbf9dd7f122459d9ac3e38c8480e4a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "590683bbbd1545c19db6240e46d5739f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b1c686a6a3141458edd35a6cb8b9fa1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7def22a844c14ea98afa5653d73189da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b27646344ad4174939605041f8e6681",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d66f3c60c43f4a76aa45138dd18cecf4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5e3ab3b26f14317b7bcdc6178768abe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5744fdb8d202497c95ee9275eabf3467",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aefec3ac5eab46af8be82f4369ecc23c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8b12397d11646eeaec8feffe067abf7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e15eb464d8814dddbd2f20ca4f9bbc9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e0cacaac22e4a35ac8fb547f04a30d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ae13a9207ba4fa8a1f0dd90f3b3877d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "865554b3155044b496c02fb0d3c27558",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d440f44f29ec4040b9837dfc03c4ae90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0537a80536f40ab86111d3aea255502",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "747362fd12114e7d8816961129bb82b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eea8a39d2b94478790320b4771dbe159",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a52142d39b3441f18e2d124cf3157f36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26e1c77227bc46ebbc313906ea7276b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "929ef445700b42d2b6150b41c78398e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc8bd21595364a60905b0a6fd6e52b50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "daa2c227790244609c58a5e1648258d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f498e9c64af4939a15d32894fdf91ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51bdc1d84d1e498f9bccea8b419296e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "063fb0e1bb124d25a9932a759e5c794a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3f07b9eb1724006be5f13dc1205f7d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3761101a69644445a2d9c15bc880b6c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b333db83309c4890922452b313a6c9fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09657b96c7284421a21d3b4a88c7b8d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b980a46a33f84ffd833576aefd3a77f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0dc66992ebe7494a80ed8e76229c31b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd12b65d89f3452090fb3037b86ac0a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f4a7bd92d6a44d383425ce574950587",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0eadbab4edec405782d30bfb0887f072",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "317ff6cbbe5e4c7b830a64ee4b675ef5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "599d09cbf06a4891b352a07aa4e26bba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd3c3cac6bad44118f473b76c7cb24c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc1755f0ec3e4dbbbd90cd7efe41a2ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7249cb23ee014d1985b62e8969064031",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44f12586a3e24e869430ba9976cd35b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1061082b034345c3a6e8b68062bdffff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e875a76b02c4d2f91e1e4b4e8ff6eb3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0252b04d7c1e498b912c3edd778d6ef9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd482784ca7d48fbae58a203febd044b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "afba8997c31e4b548135f3c213aa9324",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b5a94871fe446e1abd38935431a8b11",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c29987bc8dca481ea379461e7095e1c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "454f852429c2400fb8c3f49e8efedc66",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60eb33ad344d40ecae4779ea145bcf5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1a88f9b9bf84f57888dbcacbea3d7c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4072456c0cf7402f963cc5d146bfef77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f348ddf84484d9980b6fc6523f7e365",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5096554ccee341c995ed81ba2e226cbb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22a5d66b362e43859e64ef172e46142d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b96cf1d4a2824d0f9afe1aef15f2afdb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3be51162f37743d3bcc8c99a7edc2483",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac8cd145f0b74e68a682989aa70d5507",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9803134e568e4486b406f211975957d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61d02eced16a4f34b884717e6e5361eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a990d7ac00fa4fa0a080ecb0c3e701ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53281e0a6b7f4fe89088068a46306b44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ebfd47b458d48089c907b9e8a8f2c94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a4ce71d886349369acf17cb4b55c0e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48342a390f994c489c222044e6415d07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d01452340b34ec0bfa667c2bc4dbf4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3082af4219ac4311ac8148c990f93334",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61c5e73eed264dca810a48fdd6827cc2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4fa80643d9f04381b7bdf06bc70cb780",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb3b5b9e044b40dd9282f4e502384287",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3bfb62f1930b4eab86b65fbdb8644242",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "024ea800361d4efab2fcb032e3f67f30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68bdac8e4af249018de3890621507630",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3463511d6b114ee6a6935d6abe650f59",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69c8d72e9505493090ba84315859cf30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "849920071b8441ffbc8e3e8c050e7ea0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4d5b45ef449439c9d6e1abd36a624af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "245c0b60af624bf2b44c8ecd62dd64e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ee895c8006245baa22003c38fec8916",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bfafbe4564824bfdba3417e9ad72ec5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "623373e06dbb4dea8270637b608df2c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15343e4a312e426397120894abd3f072",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d571b1200b145f29fd87a2a73413ba5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed764ae91aed4aafbfce5bb426bfde03",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e452cf9ac7fc4aec9b18f5701db73b70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "def93dfd3a0f4d89bdeaa63a21db031a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b44f98dc82ae4649a9d6c391a10d4e14",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38859f1ff189438e849493e35d5d0b2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af691b7763aa495ca126f21cd1ecbb93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21f1a27dcec1449b91313cacabefd455",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c280ee12e4674dffa57baae22a78b996",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4fc89bf57eef49d4978d63e98d1e523b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb48466a38c44d22a84a182d6d0f412d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9e4ecf9ab7f4ebcbe628420200de011",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50d0934bf3a54825bcc15d991a721111",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "732b6430f7484b56b8ceb0cbaa3edae3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8a911f65d034f179a545339801d2cc2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf5d26bd1b104865a52351e1c4d131e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ebfc9edf93e4aa3b44accb35ff07d6c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ccc299cf9864c40a29d15d4fcd5584e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "488ca189950d499ba70cbab12dbba103",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83dc2556ed28471aad97c13d76da284e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "396544cc462545b78f627e41b2347bdd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e57c1f4bbc154c579d6437e3bda0de60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d0a012b8601464e84609bed50592630",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80b962dd5be14e0a9face0f242dd4f5c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c5810f764e04ecea894f8e677fe80e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4dfadef47f84358845b731afe437769",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd34a692fd6e465abe6177973b08dd1d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fddb3fabad124409989b8dac2392ec10",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0aef58f9e8d041dea759bc3951cd827a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee6e1fffcf1c4a7cbbeffac7c6f5f13f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e87c2b3df1ad41c39027cbf5a4003a2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd837a57f8864021ad98f4f193468be6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "476cd7d8063e48c39cada46f7c671280",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b7ef1773c2f468f8e27f0e884f69c7a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06edffb06a0c4359b466050d7d91b066",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6cf59242d0804040ac0a2848f0832b04",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b0a2863bf554007a043ae9c69595adb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd148d5d955f4778baaf5d25aa3ea939",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52af6cf5673048489f14c548e12092b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff60200fd8b7449eaf02e95d54373542",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42458dde0fa147c5a6abf9dd868843ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc03e57a788f46b4be09277409ecfbcd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "337787c55a9344e48323b8b373d0514e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b5bdc7f07124871a6e9f6c2f41f1ef3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3715d86ca1b44824b7cb564d738ac78d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c8e11a059064e6f887e5405f3245f6a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "299cbbd7973e4fe4b5804f68ff6b8741",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6591de12148e4ae59b9ccf57d86bbbe1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a66177ca6cb74f6096342323103b9712",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b70d2df42b8422fb98155d2a2a2a9e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fff6a196641e4c68b85716416c2aa9b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d4331a9860748a79bc00567a0da4ef5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c84e7b6ea444fed8eb4b145ee63c4ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30d0df8e670d4534a091428f9e4ee03b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2063eb7eb7c41a992a96a6218f131ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bbcd699bd4e245a29fed290f043d95f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0c4fa5b2f654da18b11f167214d01fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1fc84463bcc8448394f7f9e0abc344a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4bfb9d6268847d4ba884936499af004",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c8d406558b348bd81538d5fd1dcf00e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3678bcca4b834c64afb83642d21af74a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86676424388c48cf84e75be0ea89d7c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "486cc737d80b4178ac4c1f87045159b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ccadc743d44c4479a9c0d8b60a32e3fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d806f23d52fe4e69889dc443ae0db8fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "094efa6ae159431ab28c390bf088f8d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be75c970922f42a0acf106e3d0d173fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af776609ac9a4d0582ae4d71249c26cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cac9b0f10d104ec9b6a63c771933b4c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff489fdefb7b4d3a8c09616b8e9e0ced",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81296a6101f9436bb879d4c81277cae9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d4ea06b70b446518c79c71d8a7c8c10",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b499e346e3a45969e6a37ecb0e6e310",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "425bba23e85842318335357441c45bf6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c84fe13314ac4c2d8ae4c7b538ee97b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71705ede18bf4221b658a5414f6fd7bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42cddc198b244bccb6a120843c24a5c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad9ffad997a748118feeb5886c131b95",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c261c14a20384e8a964b9dec3e79a1f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a98366a3dd5a411cb77549b2c2999ee2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7850dc63f006425ebfb9be7508679e1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f970c161cc3444fea00951a10d316772",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4eef6f470b22446f99ca0f1723300cad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e71fe8e3529341899f26d57f18df0ca3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7b7bf80b38542cb93f190c198710148",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e348b5a2661146c382468bae96059bd4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3115e6a592294b7e820799bf5bd0c674",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d077ceafaa4430ba8c9dcf984faabec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7a2f543eca242b7b0f40e2820b3feab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f252faef369b4822bcf6a64101e4ef12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d37901056d1f43508802ce4732971c5c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c9958807b504fcb97f0b6adc080e691",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f82b9aba67f4b5dbd421833aadf6fe7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80ba74e46c0c4ad99afa1f27ef3414c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9716092c20ad445aadb62859d2bf0637",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c362f874edf44157aab4438f16febc1e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15f2d0edb36c493da6a36ddec3ecbbbb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b83f7dffbbb444ca2bbb37215d09000",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation Metrics:\n",
      "ROUGE-1: 0.1352\n",
      "ROUGE-2: 0.0675\n",
      "ROUGE-L: 0.1337\n",
      "BLEU: 0.0322\n",
      "Cosine Similarity: 0.8786\n",
      "BERTScore F1: 0.9142\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
    "from rouge_score import rouge_scorer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from bert_score import score as bert_score\n",
    "\n",
    "# Download required NLTK data\n",
    "nltk.download('punkt')\n",
    "\n",
    "# Initialize the SentenceTransformer model\n",
    "model = SentenceTransformer('paraphrase-MiniLM-L6-v2')  # Replace with your chosen model\n",
    "bert_scorer_model = 'roberta-large'  # Model to use for BERTScore\n",
    "\n",
    "def load_json(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        return json.load(f)\n",
    "\n",
    "def simple_tokenize(text):\n",
    "    # Simple whitespace tokenization with punctuation handling\n",
    "    return [word.strip('.,!?()[]{}:;\"\\'') for word in text.split()]\n",
    "\n",
    "def calculate_cosine_similarity(generated, reference):\n",
    "    generated_vector = model.encode([generated])\n",
    "    reference_vector = model.encode([reference])\n",
    "    return cosine_similarity(generated_vector, reference_vector)[0][0]\n",
    "\n",
    "def calculate_bert_score(pred_answers, true_answers):\n",
    "    pred_list = [pred_answers[key] for key in pred_answers if key in true_answers]\n",
    "    true_list = [true_answers[key] for key in pred_answers if key in true_answers]\n",
    "    \n",
    "    P, R, F1 = bert_score(pred_list, true_list, model_type=bert_scorer_model)\n",
    "    return np.mean(F1.cpu().numpy())  # Convert tensors to numpy arrays\n",
    "\n",
    "def calculate_metrics(pred_answers, true_answers):\n",
    "    scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=False)\n",
    "    smooth = SmoothingFunction()\n",
    "    metrics = {}\n",
    "    \n",
    "    rouge_scores = {'rouge1': [], 'rouge2': [], 'rougeL': []}\n",
    "    bleu_scores = []\n",
    "    cosine_scores = []\n",
    "    \n",
    "    for key in pred_answers:\n",
    "        if key in true_answers:\n",
    "            rouge = scorer.score(true_answers[key], pred_answers[key])\n",
    "            for metric in rouge_scores:\n",
    "                rouge_scores[metric].append(rouge[metric].fmeasure)\n",
    "            \n",
    "            reference = [simple_tokenize(true_answers[key].lower())]\n",
    "            candidate = simple_tokenize(pred_answers[key].lower())\n",
    "            \n",
    "            if reference[0] and candidate:  # Check if tokens exist\n",
    "                bleu = sentence_bleu(reference, candidate, \n",
    "                                   smoothing_function=smooth.method1)\n",
    "                bleu_scores.append(bleu)\n",
    "            \n",
    "            # Calculate Cosine Similarity\n",
    "            cosine_sim = calculate_cosine_similarity(pred_answers[key], true_answers[key])\n",
    "            cosine_scores.append(cosine_sim)\n",
    "    \n",
    "    # Calculate BERTScore\n",
    "    bert_f1_score = calculate_bert_score(pred_answers, true_answers)\n",
    "    \n",
    "    # Calculate averages\n",
    "    metrics['rouge1'] = np.mean(rouge_scores['rouge1']) if rouge_scores['rouge1'] else 0\n",
    "    metrics['rouge2'] = np.mean(rouge_scores['rouge2']) if rouge_scores['rouge2'] else 0\n",
    "    metrics['rougeL'] = np.mean(rouge_scores['rougeL']) if rouge_scores['rougeL'] else 0\n",
    "    metrics['bleu'] = np.mean(bleu_scores) if bleu_scores else 0\n",
    "    metrics['cosine'] = np.mean(cosine_scores) if cosine_scores else 0\n",
    "    metrics['bert_f1'] = bert_f1_score\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "# Load and evaluate\n",
    "pred_answers = load_json('/home/bullat/projects/rag/Interview-2.0/answers.json')\n",
    "true_answers = load_json('/home/bullat/projects/rag/Interview-2.0/Answer_fact.json')\n",
    "metrics = calculate_metrics(pred_answers, true_answers)\n",
    "\n",
    "print(\"\\nEvaluation Metrics:\")\n",
    "print(f\"ROUGE-1: {metrics['rouge1']:.4f}\")\n",
    "print(f\"ROUGE-2: {metrics['rouge2']:.4f}\")\n",
    "print(f\"ROUGE-L: {metrics['rougeL']:.4f}\")\n",
    "print(f\"BLEU: {metrics['bleu']:.4f}\")\n",
    "print(f\"Cosine Similarity: {metrics['cosine']:.4f}\")\n",
    "print(f\"BERTScore F1: {metrics['bert_f1']:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Метрики ROUGE и BLEU больше ориентируются на схожесть слов и выражений. RAG выдает ответы отличными от эталона словами, однако Cosine Similarity и BERTScore показывают, что у ответов схожая семантика и смысл."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
