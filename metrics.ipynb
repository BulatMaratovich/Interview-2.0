{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-03 19:42:44,224 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/pinecone_plugins'])\n",
      "2025-01-03 19:42:44,228 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference\n",
      "2025-01-03 19:42:44,229 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone\n",
      "2025-01-03 19:42:44,318 - sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: cpu\n",
      "2025-01-03 19:42:44,319 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: paraphrase-MiniLM-L6-v2\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import ebooklib\n",
    "from dotenv import load_dotenv\n",
    "# from env_tokens import TELEGRAM_BOT_TOKEN, MISTRAL_API_ENDPOINT, PINECONE_API_KEY\n",
    "from telegram import Update\n",
    "from telegram.ext import ApplicationBuilder, CommandHandler, MessageHandler, filters, ContextTypes\n",
    "from mistralai import Mistral\n",
    "from pinecone import Pinecone, ServerlessSpec\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from ebooklib import epub\n",
    "from bs4 import BeautifulSoup\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "TELEGRAM_BOT_TOKEN = '7466857543:AAHWnxfKJ4hpS46zoI48CaRIYMP7aCir4BY'\n",
    "MISTRAL_API_ENDPOINT = 'BbzDhJzmYPuASFVeZC7C6pLuHuC6qb6m'\n",
    "PINECONE_API_KEY = 'pcsk_3jKr3Z_SrBc6DCo3JRmssPRaJ6yhRHkK4DK2VmdZyrmwSZu6ypEUuPYhFWyY743QiDadmZ'\n",
    "\n",
    "# Enable logging\n",
    "logging.basicConfig(\n",
    "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s', level=logging.INFO\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Токен Telegram бота\n",
    "TELEGRAM_BOT_TOKEN = TELEGRAM_BOT_TOKEN\n",
    "\n",
    "# API endpoint Mistral\n",
    "MISTRAL_API_ENDPOINT = MISTRAL_API_ENDPOINT\n",
    "MISTRAL_MODEL = 'mistral-medium'  # Replace with the name of your Mistral model\n",
    "MISTRAL_CLIENT = Mistral(api_key=MISTRAL_API_ENDPOINT)\n",
    "\n",
    "# API endpoint Pinecone\n",
    "PINECONE_API_KEY = PINECONE_API_KEY\n",
    "PINECONE_ENVIRONMENT = 'us-east-1'\n",
    "INDEX_NAME = 'interview-qa2'\n",
    "\n",
    "# Initialize Pinecone\n",
    "pc = Pinecone(api_key=PINECONE_API_KEY)\n",
    "\n",
    "# Initialize SentenceTransformer model\n",
    "model = SentenceTransformer('paraphrase-MiniLM-L6-v2')\n",
    "#model = SentenceTransformer('intfloat/multilingual-e5-large')\n",
    "\n",
    "# TODO Сделать БД?\n",
    "ind_text_dict = {}\n",
    "\n",
    "\n",
    "async def start(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:\n",
    "    await update.message.reply_text(\n",
    "        'Hi! I am your Mistral RAG bot. Send me a message and I will retrieve and generate a response for you.')\n",
    "\n",
    "\n",
    "async def handle_message(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:\n",
    "    user_message = update.message.text\n",
    "    logger.info(f\"Received message: {user_message}\")\n",
    "\n",
    "    # Step 1: Retrieve relevant documents from the vector database\n",
    "    retrieved_docs = retrieve_documents(user_message)\n",
    "\n",
    "    # Step 2: Generate a response using Mistral API\n",
    "    response = generate_response(user_message, retrieved_docs)\n",
    "\n",
    "    await update.message.reply_text(response)\n",
    "\n",
    "\n",
    "def retrieve_documents(query: str):\n",
    "    # Convert the query to a vector\n",
    "    query_vector = model.encode(query).tolist()\n",
    "\n",
    "    # Query the Pinecone index with keyword arguments\n",
    "    index = pc.Index(INDEX_NAME)\n",
    "    results = index.query(vector=query_vector, top_k=5, include_metadata=True)\n",
    "    \n",
    "    # Log the retrieved results for debugging\n",
    "    logger.info(f\"Retrieved results: {results}\")\n",
    "\n",
    "    retrieved_docs = []\n",
    "    for match in results['matches']:\n",
    "        doc_id = match['id']\n",
    "        try:\n",
    "            retrieved_docs.append(ind_text_dict[doc_id])\n",
    "        except KeyError:\n",
    "            logger.warning(f\"Document ID {doc_id} not found in local dictionary.\")\n",
    "    \n",
    "    return retrieved_docs\n",
    "\n",
    "\n",
    "\n",
    "def generate_response(query: str, documents: list):\n",
    "    \"\"\"Generate a response using Mistral API.\"\"\"\n",
    "    prompt = f\"\"\"\n",
    "    You are an AI assistant designed to help users prepare for ML engineer interviews. \n",
    "    You have access to a knowledge base with information in English. \n",
    "    When a user asks a question, you should retrieve the relevant information from the knowledge base and then translate the response into the language of the user's question.\n",
    "    Knowledge base: {documents}\n",
    "    \n",
    "    Here is the user's question:\n",
    "    [{query}]\n",
    "    \n",
    "    Please provide the answer only in the language of the user's question.\n",
    "        \"\"\"\n",
    "\n",
    "    # Send the prompt to Mistral API\n",
    "    try:\n",
    "        response = MISTRAL_CLIENT.chat.complete(\n",
    "            model=MISTRAL_MODEL,\n",
    "            messages=[{'role': \"user\", 'content': prompt}]\n",
    "        )\n",
    "        return response.choices[0].message.content.strip()\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error generating response: {e}\")\n",
    "        return \"Sorry, I couldn't generate a response at the moment.\"\n",
    "\n",
    "\n",
    "def extract_text_from_epub(file_path):\n",
    "    book = epub.read_epub(file_path)\n",
    "    text = []\n",
    "    for item in book.get_items_of_type(ebooklib.ITEM_DOCUMENT):\n",
    "        soup = BeautifulSoup(item.get_body_content(), 'html.parser')\n",
    "        text.append(soup.get_text())\n",
    "    return ' '.join(text)\n",
    "\n",
    "\n",
    "def generate_embeddings(documents):\n",
    "    embeddings = []\n",
    "    for text_id, text in documents.items():\n",
    "        embedding = model.encode(text)\n",
    "        embeddings.append({'id': text_id, 'values': embedding.tolist()})\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/ebooklib/epub.py:1395: UserWarning: In the future version we will turn default option ignore_ncx to True.\n",
      "  warnings.warn('In the future version we will turn default option ignore_ncx to True.')\n",
      "/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/ebooklib/epub.py:1423: FutureWarning: This search incorrectly ignores the root element, and will be fixed in a future version.  If you rely on the current behaviour, change it to './/xmlns:rootfile[@media-type]'\n",
      "  for root_file in tree.findall('//xmlns:rootfile[@media-type]', namespaces={'xmlns': NAMESPACES['CONTAINERNS']}):\n",
      "2025-01-03 19:43:00,584 - langchain_text_splitters.base - WARNING - Created a chunk of size 3558, which is longer than the specified 2000\n",
      "2025-01-03 19:43:00,585 - langchain_text_splitters.base - WARNING - Created a chunk of size 3734, which is longer than the specified 2000\n",
      "2025-01-03 19:43:00,585 - langchain_text_splitters.base - WARNING - Created a chunk of size 2100, which is longer than the specified 2000\n",
      "2025-01-03 19:43:00,586 - langchain_text_splitters.base - WARNING - Created a chunk of size 2200, which is longer than the specified 2000\n",
      "2025-01-03 19:43:00,586 - langchain_text_splitters.base - WARNING - Created a chunk of size 2645, which is longer than the specified 2000\n",
      "2025-01-03 19:43:00,588 - langchain_text_splitters.base - WARNING - Created a chunk of size 3578, which is longer than the specified 2000\n",
      "2025-01-03 19:43:00,588 - langchain_text_splitters.base - WARNING - Created a chunk of size 2457, which is longer than the specified 2000\n",
      "2025-01-03 19:43:00,589 - langchain_text_splitters.base - WARNING - Created a chunk of size 3057, which is longer than the specified 2000\n",
      "2025-01-03 19:43:00,589 - langchain_text_splitters.base - WARNING - Created a chunk of size 2300, which is longer than the specified 2000\n",
      "2025-01-03 19:43:00,590 - langchain_text_splitters.base - WARNING - Created a chunk of size 2069, which is longer than the specified 2000\n",
      "2025-01-03 19:43:00,590 - langchain_text_splitters.base - WARNING - Created a chunk of size 2998, which is longer than the specified 2000\n",
      "2025-01-03 19:43:00,591 - langchain_text_splitters.base - WARNING - Created a chunk of size 2381, which is longer than the specified 2000\n",
      "2025-01-03 19:43:00,591 - langchain_text_splitters.base - WARNING - Created a chunk of size 2212, which is longer than the specified 2000\n",
      "2025-01-03 19:43:00,592 - langchain_text_splitters.base - WARNING - Created a chunk of size 3890, which is longer than the specified 2000\n",
      "2025-01-03 19:43:00,592 - langchain_text_splitters.base - WARNING - Created a chunk of size 2033, which is longer than the specified 2000\n",
      "2025-01-03 19:43:00,593 - langchain_text_splitters.base - WARNING - Created a chunk of size 2084, which is longer than the specified 2000\n",
      "2025-01-03 19:43:00,593 - langchain_text_splitters.base - WARNING - Created a chunk of size 3145, which is longer than the specified 2000\n",
      "2025-01-03 19:43:00,594 - langchain_text_splitters.base - WARNING - Created a chunk of size 2097, which is longer than the specified 2000\n",
      "2025-01-03 19:43:00,596 - langchain_text_splitters.base - WARNING - Created a chunk of size 10857, which is longer than the specified 2000\n",
      "2025-01-03 19:43:00,596 - langchain_text_splitters.base - WARNING - Created a chunk of size 4209, which is longer than the specified 2000\n",
      "2025-01-03 19:43:00,597 - langchain_text_splitters.base - WARNING - Created a chunk of size 2009, which is longer than the specified 2000\n",
      "2025-01-03 19:43:00,597 - langchain_text_splitters.base - WARNING - Created a chunk of size 4212, which is longer than the specified 2000\n",
      "2025-01-03 19:43:00,598 - langchain_text_splitters.base - WARNING - Created a chunk of size 4179, which is longer than the specified 2000\n",
      "2025-01-03 19:43:00,598 - langchain_text_splitters.base - WARNING - Created a chunk of size 8014, which is longer than the specified 2000\n",
      "2025-01-03 19:43:00,598 - langchain_text_splitters.base - WARNING - Created a chunk of size 2610, which is longer than the specified 2000\n",
      "2025-01-03 19:43:00,599 - langchain_text_splitters.base - WARNING - Created a chunk of size 3027, which is longer than the specified 2000\n",
      "2025-01-03 19:43:00,599 - langchain_text_splitters.base - WARNING - Created a chunk of size 4196, which is longer than the specified 2000\n",
      "2025-01-03 19:43:00,600 - langchain_text_splitters.base - WARNING - Created a chunk of size 6160, which is longer than the specified 2000\n",
      "2025-01-03 19:43:00,601 - langchain_text_splitters.base - WARNING - Created a chunk of size 4795, which is longer than the specified 2000\n",
      "2025-01-03 19:43:00,602 - langchain_text_splitters.base - WARNING - Created a chunk of size 2752, which is longer than the specified 2000\n",
      "2025-01-03 19:43:00,602 - langchain_text_splitters.base - WARNING - Created a chunk of size 6163, which is longer than the specified 2000\n",
      "2025-01-03 19:43:00,603 - langchain_text_splitters.base - WARNING - Created a chunk of size 2366, which is longer than the specified 2000\n",
      "2025-01-03 19:43:00,603 - langchain_text_splitters.base - WARNING - Created a chunk of size 10731, which is longer than the specified 2000\n",
      "2025-01-03 19:43:00,605 - langchain_text_splitters.base - WARNING - Created a chunk of size 2914, which is longer than the specified 2000\n",
      "2025-01-03 19:43:00,605 - langchain_text_splitters.base - WARNING - Created a chunk of size 2179, which is longer than the specified 2000\n",
      "2025-01-03 19:43:00,606 - langchain_text_splitters.base - WARNING - Created a chunk of size 3263, which is longer than the specified 2000\n",
      "2025-01-03 19:43:00,606 - langchain_text_splitters.base - WARNING - Created a chunk of size 5926, which is longer than the specified 2000\n",
      "2025-01-03 19:43:00,607 - langchain_text_splitters.base - WARNING - Created a chunk of size 3612, which is longer than the specified 2000\n",
      "2025-01-03 19:43:00,608 - langchain_text_splitters.base - WARNING - Created a chunk of size 5279, which is longer than the specified 2000\n",
      "2025-01-03 19:43:00,608 - langchain_text_splitters.base - WARNING - Created a chunk of size 3509, which is longer than the specified 2000\n",
      "2025-01-03 19:43:00,609 - langchain_text_splitters.base - WARNING - Created a chunk of size 5445, which is longer than the specified 2000\n",
      "2025-01-03 19:43:00,609 - langchain_text_splitters.base - WARNING - Created a chunk of size 5758, which is longer than the specified 2000\n",
      "2025-01-03 19:43:00,610 - langchain_text_splitters.base - WARNING - Created a chunk of size 7696, which is longer than the specified 2000\n",
      "2025-01-03 19:43:00,610 - langchain_text_splitters.base - WARNING - Created a chunk of size 2288, which is longer than the specified 2000\n",
      "2025-01-03 19:43:00,611 - langchain_text_splitters.base - WARNING - Created a chunk of size 3284, which is longer than the specified 2000\n",
      "2025-01-03 19:43:00,612 - langchain_text_splitters.base - WARNING - Created a chunk of size 4738, which is longer than the specified 2000\n",
      "2025-01-03 19:43:00,612 - langchain_text_splitters.base - WARNING - Created a chunk of size 4448, which is longer than the specified 2000\n",
      "2025-01-03 19:43:00,613 - langchain_text_splitters.base - WARNING - Created a chunk of size 2359, which is longer than the specified 2000\n",
      "2025-01-03 19:43:00,613 - langchain_text_splitters.base - WARNING - Created a chunk of size 3771, which is longer than the specified 2000\n",
      "2025-01-03 19:43:00,614 - langchain_text_splitters.base - WARNING - Created a chunk of size 2926, which is longer than the specified 2000\n",
      "2025-01-03 19:43:00,614 - langchain_text_splitters.base - WARNING - Created a chunk of size 2665, which is longer than the specified 2000\n",
      "2025-01-03 19:43:00,615 - langchain_text_splitters.base - WARNING - Created a chunk of size 5496, which is longer than the specified 2000\n",
      "2025-01-03 19:43:00,617 - langchain_text_splitters.base - WARNING - Created a chunk of size 2160, which is longer than the specified 2000\n",
      "2025-01-03 19:43:00,617 - langchain_text_splitters.base - WARNING - Created a chunk of size 3287, which is longer than the specified 2000\n",
      "2025-01-03 19:43:00,617 - langchain_text_splitters.base - WARNING - Created a chunk of size 2399, which is longer than the specified 2000\n",
      "2025-01-03 19:43:00,618 - langchain_text_splitters.base - WARNING - Created a chunk of size 3368, which is longer than the specified 2000\n",
      "2025-01-03 19:43:00,618 - langchain_text_splitters.base - WARNING - Created a chunk of size 5063, which is longer than the specified 2000\n",
      "2025-01-03 19:43:00,619 - langchain_text_splitters.base - WARNING - Created a chunk of size 4978, which is longer than the specified 2000\n",
      "2025-01-03 19:43:00,619 - langchain_text_splitters.base - WARNING - Created a chunk of size 2920, which is longer than the specified 2000\n",
      "2025-01-03 19:43:00,621 - langchain_text_splitters.base - WARNING - Created a chunk of size 5209, which is longer than the specified 2000\n",
      "2025-01-03 19:43:00,621 - langchain_text_splitters.base - WARNING - Created a chunk of size 3833, which is longer than the specified 2000\n",
      "2025-01-03 19:43:00,622 - langchain_text_splitters.base - WARNING - Created a chunk of size 3980, which is longer than the specified 2000\n",
      "2025-01-03 19:43:00,622 - langchain_text_splitters.base - WARNING - Created a chunk of size 2542, which is longer than the specified 2000\n",
      "2025-01-03 19:43:00,623 - langchain_text_splitters.base - WARNING - Created a chunk of size 7362, which is longer than the specified 2000\n",
      "2025-01-03 19:43:00,623 - langchain_text_splitters.base - WARNING - Created a chunk of size 2905, which is longer than the specified 2000\n",
      "2025-01-03 19:43:00,624 - langchain_text_splitters.base - WARNING - Created a chunk of size 3168, which is longer than the specified 2000\n",
      "2025-01-03 19:43:00,625 - langchain_text_splitters.base - WARNING - Created a chunk of size 3106, which is longer than the specified 2000\n",
      "2025-01-03 19:43:00,625 - langchain_text_splitters.base - WARNING - Created a chunk of size 2966, which is longer than the specified 2000\n",
      "2025-01-03 19:43:00,625 - langchain_text_splitters.base - WARNING - Created a chunk of size 2201, which is longer than the specified 2000\n",
      "2025-01-03 19:43:00,626 - langchain_text_splitters.base - WARNING - Created a chunk of size 3706, which is longer than the specified 2000\n",
      "2025-01-03 19:43:00,626 - langchain_text_splitters.base - WARNING - Created a chunk of size 3044, which is longer than the specified 2000\n",
      "2025-01-03 19:43:00,627 - langchain_text_splitters.base - WARNING - Created a chunk of size 2334, which is longer than the specified 2000\n",
      "2025-01-03 19:43:00,627 - langchain_text_splitters.base - WARNING - Created a chunk of size 3158, which is longer than the specified 2000\n",
      "2025-01-03 19:43:00,628 - langchain_text_splitters.base - WARNING - Created a chunk of size 2287, which is longer than the specified 2000\n",
      "2025-01-03 19:43:00,629 - langchain_text_splitters.base - WARNING - Created a chunk of size 7851, which is longer than the specified 2000\n",
      "2025-01-03 19:43:00,629 - langchain_text_splitters.base - WARNING - Created a chunk of size 2046, which is longer than the specified 2000\n",
      "2025-01-03 19:43:00,630 - langchain_text_splitters.base - WARNING - Created a chunk of size 2035, which is longer than the specified 2000\n",
      "2025-01-03 19:43:00,631 - langchain_text_splitters.base - WARNING - Created a chunk of size 2822, which is longer than the specified 2000\n",
      "2025-01-03 19:43:00,631 - langchain_text_splitters.base - WARNING - Created a chunk of size 4001, which is longer than the specified 2000\n",
      "2025-01-03 19:43:00,631 - langchain_text_splitters.base - WARNING - Created a chunk of size 2231, which is longer than the specified 2000\n",
      "2025-01-03 19:43:00,632 - langchain_text_splitters.base - WARNING - Created a chunk of size 5772, which is longer than the specified 2000\n",
      "2025-01-03 19:43:00,632 - langchain_text_splitters.base - WARNING - Created a chunk of size 8028, which is longer than the specified 2000\n",
      "2025-01-03 19:43:00,633 - langchain_text_splitters.base - WARNING - Created a chunk of size 4411, which is longer than the specified 2000\n",
      "2025-01-03 19:43:00,633 - langchain_text_splitters.base - WARNING - Created a chunk of size 2773, which is longer than the specified 2000\n",
      "2025-01-03 19:43:00,634 - langchain_text_splitters.base - WARNING - Created a chunk of size 5297, which is longer than the specified 2000\n",
      "2025-01-03 19:43:00,634 - langchain_text_splitters.base - WARNING - Created a chunk of size 6885, which is longer than the specified 2000\n",
      "2025-01-03 19:43:00,634 - langchain_text_splitters.base - WARNING - Created a chunk of size 3768, which is longer than the specified 2000\n",
      "2025-01-03 19:43:00,635 - langchain_text_splitters.base - WARNING - Created a chunk of size 5378, which is longer than the specified 2000\n",
      "2025-01-03 19:43:00,635 - langchain_text_splitters.base - WARNING - Created a chunk of size 7639, which is longer than the specified 2000\n",
      "2025-01-03 19:43:00,636 - langchain_text_splitters.base - WARNING - Created a chunk of size 4154, which is longer than the specified 2000\n",
      "2025-01-03 19:43:00,636 - langchain_text_splitters.base - WARNING - Created a chunk of size 3608, which is longer than the specified 2000\n",
      "2025-01-03 19:43:00,637 - langchain_text_splitters.base - WARNING - Created a chunk of size 4098, which is longer than the specified 2000\n",
      "2025-01-03 19:43:00,637 - langchain_text_splitters.base - WARNING - Created a chunk of size 2534, which is longer than the specified 2000\n",
      "2025-01-03 19:43:00,638 - langchain_text_splitters.base - WARNING - Created a chunk of size 4100, which is longer than the specified 2000\n",
      "2025-01-03 19:43:00,638 - langchain_text_splitters.base - WARNING - Created a chunk of size 3694, which is longer than the specified 2000\n",
      "2025-01-03 19:43:00,638 - langchain_text_splitters.base - WARNING - Created a chunk of size 3591, which is longer than the specified 2000\n",
      "2025-01-03 19:43:00,639 - langchain_text_splitters.base - WARNING - Created a chunk of size 3148, which is longer than the specified 2000\n",
      "2025-01-03 19:43:00,639 - langchain_text_splitters.base - WARNING - Created a chunk of size 2065, which is longer than the specified 2000\n",
      "2025-01-03 19:43:00,640 - langchain_text_splitters.base - WARNING - Created a chunk of size 3237, which is longer than the specified 2000\n",
      "2025-01-03 19:43:00,640 - langchain_text_splitters.base - WARNING - Created a chunk of size 3531, which is longer than the specified 2000\n",
      "2025-01-03 19:43:00,641 - langchain_text_splitters.base - WARNING - Created a chunk of size 3862, which is longer than the specified 2000\n",
      "2025-01-03 19:43:00,641 - langchain_text_splitters.base - WARNING - Created a chunk of size 2563, which is longer than the specified 2000\n",
      "2025-01-03 19:43:00,641 - langchain_text_splitters.base - WARNING - Created a chunk of size 3844, which is longer than the specified 2000\n",
      "2025-01-03 19:43:00,642 - langchain_text_splitters.base - WARNING - Created a chunk of size 2086, which is longer than the specified 2000\n",
      "2025-01-03 19:43:00,642 - langchain_text_splitters.base - WARNING - Created a chunk of size 4252, which is longer than the specified 2000\n",
      "2025-01-03 19:43:00,643 - langchain_text_splitters.base - WARNING - Created a chunk of size 7390, which is longer than the specified 2000\n",
      "2025-01-03 19:43:00,643 - langchain_text_splitters.base - WARNING - Created a chunk of size 2273, which is longer than the specified 2000\n",
      "2025-01-03 19:43:00,644 - langchain_text_splitters.base - WARNING - Created a chunk of size 3019, which is longer than the specified 2000\n",
      "2025-01-03 19:43:00,644 - langchain_text_splitters.base - WARNING - Created a chunk of size 2779, which is longer than the specified 2000\n",
      "2025-01-03 19:43:00,644 - langchain_text_splitters.base - WARNING - Created a chunk of size 2835, which is longer than the specified 2000\n",
      "2025-01-03 19:43:00,645 - langchain_text_splitters.base - WARNING - Created a chunk of size 2570, which is longer than the specified 2000\n",
      "2025-01-03 19:43:00,646 - langchain_text_splitters.base - WARNING - Created a chunk of size 3454, which is longer than the specified 2000\n",
      "2025-01-03 19:43:00,646 - langchain_text_splitters.base - WARNING - Created a chunk of size 3972, which is longer than the specified 2000\n",
      "2025-01-03 19:43:00,646 - langchain_text_splitters.base - WARNING - Created a chunk of size 2029, which is longer than the specified 2000\n",
      "2025-01-03 19:43:00,647 - langchain_text_splitters.base - WARNING - Created a chunk of size 2924, which is longer than the specified 2000\n",
      "2025-01-03 19:43:00,651 - langchain_text_splitters.base - WARNING - Created a chunk of size 3306, which is longer than the specified 2000\n",
      "2025-01-03 19:43:00,656 - langchain_text_splitters.base - WARNING - Created a chunk of size 8481, which is longer than the specified 2000\n",
      "2025-01-03 19:43:00,657 - langchain_text_splitters.base - WARNING - Created a chunk of size 2419, which is longer than the specified 2000\n",
      "2025-01-03 19:43:00,658 - langchain_text_splitters.base - WARNING - Created a chunk of size 4844, which is longer than the specified 2000\n",
      "2025-01-03 19:43:00,659 - langchain_text_splitters.base - WARNING - Created a chunk of size 7062, which is longer than the specified 2000\n",
      "2025-01-03 19:43:00,659 - langchain_text_splitters.base - WARNING - Created a chunk of size 2376, which is longer than the specified 2000\n",
      "2025-01-03 19:43:00,660 - langchain_text_splitters.base - WARNING - Created a chunk of size 5008, which is longer than the specified 2000\n",
      "2025-01-03 19:43:00,660 - langchain_text_splitters.base - WARNING - Created a chunk of size 2961, which is longer than the specified 2000\n",
      "2025-01-03 19:43:00,661 - langchain_text_splitters.base - WARNING - Created a chunk of size 5556, which is longer than the specified 2000\n",
      "2025-01-03 19:43:00,661 - langchain_text_splitters.base - WARNING - Created a chunk of size 7890, which is longer than the specified 2000\n",
      "2025-01-03 19:43:00,662 - langchain_text_splitters.base - WARNING - Created a chunk of size 5965, which is longer than the specified 2000\n",
      "2025-01-03 19:43:00,662 - langchain_text_splitters.base - WARNING - Created a chunk of size 2080, which is longer than the specified 2000\n",
      "2025-01-03 19:43:00,663 - langchain_text_splitters.base - WARNING - Created a chunk of size 2510, which is longer than the specified 2000\n",
      "2025-01-03 19:43:00,663 - langchain_text_splitters.base - WARNING - Created a chunk of size 7993, which is longer than the specified 2000\n",
      "2025-01-03 19:43:00,663 - langchain_text_splitters.base - WARNING - Created a chunk of size 2766, which is longer than the specified 2000\n",
      "2025-01-03 19:43:00,664 - langchain_text_splitters.base - WARNING - Created a chunk of size 2938, which is longer than the specified 2000\n",
      "2025-01-03 19:43:00,664 - langchain_text_splitters.base - WARNING - Created a chunk of size 4552, which is longer than the specified 2000\n",
      "2025-01-03 19:43:00,665 - langchain_text_splitters.base - WARNING - Created a chunk of size 3701, which is longer than the specified 2000\n",
      "2025-01-03 19:43:00,665 - langchain_text_splitters.base - WARNING - Created a chunk of size 2389, which is longer than the specified 2000\n",
      "2025-01-03 19:43:00,666 - langchain_text_splitters.base - WARNING - Created a chunk of size 9571, which is longer than the specified 2000\n",
      "2025-01-03 19:43:00,666 - langchain_text_splitters.base - WARNING - Created a chunk of size 2148, which is longer than the specified 2000\n",
      "2025-01-03 19:43:00,667 - langchain_text_splitters.base - WARNING - Created a chunk of size 2617, which is longer than the specified 2000\n",
      "2025-01-03 19:43:00,667 - langchain_text_splitters.base - WARNING - Created a chunk of size 3551, which is longer than the specified 2000\n",
      "2025-01-03 19:43:00,668 - langchain_text_splitters.base - WARNING - Created a chunk of size 3217, which is longer than the specified 2000\n",
      "2025-01-03 19:43:00,668 - langchain_text_splitters.base - WARNING - Created a chunk of size 2859, which is longer than the specified 2000\n",
      "2025-01-03 19:43:00,668 - langchain_text_splitters.base - WARNING - Created a chunk of size 9345, which is longer than the specified 2000\n",
      "2025-01-03 19:43:00,669 - langchain_text_splitters.base - WARNING - Created a chunk of size 2416, which is longer than the specified 2000\n",
      "2025-01-03 19:43:00,669 - langchain_text_splitters.base - WARNING - Created a chunk of size 5800, which is longer than the specified 2000\n",
      "2025-01-03 19:43:00,670 - langchain_text_splitters.base - WARNING - Created a chunk of size 3103, which is longer than the specified 2000\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3d2c6eacc5c426cb82723bbd8f58252",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f8dd6877f53490894c10b6b6adad301",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4512336ebe124079905ed9bf9a4bdc0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a3d99951a254e1288b99a5dad5a37b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42370e635a5a4e50892de1f23c155d8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dcc1f8727250438cae405bcdc00ad1f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b104025eeaa4b469c2d9e6b1b59f8c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "758e59fbcc2240efa74dad282c7f2781",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa78c71fbb764c2ab7e35594556d937a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b9112aa8ce247e7b763779c34b6de1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd9989c8657941769ccb2f5527385d44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23eb798d1bb5498db02bf72f7d2639c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4408909bca844435a5408fa81f288a0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "100820abf32748c7a1d8d7487f2581c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7148c866b7e4339903392fbcfab52ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a00bcc3d4cc941539519334f4b5ee117",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac865b79bf3244e78de3788f909457e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53fcd0779aca477b9d531e2f6d62fbc6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc4256ee09bd4212ba4141267e1b098b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc934e0136404b47ba8a128bebd86864",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54a8c0f8646349bfaf2155208db5f12d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ada969cc0f474fd893e5ce25861c3c22",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1baf49e2a4aa4a51ba5f462b82189e91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07ce5932c8514337ba271b6d2792b214",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cfc9ce1e544942e38308f03fab1487e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5eb0e2701d041d39807667c49e12742",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee6bb63279204644a82ba1beb225fef9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0554ec5ced6f436e914b2b606e6598cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3ee5d92bbb74598b9b0c6ec0c01c047",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cecabf0b33534939862836c869953bef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6bcc6716289344d0a1f721ced1638f65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63e626b3739d447ba437ec89ff0a8833",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aadbb0cae05b494f9ec0ce1afb846d77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4e68500bcfe461ab0ffd209d2658c91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ef78d56d6ce4cd5a16237e4efbea319",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d690a6c7bd44196b17b14d3fd94c915",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62198ebdc4b14501b1440a203d3288ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac37b48e63bf4ddd851ac6010b7493b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c8eadf66f374cba878d189f952bff13",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a102985f879a415a871a66dc46258c60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec9574a9ecf84172a2df576d8626213f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "457d14afe4b745029c62c35a431c08cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0731790205d446782d796f77f2e86fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71dc06d0ff1842028487e4bfc68b25f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1fc1a79cae24a19acb404b32eb06703",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7cc451c2458b41e4a11b3c3966d8ee5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01f3d50a5c144ddda4d8836d387e46fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db31f53e6e5a4e91a22e35bf0d6efb94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f4ab66678a849ad9a309409fb61b43e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b299c74f03494e30831617cb884e8dfd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6bb11e9c3010434fa8fb74124e3b3c54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "678070a96fc846bd953d7ec673a27c70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0181da2a980442e690294a1687c3dfdf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21a048e1da6b40d5a5f0848532133141",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "efb1e9c80d1840918780ce1e4ddb6e71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2bfecec87ca74f14bc5e923a3aff2144",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3b82c07792744bbbbb89892bb64ba9f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10f19bbbc25d480aac9c85af7a06503c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5a3c98e637f4ef29653d4e57ebdae48",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb4de5e6260340f5aac6bd5ebab7df32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f51f89462dd4848bcdd51f767c18abd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc8b244d726f40c9866acfcafdce5b17",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bcf7ff1a4c3741bb9f6cb230d34a31a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1756db7ad2c4f248e6aa58e6663257e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "550e6f682fed46dbbd665fa87e44c4f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96e7141dc0634a00818f2fed71c60a43",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40683a9c8fb748eb9f180c89acfe543a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5073a446e112419d9e8a36e1f1f2f006",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5abc4acd77c540aab5d116b140e2f6a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9dfeb3f845924bc18bbaa171f33e7258",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c89d646d41f45c7aa976effca7fd33c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e060c9bd38945fe920104ccb22bbd1d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef18e15de290492da51cd3af545a6aa6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c45b0b6389bd44eb9c43f643e40aaa9f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "892ea726359040fea42a5b74c9390b2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bffbadf1cd7041629857517eb38d0c22",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "959bc87f07d84a2d87d8423ac463ccba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b995be32d2704082a6ec3df7cb59e388",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "326c1d510f7042ff9957a13679629cb0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e587aaca4ef4ce0a30b5cff8eb1e913",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31e5587dfa99409a946edfb30ce64362",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0764dc0029774274b7e6dcf2ebea9562",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c28d225f261a48c5aeb700033522bebf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "260102b51f224a4abd3f67e133a455a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a027152b8db47a88760e8f059c51e05",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e9ea4a7e1f1473ebf665a1ad0df0638",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4efc5ba652e5425fb02a3afbd7d63531",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4f003d53b5746aeb168b43cedb0bc44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "807b6446bd2c4b87af465035c80c54b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3603db8310c7433687c5dfca121e9ecb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3bfee3245730415f91ae3fc64d705028",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7059d4222ad43868d5cd2e932bc57a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b55d44056744701bf4aa7b8ed431cb7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "173abf6ba4504b16bc333bcdfa157b4f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c533fd89e2f7499ca89dd5b1549bfee0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f393ebcaa8914d8db4d8673dc2313bd9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1765b9104fa48cf98ff3bb258f371d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bed75f052af546248afabbb8bfb52f45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d38adc2cbefa4a2d8ac9563b68394327",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fad154a353ab49e2bceb0615d71e9b9c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e42549a0c55844a296ccb6077712aff3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5700e51514964bb78e88a195618f3be8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86e3fc28c47347d28736c9b48c97fdb6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0e70ef5ceb74f87b4ee6c32b6ceb1bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e03c024f89eb4d13bec70c578b97e660",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e01f84fe48d942a0a435630d9d1b138e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c755c1333a794bb9b61c7ea34a7b851d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e23d2bc785c4e16b83935edfd2d3e19",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db9a0641c17040cdafc5f13d94f0157b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c38cd786e23408594ca86d72693d99f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c30842364c2242c5be19c6f57591efb3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2fb3d7078be546c592283d97aa8244a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "277c5999f14f4c3fbfaeb4d2b6e2f977",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "724afbb198504b4a944b444f34456466",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d574f9445ec047b482d6b7efe5f548c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b8272ed55df49d4bfd415f07e3a6702",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f75f549d184444d890553f1f64cc1030",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7572c9d1bea42dcb1ee6589c7736001",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64417494941048d89035e2a627b6b1b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a1cf2ff4b0d4766ae529bb2b748a1e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57b4668c0dae450fa004cc4d3cc539d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce77b101f5404cf691973ac2e7857811",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f16dfbadcf0447809cd7fc3b266f9a9f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cea26b6c513b4fb28c0eda43cc86a8cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "684705e933144cac9ce50c374f5ab125",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eda0a205826b4f4bb8c8d5a245cae59a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fda58f2f563a4bea9ce40ab1643be65a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a20b290ec7704a24b818bb67a75dcc53",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94780ac986ba4b7e80f9e8cbc6c17d20",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e69d94cea7294c429a1e75b63b1aeee4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d6828c9cf6647ee892bf5ae906f2b34",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ba07ea73a814e749201b248455f48bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "691b1fc741ce4336a345d9364e4b1c00",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b0e9bc77e3040068a833e6633a02de6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "241b624b787044cd9409c3a8cecbf49b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e0aafb62f8d4c42b5ce197e12a6e257",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af63949245da44c291fc118baf109a88",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3cacefda37747caa20a7ce3d0253078",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ab1f1c13abb46108cd1196429963bfb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2269b9ac06654d8283669a44c0951e86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35116c01237e425f86526d416dc58b81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "179e9459f409426a95d4483351e477c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29e38051c91549349e449f8940c518ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27d55bf564764851a7c9b0690804c20d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f7d22dfa64441b4aaf64077f3a8e405",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f51729f35a244f8b199118dc3ac14e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59aba6162a134e7eb19379806eded3e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "066433a7ef214537b00b7f2937931dc4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3205a91283d41d49c4d75b0f9636656",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aba68a64f1b04b04b0f88d22e23a5c85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0079b8a27ce848e7a0a069d400e60722",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "049d27db7648468eb7e5ad99941332e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73904657f3fb436d95bf5679d504a9a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "661238b156794dbe8d936bf5cac985cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98c51b2459334e2da4086c7a0ce03ede",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc021a2c646c4416a17e4c232e5b07fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20eb58b3a5a241df9e522257af7be139",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86976e7d137f448c9bbe3dacae7dd88b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4cfdd3d3b9694dd08317c06ddf7842ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4bf1a9058ab54a3b8cba1f518a96efc6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "015f7c6b5f1c4f16b6e1cc2889be7c16",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d88ce90367a7444099ade5d7e4905934",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05eb2cf053454467abc025219575ca09",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12b092cce60141618be51f8b5a203ed4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e109c71eab34e129e22ec9eb07e3095",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5c825b031274a8584707488dee592cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc3ed589055d419d84dd53b44d8f5a2b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44a847b1dc4f4f108c7d38b5ac1f9d16",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13c7001a910a47e2b43bd2510105555b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f62dd2ea2b454903b9584548a33e3f04",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a61bfa25b3b4aa68c340f2390dc0474",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8fd54bd9a2c4a02bcaa05c14064d1f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21a3685d56bf47b1baeaa48e86ee7492",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ccb58c35ccc1490eb03931c67ea0743d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24bf9de0136e49c599f379071a67c64b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37d93f2ff198436daf7385c521deeeb6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8450f4361814f019d8445c68d3b06ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2793af1671f541ca9ff0da420798d0a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89c325bd6694469099b3b2ed5cb26613",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b248d50ab2234c59bc4b95782a78e793",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8465d875f1db4a5e934491dcce77a10c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "845b01087b8c48f58c06a991e27e7671",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "016b848d25c64d7bb0c2631414f22de2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28cf30718e6f48439f417900db9e9919",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e594b51b6d54441281f54c1f853cbb7c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e1425f3a97f4925a53c2d3eaca730f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70d9a832b5e5451a9a93ec1a08057cb8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03efbfa5760a49f8b14515652686dd99",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "688a3c75240e40828bc3c5a12ab1788a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bcf5ab3905bc4c9598818e901a24d99e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb3424aa89284eb2a1fd848cf419bd98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5948283140f3464e894f27b400512202",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0283bad95bcd4411816c8a1b2c7bf985",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8042452b0a448be84c7f7a2d2df73d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81c56d01885e49d5be911abe85c85953",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb0ab67ba14f41449a352132ace5d969",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1adaf63e7cb4324b5fcabd4ecb71101",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1eeba5ea4a94b18a3ea257ec9633765",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3208b18173f54831b5591f1a79a0bba0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ead0314165fe4071aa6fd1255e34e022",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d337b77d1e447ddb23bf5302c20c242",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4181ff08b4a4a70bc620af787613738",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8aa2671478548e4a9638b012a7bb913",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5386b839036140048845d0b5d76136d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b139f72f78e49ba8e34f3e742364a54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8729476f194542a38e66cf5f9ece3580",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "147c226cb7f24cb3a1f2563608f7ac4e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02e5b0210c6c46e688646e3215c2290c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf1b55edb14542d2a1a34d05f83ea71e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d6934f001404817a2b6783e2d8f2e65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35c504fc01e94e31b02488711d476708",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c4ec8575b794e24b254643662b32dce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43ab4f0f5cb841afabfd217630813959",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5bd14b31ed604c25a15791d734e516c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a139287ebe7a423eb3efe1e5e8188421",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cce56eb40395429fba2909648c24e860",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ee4fbd03bdd43b78cbc8997b42590e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e67090140b9f4ca9b7a3aae643baec39",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "309653ed15d8472b9bf433797655fc2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad0b8b18b9bd4b0f9b6a5be4ac5a5447",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a8dee21fc4a40d3a96d5599ddfd0e44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03555d9de0c843248d3516e61ad2039b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2985af6b5504390ad762bae22b94ea5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b9f07c321fd4e9ab911aca91cafcc45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91da7eda7cae420785490a25bfa486df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a77b4c0792b40039ff49e506210732c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db6088947bcc434ebbabceff0e411b80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac4c024bfb2648c5af2f051996c8d9a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd4a42c124eb4ffab36830252d434767",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24acc5721e1b40aea69958d4411a5d7f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d941ec80ee945c7903da98c443c3d6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7fa5ee40cadf43f39f440dda1ee6fbc0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c576643ad963435b83127cb17ef4302e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21919c01d15b497397c0dc0d219f72f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf602bd862bd4ec4b0ba20987df9441b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a396a59b779c4dcab8b485962d354552",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a96ceb0ec0604917855f8c127f73b3ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8dd504c149074634b4e23103ed069a97",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b66078f0b42450c91b18e56cdf686af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5acf30e253d461a8f242a155e80566e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "009605ae713a40e99bd31a40c009cc0f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce0857aae4314b0b92a59a471162698f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "670f7345a7f542aaace5c513acc53e55",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "339484d0a2a14149b95857e6a566c44b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf58606c2a574635af46740ac5629926",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a05d400aedd4d05a6c6aa6136b5c640",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3451009a453a4027883c94ce0f4315d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c26e23dcad1d4724963d420022fab5a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c79a2b473d194422a9ac7d451954e52b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d5fd951694d4836baae299bd55773ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61c14776a7ac46ce8135792ca8fa47bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85067cd08e9d4d7ba9381ee5058d1b7b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88bc068a95904d1790ccc4c30c13554e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b3fbcc02cc345d5ab9e3c1faf278d0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a90de43e178413ea5d01a83b35f07d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a563612eae8b4363937d0598c4b22306",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8eed82d017a9448ea62a1d82f26f3752",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b21ac9de2ae0468a890ce9d0f5b099df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14709e153f8c4f1f84f033f6c16a4bd3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "847191b4ef524ed4864876d863e913dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e25b816e1034c2887a6f8c2879ef1cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "530ad56633594164ac9782ec48677785",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63640f574b8b4e3fbdc006ed4e29c7fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "afa979843ee844feb29f56d5a20b99e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b7a458fffc44dce96a3a08677480f41",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fad87d10843a4f228016106816e9d56f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b779a9704be24337b46fa1bb594bbacb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b32d7da94d594cc3acb4d3d8a7683028",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dede33046cfb4557bbd10f32b288790b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6c13ca8ea1b47f6b64c679a54afe6fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b4c4e91ade24ec2b129850bd8ed3d43",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba3f94111946494d996832a23d8d1543",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4628621289b48f7991724918afdac4e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef8e0f8e175b4fe7836ab1256708152e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95424511aa2c4952a6a14f23540cf600",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f6b3801beb44172ae41a1e4803e81d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8306d4bbba184b439fa6220bbaef4a51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49530c39ae5e4efd846a22234eb192aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8df05edc1b4d433cb794d69566c38f75",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a7fbe3d291d46589aefecb083139bf8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cbd6ed87a519451682199d7b98df9651",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe66fea33e70459e850f49c867696674",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a6d4f64136d4f898fa8f7761f14119a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d52513e91b24050afd7f5888b08bbea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b5bea5e643245dcb44d41613ab816d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e81ae719e814552a2030dc9b916c147",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76b56ef74d384586a4f76645a4c856f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc4b15f39a2848f4b3e099b3a482a34d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "490543573df24975bb2645bf464b7622",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56a33241fd754586ba5974e3b4fac6cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e32a476ff70c4e6e8be2603e5fe588e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dcbbd84a0dbb4b7fb2daecab4772d2fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc1b803a9f014210bf9220355b45235a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "420554fc06d048db9402afd4162bbe0f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3e34b42a8a940ec9d8cfd7f5122ec46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a899c4426f3e46ecb0b721682f1c8cdc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6facf71926bf4ed6be790e3865bfb73c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ff3cd83196641a59e1c0a1ebac99184",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c396a9c264e04c328c3b4ebb28afefec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86d5e3eec2564626ab51f56a62da4ce8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "790b16bc921448c18d8ec68dacd49c96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15153fefe5824b0fb45afc7c9be4233e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "123bb43cfee94702870e626dea8f44aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59cd70b0458e4c7e954c9e2e9e829229",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42864cbe39ae4b06834bf8b57b7be736",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17d5f8286db7418fa383151766dce0f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e98ffb82f5f4a4cb588223eb595449e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de2d37b4d18a4e0f83115df0deeb2310",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12abb980182d4b2fa9c5422116351fe4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b11c7890e3b41a0817071fc607a75a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c768b71c44845ec9282488db0dc43ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "939da02ba4a642db82ec199bcc6a47d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf692bd7d8c7440084fcb3a14adff6d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "951e27971fd24bc9828bb57cad4379a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78a9b035f893428b931212a578647b95",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8bef2c0abd4a4186832e51e4b07aeaba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "740d0167c785438eb036848bb0d96d83",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "124fa9de56bf424c9ca2ceb48b64f90c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92d3191c1c6c4f3585f092c6c525b6da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c20b40219b0b4d77a99d44f3adac5cdc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5dca98fd7fb34ba890128aadc45b86c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7554d13a28ff47e99c4b53e64fc9df5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "929e5f70c7404a6d8766e29a4420f368",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8ca95fa94384a59a8474d318f5a0764",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7bd3e9a80e6408c89b532974dfa3450",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5dcfc824145f41899ce3db9c4577a262",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a93e54b8374458786eb822ac9feb5c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23846c705023408b8594345c4bc842bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54c381628337489b8543a5cbdc935348",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74bb27cc4ac240c899288be58680b881",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21362a7684c9421fa6630c3c434b1972",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34b7bbc8fd804e84ba45cee88aaa3f65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b52054b12d446c68911e9af402f0163",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ff7084340f8479faf1a58ad20d0c105",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d91f22ccc1c3427d81e735b6da7a5b7e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b79a47b23cb4311bb7f2c4794b9787e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e88e5cbb86942709e393f5ed3ac2b0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5ced6405b5a456da36a765c1b9c5bd1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fddd079411c04b199ab6f6ec0b623df3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "072a976c73424ae6bbafe8670af49f24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24262409153542b9914587a9f717eab7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07dc29345102441790ed8f117a30a836",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3a3ecf296ee4b8eb97f43b231dad5da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d84b143d2b4542fc8b1ea957b07966aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "062e8d28b3c84e8790493c51b7269261",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b841774bd3c74ed185b65871486a4813",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99466fe814af4afa9cc717ab874b0be2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f2a81941824467eb25d4e3754783c40",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1b57d7657574e5b9ecd458eb7ebf06c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b090396e447455dade79e520dd88c4d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98df7cf256114b978105077d5f0f5857",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7c02b58e7ea4507b30f7a5d61224652",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6218bb42391e4ce7a77373030db7baa2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7385ee66ed694bc48d8239695a732a53",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d55fc78786e94af68db392d7c7bc5248",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "654b380820a749d69a39140d8f8eab50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65d5e51f84f74f159d737be87d5c1958",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6dd8dc37e3c244839ef320e5cd4d19fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e50ed79aecab438db8d9b8ab66082536",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f24f9d99a1f45e18e4be30711091856",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5ac56447a314d6fae5f26a634cd6cc8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7a88a09349247d6b541b136c49f15f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12a118d278dd481d85198630e1e9e7a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c10271ea41614df68f775e3885244c95",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2aa885c39b844b7dbc4e36eebca5c0f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f554dfd889a40f096940fd1dbf3e9ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1e8e0d409a74f77b941980a2ecb3a9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de81028782044b9ea859b7514bdb5335",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2070a9aa586f4055a10f88df42b70eed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a88259b27f784fd98aa46da2774a3bb3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9749faa74d2d4229906c17d504e80543",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eede8df10e7343d59c25964e2cbafaa6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "831e7f6c51cc4849a90499670b81a67e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d2a58912bd9422cb5c09f737971d06e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1dc622c49fad480fa286191abef5c2c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5b8a797f4bc4340a0589162352e36a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f125d20749a54da5b5c694ffc70eaaa5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2197d4f5dc2d48b1b184b91a1174ff63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b413801b1de48a6b1b756e87dbc2b25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d38a083a0d8410791284363cdf4028f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2aed62863af4469da3e3f121b9488c0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "177b38a7502d498e8a7804efc67dafa5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "155731a162e74439b1cda72d9e07f6ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f501b18ed5a4572b0d02b5b7f7b94e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a042ee30dce4703921973f8c2869878",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58ffa8ab1d294e11b9b2044d2ef505f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0901e362e554ecd906109f5d8d62ad2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "842471624ae240e1b58dbb1a1b816fb4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d769791c90cc4e0bb875bb72c4252b0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50987533e16d42e89215b1f1a8f1fccc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b6ece84c674479c9777598fbfb595c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b8cd648da664562b77d14dc5ae067d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3698cc9fc7b345a699a16ff07832aae6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f29438828234006b2412f6c1b315dd7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca9ccd76f9d445e984d30719692c4103",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf4840a30f754122be2551e3e76251de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1265bf9b5f71448fb79f4cb4cb821edd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d35c8518d4e4718a19e12c0b3c15256",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "579304feb924417da1c735eb584529bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a7cfd36ff4b4cf7a63d4fc271106700",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b2b4aed66284462824e457f4c78a6ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f520357659764118b166bccf72d053df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60963c28b8b640e58150dc12d515d7ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64e416253e6f462cb5188f35347b5fd6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81c0d1fdb4ef49dcbf3cf8c66e482b0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8890b94991194d01bb13c60d71ff835d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4630ff23b864344b60b072e1f92d05f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf14691ba6aa4668bf45e8b3bc879128",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "946a72b8f5064b8ea017577fcc0e0698",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce6f5e62c6ab4f9e864835976bfb5f38",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06826c2b4b744c43b3115ab6d18e1b4f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bda74c9547ff4ccd926cc64cadcee661",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9618973ec9be43d8afef0e189cb7e8a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f48fdcab5be24219a96e700a1d9cf53e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c83933e183d142a9a535c0f633461ad5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec472843e7ad44388cff25dcc815bf39",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "752dcdedc2284fd48b236a6b18a8dc78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9cd1dae9a50463e99abf0b23c0610ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45033eec70a24f19a29f5be572a2cb56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f553a10851e74fbfb64b4e8e433a90b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a0a01a051ee4b04a9f78fc20caf904b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93288f604ea74e7ebf7b10b72561187c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e61e45bfe24405aa2d2b3785f06195e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e450712c46d4fa5a1efc736e27f025c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1768bb676f44eb587a4f982e2e4dd26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c77610476df04c8b9663179aca531047",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d527e7e638ae4a9eb80751087132aa2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "504e0475a1d44587acc882f558968cfa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e5a88674fcd48578fb7599c6c151110",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6dfd46e292164f57b6e8d13d8503f4e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d601205990b4973b9d01b7ca21ae216",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a43350532cdd4053ae5489b972723656",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41aba9703cc54834963f258197a41620",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b97bde77ee134d0b8b5a533c630d1f0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd8603e700a3497cabb21b30c5e1acbf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2deaecfda2fd4b3fb680041d4d7982ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "790722387e8249fa85b79a0215466192",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c54420aabf24eacb455e96810589f4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "903a41d6e20a44629395bd74f09857ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f93293fc4b3c40739c5671e8ef088858",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f57cd3343e24d139432e88a267e4323",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d57b48ac89944e78f3d42f9c53fd1af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1d39c9de60240a797217f33baba3230",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45f1594d513047d2bc17472ff38d8e6a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe7dac32b45641c1803f2708aab156f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e296658f77e4b849a707dfbed63e6e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0ddd533fe884dda8070c6418465dcb6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb49b95514a140ab8a6e78b1e01e82c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8c881506c0742beacfd22f6263954b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ddacd68cf56d4496a1b0d277a57cddb2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a21e3330188946cd8366583b1d195beb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f911fa7f95c4030b7509684a0195167",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d55eecd35ac640b4ad6126bd12a3e3ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f589528c6b224ac3b7bc1610c9910c52",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f566f6c4d2f5495795387351745ee78f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3627fec8395f45a98ead46131a606394",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79d162671d2247e18d2ee5e5784e5ad2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30192dda74d8490982fede0b9c39da5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff7b633b08dd43beab6a827611085aed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9efb5f8352846f4a27bc23df32653eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b2bcac562834c899ccd8f713f8a73d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5521563bf9544d8a4fc3f6618e10bb4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7784ac9362ef4a0c97a15c713da6411a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc7ee85f115b4b67822c653014fce6eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f81b29b7ac184c3b9304646ab42f4579",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50a2cd5e929e48d8b4e68d52fb7eef1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a039a5690d544903bdd7c5ade9bd186e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5aa6160f5c174f0ba6a323490f0d6317",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9bf72f495bc4aae8946d5fbc1195d83",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72144f4734c54cccb2107d9d923e702d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "453d87c815524c24a2b1754307dadd7d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29b7f4ecc82540b3a9a24aafc3a70524",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e3d5bf376ca4d08b66b7eb27c9b6307",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "772a6df0d3604c629407d354c3756eae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4df1985baf04ab0a7ea83dc6d925551",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf87940f49b74accb950a2b2499d5327",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6db88ae6e62d4c8d93046ded5215930c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01c92906fc324fc7b9220497702f0984",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5bd4c88131b745608fd22067db262d0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5ea2d53ecc24a42a0fbdf3564de522a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc3615c5b8824578b21446b9a85b4a73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b186ef247274397ac450d9424aca4f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aaf7bfa4cc0942138da8a5b390be948d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec50c86c76ec48a29fd2ef07070ac29a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8e71e37a5b74cfd9746387f6afeb4a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2595c2fa823c419ea26dd652cca67470",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3bda4088d7bd4510bf221baa31c994d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a67d4b13707c4bff8b0e51f885b1c361",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4450eb057be045199f62e5ac72c75ecd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9546187da1f641da8e98cdfa17192ee7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef0bfb3cea9e4737b6bba7642bb7dfe0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0acf16ff6e0b44ceb40e8a21d938a62d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d25ada3c05e419b8fbf36ab29b1745f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc67396a7024432cbb06d7ac2a80e09a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "674238be04c04b469fb40e5d7ba551f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cdf574b25c0046b697c278b6ebc6682a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4fa4fcf6e4b247e0a209535f00a1edff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2500fc11edb4bf4ab5e52f6554057f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64d5022543ca456089c8c6b19cd996c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eaa00ff90bee4bfb96394cf18f5966d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca6c169032b9460bb99bee4e30d50e78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1edaa1259439487aba4fc91886f06a66",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8cb387cf7d7049029d54a2ef685019a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05e6a56287cf464f9054dc5646bd6aaa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "afc1b7872d2d4f18836a0e76833fbcd4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88012b8b07f3482c9e0c1318129a5f31",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5750a567bee2414faff459fa8eb9cf17",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3b209667f9e4bdd9485dcaacd2b4fbd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3addbdd39ee843f4b3f2b5db4fcdb232",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8bf128e9f634233b8a9b220633c778e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4509e762d5404f3fa3182c72a7d32019",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d94cd689afbd433782b0103841adb238",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d339ac0d4fd740688c19b137696df918",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b61ec6d62ba45debf740cd42079c434",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fbfa144e40c74a889e7ec8e0c677b81b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dfefba84e02347ceb09afbd33414aa1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b24d26b3dd3a4299bb9bd750658e821e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5fd23dcf06bf455996ec776345cd0629",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ddacbb33c21e406b841c218e857aba08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7bf41edea4f42b5bcda358760f66614",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0d305600b9a4b23b1f961006460ba87",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f28752851a92493b8ebc93790ef3f8cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1abb19af8b804536ac9066cf478da258",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3a4e80a9ffd418d842695f5758a06ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87ff71aded134e84aa67495d31088634",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50587882bfca4b4697e602d900f9588f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3dbbc310edd4235aa654c03a830a77a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "987301993b0b43ae88695f28b6b5bb03",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9ddc471caa04a4d97cf49c76f7f0874",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc2ef6100acc4946a7f33eb7c68918b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "298720984bd142bb9d00e554cf0be175",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f68ca4e471f44a4a444d9aadfe3c9d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ee318c96f2040afaa1ba22552f003f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a24386dfcb9c403b9d06adb7e80591bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98bd4c81d92e4f42a8a6ba72e322f59d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31c8319360ce43cfb3d133c7f6efca69",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4880988efc04bd4b4df574165f06f66",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "403aa7fb89cb4701937068afa1ef0a00",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e680115310274d1aa184d0e99a31cd09",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c76c213ef0bd4528b766dd3878737523",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2943a3b3db204af08cba0c9c009a30ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e363d593581a4b65875763cdbc01a784",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29feadc4d743422f9c5f38ce2cd98ccc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e3447483ad2467a9d6c2ccccebe375d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "864225ebfc334391a1cacb10b0c21c64",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef0453dd4a7a4783a0c72cb83d7fde34",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8019952972b43f5bdfa6cf2a10a0ce0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "055c4e87aeec4d9b8503bbf1eea28db3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23c6850b57904f6483068afd766af91f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d26b1bb0a27e460bb6a28ae168bdaa8d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d53fafab8b140678de07311af538679",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51343b65c4ee473394899b3b4662d42c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4da31045a7fb4bdd86bfcd1039871954",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9bf003865c44829afa9920f44e6d90c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "149009eb195e4ac4b97718ff7559e04f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed714bcf337543dc8ae5c01fe5f12485",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09f89695f7e44f9eaeb03b4bf2377ece",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8cdc50be1bb34bab92a180c765c59164",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e517ef1fbe34e46a06238b3f7646773",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95f59d518e0e421699dd02a8d9deff01",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d8d7f2474b842aa847b9b710965fd5d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab6362f0866140b383c7b7fcc2ca51a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba89e45585df4749982423bb6485fe9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "885bb3ac2bda48ebb7700e2b7ce12c2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e6fa63746a34c9595d388cb0f038cbc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8151d56ac1944b6e8c49991448432b89",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f657c31925f84984950239d7677b4c5f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af013bd0636e47f3948af288044a0ca5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f9ec1a48136421fb3d2cd2124ec8a0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91e0a3f61e054cc8984f3b5a57cc4716",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dbca0560170043a1b733353688b47b65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30b7c2fa01014946bce4d413e66395e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eefe25e331a649a1a0d0901045b6fd0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb2a6d7a0dd6498d96607b158c9ce03e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6bddc804b6e14501ba4c1f7cc55b738e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2253f55fdf924e96a2770bd5951966e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60e3db2c757e460787db13a54ebebdec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd24f1da1ed0409f9072cd7811831b45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67f9fcc23c9349bda8ed58edeb468cac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "374daacf6f89414e962f1ea13b5fc35d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d5f79eaa5d24c3a9071fd6de81e0f8f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a4cc19555014399bdb3e7ebdc563f42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ecad4f69c5e477297ca2420c7c4b404",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d923bbf697540fe9e5d3c7807907213",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd7dce1d1b0f43a29d84d2cef9f10153",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bbd3c88e9e0e47978e395030e2dce9b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37802751ea5f449cb4d328b94e212431",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97e98b4f08294855afa6fa6c42df27a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3301ec1f9864954959ec4a2538ca582",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab0d69bc93d546e6a5703982166a72a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed8c747e5957479ca03610ee49d9c79e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e81eaac2bf14e80a060261042301fc8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a3668078b49409a91cbd280b25c8e16",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a035cf4a05e40f89ad2cd167a4921c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f7a24f4086b41c48584fa0d4047e533",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e2c57db38c44c21a93ebf2d19d7486c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d29ee4143f24ac49878799f0923fb6b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aadeaba7a2204f78a2889abc7687964b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c3ca6fb51f04e2d8954ad8b08fec51e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "deb40b615516450caed626826e67a9a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4562b7997a04356af1f72bbaed9aed7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4fbfa08e94e041828652f72d55ad11f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1fd5b63e43cd4bfabf32144ecfa5e182",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "756b786d813b42bda91a625945c37d41",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04faa9500bcf43b198d0fadad24fff72",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3bc4d41c7b654add8c1d20a6e8eebe27",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3dce84af96747c595cbcd840035ed41",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08ce75bbd4ed47fa9bcca199574edd15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad188563d22b44d5b3a5fbb54ddece9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2bb375f926454b349fbb6166a2adcb20",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c7ca3038bc8459c97aa2ffeed17cfed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57dad8bb812c45578442d93ddbf084c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f8ba872bbe74ceaa3b1344bd5ae3ac7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb02cdd4966d491a8373a07981fe56ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "929c3d9b983f46848da905b6dbc37794",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2164fa26e9540c4b385c270fb4ab00f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac35beeb46ec48b6a90ef9f0e2e81da7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "492daa072ff340ff92e0ec5a9d2a42ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f886896d61974aad8f9a4aa3441feb07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3946c59ae7d04973b9987b1720cfbf01",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f669484adb84c078a50861be97f0090",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c67a39f874b474e9a0bb44ef9917ebc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e919514ff4f4047bed958ec60f5c5d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37f2a3b499bc48628814c4a6a0ad2d1d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd2ae867833e44e38ed7e20954c09edc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f22bd840986d4dcca8039b6f22f00238",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3416ffe36394a60af39997db6803f56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f994be9b9dca4346be46e289298326c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51d46936830a4334882b82931c292e85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "276a72ee7eec4abaaa65ef73924c822f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "146087083e7c4b74a8b6dfdf08ce9565",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd0ba7b2c3a74cb782d7d130c1a2dac8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "220ef1d8db4943ed92ac245421dcc4aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33f6de63c0b940258f462d0b03768344",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "acbcc1cbf42441f3b0305a5e24890e72",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7915772a606f4e06912c2fe874409fce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2357ecc77c154a3b980fc0be8a58b765",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34d0f0202407436d9e0c54948ca30856",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b2e4c7bae2f4cdeb22dc4a07452ea9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4b856c08f7e4d4bae0a647666fb106e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "558c318b56004099aa8015672629d5f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b61fd7875f2b41dd9c519547185a67fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c104131c07e4f6a9bbf76e7cc1e1bda",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e70f3fada794c968f7901bbf8353d18",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79985bddf4414acdb00eb9ffa879126f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b847163c3394d09b040f2056a5e12e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c4c56c816874a17af15228459df5c0f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2fe6afddafbb477989f34113b76b81e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f147362ff40d413a9b4f6722fbc2a2cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e9c6997189d4cefa2bd5c73d0330781",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4d0b12cd07d4e3a9a1aa5d3667f61f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a770a65e1614925b780fa9ed889afaa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f261e326fbda46679b2a3233081e718d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23f5b6cceb59407d9f0dac8d53d6c249",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43b6c716353d4c78b011c6c2b929cc0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a430ca0fde8441008a45d18d27ebb0a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bfc4111bdc7c4f24a65074ff56df1640",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2eea10647eb74026863f8b45d8d9f5f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0cf5f5a9989f428290b80322e9c004bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25e1bf7e1c4c4826a170eb849a4eedcd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1c0efd17d6a4e628c45f03a0e9460fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad3305ef92af413c9d9c498774180a74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c4605db4e9442769259be76e49f5255",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1cf9a450460648839348c85d240b18dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf262b0572ed42a9a8384312a6b7b903",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83a72baf2fb84907b942208669475e5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cce89c9a530f4a1f83303297cf94009a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "522b8b6009d342948826f1b66be0fae6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69749fbd380b420eb97cdda525ecfef6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d534a8dd811948009e5e7aa04e03f5be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10ca967e848f468e8c8dfdca243dd39b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62c20f8770ee4af39a145a9d5b0ee988",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9d8d20a67c84813b33176ff3adc3980",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa87e3ed76db4b56aa201bb15f45e002",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a190512c77e4ae2a34d12e7d8a525b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81df3ea8cf784c0889391432424a71d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c317d1b39c74c0a87f11035ace55349",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6407a966dac64e1885f61018dc29d960",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1dbdf44b5bf445cbf9ce2062f34439b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9720faf537b44f33b616cfd3f18b81b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4754b00a99894232b21e059e2c78c82a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5c4afcae6a84d39b7813354403a91b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f642d613c2a549bc8d6f5125192aec26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04eb5641b4af44c5a854af6ed10d3fb0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf950fd3776247d5bcf331cf86359b63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "290400bd50004c7b9aaa1adc23d4715d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "502b2bfb56a24197b22c33a99a964b56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91ce5ebb5b4443798c8893fe9b5a332d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f9595a355104b17ad6134b9dbe9471b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "200b92bb2a2044028cab321bce24e5e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe298cb85924421eb8965fb1106693a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a42db85fb944cdfa73e191526a73904",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e9936b7f3b2440cbd01f40a3167237d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc30f356e30b4e06981e9d1c76c9268b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5bed9853541242e1be2519b1caac2f84",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42cc990ab07a4b889eb6be54b3837532",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-03 19:48:34,209 - urllib3.connectionpool - WARNING - Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ConnectionResetError(104, 'Connection reset by peer')': /indexes\n",
      "2025-01-03 19:48:35,842 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/pinecone_plugins'])\n",
      "2025-01-03 19:48:35,843 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'upserted_count': 696}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "INDEX_NAME = 'interview-qa2'\n",
    "epub_folder = '/home/bullat/projects/rag/Interview-2.0/data'\n",
    "documents = []\n",
    "for filename in os.listdir(epub_folder):\n",
    "    if filename.endswith('.epub'):\n",
    "        file_path = os.path.join(epub_folder, filename)\n",
    "        text = extract_text_from_epub(file_path)\n",
    "        #TODO использовать name для ссылки на источник\n",
    "        documents.append({'name': filename, 'text': text})\n",
    "\n",
    "text_splitter = CharacterTextSplitter(chunk_size=2000, chunk_overlap=200)\n",
    "texts = []\n",
    "for doc in documents:\n",
    "    chunks = text_splitter.split_text(doc['text'])\n",
    "    for chunk in chunks:\n",
    "        text_id = f\"{doc['name']}_{chunks.index(chunk)}\" \n",
    "        ind_text_dict[text_id] = chunk\n",
    "    # texts.extend(text_splitter.split_text(doc['text']))\n",
    "# print(ind_text_dict[0])\n",
    "\n",
    "embeddings = generate_embeddings(ind_text_dict)\n",
    "# print(embeddings[0])\n",
    "# Create the index if it doesn't exist\n",
    "if INDEX_NAME not in pc.list_indexes().names():\n",
    "    pc.create_index(\n",
    "        name=INDEX_NAME,\n",
    "        dimension=len(embeddings[0]['values']),\n",
    "        metric='cosine',\n",
    "        spec=ServerlessSpec(\n",
    "            cloud='aws',\n",
    "            region='us-east-1'\n",
    "        )\n",
    "    )\n",
    "\n",
    "# Upsert embeddings to the Pinecone index\n",
    "index = pc.Index(INDEX_NAME)\n",
    "index.upsert(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fdb925c81a24496994723f3c4f469b76",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-03 19:48:38,838 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/pinecone_plugins'])\n",
      "2025-01-03 19:48:38,839 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference\n",
      "2025-01-03 19:48:39,580 - __main__ - INFO - Retrieved results: {'matches': [{'id': 'John Mongan - Programming Interviews Exposed_ Coding Your '\n",
      "                    'Way Through the Interview (2018, Wrox Press) - '\n",
      "                    'libgen.li.epub_181',\n",
      "              'score': 0.315634668,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_37',\n",
      "              'score': 0.282967895,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_48',\n",
      "              'score': 0.276279628,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_52',\n",
      "              'score': 0.276162028,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_6',\n",
      "              'score': 0.247066781,\n",
      "              'values': []}],\n",
      " 'namespace': '',\n",
      " 'usage': {'read_units': 6}}\n",
      "2025-01-03 19:48:43,649 - httpx - INFO - HTTP Request: POST https://api.mistral.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d71a703fbfc40f98c1342834c530f8f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-03 19:48:43,678 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/pinecone_plugins'])\n",
      "2025-01-03 19:48:43,680 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference\n",
      "2025-01-03 19:48:44,386 - __main__ - INFO - Retrieved results: {'matches': [{'id': 'John Mongan - Programming Interviews Exposed_ Coding Your '\n",
      "                    'Way Through the Interview (2018, Wrox Press) - '\n",
      "                    'libgen.li.epub_181',\n",
      "              'score': 0.283690453,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_52',\n",
      "              'score': 0.271557957,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_37',\n",
      "              'score': 0.263224483,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_48',\n",
      "              'score': 0.250147671,\n",
      "              'values': []},\n",
      "             {'id': 'John Mongan - Programming Interviews Exposed_ Coding Your '\n",
      "                    'Way Through the Interview (2018, Wrox Press) - '\n",
      "                    'libgen.li.epub_222',\n",
      "              'score': 0.242047071,\n",
      "              'values': []}],\n",
      " 'namespace': '',\n",
      " 'usage': {'read_units': 6}}\n",
      "2025-01-03 19:48:53,773 - httpx - INFO - HTTP Request: POST https://api.mistral.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d96c3b1d125406c8cdea01ca9a64527",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-03 19:48:53,818 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/pinecone_plugins'])\n",
      "2025-01-03 19:48:53,823 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference\n",
      "2025-01-03 19:48:54,501 - __main__ - INFO - Retrieved results: {'matches': [{'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_52',\n",
      "              'score': 0.265813738,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_37',\n",
      "              'score': 0.263616115,\n",
      "              'values': []},\n",
      "             {'id': 'John Mongan - Programming Interviews Exposed_ Coding Your '\n",
      "                    'Way Through the Interview (2018, Wrox Press) - '\n",
      "                    'libgen.li.epub_181',\n",
      "              'score': 0.259607375,\n",
      "              'values': []},\n",
      "             {'id': 'John Mongan - Programming Interviews Exposed_ Coding Your '\n",
      "                    'Way Through the Interview (2018, Wrox Press) - '\n",
      "                    'libgen.li.epub_222',\n",
      "              'score': 0.257264197,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_48',\n",
      "              'score': 0.229598939,\n",
      "              'values': []}],\n",
      " 'namespace': '',\n",
      " 'usage': {'read_units': 6}}\n",
      "2025-01-03 19:49:02,810 - httpx - INFO - HTTP Request: POST https://api.mistral.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c62661541aa2423bb3d0c348013ee21e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-03 19:49:02,837 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/pinecone_plugins'])\n",
      "2025-01-03 19:49:02,838 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference\n",
      "2025-01-03 19:49:03,482 - __main__ - INFO - Retrieved results: {'matches': [{'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_37',\n",
      "              'score': 0.263424,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_52',\n",
      "              'score': 0.249376684,\n",
      "              'values': []},\n",
      "             {'id': 'John Mongan - Programming Interviews Exposed_ Coding Your '\n",
      "                    'Way Through the Interview (2018, Wrox Press) - '\n",
      "                    'libgen.li.epub_181',\n",
      "              'score': 0.242394552,\n",
      "              'values': []},\n",
      "             {'id': 'John Mongan - Programming Interviews Exposed_ Coding Your '\n",
      "                    'Way Through the Interview (2018, Wrox Press) - '\n",
      "                    'libgen.li.epub_222',\n",
      "              'score': 0.237621799,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_48',\n",
      "              'score': 0.233924255,\n",
      "              'values': []}],\n",
      " 'namespace': '',\n",
      " 'usage': {'read_units': 6}}\n",
      "2025-01-03 19:49:09,388 - httpx - INFO - HTTP Request: POST https://api.mistral.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "517d3c942604457a974f06f328406652",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-03 19:49:09,417 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/pinecone_plugins'])\n",
      "2025-01-03 19:49:09,418 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference\n",
      "2025-01-03 19:49:10,050 - __main__ - INFO - Retrieved results: {'matches': [{'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_37',\n",
      "              'score': 0.252271444,\n",
      "              'values': []},\n",
      "             {'id': 'Narayanan Vishwanathan - SQL and NoSQL Interview '\n",
      "                    'Questions_ Your essential guide to acing SQL and NoSQL '\n",
      "                    'job interviews (English Edition)-BPB Publications '\n",
      "                    '(2023).epub_4',\n",
      "              'score': 0.249290153,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_48',\n",
      "              'score': 0.2476217,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_28',\n",
      "              'score': 0.229124576,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_0',\n",
      "              'score': 0.223165125,\n",
      "              'values': []}],\n",
      " 'namespace': '',\n",
      " 'usage': {'read_units': 6}}\n",
      "2025-01-03 19:49:21,601 - httpx - INFO - HTTP Request: POST https://api.mistral.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1daeeea490194cd696e5909eb3714c87",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-03 19:49:21,628 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/pinecone_plugins'])\n",
      "2025-01-03 19:49:21,629 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference\n",
      "2025-01-03 19:49:22,253 - __main__ - INFO - Retrieved results: {'matches': [{'id': 'John Mongan - Programming Interviews Exposed_ Coding Your '\n",
      "                    'Way Through the Interview (2018, Wrox Press) - '\n",
      "                    'libgen.li.epub_181',\n",
      "              'score': 0.281535089,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_52',\n",
      "              'score': 0.275243282,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_37',\n",
      "              'score': 0.250266701,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_48',\n",
      "              'score': 0.226984143,\n",
      "              'values': []},\n",
      "             {'id': 'John Mongan - Programming Interviews Exposed_ Coding Your '\n",
      "                    'Way Through the Interview (2018, Wrox Press) - '\n",
      "                    'libgen.li.epub_222',\n",
      "              'score': 0.201069236,\n",
      "              'values': []}],\n",
      " 'namespace': '',\n",
      " 'usage': {'read_units': 6}}\n",
      "2025-01-03 19:49:31,167 - httpx - INFO - HTTP Request: POST https://api.mistral.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1be1394fe084c41bab03455efa60150",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-03 19:49:31,192 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/pinecone_plugins'])\n",
      "2025-01-03 19:49:31,193 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference\n",
      "2025-01-03 19:49:31,853 - __main__ - INFO - Retrieved results: {'matches': [{'id': 'John Mongan - Programming Interviews Exposed_ Coding Your '\n",
      "                    'Way Through the Interview (2018, Wrox Press) - '\n",
      "                    'libgen.li.epub_181',\n",
      "              'score': 0.268440485,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_37',\n",
      "              'score': 0.255766809,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_52',\n",
      "              'score': 0.25068441,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_48',\n",
      "              'score': 0.232309654,\n",
      "              'values': []},\n",
      "             {'id': 'Narayanan Vishwanathan - SQL and NoSQL Interview '\n",
      "                    'Questions_ Your essential guide to acing SQL and NoSQL '\n",
      "                    'job interviews (English Edition)-BPB Publications '\n",
      "                    '(2023).epub_4',\n",
      "              'score': 0.222782165,\n",
      "              'values': []}],\n",
      " 'namespace': '',\n",
      " 'usage': {'read_units': 6}}\n",
      "2025-01-03 19:49:45,530 - httpx - INFO - HTTP Request: POST https://api.mistral.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ab9441b1fb44cd5bf27cfac3958f4c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-03 19:49:45,558 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/pinecone_plugins'])\n",
      "2025-01-03 19:49:45,560 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference\n",
      "2025-01-03 19:49:46,196 - __main__ - INFO - Retrieved results: {'matches': [{'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_52',\n",
      "              'score': 0.284159511,\n",
      "              'values': []},\n",
      "             {'id': 'John Mongan - Programming Interviews Exposed_ Coding Your '\n",
      "                    'Way Through the Interview (2018, Wrox Press) - '\n",
      "                    'libgen.li.epub_181',\n",
      "              'score': 0.259851575,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_37',\n",
      "              'score': 0.254846752,\n",
      "              'values': []},\n",
      "             {'id': 'John Mongan - Programming Interviews Exposed_ Coding Your '\n",
      "                    'Way Through the Interview (2018, Wrox Press) - '\n",
      "                    'libgen.li.epub_222',\n",
      "              'score': 0.230557069,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_0',\n",
      "              'score': 0.218190879,\n",
      "              'values': []}],\n",
      " 'namespace': '',\n",
      " 'usage': {'read_units': 6}}\n",
      "2025-01-03 19:49:53,899 - httpx - INFO - HTTP Request: POST https://api.mistral.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47b86eedbb2446dc89796c52af790d62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-03 19:49:53,928 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/pinecone_plugins'])\n",
      "2025-01-03 19:49:53,929 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference\n",
      "2025-01-03 19:49:54,594 - __main__ - INFO - Retrieved results: {'matches': [{'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_37',\n",
      "              'score': 0.230281293,\n",
      "              'values': []},\n",
      "             {'id': 'John Mongan - Programming Interviews Exposed_ Coding Your '\n",
      "                    'Way Through the Interview (2018, Wrox Press) - '\n",
      "                    'libgen.li.epub_181',\n",
      "              'score': 0.225543305,\n",
      "              'values': []},\n",
      "             {'id': 'Narayanan Vishwanathan - SQL and NoSQL Interview '\n",
      "                    'Questions_ Your essential guide to acing SQL and NoSQL '\n",
      "                    'job interviews (English Edition)-BPB Publications '\n",
      "                    '(2023).epub_4',\n",
      "              'score': 0.224687412,\n",
      "              'values': []},\n",
      "             {'id': 'John Mongan - Programming Interviews Exposed_ Coding Your '\n",
      "                    'Way Through the Interview (2018, Wrox Press) - '\n",
      "                    'libgen.li.epub_222',\n",
      "              'score': 0.219514564,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_48',\n",
      "              'score': 0.210788757,\n",
      "              'values': []}],\n",
      " 'namespace': '',\n",
      " 'usage': {'read_units': 6}}\n",
      "2025-01-03 19:50:00,114 - httpx - INFO - HTTP Request: POST https://api.mistral.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db7ea8a9e0144cb8bd3c29ad081dad66",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-03 19:50:00,142 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/pinecone_plugins'])\n",
      "2025-01-03 19:50:00,144 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference\n",
      "2025-01-03 19:50:00,779 - __main__ - INFO - Retrieved results: {'matches': [{'id': 'John Mongan - Programming Interviews Exposed_ Coding Your '\n",
      "                    'Way Through the Interview (2018, Wrox Press) - '\n",
      "                    'libgen.li.epub_181',\n",
      "              'score': 0.306645334,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_7',\n",
      "              'score': 0.303710729,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_0',\n",
      "              'score': 0.289489806,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_52',\n",
      "              'score': 0.264792651,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_179',\n",
      "              'score': 0.255771339,\n",
      "              'values': []}],\n",
      " 'namespace': '',\n",
      " 'usage': {'read_units': 6}}\n",
      "2025-01-03 19:50:08,618 - httpx - INFO - HTTP Request: POST https://api.mistral.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b59e9f9c071b47eeb42d2c2e7341c894",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-03 19:50:08,658 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/pinecone_plugins'])\n",
      "2025-01-03 19:50:08,660 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference\n",
      "2025-01-03 19:50:09,315 - __main__ - INFO - Retrieved results: {'matches': [{'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_52',\n",
      "              'score': 0.259976834,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_37',\n",
      "              'score': 0.253669202,\n",
      "              'values': []},\n",
      "             {'id': 'John Mongan - Programming Interviews Exposed_ Coding Your '\n",
      "                    'Way Through the Interview (2018, Wrox Press) - '\n",
      "                    'libgen.li.epub_222',\n",
      "              'score': 0.24727577,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_48',\n",
      "              'score': 0.240441695,\n",
      "              'values': []},\n",
      "             {'id': 'John Mongan - Programming Interviews Exposed_ Coding Your '\n",
      "                    'Way Through the Interview (2018, Wrox Press) - '\n",
      "                    'libgen.li.epub_181',\n",
      "              'score': 0.238895208,\n",
      "              'values': []}],\n",
      " 'namespace': '',\n",
      " 'usage': {'read_units': 6}}\n",
      "2025-01-03 19:50:14,712 - httpx - INFO - HTTP Request: POST https://api.mistral.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dce0682e789743eb87d1d6947feb1348",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-03 19:50:14,739 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/pinecone_plugins'])\n",
      "2025-01-03 19:50:14,740 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference\n",
      "2025-01-03 19:50:15,385 - __main__ - INFO - Retrieved results: {'matches': [{'id': 'John Mongan - Programming Interviews Exposed_ Coding Your '\n",
      "                    'Way Through the Interview (2018, Wrox Press) - '\n",
      "                    'libgen.li.epub_181',\n",
      "              'score': 0.286523938,\n",
      "              'values': []},\n",
      "             {'id': 'John Mongan - Programming Interviews Exposed_ Coding Your '\n",
      "                    'Way Through the Interview (2018, Wrox Press) - '\n",
      "                    'libgen.li.epub_222',\n",
      "              'score': 0.27295202,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_52',\n",
      "              'score': 0.26908192,\n",
      "              'values': []},\n",
      "             {'id': 'Narayanan Vishwanathan - SQL and NoSQL Interview '\n",
      "                    'Questions_ Your essential guide to acing SQL and NoSQL '\n",
      "                    'job interviews (English Edition)-BPB Publications '\n",
      "                    '(2023).epub_4',\n",
      "              'score': 0.238834202,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_0',\n",
      "              'score': 0.229403257,\n",
      "              'values': []}],\n",
      " 'namespace': '',\n",
      " 'usage': {'read_units': 6}}\n",
      "2025-01-03 19:50:24,948 - httpx - INFO - HTTP Request: POST https://api.mistral.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9de8005d232490bb667ac90e8b536fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-03 19:50:24,974 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/pinecone_plugins'])\n",
      "2025-01-03 19:50:24,975 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference\n",
      "2025-01-03 19:50:25,625 - __main__ - INFO - Retrieved results: {'matches': [{'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_48',\n",
      "              'score': 0.3224819,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_37',\n",
      "              'score': 0.284793794,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_52',\n",
      "              'score': 0.259101689,\n",
      "              'values': []},\n",
      "             {'id': 'John Mongan - Programming Interviews Exposed_ Coding Your '\n",
      "                    'Way Through the Interview (2018, Wrox Press) - '\n",
      "                    'libgen.li.epub_181',\n",
      "              'score': 0.255170316,\n",
      "              'values': []},\n",
      "             {'id': 'Narayanan Vishwanathan - SQL and NoSQL Interview '\n",
      "                    'Questions_ Your essential guide to acing SQL and NoSQL '\n",
      "                    'job interviews (English Edition)-BPB Publications '\n",
      "                    '(2023).epub_4',\n",
      "              'score': 0.243956819,\n",
      "              'values': []}],\n",
      " 'namespace': '',\n",
      " 'usage': {'read_units': 6}}\n",
      "2025-01-03 19:50:32,812 - httpx - INFO - HTTP Request: POST https://api.mistral.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67d1bcae323c4e85af382a183fd1c165",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-03 19:50:32,840 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/pinecone_plugins'])\n",
      "2025-01-03 19:50:32,842 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference\n",
      "2025-01-03 19:50:33,517 - __main__ - INFO - Retrieved results: {'matches': [{'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_52',\n",
      "              'score': 0.296857208,\n",
      "              'values': []},\n",
      "             {'id': 'John Mongan - Programming Interviews Exposed_ Coding Your '\n",
      "                    'Way Through the Interview (2018, Wrox Press) - '\n",
      "                    'libgen.li.epub_181',\n",
      "              'score': 0.254925519,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_37',\n",
      "              'score': 0.240546852,\n",
      "              'values': []},\n",
      "             {'id': 'John Mongan - Programming Interviews Exposed_ Coding Your '\n",
      "                    'Way Through the Interview (2018, Wrox Press) - '\n",
      "                    'libgen.li.epub_222',\n",
      "              'score': 0.231162041,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_179',\n",
      "              'score': 0.225529909,\n",
      "              'values': []}],\n",
      " 'namespace': '',\n",
      " 'usage': {'read_units': 6}}\n",
      "2025-01-03 19:50:36,667 - httpx - INFO - HTTP Request: POST https://api.mistral.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6224d97ba03d47858f94d02c527e3d54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-03 19:50:36,693 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/pinecone_plugins'])\n",
      "2025-01-03 19:50:36,694 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference\n",
      "2025-01-03 19:50:37,303 - __main__ - INFO - Retrieved results: {'matches': [{'id': 'John Mongan - Programming Interviews Exposed_ Coding Your '\n",
      "                    'Way Through the Interview (2018, Wrox Press) - '\n",
      "                    'libgen.li.epub_181',\n",
      "              'score': 0.298918873,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_37',\n",
      "              'score': 0.275815427,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_48',\n",
      "              'score': 0.258046895,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_52',\n",
      "              'score': 0.242811069,\n",
      "              'values': []},\n",
      "             {'id': 'John Mongan - Programming Interviews Exposed_ Coding Your '\n",
      "                    'Way Through the Interview (2018, Wrox Press) - '\n",
      "                    'libgen.li.epub_222',\n",
      "              'score': 0.221408248,\n",
      "              'values': []}],\n",
      " 'namespace': '',\n",
      " 'usage': {'read_units': 6}}\n",
      "2025-01-03 19:50:48,847 - httpx - INFO - HTTP Request: POST https://api.mistral.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "976b4461212a468b8c2c013c7b363133",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-03 19:50:48,872 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/pinecone_plugins'])\n",
      "2025-01-03 19:50:48,874 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference\n",
      "2025-01-03 19:50:49,510 - __main__ - INFO - Retrieved results: {'matches': [{'id': 'John Mongan - Programming Interviews Exposed_ Coding Your '\n",
      "                    'Way Through the Interview (2018, Wrox Press) - '\n",
      "                    'libgen.li.epub_181',\n",
      "              'score': 0.298349589,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_37',\n",
      "              'score': 0.291206658,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_52',\n",
      "              'score': 0.282725066,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_48',\n",
      "              'score': 0.26460132,\n",
      "              'values': []},\n",
      "             {'id': 'John Mongan - Programming Interviews Exposed_ Coding Your '\n",
      "                    'Way Through the Interview (2018, Wrox Press) - '\n",
      "                    'libgen.li.epub_222',\n",
      "              'score': 0.264385283,\n",
      "              'values': []}],\n",
      " 'namespace': '',\n",
      " 'usage': {'read_units': 6}}\n",
      "2025-01-03 19:50:59,173 - httpx - INFO - HTTP Request: POST https://api.mistral.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e961faf0c7b4290928dffc2b1da0df9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-03 19:50:59,201 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/pinecone_plugins'])\n",
      "2025-01-03 19:50:59,202 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference\n",
      "2025-01-03 19:50:59,907 - __main__ - INFO - Retrieved results: {'matches': [{'id': 'John Mongan - Programming Interviews Exposed_ Coding Your '\n",
      "                    'Way Through the Interview (2018, Wrox Press) - '\n",
      "                    'libgen.li.epub_222',\n",
      "              'score': 0.272903144,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_52',\n",
      "              'score': 0.267158419,\n",
      "              'values': []},\n",
      "             {'id': 'John Mongan - Programming Interviews Exposed_ Coding Your '\n",
      "                    'Way Through the Interview (2018, Wrox Press) - '\n",
      "                    'libgen.li.epub_181',\n",
      "              'score': 0.26070556,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_37',\n",
      "              'score': 0.251920372,\n",
      "              'values': []},\n",
      "             {'id': 'Narayanan Vishwanathan - SQL and NoSQL Interview '\n",
      "                    'Questions_ Your essential guide to acing SQL and NoSQL '\n",
      "                    'job interviews (English Edition)-BPB Publications '\n",
      "                    '(2023).epub_4',\n",
      "              'score': 0.244445667,\n",
      "              'values': []}],\n",
      " 'namespace': '',\n",
      " 'usage': {'read_units': 6}}\n",
      "2025-01-03 19:51:07,466 - httpx - INFO - HTTP Request: POST https://api.mistral.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af5facc9d91b4c738684b8f80aa36a6c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-03 19:51:07,497 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/pinecone_plugins'])\n",
      "2025-01-03 19:51:07,498 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference\n",
      "2025-01-03 19:51:08,146 - __main__ - INFO - Retrieved results: {'matches': [{'id': 'John Mongan - Programming Interviews Exposed_ Coding Your '\n",
      "                    'Way Through the Interview (2018, Wrox Press) - '\n",
      "                    'libgen.li.epub_181',\n",
      "              'score': 0.25149855,\n",
      "              'values': []},\n",
      "             {'id': 'Narayanan Vishwanathan - SQL and NoSQL Interview '\n",
      "                    'Questions_ Your essential guide to acing SQL and NoSQL '\n",
      "                    'job interviews (English Edition)-BPB Publications '\n",
      "                    '(2023).epub_4',\n",
      "              'score': 0.243961647,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_37',\n",
      "              'score': 0.241372555,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_48',\n",
      "              'score': 0.230153069,\n",
      "              'values': []},\n",
      "             {'id': 'John Mongan - Programming Interviews Exposed_ Coding Your '\n",
      "                    'Way Through the Interview (2018, Wrox Press) - '\n",
      "                    'libgen.li.epub_222',\n",
      "              'score': 0.229636654,\n",
      "              'values': []}],\n",
      " 'namespace': '',\n",
      " 'usage': {'read_units': 6}}\n",
      "2025-01-03 19:51:11,577 - httpx - INFO - HTTP Request: POST https://api.mistral.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "373bee6d2c7e44c9b41225dfcf89e8c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-03 19:51:11,604 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/pinecone_plugins'])\n",
      "2025-01-03 19:51:11,605 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference\n",
      "2025-01-03 19:51:12,509 - __main__ - INFO - Retrieved results: {'matches': [{'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_48',\n",
      "              'score': 0.31613645,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_37',\n",
      "              'score': 0.311274737,\n",
      "              'values': []},\n",
      "             {'id': 'John Mongan - Programming Interviews Exposed_ Coding Your '\n",
      "                    'Way Through the Interview (2018, Wrox Press) - '\n",
      "                    'libgen.li.epub_181',\n",
      "              'score': 0.305254102,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_52',\n",
      "              'score': 0.283624589,\n",
      "              'values': []},\n",
      "             {'id': 'John Mongan - Programming Interviews Exposed_ Coding Your '\n",
      "                    'Way Through the Interview (2018, Wrox Press) - '\n",
      "                    'libgen.li.epub_222',\n",
      "              'score': 0.231838882,\n",
      "              'values': []}],\n",
      " 'namespace': '',\n",
      " 'usage': {'read_units': 6}}\n",
      "2025-01-03 19:51:19,951 - httpx - INFO - HTTP Request: POST https://api.mistral.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0de874c0c5eb4bcdbd91550005438cc1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-03 19:51:19,985 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/pinecone_plugins'])\n",
      "2025-01-03 19:51:19,987 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference\n",
      "2025-01-03 19:51:20,637 - __main__ - INFO - Retrieved results: {'matches': [{'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_37',\n",
      "              'score': 0.232715517,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_48',\n",
      "              'score': 0.22874783,\n",
      "              'values': []},\n",
      "             {'id': 'Narayanan Vishwanathan - SQL and NoSQL Interview '\n",
      "                    'Questions_ Your essential guide to acing SQL and NoSQL '\n",
      "                    'job interviews (English Edition)-BPB Publications '\n",
      "                    '(2023).epub_4',\n",
      "              'score': 0.218591735,\n",
      "              'values': []},\n",
      "             {'id': 'John Mongan - Programming Interviews Exposed_ Coding Your '\n",
      "                    'Way Through the Interview (2018, Wrox Press) - '\n",
      "                    'libgen.li.epub_181',\n",
      "              'score': 0.200412124,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_179',\n",
      "              'score': 0.199679285,\n",
      "              'values': []}],\n",
      " 'namespace': '',\n",
      " 'usage': {'read_units': 6}}\n",
      "2025-01-03 19:51:26,942 - httpx - INFO - HTTP Request: POST https://api.mistral.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10f09ae25fd749a5810a092e903286e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-03 19:51:26,972 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/pinecone_plugins'])\n",
      "2025-01-03 19:51:26,973 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference\n",
      "2025-01-03 19:51:27,592 - __main__ - INFO - Retrieved results: {'matches': [{'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_52',\n",
      "              'score': 0.268253088,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_37',\n",
      "              'score': 0.268057764,\n",
      "              'values': []},\n",
      "             {'id': 'John Mongan - Programming Interviews Exposed_ Coding Your '\n",
      "                    'Way Through the Interview (2018, Wrox Press) - '\n",
      "                    'libgen.li.epub_181',\n",
      "              'score': 0.259692,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_6',\n",
      "              'score': 0.218142748,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_48',\n",
      "              'score': 0.216673225,\n",
      "              'values': []}],\n",
      " 'namespace': '',\n",
      " 'usage': {'read_units': 6}}\n",
      "2025-01-03 19:51:34,503 - httpx - INFO - HTTP Request: POST https://api.mistral.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7002953f7c04c9e979d67bb37c16e5f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-03 19:51:34,531 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/pinecone_plugins'])\n",
      "2025-01-03 19:51:34,532 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference\n",
      "2025-01-03 19:51:35,298 - __main__ - INFO - Retrieved results: {'matches': [{'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_112',\n",
      "              'score': 0.324085265,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_141',\n",
      "              'score': 0.287549675,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_48',\n",
      "              'score': 0.2800982,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_189',\n",
      "              'score': 0.279964685,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_37',\n",
      "              'score': 0.279394299,\n",
      "              'values': []}],\n",
      " 'namespace': '',\n",
      " 'usage': {'read_units': 6}}\n",
      "2025-01-03 19:51:56,763 - httpx - INFO - HTTP Request: POST https://api.mistral.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8530ea822ceb49ce8af447a4755d76ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-03 19:51:56,790 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/pinecone_plugins'])\n",
      "2025-01-03 19:51:56,791 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference\n",
      "2025-01-03 19:51:57,443 - __main__ - INFO - Retrieved results: {'matches': [{'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_52',\n",
      "              'score': 0.291153252,\n",
      "              'values': []},\n",
      "             {'id': 'Narayanan Vishwanathan - SQL and NoSQL Interview '\n",
      "                    'Questions_ Your essential guide to acing SQL and NoSQL '\n",
      "                    'job interviews (English Edition)-BPB Publications '\n",
      "                    '(2023).epub_4',\n",
      "              'score': 0.265570283,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_179',\n",
      "              'score': 0.264512271,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_99',\n",
      "              'score': 0.2611444,\n",
      "              'values': []},\n",
      "             {'id': 'John Mongan - Programming Interviews Exposed_ Coding Your '\n",
      "                    'Way Through the Interview (2018, Wrox Press) - '\n",
      "                    'libgen.li.epub_222',\n",
      "              'score': 0.251154453,\n",
      "              'values': []}],\n",
      " 'namespace': '',\n",
      " 'usage': {'read_units': 6}}\n",
      "2025-01-03 19:52:06,498 - httpx - INFO - HTTP Request: POST https://api.mistral.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e0282310e9e416d896fe820f5fbe0e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-03 19:52:06,524 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/pinecone_plugins'])\n",
      "2025-01-03 19:52:06,525 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference\n",
      "2025-01-03 19:52:07,177 - __main__ - INFO - Retrieved results: {'matches': [{'id': 'John Mongan - Programming Interviews Exposed_ Coding Your '\n",
      "                    'Way Through the Interview (2018, Wrox Press) - '\n",
      "                    'libgen.li.epub_75',\n",
      "              'score': 0.325372338,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_141',\n",
      "              'score': 0.292265236,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_148',\n",
      "              'score': 0.279181212,\n",
      "              'values': []},\n",
      "             {'id': 'John Mongan - Programming Interviews Exposed_ Coding Your '\n",
      "                    'Way Through the Interview (2018, Wrox Press) - '\n",
      "                    'libgen.li.epub_181',\n",
      "              'score': 0.275000304,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_6',\n",
      "              'score': 0.266727895,\n",
      "              'values': []}],\n",
      " 'namespace': '',\n",
      " 'usage': {'read_units': 6}}\n",
      "2025-01-03 19:52:19,117 - httpx - INFO - HTTP Request: POST https://api.mistral.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7303960eaae541efbf4e046d46f00fb9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-03 19:52:19,148 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/pinecone_plugins'])\n",
      "2025-01-03 19:52:19,149 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference\n",
      "2025-01-03 19:52:19,833 - __main__ - INFO - Retrieved results: {'matches': [{'id': 'John Mongan - Programming Interviews Exposed_ Coding Your '\n",
      "                    'Way Through the Interview (2018, Wrox Press) - '\n",
      "                    'libgen.li.epub_181',\n",
      "              'score': 0.324195772,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_52',\n",
      "              'score': 0.258238375,\n",
      "              'values': []},\n",
      "             {'id': 'Narayanan Vishwanathan - SQL and NoSQL Interview '\n",
      "                    'Questions_ Your essential guide to acing SQL and NoSQL '\n",
      "                    'job interviews (English Edition)-BPB Publications '\n",
      "                    '(2023).epub_4',\n",
      "              'score': 0.226562634,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_7',\n",
      "              'score': 0.218683168,\n",
      "              'values': []},\n",
      "             {'id': 'John Mongan - Programming Interviews Exposed_ Coding Your '\n",
      "                    'Way Through the Interview (2018, Wrox Press) - '\n",
      "                    'libgen.li.epub_222',\n",
      "              'score': 0.209943891,\n",
      "              'values': []}],\n",
      " 'namespace': '',\n",
      " 'usage': {'read_units': 6}}\n",
      "2025-01-03 19:52:30,055 - httpx - INFO - HTTP Request: POST https://api.mistral.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "221a7c48df12487a89749b58a8f31ba9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-03 19:52:30,082 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/pinecone_plugins'])\n",
      "2025-01-03 19:52:30,083 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference\n",
      "2025-01-03 19:52:30,758 - __main__ - INFO - Retrieved results: {'matches': [{'id': 'Narayanan Vishwanathan - SQL and NoSQL Interview '\n",
      "                    'Questions_ Your essential guide to acing SQL and NoSQL '\n",
      "                    'job interviews (English Edition)-BPB Publications '\n",
      "                    '(2023).epub_4',\n",
      "              'score': 0.235818312,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_48',\n",
      "              'score': 0.234484687,\n",
      "              'values': []},\n",
      "             {'id': 'John Mongan - Programming Interviews Exposed_ Coding Your '\n",
      "                    'Way Through the Interview (2018, Wrox Press) - '\n",
      "                    'libgen.li.epub_181',\n",
      "              'score': 0.232513577,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_0',\n",
      "              'score': 0.228299633,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_37',\n",
      "              'score': 0.222052664,\n",
      "              'values': []}],\n",
      " 'namespace': '',\n",
      " 'usage': {'read_units': 6}}\n",
      "2025-01-03 19:52:42,253 - httpx - INFO - HTTP Request: POST https://api.mistral.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a19201cb62bb4461894a137de7ec9ca4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-03 19:52:42,298 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/pinecone_plugins'])\n",
      "2025-01-03 19:52:42,300 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference\n",
      "2025-01-03 19:52:43,086 - __main__ - INFO - Retrieved results: {'matches': [{'id': 'John Mongan - Programming Interviews Exposed_ Coding Your '\n",
      "                    'Way Through the Interview (2018, Wrox Press) - '\n",
      "                    'libgen.li.epub_181',\n",
      "              'score': 0.25756672,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_99',\n",
      "              'score': 0.238736466,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_48',\n",
      "              'score': 0.222472578,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_150',\n",
      "              'score': 0.222290114,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_179',\n",
      "              'score': 0.217392,\n",
      "              'values': []}],\n",
      " 'namespace': '',\n",
      " 'usage': {'read_units': 6}}\n",
      "2025-01-03 19:52:47,290 - httpx - INFO - HTTP Request: POST https://api.mistral.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c3c8c4cd0bc468cb3b7a19c7a288b5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-03 19:52:47,315 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/pinecone_plugins'])\n",
      "2025-01-03 19:52:47,316 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference\n",
      "2025-01-03 19:52:47,934 - __main__ - INFO - Retrieved results: {'matches': [{'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_135',\n",
      "              'score': 0.306405783,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_166',\n",
      "              'score': 0.299626648,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_64',\n",
      "              'score': 0.292105347,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_137',\n",
      "              'score': 0.291023016,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_90',\n",
      "              'score': 0.284864,\n",
      "              'values': []}],\n",
      " 'namespace': '',\n",
      " 'usage': {'read_units': 6}}\n",
      "2025-01-03 19:52:51,692 - httpx - INFO - HTTP Request: POST https://api.mistral.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7c2e5edd3f1457d92f8fd5e610bbe9c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-03 19:52:51,719 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/pinecone_plugins'])\n",
      "2025-01-03 19:52:51,720 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference\n",
      "2025-01-03 19:52:52,349 - __main__ - INFO - Retrieved results: {'matches': [{'id': 'John Mongan - Programming Interviews Exposed_ Coding Your '\n",
      "                    'Way Through the Interview (2018, Wrox Press) - '\n",
      "                    'libgen.li.epub_181',\n",
      "              'score': 0.291990459,\n",
      "              'values': []},\n",
      "             {'id': 'John Mongan - Programming Interviews Exposed_ Coding Your '\n",
      "                    'Way Through the Interview (2018, Wrox Press) - '\n",
      "                    'libgen.li.epub_222',\n",
      "              'score': 0.261368066,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_52',\n",
      "              'score': 0.245584324,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_37',\n",
      "              'score': 0.245211601,\n",
      "              'values': []},\n",
      "             {'id': 'Narayanan Vishwanathan - SQL and NoSQL Interview '\n",
      "                    'Questions_ Your essential guide to acing SQL and NoSQL '\n",
      "                    'job interviews (English Edition)-BPB Publications '\n",
      "                    '(2023).epub_4',\n",
      "              'score': 0.234642655,\n",
      "              'values': []}],\n",
      " 'namespace': '',\n",
      " 'usage': {'read_units': 6}}\n",
      "2025-01-03 19:53:00,399 - httpx - INFO - HTTP Request: POST https://api.mistral.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19e3376744e74acd872a5879968cb7fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-03 19:53:00,426 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/pinecone_plugins'])\n",
      "2025-01-03 19:53:00,427 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference\n",
      "2025-01-03 19:53:01,047 - __main__ - INFO - Retrieved results: {'matches': [{'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_52',\n",
      "              'score': 0.265345573,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_37',\n",
      "              'score': 0.253982931,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_48',\n",
      "              'score': 0.249373764,\n",
      "              'values': []},\n",
      "             {'id': 'John Mongan - Programming Interviews Exposed_ Coding Your '\n",
      "                    'Way Through the Interview (2018, Wrox Press) - '\n",
      "                    'libgen.li.epub_181',\n",
      "              'score': 0.248794287,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_0',\n",
      "              'score': 0.231311634,\n",
      "              'values': []}],\n",
      " 'namespace': '',\n",
      " 'usage': {'read_units': 6}}\n",
      "2025-01-03 19:53:08,288 - httpx - INFO - HTTP Request: POST https://api.mistral.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb147355716c4cbb82ef9c293c7cae9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-03 19:53:08,316 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/pinecone_plugins'])\n",
      "2025-01-03 19:53:08,318 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference\n",
      "2025-01-03 19:53:09,026 - __main__ - INFO - Retrieved results: {'matches': [{'id': 'John Mongan - Programming Interviews Exposed_ Coding Your '\n",
      "                    'Way Through the Interview (2018, Wrox Press) - '\n",
      "                    'libgen.li.epub_181',\n",
      "              'score': 0.28613323,\n",
      "              'values': []},\n",
      "             {'id': 'Narayanan Vishwanathan - SQL and NoSQL Interview '\n",
      "                    'Questions_ Your essential guide to acing SQL and NoSQL '\n",
      "                    'job interviews (English Edition)-BPB Publications '\n",
      "                    '(2023).epub_4',\n",
      "              'score': 0.258019835,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_37',\n",
      "              'score': 0.248957485,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_52',\n",
      "              'score': 0.245619804,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_48',\n",
      "              'score': 0.241212398,\n",
      "              'values': []}],\n",
      " 'namespace': '',\n",
      " 'usage': {'read_units': 6}}\n",
      "2025-01-03 19:53:16,541 - httpx - INFO - HTTP Request: POST https://api.mistral.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c8b01ea524f436fa56415f534aa5efe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-03 19:53:16,565 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/pinecone_plugins'])\n",
      "2025-01-03 19:53:16,566 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference\n",
      "2025-01-03 19:53:17,192 - __main__ - INFO - Retrieved results: {'matches': [{'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_48',\n",
      "              'score': 0.234899819,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_37',\n",
      "              'score': 0.222914785,\n",
      "              'values': []},\n",
      "             {'id': 'John Mongan - Programming Interviews Exposed_ Coding Your '\n",
      "                    'Way Through the Interview (2018, Wrox Press) - '\n",
      "                    'libgen.li.epub_181',\n",
      "              'score': 0.212896317,\n",
      "              'values': []},\n",
      "             {'id': 'Narayanan Vishwanathan - SQL and NoSQL Interview '\n",
      "                    'Questions_ Your essential guide to acing SQL and NoSQL '\n",
      "                    'job interviews (English Edition)-BPB Publications '\n",
      "                    '(2023).epub_4',\n",
      "              'score': 0.205744907,\n",
      "              'values': []},\n",
      "             {'id': 'John Mongan - Programming Interviews Exposed_ Coding Your '\n",
      "                    'Way Through the Interview (2018, Wrox Press) - '\n",
      "                    'libgen.li.epub_222',\n",
      "              'score': 0.199128509,\n",
      "              'values': []}],\n",
      " 'namespace': '',\n",
      " 'usage': {'read_units': 6}}\n",
      "2025-01-03 19:53:23,068 - httpx - INFO - HTTP Request: POST https://api.mistral.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7405e83a348c440395a141fa67ff0374",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-03 19:53:23,096 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/pinecone_plugins'])\n",
      "2025-01-03 19:53:23,097 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference\n",
      "2025-01-03 19:53:23,876 - __main__ - INFO - Retrieved results: {'matches': [{'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_52',\n",
      "              'score': 0.317212522,\n",
      "              'values': []},\n",
      "             {'id': 'John Mongan - Programming Interviews Exposed_ Coding Your '\n",
      "                    'Way Through the Interview (2018, Wrox Press) - '\n",
      "                    'libgen.li.epub_181',\n",
      "              'score': 0.299772978,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_37',\n",
      "              'score': 0.244633883,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_0',\n",
      "              'score': 0.219208121,\n",
      "              'values': []},\n",
      "             {'id': 'John Mongan - Programming Interviews Exposed_ Coding Your '\n",
      "                    'Way Through the Interview (2018, Wrox Press) - '\n",
      "                    'libgen.li.epub_222',\n",
      "              'score': 0.214474499,\n",
      "              'values': []}],\n",
      " 'namespace': '',\n",
      " 'usage': {'read_units': 6}}\n",
      "2025-01-03 19:53:28,991 - httpx - INFO - HTTP Request: POST https://api.mistral.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "efcf81d844014492aec0269c9838653a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-03 19:53:29,016 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/pinecone_plugins'])\n",
      "2025-01-03 19:53:29,017 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference\n",
      "2025-01-03 19:53:30,214 - __main__ - INFO - Retrieved results: {'matches': [{'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_109',\n",
      "              'score': 0.418812931,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_101',\n",
      "              'score': 0.400686473,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_11',\n",
      "              'score': 0.312406123,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_78',\n",
      "              'score': 0.280319512,\n",
      "              'values': []},\n",
      "             {'id': 'John Mongan - Programming Interviews Exposed_ Coding Your '\n",
      "                    'Way Through the Interview (2018, Wrox Press) - '\n",
      "                    'libgen.li.epub_181',\n",
      "              'score': 0.277171254,\n",
      "              'values': []}],\n",
      " 'namespace': '',\n",
      " 'usage': {'read_units': 6}}\n",
      "2025-01-03 19:53:35,783 - httpx - INFO - HTTP Request: POST https://api.mistral.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c9e508dba174a91a483723b9f5704c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-03 19:53:35,810 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/pinecone_plugins'])\n",
      "2025-01-03 19:53:35,812 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference\n",
      "2025-01-03 19:53:36,473 - __main__ - INFO - Retrieved results: {'matches': [{'id': 'John Mongan - Programming Interviews Exposed_ Coding Your '\n",
      "                    'Way Through the Interview (2018, Wrox Press) - '\n",
      "                    'libgen.li.epub_181',\n",
      "              'score': 0.290299475,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_37',\n",
      "              'score': 0.246047184,\n",
      "              'values': []},\n",
      "             {'id': 'Narayanan Vishwanathan - SQL and NoSQL Interview '\n",
      "                    'Questions_ Your essential guide to acing SQL and NoSQL '\n",
      "                    'job interviews (English Edition)-BPB Publications '\n",
      "                    '(2023).epub_4',\n",
      "              'score': 0.245066926,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_52',\n",
      "              'score': 0.238940105,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_48',\n",
      "              'score': 0.218876556,\n",
      "              'values': []}],\n",
      " 'namespace': '',\n",
      " 'usage': {'read_units': 6}}\n",
      "2025-01-03 19:53:50,724 - httpx - INFO - HTTP Request: POST https://api.mistral.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6706b01b1a8f4942afc0b0255244e3de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-03 19:53:50,768 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/pinecone_plugins'])\n",
      "2025-01-03 19:53:50,769 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference\n",
      "2025-01-03 19:53:51,453 - __main__ - INFO - Retrieved results: {'matches': [{'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_7',\n",
      "              'score': 0.298514456,\n",
      "              'values': []},\n",
      "             {'id': 'John Mongan - Programming Interviews Exposed_ Coding Your '\n",
      "                    'Way Through the Interview (2018, Wrox Press) - '\n",
      "                    'libgen.li.epub_181',\n",
      "              'score': 0.285708129,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_48',\n",
      "              'score': 0.256853431,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_167',\n",
      "              'score': 0.251374483,\n",
      "              'values': []},\n",
      "             {'id': 'John Mongan - Programming Interviews Exposed_ Coding Your '\n",
      "                    'Way Through the Interview (2018, Wrox Press) - '\n",
      "                    'libgen.li.epub_317',\n",
      "              'score': 0.24653843,\n",
      "              'values': []}],\n",
      " 'namespace': '',\n",
      " 'usage': {'read_units': 6}}\n",
      "2025-01-03 19:53:59,326 - httpx - INFO - HTTP Request: POST https://api.mistral.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2832444984b34a329052738ea764edf7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-03 19:53:59,352 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/pinecone_plugins'])\n",
      "2025-01-03 19:53:59,353 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference\n",
      "2025-01-03 19:54:00,011 - __main__ - INFO - Retrieved results: {'matches': [{'id': 'John Mongan - Programming Interviews Exposed_ Coding Your '\n",
      "                    'Way Through the Interview (2018, Wrox Press) - '\n",
      "                    'libgen.li.epub_181',\n",
      "              'score': 0.333663136,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_44',\n",
      "              'score': 0.329024702,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_48',\n",
      "              'score': 0.323168337,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_136',\n",
      "              'score': 0.321733445,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_161',\n",
      "              'score': 0.302500933,\n",
      "              'values': []}],\n",
      " 'namespace': '',\n",
      " 'usage': {'read_units': 6}}\n",
      "2025-01-03 19:54:06,284 - httpx - INFO - HTTP Request: POST https://api.mistral.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7d2707b3dc04529a3e39109bd05be7e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-03 19:54:06,308 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/pinecone_plugins'])\n",
      "2025-01-03 19:54:06,310 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference\n",
      "2025-01-03 19:54:06,947 - __main__ - INFO - Retrieved results: {'matches': [{'id': 'John Mongan - Programming Interviews Exposed_ Coding Your '\n",
      "                    'Way Through the Interview (2018, Wrox Press) - '\n",
      "                    'libgen.li.epub_181',\n",
      "              'score': 0.299953878,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_52',\n",
      "              'score': 0.274503917,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_37',\n",
      "              'score': 0.252562702,\n",
      "              'values': []},\n",
      "             {'id': 'Narayanan Vishwanathan - SQL and NoSQL Interview '\n",
      "                    'Questions_ Your essential guide to acing SQL and NoSQL '\n",
      "                    'job interviews (English Edition)-BPB Publications '\n",
      "                    '(2023).epub_4',\n",
      "              'score': 0.252410084,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_0',\n",
      "              'score': 0.246245027,\n",
      "              'values': []}],\n",
      " 'namespace': '',\n",
      " 'usage': {'read_units': 6}}\n",
      "2025-01-03 19:54:16,495 - httpx - INFO - HTTP Request: POST https://api.mistral.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "722837b774c34441a416cee138703e56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-03 19:54:16,522 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/pinecone_plugins'])\n",
      "2025-01-03 19:54:16,523 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference\n",
      "2025-01-03 19:54:17,135 - __main__ - INFO - Retrieved results: {'matches': [{'id': 'John Mongan - Programming Interviews Exposed_ Coding Your '\n",
      "                    'Way Through the Interview (2018, Wrox Press) - '\n",
      "                    'libgen.li.epub_181',\n",
      "              'score': 0.281829625,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_37',\n",
      "              'score': 0.267004788,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_52',\n",
      "              'score': 0.266520917,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_48',\n",
      "              'score': 0.250588059,\n",
      "              'values': []},\n",
      "             {'id': 'John Mongan - Programming Interviews Exposed_ Coding Your '\n",
      "                    'Way Through the Interview (2018, Wrox Press) - '\n",
      "                    'libgen.li.epub_222',\n",
      "              'score': 0.2400942,\n",
      "              'values': []}],\n",
      " 'namespace': '',\n",
      " 'usage': {'read_units': 6}}\n",
      "2025-01-03 19:54:26,369 - httpx - INFO - HTTP Request: POST https://api.mistral.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f07a6c004c3497c9ce5360fa4a91841",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-03 19:54:26,397 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/pinecone_plugins'])\n",
      "2025-01-03 19:54:26,398 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference\n",
      "2025-01-03 19:54:27,139 - __main__ - INFO - Retrieved results: {'matches': [{'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_52',\n",
      "              'score': 0.294229925,\n",
      "              'values': []},\n",
      "             {'id': 'John Mongan - Programming Interviews Exposed_ Coding Your '\n",
      "                    'Way Through the Interview (2018, Wrox Press) - '\n",
      "                    'libgen.li.epub_181',\n",
      "              'score': 0.257864982,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_48',\n",
      "              'score': 0.251392722,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_0',\n",
      "              'score': 0.242465198,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_37',\n",
      "              'score': 0.238301039,\n",
      "              'values': []}],\n",
      " 'namespace': '',\n",
      " 'usage': {'read_units': 6}}\n",
      "2025-01-03 19:54:34,941 - httpx - INFO - HTTP Request: POST https://api.mistral.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7a974e9f9794ad196c8fa64af89dbb9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-03 19:54:34,970 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/pinecone_plugins'])\n",
      "2025-01-03 19:54:34,971 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference\n",
      "2025-01-03 19:54:35,605 - __main__ - INFO - Retrieved results: {'matches': [{'id': 'John Mongan - Programming Interviews Exposed_ Coding Your '\n",
      "                    'Way Through the Interview (2018, Wrox Press) - '\n",
      "                    'libgen.li.epub_181',\n",
      "              'score': 0.28787908,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_52',\n",
      "              'score': 0.262246788,\n",
      "              'values': []},\n",
      "             {'id': 'John Mongan - Programming Interviews Exposed_ Coding Your '\n",
      "                    'Way Through the Interview (2018, Wrox Press) - '\n",
      "                    'libgen.li.epub_222',\n",
      "              'score': 0.261518091,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_37',\n",
      "              'score': 0.233135715,\n",
      "              'values': []},\n",
      "             {'id': 'Narayanan Vishwanathan - SQL and NoSQL Interview '\n",
      "                    'Questions_ Your essential guide to acing SQL and NoSQL '\n",
      "                    'job interviews (English Edition)-BPB Publications '\n",
      "                    '(2023).epub_4',\n",
      "              'score': 0.227601781,\n",
      "              'values': []}],\n",
      " 'namespace': '',\n",
      " 'usage': {'read_units': 6}}\n",
      "2025-01-03 19:54:44,963 - httpx - INFO - HTTP Request: POST https://api.mistral.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab13c75c8dbe46498a15e2dba8789440",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-03 19:54:44,990 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/pinecone_plugins'])\n",
      "2025-01-03 19:54:44,992 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference\n",
      "2025-01-03 19:54:45,698 - __main__ - INFO - Retrieved results: {'matches': [{'id': 'John Mongan - Programming Interviews Exposed_ Coding Your '\n",
      "                    'Way Through the Interview (2018, Wrox Press) - '\n",
      "                    'libgen.li.epub_181',\n",
      "              'score': 0.286364406,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_52',\n",
      "              'score': 0.273888618,\n",
      "              'values': []},\n",
      "             {'id': 'John Mongan - Programming Interviews Exposed_ Coding Your '\n",
      "                    'Way Through the Interview (2018, Wrox Press) - '\n",
      "                    'libgen.li.epub_222',\n",
      "              'score': 0.252749652,\n",
      "              'values': []},\n",
      "             {'id': 'Narayanan Vishwanathan - SQL and NoSQL Interview '\n",
      "                    'Questions_ Your essential guide to acing SQL and NoSQL '\n",
      "                    'job interviews (English Edition)-BPB Publications '\n",
      "                    '(2023).epub_4',\n",
      "              'score': 0.230519757,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_37',\n",
      "              'score': 0.224087417,\n",
      "              'values': []}],\n",
      " 'namespace': '',\n",
      " 'usage': {'read_units': 6}}\n",
      "2025-01-03 19:54:51,033 - httpx - INFO - HTTP Request: POST https://api.mistral.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e56b220332db4a56a24deb82012dfab8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-03 19:54:51,062 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/pinecone_plugins'])\n",
      "2025-01-03 19:54:51,063 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference\n",
      "2025-01-03 19:54:51,752 - __main__ - INFO - Retrieved results: {'matches': [{'id': 'John Mongan - Programming Interviews Exposed_ Coding Your '\n",
      "                    'Way Through the Interview (2018, Wrox Press) - '\n",
      "                    'libgen.li.epub_181',\n",
      "              'score': 0.283463031,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_52',\n",
      "              'score': 0.267035484,\n",
      "              'values': []},\n",
      "             {'id': 'John Mongan - Programming Interviews Exposed_ Coding Your '\n",
      "                    'Way Through the Interview (2018, Wrox Press) - '\n",
      "                    'libgen.li.epub_222',\n",
      "              'score': 0.228137285,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_37',\n",
      "              'score': 0.227490842,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_179',\n",
      "              'score': 0.22243996,\n",
      "              'values': []}],\n",
      " 'namespace': '',\n",
      " 'usage': {'read_units': 6}}\n",
      "2025-01-03 19:54:59,429 - httpx - INFO - HTTP Request: POST https://api.mistral.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "322547f121f04a2facea3d622baeb68b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-03 19:54:59,455 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/pinecone_plugins'])\n",
      "2025-01-03 19:54:59,456 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference\n",
      "2025-01-03 19:55:00,095 - __main__ - INFO - Retrieved results: {'matches': [{'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_166',\n",
      "              'score': 0.296187967,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_48',\n",
      "              'score': 0.272540152,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_37',\n",
      "              'score': 0.272488475,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_28',\n",
      "              'score': 0.271734506,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_89',\n",
      "              'score': 0.26581046,\n",
      "              'values': []}],\n",
      " 'namespace': '',\n",
      " 'usage': {'read_units': 6}}\n",
      "2025-01-03 19:55:07,210 - httpx - INFO - HTTP Request: POST https://api.mistral.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d879b89bae448aca361cacbf5c40e7e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-03 19:55:07,239 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/pinecone_plugins'])\n",
      "2025-01-03 19:55:07,241 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference\n",
      "2025-01-03 19:55:07,882 - __main__ - INFO - Retrieved results: {'matches': [{'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_52',\n",
      "              'score': 0.326943576,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_37',\n",
      "              'score': 0.289963633,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_0',\n",
      "              'score': 0.278860122,\n",
      "              'values': []},\n",
      "             {'id': 'John Mongan - Programming Interviews Exposed_ Coding Your '\n",
      "                    'Way Through the Interview (2018, Wrox Press) - '\n",
      "                    'libgen.li.epub_181',\n",
      "              'score': 0.268898964,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_48',\n",
      "              'score': 0.256628096,\n",
      "              'values': []}],\n",
      " 'namespace': '',\n",
      " 'usage': {'read_units': 6}}\n",
      "2025-01-03 19:55:15,097 - httpx - INFO - HTTP Request: POST https://api.mistral.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e6dca29a7d243eca9cb435eaffc9335",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-03 19:55:15,122 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/pinecone_plugins'])\n",
      "2025-01-03 19:55:15,123 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference\n",
      "2025-01-03 19:55:15,767 - __main__ - INFO - Retrieved results: {'matches': [{'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_48',\n",
      "              'score': 0.304641575,\n",
      "              'values': []},\n",
      "             {'id': 'John Mongan - Programming Interviews Exposed_ Coding Your '\n",
      "                    'Way Through the Interview (2018, Wrox Press) - '\n",
      "                    'libgen.li.epub_181',\n",
      "              'score': 0.282812,\n",
      "              'values': []},\n",
      "             {'id': 'Narayanan Vishwanathan - SQL and NoSQL Interview '\n",
      "                    'Questions_ Your essential guide to acing SQL and NoSQL '\n",
      "                    'job interviews (English Edition)-BPB Publications '\n",
      "                    '(2023).epub_4',\n",
      "              'score': 0.26410073,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_28',\n",
      "              'score': 0.244292945,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_179',\n",
      "              'score': 0.235641,\n",
      "              'values': []}],\n",
      " 'namespace': '',\n",
      " 'usage': {'read_units': 6}}\n",
      "2025-01-03 19:55:20,073 - httpx - INFO - HTTP Request: POST https://api.mistral.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7beb7248ea24f25b321e13d3a48d916",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-03 19:55:20,101 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/pinecone_plugins'])\n",
      "2025-01-03 19:55:20,103 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference\n",
      "2025-01-03 19:55:20,769 - __main__ - INFO - Retrieved results: {'matches': [{'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_7',\n",
      "              'score': 0.314124167,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_48',\n",
      "              'score': 0.3004421,\n",
      "              'values': []},\n",
      "             {'id': 'John Mongan - Programming Interviews Exposed_ Coding Your '\n",
      "                    'Way Through the Interview (2018, Wrox Press) - '\n",
      "                    'libgen.li.epub_181',\n",
      "              'score': 0.262610316,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_37',\n",
      "              'score': 0.262156814,\n",
      "              'values': []},\n",
      "             {'id': 'John Mongan - Programming Interviews Exposed_ Coding Your '\n",
      "                    'Way Through the Interview (2018, Wrox Press) - '\n",
      "                    'libgen.li.epub_287',\n",
      "              'score': 0.251761168,\n",
      "              'values': []}],\n",
      " 'namespace': '',\n",
      " 'usage': {'read_units': 6}}\n",
      "2025-01-03 19:55:29,630 - httpx - INFO - HTTP Request: POST https://api.mistral.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "372fb6ae7b8d44e8aabd1a80d64cd213",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-03 19:55:29,656 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/pinecone_plugins'])\n",
      "2025-01-03 19:55:29,657 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference\n",
      "2025-01-03 19:55:30,352 - __main__ - INFO - Retrieved results: {'matches': [{'id': 'John Mongan - Programming Interviews Exposed_ Coding Your '\n",
      "                    'Way Through the Interview (2018, Wrox Press) - '\n",
      "                    'libgen.li.epub_181',\n",
      "              'score': 0.277388036,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_48',\n",
      "              'score': 0.273377419,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_37',\n",
      "              'score': 0.261703789,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_52',\n",
      "              'score': 0.259345591,\n",
      "              'values': []},\n",
      "             {'id': 'John Mongan - Programming Interviews Exposed_ Coding Your '\n",
      "                    'Way Through the Interview (2018, Wrox Press) - '\n",
      "                    'libgen.li.epub_222',\n",
      "              'score': 0.251933962,\n",
      "              'values': []}],\n",
      " 'namespace': '',\n",
      " 'usage': {'read_units': 6}}\n",
      "2025-01-03 19:55:35,337 - httpx - INFO - HTTP Request: POST https://api.mistral.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a08af072752445aa970d623b7951df46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-03 19:55:35,365 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/pinecone_plugins'])\n",
      "2025-01-03 19:55:35,366 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference\n",
      "2025-01-03 19:55:36,004 - __main__ - INFO - Retrieved results: {'matches': [{'id': 'John Mongan - Programming Interviews Exposed_ Coding Your '\n",
      "                    'Way Through the Interview (2018, Wrox Press) - '\n",
      "                    'libgen.li.epub_181',\n",
      "              'score': 0.349823356,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_52',\n",
      "              'score': 0.28272149,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_37',\n",
      "              'score': 0.275399476,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_48',\n",
      "              'score': 0.256613582,\n",
      "              'values': []},\n",
      "             {'id': 'Narayanan Vishwanathan - SQL and NoSQL Interview '\n",
      "                    'Questions_ Your essential guide to acing SQL and NoSQL '\n",
      "                    'job interviews (English Edition)-BPB Publications '\n",
      "                    '(2023).epub_4',\n",
      "              'score': 0.239983082,\n",
      "              'values': []}],\n",
      " 'namespace': '',\n",
      " 'usage': {'read_units': 6}}\n",
      "2025-01-03 19:55:49,391 - httpx - INFO - HTTP Request: POST https://api.mistral.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80f4ba01d6c84b34974face607be92d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-03 19:55:49,444 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/pinecone_plugins'])\n",
      "2025-01-03 19:55:49,445 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference\n",
      "2025-01-03 19:55:50,122 - __main__ - INFO - Retrieved results: {'matches': [{'id': 'Narayanan Vishwanathan - SQL and NoSQL Interview '\n",
      "                    'Questions_ Your essential guide to acing SQL and NoSQL '\n",
      "                    'job interviews (English Edition)-BPB Publications '\n",
      "                    '(2023).epub_4',\n",
      "              'score': 0.273272127,\n",
      "              'values': []},\n",
      "             {'id': 'John Mongan - Programming Interviews Exposed_ Coding Your '\n",
      "                    'Way Through the Interview (2018, Wrox Press) - '\n",
      "                    'libgen.li.epub_181',\n",
      "              'score': 0.262307584,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_52',\n",
      "              'score': 0.253024936,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_0',\n",
      "              'score': 0.227224678,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_48',\n",
      "              'score': 0.224550083,\n",
      "              'values': []}],\n",
      " 'namespace': '',\n",
      " 'usage': {'read_units': 6}}\n",
      "2025-01-03 19:55:52,990 - httpx - INFO - HTTP Request: POST https://api.mistral.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2549f3056e64c378f5f3f44e00ad8d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-03 19:55:53,017 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/pinecone_plugins'])\n",
      "2025-01-03 19:55:53,018 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference\n",
      "2025-01-03 19:55:53,642 - __main__ - INFO - Retrieved results: {'matches': [{'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_37',\n",
      "              'score': 0.277405053,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_48',\n",
      "              'score': 0.275306165,\n",
      "              'values': []},\n",
      "             {'id': 'John Mongan - Programming Interviews Exposed_ Coding Your '\n",
      "                    'Way Through the Interview (2018, Wrox Press) - '\n",
      "                    'libgen.li.epub_181',\n",
      "              'score': 0.275160164,\n",
      "              'values': []},\n",
      "             {'id': 'Narayanan Vishwanathan - SQL and NoSQL Interview '\n",
      "                    'Questions_ Your essential guide to acing SQL and NoSQL '\n",
      "                    'job interviews (English Edition)-BPB Publications '\n",
      "                    '(2023).epub_4',\n",
      "              'score': 0.247607455,\n",
      "              'values': []},\n",
      "             {'id': 'John Mongan - Programming Interviews Exposed_ Coding Your '\n",
      "                    'Way Through the Interview (2018, Wrox Press) - '\n",
      "                    'libgen.li.epub_222',\n",
      "              'score': 0.239187911,\n",
      "              'values': []}],\n",
      " 'namespace': '',\n",
      " 'usage': {'read_units': 6}}\n",
      "2025-01-03 19:56:08,286 - httpx - INFO - HTTP Request: POST https://api.mistral.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "afb9063a71ae4eaa959bf1feeab10cc9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-03 19:56:08,344 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/pinecone_plugins'])\n",
      "2025-01-03 19:56:08,345 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference\n",
      "2025-01-03 19:56:08,993 - __main__ - INFO - Retrieved results: {'matches': [{'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_52',\n",
      "              'score': 0.260013312,\n",
      "              'values': []},\n",
      "             {'id': 'John Mongan - Programming Interviews Exposed_ Coding Your '\n",
      "                    'Way Through the Interview (2018, Wrox Press) - '\n",
      "                    'libgen.li.epub_181',\n",
      "              'score': 0.247466981,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_37',\n",
      "              'score': 0.238734409,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_48',\n",
      "              'score': 0.23227568,\n",
      "              'values': []},\n",
      "             {'id': 'John Mongan - Programming Interviews Exposed_ Coding Your '\n",
      "                    'Way Through the Interview (2018, Wrox Press) - '\n",
      "                    'libgen.li.epub_222',\n",
      "              'score': 0.222193792,\n",
      "              'values': []}],\n",
      " 'namespace': '',\n",
      " 'usage': {'read_units': 6}}\n",
      "2025-01-03 19:56:15,136 - httpx - INFO - HTTP Request: POST https://api.mistral.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b7618163a3647fdba7e2cf0d99471d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-03 19:56:15,162 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/pinecone_plugins'])\n",
      "2025-01-03 19:56:15,163 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference\n",
      "2025-01-03 19:56:15,820 - __main__ - INFO - Retrieved results: {'matches': [{'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_7',\n",
      "              'score': 0.292149216,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_48',\n",
      "              'score': 0.284943,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_37',\n",
      "              'score': 0.269664615,\n",
      "              'values': []},\n",
      "             {'id': 'John Mongan - Programming Interviews Exposed_ Coding Your '\n",
      "                    'Way Through the Interview (2018, Wrox Press) - '\n",
      "                    'libgen.li.epub_317',\n",
      "              'score': 0.253210098,\n",
      "              'values': []},\n",
      "             {'id': 'John Mongan - Programming Interviews Exposed_ Coding Your '\n",
      "                    'Way Through the Interview (2018, Wrox Press) - '\n",
      "                    'libgen.li.epub_181',\n",
      "              'score': 0.248427719,\n",
      "              'values': []}],\n",
      " 'namespace': '',\n",
      " 'usage': {'read_units': 6}}\n",
      "2025-01-03 19:56:26,280 - httpx - INFO - HTTP Request: POST https://api.mistral.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69116af599c843a58ccbba22a8d3b9fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-03 19:56:26,315 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/pinecone_plugins'])\n",
      "2025-01-03 19:56:26,317 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference\n",
      "2025-01-03 19:56:26,964 - __main__ - INFO - Retrieved results: {'matches': [{'id': 'John Mongan - Programming Interviews Exposed_ Coding Your '\n",
      "                    'Way Through the Interview (2018, Wrox Press) - '\n",
      "                    'libgen.li.epub_181',\n",
      "              'score': 0.324158818,\n",
      "              'values': []},\n",
      "             {'id': 'John Mongan - Programming Interviews Exposed_ Coding Your '\n",
      "                    'Way Through the Interview (2018, Wrox Press) - '\n",
      "                    'libgen.li.epub_222',\n",
      "              'score': 0.244371057,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_52',\n",
      "              'score': 0.23594749,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_37',\n",
      "              'score': 0.235508472,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_7',\n",
      "              'score': 0.231052846,\n",
      "              'values': []}],\n",
      " 'namespace': '',\n",
      " 'usage': {'read_units': 6}}\n",
      "2025-01-03 19:56:36,395 - httpx - INFO - HTTP Request: POST https://api.mistral.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d43975bdd94b437eac1557c8a0fa235c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-03 19:56:36,425 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/pinecone_plugins'])\n",
      "2025-01-03 19:56:36,426 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference\n",
      "2025-01-03 19:56:37,088 - __main__ - INFO - Retrieved results: {'matches': [{'id': 'John Mongan - Programming Interviews Exposed_ Coding Your '\n",
      "                    'Way Through the Interview (2018, Wrox Press) - '\n",
      "                    'libgen.li.epub_181',\n",
      "              'score': 0.286823571,\n",
      "              'values': []},\n",
      "             {'id': 'John Mongan - Programming Interviews Exposed_ Coding Your '\n",
      "                    'Way Through the Interview (2018, Wrox Press) - '\n",
      "                    'libgen.li.epub_222',\n",
      "              'score': 0.252832562,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_37',\n",
      "              'score': 0.239768788,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_52',\n",
      "              'score': 0.232802123,\n",
      "              'values': []},\n",
      "             {'id': 'Narayanan Vishwanathan - SQL and NoSQL Interview '\n",
      "                    'Questions_ Your essential guide to acing SQL and NoSQL '\n",
      "                    'job interviews (English Edition)-BPB Publications '\n",
      "                    '(2023).epub_4',\n",
      "              'score': 0.222159386,\n",
      "              'values': []}],\n",
      " 'namespace': '',\n",
      " 'usage': {'read_units': 6}}\n",
      "2025-01-03 19:56:49,907 - httpx - INFO - HTTP Request: POST https://api.mistral.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85cea8ec420d4043ad1a503a35943cec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-03 19:56:49,933 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/pinecone_plugins'])\n",
      "2025-01-03 19:56:49,935 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference\n",
      "2025-01-03 19:56:50,599 - __main__ - INFO - Retrieved results: {'matches': [{'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_166',\n",
      "              'score': 0.2810103,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_99',\n",
      "              'score': 0.276640981,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_179',\n",
      "              'score': 0.272053629,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_48',\n",
      "              'score': 0.260253102,\n",
      "              'values': []},\n",
      "             {'id': 'John Mongan - Programming Interviews Exposed_ Coding Your '\n",
      "                    'Way Through the Interview (2018, Wrox Press) - '\n",
      "                    'libgen.li.epub_325',\n",
      "              'score': 0.258440256,\n",
      "              'values': []}],\n",
      " 'namespace': '',\n",
      " 'usage': {'read_units': 6}}\n",
      "2025-01-03 19:57:00,596 - httpx - INFO - HTTP Request: POST https://api.mistral.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4a7565f6c9a4f3e8ac3b14f4bad1fa6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-03 19:57:00,621 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/pinecone_plugins'])\n",
      "2025-01-03 19:57:00,622 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference\n",
      "2025-01-03 19:57:01,273 - __main__ - INFO - Retrieved results: {'matches': [{'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_52',\n",
      "              'score': 0.300099969,\n",
      "              'values': []},\n",
      "             {'id': 'John Mongan - Programming Interviews Exposed_ Coding Your '\n",
      "                    'Way Through the Interview (2018, Wrox Press) - '\n",
      "                    'libgen.li.epub_181',\n",
      "              'score': 0.289401054,\n",
      "              'values': []},\n",
      "             {'id': 'Narayanan Vishwanathan - SQL and NoSQL Interview '\n",
      "                    'Questions_ Your essential guide to acing SQL and NoSQL '\n",
      "                    'job interviews (English Edition)-BPB Publications '\n",
      "                    '(2023).epub_4',\n",
      "              'score': 0.2598387,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_37',\n",
      "              'score': 0.255283415,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_179',\n",
      "              'score': 0.231203049,\n",
      "              'values': []}],\n",
      " 'namespace': '',\n",
      " 'usage': {'read_units': 6}}\n",
      "2025-01-03 19:57:14,302 - httpx - INFO - HTTP Request: POST https://api.mistral.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a3bb72d52454681a47cbb31c50d1265",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-03 19:57:14,328 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/pinecone_plugins'])\n",
      "2025-01-03 19:57:14,329 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference\n",
      "2025-01-03 19:57:14,976 - __main__ - INFO - Retrieved results: {'matches': [{'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_48',\n",
      "              'score': 0.285371482,\n",
      "              'values': []},\n",
      "             {'id': 'John Mongan - Programming Interviews Exposed_ Coding Your '\n",
      "                    'Way Through the Interview (2018, Wrox Press) - '\n",
      "                    'libgen.li.epub_181',\n",
      "              'score': 0.280431688,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_37',\n",
      "              'score': 0.276791781,\n",
      "              'values': []},\n",
      "             {'id': 'John Mongan - Programming Interviews Exposed_ Coding Your '\n",
      "                    'Way Through the Interview (2018, Wrox Press) - '\n",
      "                    'libgen.li.epub_222',\n",
      "              'score': 0.258408248,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_52',\n",
      "              'score': 0.253382117,\n",
      "              'values': []}],\n",
      " 'namespace': '',\n",
      " 'usage': {'read_units': 6}}\n",
      "2025-01-03 19:57:20,346 - httpx - INFO - HTTP Request: POST https://api.mistral.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b14e2b92fa774178a28f450029c50815",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-03 19:57:20,371 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/pinecone_plugins'])\n",
      "2025-01-03 19:57:20,372 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference\n",
      "2025-01-03 19:57:21,042 - __main__ - INFO - Retrieved results: {'matches': [{'id': 'John Mongan - Programming Interviews Exposed_ Coding Your '\n",
      "                    'Way Through the Interview (2018, Wrox Press) - '\n",
      "                    'libgen.li.epub_181',\n",
      "              'score': 0.292211503,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_52',\n",
      "              'score': 0.26211974,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_37',\n",
      "              'score': 0.261454314,\n",
      "              'values': []},\n",
      "             {'id': 'John Mongan - Programming Interviews Exposed_ Coding Your '\n",
      "                    'Way Through the Interview (2018, Wrox Press) - '\n",
      "                    'libgen.li.epub_222',\n",
      "              'score': 0.248256445,\n",
      "              'values': []},\n",
      "             {'id': 'Narayanan Vishwanathan - SQL and NoSQL Interview '\n",
      "                    'Questions_ Your essential guide to acing SQL and NoSQL '\n",
      "                    'job interviews (English Edition)-BPB Publications '\n",
      "                    '(2023).epub_4',\n",
      "              'score': 0.238517284,\n",
      "              'values': []}],\n",
      " 'namespace': '',\n",
      " 'usage': {'read_units': 6}}\n",
      "2025-01-03 19:57:33,010 - httpx - INFO - HTTP Request: POST https://api.mistral.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27a15bb00fdd4b458189989443284fe0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-03 19:57:33,036 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/pinecone_plugins'])\n",
      "2025-01-03 19:57:33,037 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference\n",
      "2025-01-03 19:57:33,656 - __main__ - INFO - Retrieved results: {'matches': [{'id': 'Narayanan Vishwanathan - SQL and NoSQL Interview '\n",
      "                    'Questions_ Your essential guide to acing SQL and NoSQL '\n",
      "                    'job interviews (English Edition)-BPB Publications '\n",
      "                    '(2023).epub_28',\n",
      "              'score': 0.321691751,\n",
      "              'values': []},\n",
      "             {'id': 'John Mongan - Programming Interviews Exposed_ Coding Your '\n",
      "                    'Way Through the Interview (2018, Wrox Press) - '\n",
      "                    'libgen.li.epub_292',\n",
      "              'score': 0.312131971,\n",
      "              'values': []},\n",
      "             {'id': 'John Mongan - Programming Interviews Exposed_ Coding Your '\n",
      "                    'Way Through the Interview (2018, Wrox Press) - '\n",
      "                    'libgen.li.epub_120',\n",
      "              'score': 0.303717077,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_99',\n",
      "              'score': 0.301971257,\n",
      "              'values': []},\n",
      "             {'id': 'John Mongan - Programming Interviews Exposed_ Coding Your '\n",
      "                    'Way Through the Interview (2018, Wrox Press) - '\n",
      "                    'libgen.li.epub_338',\n",
      "              'score': 0.28683573,\n",
      "              'values': []}],\n",
      " 'namespace': '',\n",
      " 'usage': {'read_units': 6}}\n",
      "2025-01-03 19:57:40,673 - httpx - INFO - HTTP Request: POST https://api.mistral.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b7da3a7d4c34aef9f85e252fd9dc600",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-03 19:57:40,699 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/pinecone_plugins'])\n",
      "2025-01-03 19:57:40,700 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference\n",
      "2025-01-03 19:57:41,324 - __main__ - INFO - Retrieved results: {'matches': [{'id': 'John Mongan - Programming Interviews Exposed_ Coding Your '\n",
      "                    'Way Through the Interview (2018, Wrox Press) - '\n",
      "                    'libgen.li.epub_181',\n",
      "              'score': 0.30548057,\n",
      "              'values': []},\n",
      "             {'id': 'Narayanan Vishwanathan - SQL and NoSQL Interview '\n",
      "                    'Questions_ Your essential guide to acing SQL and NoSQL '\n",
      "                    'job interviews (English Edition)-BPB Publications '\n",
      "                    '(2023).epub_4',\n",
      "              'score': 0.302054256,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_37',\n",
      "              'score': 0.279734969,\n",
      "              'values': []},\n",
      "             {'id': 'John Mongan - Programming Interviews Exposed_ Coding Your '\n",
      "                    'Way Through the Interview (2018, Wrox Press) - '\n",
      "                    'libgen.li.epub_222',\n",
      "              'score': 0.265095681,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_48',\n",
      "              'score': 0.247248173,\n",
      "              'values': []}],\n",
      " 'namespace': '',\n",
      " 'usage': {'read_units': 6}}\n",
      "2025-01-03 19:57:54,402 - httpx - INFO - HTTP Request: POST https://api.mistral.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f56de6e19b1498496ff59d9b44a7f85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-03 19:57:54,430 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/pinecone_plugins'])\n",
      "2025-01-03 19:57:54,431 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference\n",
      "2025-01-03 19:57:55,079 - __main__ - INFO - Retrieved results: {'matches': [{'id': 'John Mongan - Programming Interviews Exposed_ Coding Your '\n",
      "                    'Way Through the Interview (2018, Wrox Press) - '\n",
      "                    'libgen.li.epub_181',\n",
      "              'score': 0.294126868,\n",
      "              'values': []},\n",
      "             {'id': 'John Mongan - Programming Interviews Exposed_ Coding Your '\n",
      "                    'Way Through the Interview (2018, Wrox Press) - '\n",
      "                    'libgen.li.epub_222',\n",
      "              'score': 0.25473389,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_37',\n",
      "              'score': 0.25097844,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_52',\n",
      "              'score': 0.242074415,\n",
      "              'values': []},\n",
      "             {'id': 'Narayanan Vishwanathan - SQL and NoSQL Interview '\n",
      "                    'Questions_ Your essential guide to acing SQL and NoSQL '\n",
      "                    'job interviews (English Edition)-BPB Publications '\n",
      "                    '(2023).epub_4',\n",
      "              'score': 0.234278187,\n",
      "              'values': []}],\n",
      " 'namespace': '',\n",
      " 'usage': {'read_units': 6}}\n",
      "2025-01-03 19:57:59,162 - httpx - INFO - HTTP Request: POST https://api.mistral.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a76c5ec31e747d7b99b9423095e4167",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-03 19:57:59,188 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/pinecone_plugins'])\n",
      "2025-01-03 19:57:59,189 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference\n",
      "2025-01-03 19:57:59,800 - __main__ - INFO - Retrieved results: {'matches': [{'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_37',\n",
      "              'score': 0.290627152,\n",
      "              'values': []},\n",
      "             {'id': 'John Mongan - Programming Interviews Exposed_ Coding Your '\n",
      "                    'Way Through the Interview (2018, Wrox Press) - '\n",
      "                    'libgen.li.epub_181',\n",
      "              'score': 0.282362103,\n",
      "              'values': []},\n",
      "             {'id': 'John Mongan - Programming Interviews Exposed_ Coding Your '\n",
      "                    'Way Through the Interview (2018, Wrox Press) - '\n",
      "                    'libgen.li.epub_195',\n",
      "              'score': 0.278759629,\n",
      "              'values': []},\n",
      "             {'id': 'John Mongan - Programming Interviews Exposed_ Coding Your '\n",
      "                    'Way Through the Interview (2018, Wrox Press) - '\n",
      "                    'libgen.li.epub_188',\n",
      "              'score': 0.26987,\n",
      "              'values': []},\n",
      "             {'id': 'John Mongan - Programming Interviews Exposed_ Coding Your '\n",
      "                    'Way Through the Interview (2018, Wrox Press) - '\n",
      "                    'libgen.li.epub_399',\n",
      "              'score': 0.262482524,\n",
      "              'values': []}],\n",
      " 'namespace': '',\n",
      " 'usage': {'read_units': 6}}\n",
      "2025-01-03 19:58:04,642 - httpx - INFO - HTTP Request: POST https://api.mistral.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e87fce0b06164e0bb5623bf53545a5ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-03 19:58:04,666 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/pinecone_plugins'])\n",
      "2025-01-03 19:58:04,668 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference\n",
      "2025-01-03 19:58:05,320 - __main__ - INFO - Retrieved results: {'matches': [{'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_52',\n",
      "              'score': 0.276996076,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_48',\n",
      "              'score': 0.267659903,\n",
      "              'values': []},\n",
      "             {'id': 'John Mongan - Programming Interviews Exposed_ Coding Your '\n",
      "                    'Way Through the Interview (2018, Wrox Press) - '\n",
      "                    'libgen.li.epub_181',\n",
      "              'score': 0.254439503,\n",
      "              'values': []},\n",
      "             {'id': 'John Mongan - Programming Interviews Exposed_ Coding Your '\n",
      "                    'Way Through the Interview (2018, Wrox Press) - '\n",
      "                    'libgen.li.epub_69',\n",
      "              'score': 0.229095444,\n",
      "              'values': []},\n",
      "             {'id': 'Narayanan Vishwanathan - SQL and NoSQL Interview '\n",
      "                    'Questions_ Your essential guide to acing SQL and NoSQL '\n",
      "                    'job interviews (English Edition)-BPB Publications '\n",
      "                    '(2023).epub_4',\n",
      "              'score': 0.22800684,\n",
      "              'values': []}],\n",
      " 'namespace': '',\n",
      " 'usage': {'read_units': 6}}\n",
      "2025-01-03 19:58:12,668 - httpx - INFO - HTTP Request: POST https://api.mistral.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b829f71274046b099d3e8f991b9026d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-03 19:58:12,693 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/pinecone_plugins'])\n",
      "2025-01-03 19:58:12,695 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference\n",
      "2025-01-03 19:58:13,333 - __main__ - INFO - Retrieved results: {'matches': [{'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_0',\n",
      "              'score': 0.241008,\n",
      "              'values': []},\n",
      "             {'id': 'John Mongan - Programming Interviews Exposed_ Coding Your '\n",
      "                    'Way Through the Interview (2018, Wrox Press) - '\n",
      "                    'libgen.li.epub_222',\n",
      "              'score': 0.231490552,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_7',\n",
      "              'score': 0.230072603,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_52',\n",
      "              'score': 0.226709098,\n",
      "              'values': []},\n",
      "             {'id': 'John Mongan - Programming Interviews Exposed_ Coding Your '\n",
      "                    'Way Through the Interview (2018, Wrox Press) - '\n",
      "                    'libgen.li.epub_181',\n",
      "              'score': 0.213150203,\n",
      "              'values': []}],\n",
      " 'namespace': '',\n",
      " 'usage': {'read_units': 6}}\n",
      "2025-01-03 19:58:17,105 - httpx - INFO - HTTP Request: POST https://api.mistral.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a33a5d9161f42608c4a60fb3ccedc38",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-03 19:58:17,132 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/pinecone_plugins'])\n",
      "2025-01-03 19:58:17,134 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference\n",
      "2025-01-03 19:58:18,140 - __main__ - INFO - Retrieved results: {'matches': [{'id': 'John Mongan - Programming Interviews Exposed_ Coding Your '\n",
      "                    'Way Through the Interview (2018, Wrox Press) - '\n",
      "                    'libgen.li.epub_181',\n",
      "              'score': 0.287749529,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_37',\n",
      "              'score': 0.282813281,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_52',\n",
      "              'score': 0.269303441,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_48',\n",
      "              'score': 0.266718268,\n",
      "              'values': []},\n",
      "             {'id': 'Narayanan Vishwanathan - SQL and NoSQL Interview '\n",
      "                    'Questions_ Your essential guide to acing SQL and NoSQL '\n",
      "                    'job interviews (English Edition)-BPB Publications '\n",
      "                    '(2023).epub_4',\n",
      "              'score': 0.244296849,\n",
      "              'values': []}],\n",
      " 'namespace': '',\n",
      " 'usage': {'read_units': 6}}\n",
      "2025-01-03 19:58:26,734 - httpx - INFO - HTTP Request: POST https://api.mistral.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a6643e4369e4b03bdff5dca898fec66",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-03 19:58:26,762 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/pinecone_plugins'])\n",
      "2025-01-03 19:58:26,764 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference\n",
      "2025-01-03 19:58:27,442 - __main__ - INFO - Retrieved results: {'matches': [{'id': 'John Mongan - Programming Interviews Exposed_ Coding Your '\n",
      "                    'Way Through the Interview (2018, Wrox Press) - '\n",
      "                    'libgen.li.epub_181',\n",
      "              'score': 0.271440297,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_52',\n",
      "              'score': 0.26648,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_37',\n",
      "              'score': 0.234081224,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_48',\n",
      "              'score': 0.231471315,\n",
      "              'values': []},\n",
      "             {'id': 'John Mongan - Programming Interviews Exposed_ Coding Your '\n",
      "                    'Way Through the Interview (2018, Wrox Press) - '\n",
      "                    'libgen.li.epub_222',\n",
      "              'score': 0.225782558,\n",
      "              'values': []}],\n",
      " 'namespace': '',\n",
      " 'usage': {'read_units': 6}}\n",
      "2025-01-03 19:58:30,594 - httpx - INFO - HTTP Request: POST https://api.mistral.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "172ce3b21e6d4b659ac3064ea0c8a563",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-03 19:58:30,619 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/pinecone_plugins'])\n",
      "2025-01-03 19:58:30,620 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference\n",
      "2025-01-03 19:58:31,235 - __main__ - INFO - Retrieved results: {'matches': [{'id': 'John Mongan - Programming Interviews Exposed_ Coding Your '\n",
      "                    'Way Through the Interview (2018, Wrox Press) - '\n",
      "                    'libgen.li.epub_181',\n",
      "              'score': 0.328024983,\n",
      "              'values': []},\n",
      "             {'id': 'John Mongan - Programming Interviews Exposed_ Coding Your '\n",
      "                    'Way Through the Interview (2018, Wrox Press) - '\n",
      "                    'libgen.li.epub_222',\n",
      "              'score': 0.260980397,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_37',\n",
      "              'score': 0.255718082,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_52',\n",
      "              'score': 0.248748034,\n",
      "              'values': []},\n",
      "             {'id': 'Narayanan Vishwanathan - SQL and NoSQL Interview '\n",
      "                    'Questions_ Your essential guide to acing SQL and NoSQL '\n",
      "                    'job interviews (English Edition)-BPB Publications '\n",
      "                    '(2023).epub_4',\n",
      "              'score': 0.237782821,\n",
      "              'values': []}],\n",
      " 'namespace': '',\n",
      " 'usage': {'read_units': 6}}\n",
      "2025-01-03 19:58:40,567 - httpx - INFO - HTTP Request: POST https://api.mistral.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d155d28e9b94e6da7b972af3bd86f25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-03 19:58:40,592 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/pinecone_plugins'])\n",
      "2025-01-03 19:58:40,593 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference\n",
      "2025-01-03 19:58:41,248 - __main__ - INFO - Retrieved results: {'matches': [{'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_37',\n",
      "              'score': 0.294479579,\n",
      "              'values': []},\n",
      "             {'id': 'John Mongan - Programming Interviews Exposed_ Coding Your '\n",
      "                    'Way Through the Interview (2018, Wrox Press) - '\n",
      "                    'libgen.li.epub_375',\n",
      "              'score': 0.282921165,\n",
      "              'values': []},\n",
      "             {'id': 'John Mongan - Programming Interviews Exposed_ Coding Your '\n",
      "                    'Way Through the Interview (2018, Wrox Press) - '\n",
      "                    'libgen.li.epub_260',\n",
      "              'score': 0.270358682,\n",
      "              'values': []},\n",
      "             {'id': 'John Mongan - Programming Interviews Exposed_ Coding Your '\n",
      "                    'Way Through the Interview (2018, Wrox Press) - '\n",
      "                    'libgen.li.epub_181',\n",
      "              'score': 0.267140955,\n",
      "              'values': []},\n",
      "             {'id': 'Narayanan Vishwanathan - SQL and NoSQL Interview '\n",
      "                    'Questions_ Your essential guide to acing SQL and NoSQL '\n",
      "                    'job interviews (English Edition)-BPB Publications '\n",
      "                    '(2023).epub_4',\n",
      "              'score': 0.256685942,\n",
      "              'values': []}],\n",
      " 'namespace': '',\n",
      " 'usage': {'read_units': 6}}\n",
      "2025-01-03 19:58:54,526 - httpx - INFO - HTTP Request: POST https://api.mistral.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b568b5465b7a44128e47ea6bc861e3ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-03 19:58:54,553 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/pinecone_plugins'])\n",
      "2025-01-03 19:58:54,554 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference\n",
      "2025-01-03 19:58:55,517 - __main__ - INFO - Retrieved results: {'matches': [{'id': 'John Mongan - Programming Interviews Exposed_ Coding Your '\n",
      "                    'Way Through the Interview (2018, Wrox Press) - '\n",
      "                    'libgen.li.epub_181',\n",
      "              'score': 0.292685181,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_52',\n",
      "              'score': 0.291401058,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_48',\n",
      "              'score': 0.255780339,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_99',\n",
      "              'score': 0.251876682,\n",
      "              'values': []},\n",
      "             {'id': 'Narayanan Vishwanathan - SQL and NoSQL Interview '\n",
      "                    'Questions_ Your essential guide to acing SQL and NoSQL '\n",
      "                    'job interviews (English Edition)-BPB Publications '\n",
      "                    '(2023).epub_4',\n",
      "              'score': 0.239222556,\n",
      "              'values': []}],\n",
      " 'namespace': '',\n",
      " 'usage': {'read_units': 6}}\n",
      "2025-01-03 19:59:01,770 - httpx - INFO - HTTP Request: POST https://api.mistral.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8ce4073be644c148ce21569f6096dd1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-03 19:59:01,799 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/pinecone_plugins'])\n",
      "2025-01-03 19:59:01,800 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference\n",
      "2025-01-03 19:59:02,433 - __main__ - INFO - Retrieved results: {'matches': [{'id': 'John Mongan - Programming Interviews Exposed_ Coding Your '\n",
      "                    'Way Through the Interview (2018, Wrox Press) - '\n",
      "                    'libgen.li.epub_181',\n",
      "              'score': 0.28408736,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_52',\n",
      "              'score': 0.281413406,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_48',\n",
      "              'score': 0.275055677,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_37',\n",
      "              'score': 0.247013077,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_0',\n",
      "              'score': 0.23984012,\n",
      "              'values': []}],\n",
      " 'namespace': '',\n",
      " 'usage': {'read_units': 6}}\n",
      "2025-01-03 19:59:06,728 - httpx - INFO - HTTP Request: POST https://api.mistral.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8325e02b2123479bb4e686ebd508dfd6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-03 19:59:06,757 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/pinecone_plugins'])\n",
      "2025-01-03 19:59:06,758 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference\n",
      "2025-01-03 19:59:07,395 - __main__ - INFO - Retrieved results: {'matches': [{'id': 'John Mongan - Programming Interviews Exposed_ Coding Your '\n",
      "                    'Way Through the Interview (2018, Wrox Press) - '\n",
      "                    'libgen.li.epub_181',\n",
      "              'score': 0.317296982,\n",
      "              'values': []},\n",
      "             {'id': 'Narayanan Vishwanathan - SQL and NoSQL Interview '\n",
      "                    'Questions_ Your essential guide to acing SQL and NoSQL '\n",
      "                    'job interviews (English Edition)-BPB Publications '\n",
      "                    '(2023).epub_4',\n",
      "              'score': 0.260387927,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_52',\n",
      "              'score': 0.254974663,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_7',\n",
      "              'score': 0.250501633,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_48',\n",
      "              'score': 0.242010638,\n",
      "              'values': []}],\n",
      " 'namespace': '',\n",
      " 'usage': {'read_units': 6}}\n",
      "2025-01-03 19:59:18,479 - httpx - INFO - HTTP Request: POST https://api.mistral.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34798b582b134c66a994e08d77ccf2c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-03 19:59:18,505 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/pinecone_plugins'])\n",
      "2025-01-03 19:59:18,506 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference\n",
      "2025-01-03 19:59:19,132 - __main__ - INFO - Retrieved results: {'matches': [{'id': 'John Mongan - Programming Interviews Exposed_ Coding Your '\n",
      "                    'Way Through the Interview (2018, Wrox Press) - '\n",
      "                    'libgen.li.epub_181',\n",
      "              'score': 0.267123282,\n",
      "              'values': []},\n",
      "             {'id': 'John Mongan - Programming Interviews Exposed_ Coding Your '\n",
      "                    'Way Through the Interview (2018, Wrox Press) - '\n",
      "                    'libgen.li.epub_222',\n",
      "              'score': 0.251824647,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_52',\n",
      "              'score': 0.245113626,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_48',\n",
      "              'score': 0.236920565,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_37',\n",
      "              'score': 0.228835464,\n",
      "              'values': []}],\n",
      " 'namespace': '',\n",
      " 'usage': {'read_units': 6}}\n",
      "2025-01-03 19:59:28,498 - httpx - INFO - HTTP Request: POST https://api.mistral.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7eea038741a452bb4c5cce00fffad07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-03 19:59:28,527 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/pinecone_plugins'])\n",
      "2025-01-03 19:59:28,528 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference\n",
      "2025-01-03 19:59:29,163 - __main__ - INFO - Retrieved results: {'matches': [{'id': 'John Mongan - Programming Interviews Exposed_ Coding Your '\n",
      "                    'Way Through the Interview (2018, Wrox Press) - '\n",
      "                    'libgen.li.epub_181',\n",
      "              'score': 0.311074287,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_52',\n",
      "              'score': 0.254956633,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_37',\n",
      "              'score': 0.253498048,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_48',\n",
      "              'score': 0.251823485,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_94',\n",
      "              'score': 0.2501598,\n",
      "              'values': []}],\n",
      " 'namespace': '',\n",
      " 'usage': {'read_units': 6}}\n",
      "2025-01-03 19:59:31,809 - httpx - INFO - HTTP Request: POST https://api.mistral.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "906a23d03c904da6ae41e32458e833dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-03 19:59:31,838 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/pinecone_plugins'])\n",
      "2025-01-03 19:59:31,839 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference\n",
      "2025-01-03 19:59:32,478 - __main__ - INFO - Retrieved results: {'matches': [{'id': 'John Mongan - Programming Interviews Exposed_ Coding Your '\n",
      "                    'Way Through the Interview (2018, Wrox Press) - '\n",
      "                    'libgen.li.epub_181',\n",
      "              'score': 0.27492553,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_48',\n",
      "              'score': 0.252723753,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_37',\n",
      "              'score': 0.246262699,\n",
      "              'values': []},\n",
      "             {'id': 'Narayanan Vishwanathan - SQL and NoSQL Interview '\n",
      "                    'Questions_ Your essential guide to acing SQL and NoSQL '\n",
      "                    'job interviews (English Edition)-BPB Publications '\n",
      "                    '(2023).epub_4',\n",
      "              'score': 0.236164406,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_52',\n",
      "              'score': 0.235876769,\n",
      "              'values': []}],\n",
      " 'namespace': '',\n",
      " 'usage': {'read_units': 6}}\n",
      "2025-01-03 19:59:39,650 - httpx - INFO - HTTP Request: POST https://api.mistral.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8246a5a95cb44129736b2119ffc1076",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-03 19:59:39,676 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/pinecone_plugins'])\n",
      "2025-01-03 19:59:39,678 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference\n",
      "2025-01-03 19:59:40,452 - __main__ - INFO - Retrieved results: {'matches': [{'id': 'John Mongan - Programming Interviews Exposed_ Coding Your '\n",
      "                    'Way Through the Interview (2018, Wrox Press) - '\n",
      "                    'libgen.li.epub_181',\n",
      "              'score': 0.332659751,\n",
      "              'values': []},\n",
      "             {'id': 'Narayanan Vishwanathan - SQL and NoSQL Interview '\n",
      "                    'Questions_ Your essential guide to acing SQL and NoSQL '\n",
      "                    'job interviews (English Edition)-BPB Publications '\n",
      "                    '(2023).epub_4',\n",
      "              'score': 0.23411724,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_37',\n",
      "              'score': 0.232524693,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_52',\n",
      "              'score': 0.218199268,\n",
      "              'values': []},\n",
      "             {'id': 'John Mongan - Programming Interviews Exposed_ Coding Your '\n",
      "                    'Way Through the Interview (2018, Wrox Press) - '\n",
      "                    'libgen.li.epub_5',\n",
      "              'score': 0.213396013,\n",
      "              'values': []}],\n",
      " 'namespace': '',\n",
      " 'usage': {'read_units': 6}}\n",
      "2025-01-03 19:59:47,426 - httpx - INFO - HTTP Request: POST https://api.mistral.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7a78b0c89124a0f88427d456c3239b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-03 19:59:47,463 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/pinecone_plugins'])\n",
      "2025-01-03 19:59:47,464 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference\n",
      "2025-01-03 19:59:48,142 - __main__ - INFO - Retrieved results: {'matches': [{'id': 'John Mongan - Programming Interviews Exposed_ Coding Your '\n",
      "                    'Way Through the Interview (2018, Wrox Press) - '\n",
      "                    'libgen.li.epub_181',\n",
      "              'score': 0.308670461,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_52',\n",
      "              'score': 0.24728252,\n",
      "              'values': []},\n",
      "             {'id': 'Narayanan Vishwanathan - SQL and NoSQL Interview '\n",
      "                    'Questions_ Your essential guide to acing SQL and NoSQL '\n",
      "                    'job interviews (English Edition)-BPB Publications '\n",
      "                    '(2023).epub_4',\n",
      "              'score': 0.23009266,\n",
      "              'values': []},\n",
      "             {'id': 'John Mongan - Programming Interviews Exposed_ Coding Your '\n",
      "                    'Way Through the Interview (2018, Wrox Press) - '\n",
      "                    'libgen.li.epub_222',\n",
      "              'score': 0.226064265,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_37',\n",
      "              'score': 0.21588932,\n",
      "              'values': []}],\n",
      " 'namespace': '',\n",
      " 'usage': {'read_units': 6}}\n",
      "2025-01-03 19:59:51,543 - httpx - INFO - HTTP Request: POST https://api.mistral.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2d226e57f504e4d9c8db08e807a55d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-03 19:59:51,586 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/pinecone_plugins'])\n",
      "2025-01-03 19:59:51,587 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference\n",
      "2025-01-03 19:59:52,214 - __main__ - INFO - Retrieved results: {'matches': [{'id': 'John Mongan - Programming Interviews Exposed_ Coding Your '\n",
      "                    'Way Through the Interview (2018, Wrox Press) - '\n",
      "                    'libgen.li.epub_181',\n",
      "              'score': 0.297766387,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_52',\n",
      "              'score': 0.272924632,\n",
      "              'values': []},\n",
      "             {'id': 'John Mongan - Programming Interviews Exposed_ Coding Your '\n",
      "                    'Way Through the Interview (2018, Wrox Press) - '\n",
      "                    'libgen.li.epub_222',\n",
      "              'score': 0.242970958,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_48',\n",
      "              'score': 0.221272126,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_0',\n",
      "              'score': 0.21934478,\n",
      "              'values': []}],\n",
      " 'namespace': '',\n",
      " 'usage': {'read_units': 6}}\n",
      "2025-01-03 19:59:56,416 - httpx - INFO - HTTP Request: POST https://api.mistral.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cda842d3c8924cf2a43d5c8d41eae52c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-03 19:59:56,442 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/pinecone_plugins'])\n",
      "2025-01-03 19:59:56,443 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference\n",
      "2025-01-03 19:59:57,102 - __main__ - INFO - Retrieved results: {'matches': [{'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_52',\n",
      "              'score': 0.269368321,\n",
      "              'values': []},\n",
      "             {'id': 'John Mongan - Programming Interviews Exposed_ Coding Your '\n",
      "                    'Way Through the Interview (2018, Wrox Press) - '\n",
      "                    'libgen.li.epub_181',\n",
      "              'score': 0.26564011,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_48',\n",
      "              'score': 0.229912907,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_37',\n",
      "              'score': 0.213486537,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_0',\n",
      "              'score': 0.200875491,\n",
      "              'values': []}],\n",
      " 'namespace': '',\n",
      " 'usage': {'read_units': 6}}\n",
      "2025-01-03 20:00:03,602 - httpx - INFO - HTTP Request: POST https://api.mistral.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c53a81519c8d4531a433168259e4b16f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-03 20:00:03,629 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/pinecone_plugins'])\n",
      "2025-01-03 20:00:03,630 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference\n",
      "2025-01-03 20:00:04,277 - __main__ - INFO - Retrieved results: {'matches': [{'id': 'John Mongan - Programming Interviews Exposed_ Coding Your '\n",
      "                    'Way Through the Interview (2018, Wrox Press) - '\n",
      "                    'libgen.li.epub_181',\n",
      "              'score': 0.275399208,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_48',\n",
      "              'score': 0.263355404,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_37',\n",
      "              'score': 0.254526556,\n",
      "              'values': []},\n",
      "             {'id': 'Narayanan Vishwanathan - SQL and NoSQL Interview '\n",
      "                    'Questions_ Your essential guide to acing SQL and NoSQL '\n",
      "                    'job interviews (English Edition)-BPB Publications '\n",
      "                    '(2023).epub_4',\n",
      "              'score': 0.248807847,\n",
      "              'values': []},\n",
      "             {'id': 'John Mongan - Programming Interviews Exposed_ Coding Your '\n",
      "                    'Way Through the Interview (2018, Wrox Press) - '\n",
      "                    'libgen.li.epub_222',\n",
      "              'score': 0.244451553,\n",
      "              'values': []}],\n",
      " 'namespace': '',\n",
      " 'usage': {'read_units': 6}}\n",
      "2025-01-03 20:00:08,587 - httpx - INFO - HTTP Request: POST https://api.mistral.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0270d98b9cb8482ead4f6a25ba3f55ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-03 20:00:08,617 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/pinecone_plugins'])\n",
      "2025-01-03 20:00:08,618 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference\n",
      "2025-01-03 20:00:09,256 - __main__ - INFO - Retrieved results: {'matches': [{'id': 'John Mongan - Programming Interviews Exposed_ Coding Your '\n",
      "                    'Way Through the Interview (2018, Wrox Press) - '\n",
      "                    'libgen.li.epub_181',\n",
      "              'score': 0.305596232,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_37',\n",
      "              'score': 0.25141418,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_52',\n",
      "              'score': 0.240297943,\n",
      "              'values': []},\n",
      "             {'id': 'Narayanan Vishwanathan - SQL and NoSQL Interview '\n",
      "                    'Questions_ Your essential guide to acing SQL and NoSQL '\n",
      "                    'job interviews (English Edition)-BPB Publications '\n",
      "                    '(2023).epub_4',\n",
      "              'score': 0.239105672,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_48',\n",
      "              'score': 0.228473544,\n",
      "              'values': []}],\n",
      " 'namespace': '',\n",
      " 'usage': {'read_units': 6}}\n",
      "2025-01-03 20:00:20,990 - httpx - INFO - HTTP Request: POST https://api.mistral.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a27627232a63466bae834e3ca9efc24d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-03 20:00:21,035 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/pinecone_plugins'])\n",
      "2025-01-03 20:00:21,036 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference\n",
      "2025-01-03 20:00:21,665 - __main__ - INFO - Retrieved results: {'matches': [{'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_99',\n",
      "              'score': 0.297108591,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_76',\n",
      "              'score': 0.272681236,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_52',\n",
      "              'score': 0.270078838,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_179',\n",
      "              'score': 0.260131717,\n",
      "              'values': []},\n",
      "             {'id': 'John Mongan - Programming Interviews Exposed_ Coding Your '\n",
      "                    'Way Through the Interview (2018, Wrox Press) - '\n",
      "                    'libgen.li.epub_342',\n",
      "              'score': 0.255145818,\n",
      "              'values': []}],\n",
      " 'namespace': '',\n",
      " 'usage': {'read_units': 6}}\n",
      "2025-01-03 20:00:30,861 - httpx - INFO - HTTP Request: POST https://api.mistral.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74dfc11586a44a14ab46aefafadaac03",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-03 20:00:30,887 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/pinecone_plugins'])\n",
      "2025-01-03 20:00:30,888 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference\n",
      "2025-01-03 20:00:31,542 - __main__ - INFO - Retrieved results: {'matches': [{'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_52',\n",
      "              'score': 0.299828053,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_37',\n",
      "              'score': 0.273429692,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_48',\n",
      "              'score': 0.254696161,\n",
      "              'values': []},\n",
      "             {'id': 'John Mongan - Programming Interviews Exposed_ Coding Your '\n",
      "                    'Way Through the Interview (2018, Wrox Press) - '\n",
      "                    'libgen.li.epub_181',\n",
      "              'score': 0.248862728,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_99',\n",
      "              'score': 0.248832926,\n",
      "              'values': []}],\n",
      " 'namespace': '',\n",
      " 'usage': {'read_units': 6}}\n",
      "2025-01-03 20:00:48,416 - httpx - INFO - HTTP Request: POST https://api.mistral.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56c4d8caf1c14707be68c9e66df93ca6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-03 20:00:48,474 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/pinecone_plugins'])\n",
      "2025-01-03 20:00:48,475 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference\n",
      "2025-01-03 20:00:49,130 - __main__ - INFO - Retrieved results: {'matches': [{'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_52',\n",
      "              'score': 0.279378623,\n",
      "              'values': []},\n",
      "             {'id': 'John Mongan - Programming Interviews Exposed_ Coding Your '\n",
      "                    'Way Through the Interview (2018, Wrox Press) - '\n",
      "                    'libgen.li.epub_181',\n",
      "              'score': 0.239135236,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_37',\n",
      "              'score': 0.22211948,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_48',\n",
      "              'score': 0.213197768,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_6',\n",
      "              'score': 0.189673245,\n",
      "              'values': []}],\n",
      " 'namespace': '',\n",
      " 'usage': {'read_units': 6}}\n",
      "2025-01-03 20:00:56,640 - httpx - INFO - HTTP Request: POST https://api.mistral.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3d0a3cad0c5443b88a4c4941102966d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-03 20:00:56,665 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/pinecone_plugins'])\n",
      "2025-01-03 20:00:56,666 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference\n",
      "2025-01-03 20:00:57,295 - __main__ - INFO - Retrieved results: {'matches': [{'id': 'John Mongan - Programming Interviews Exposed_ Coding Your '\n",
      "                    'Way Through the Interview (2018, Wrox Press) - '\n",
      "                    'libgen.li.epub_337',\n",
      "              'score': 0.299982399,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_99',\n",
      "              'score': 0.298641801,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_48',\n",
      "              'score': 0.28348431,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_179',\n",
      "              'score': 0.268731117,\n",
      "              'values': []},\n",
      "             {'id': 'John Mongan - Programming Interviews Exposed_ Coding Your '\n",
      "                    'Way Through the Interview (2018, Wrox Press) - '\n",
      "                    'libgen.li.epub_317',\n",
      "              'score': 0.267092347,\n",
      "              'values': []}],\n",
      " 'namespace': '',\n",
      " 'usage': {'read_units': 6}}\n",
      "2025-01-03 20:01:10,651 - httpx - INFO - HTTP Request: POST https://api.mistral.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3f485b98b784f50b9235357b90c571e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-03 20:01:10,678 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/pinecone_plugins'])\n",
      "2025-01-03 20:01:10,679 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference\n",
      "2025-01-03 20:01:11,318 - __main__ - INFO - Retrieved results: {'matches': [{'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_139',\n",
      "              'score': 0.271520138,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_141',\n",
      "              'score': 0.259293199,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_179',\n",
      "              'score': 0.255646259,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_150',\n",
      "              'score': 0.239854321,\n",
      "              'values': []},\n",
      "             {'id': 'John Mongan - Programming Interviews Exposed_ Coding Your '\n",
      "                    'Way Through the Interview (2018, Wrox Press) - '\n",
      "                    'libgen.li.epub_351',\n",
      "              'score': 0.229442075,\n",
      "              'values': []}],\n",
      " 'namespace': '',\n",
      " 'usage': {'read_units': 6}}\n",
      "2025-01-03 20:01:16,578 - httpx - INFO - HTTP Request: POST https://api.mistral.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f66cffc207c8452fa9305eeb5f588a26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-03 20:01:16,605 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/pinecone_plugins'])\n",
      "2025-01-03 20:01:16,606 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference\n",
      "2025-01-03 20:01:17,260 - __main__ - INFO - Retrieved results: {'matches': [{'id': 'John Mongan - Programming Interviews Exposed_ Coding Your '\n",
      "                    'Way Through the Interview (2018, Wrox Press) - '\n",
      "                    'libgen.li.epub_181',\n",
      "              'score': 0.330240875,\n",
      "              'values': []},\n",
      "             {'id': 'John Mongan - Programming Interviews Exposed_ Coding Your '\n",
      "                    'Way Through the Interview (2018, Wrox Press) - '\n",
      "                    'libgen.li.epub_222',\n",
      "              'score': 0.272732764,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_52',\n",
      "              'score': 0.272226304,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_0',\n",
      "              'score': 0.251258492,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_37',\n",
      "              'score': 0.248157218,\n",
      "              'values': []}],\n",
      " 'namespace': '',\n",
      " 'usage': {'read_units': 6}}\n",
      "2025-01-03 20:12:00,303 - httpx - INFO - HTTP Request: POST https://api.mistral.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f94f8edc603144bf9a19d99c14ae67ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-03 20:12:00,355 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/pinecone_plugins'])\n",
      "2025-01-03 20:12:00,357 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference\n",
      "2025-01-03 20:12:01,106 - __main__ - INFO - Retrieved results: {'matches': [{'id': 'John Mongan - Programming Interviews Exposed_ Coding Your '\n",
      "                    'Way Through the Interview (2018, Wrox Press) - '\n",
      "                    'libgen.li.epub_181',\n",
      "              'score': 0.30542022,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_52',\n",
      "              'score': 0.28920728,\n",
      "              'values': []},\n",
      "             {'id': 'John Mongan - Programming Interviews Exposed_ Coding Your '\n",
      "                    'Way Through the Interview (2018, Wrox Press) - '\n",
      "                    'libgen.li.epub_222',\n",
      "              'score': 0.265515804,\n",
      "              'values': []},\n",
      "             {'id': 'Narayanan Vishwanathan - SQL and NoSQL Interview '\n",
      "                    'Questions_ Your essential guide to acing SQL and NoSQL '\n",
      "                    'job interviews (English Edition)-BPB Publications '\n",
      "                    '(2023).epub_4',\n",
      "              'score': 0.249273881,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_37',\n",
      "              'score': 0.246808946,\n",
      "              'values': []}],\n",
      " 'namespace': '',\n",
      " 'usage': {'read_units': 6}}\n",
      "2025-01-03 20:12:05,557 - httpx - INFO - HTTP Request: POST https://api.mistral.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a49e451954c74da4bf04e9c0977111ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-03 20:12:05,584 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/pinecone_plugins'])\n",
      "2025-01-03 20:12:05,585 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference\n",
      "2025-01-03 20:12:06,231 - __main__ - INFO - Retrieved results: {'matches': [{'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_37',\n",
      "              'score': 0.253360063,\n",
      "              'values': []},\n",
      "             {'id': 'John Mongan - Programming Interviews Exposed_ Coding Your '\n",
      "                    'Way Through the Interview (2018, Wrox Press) - '\n",
      "                    'libgen.li.epub_222',\n",
      "              'score': 0.246871546,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_52',\n",
      "              'score': 0.241594315,\n",
      "              'values': []},\n",
      "             {'id': 'John Mongan - Programming Interviews Exposed_ Coding Your '\n",
      "                    'Way Through the Interview (2018, Wrox Press) - '\n",
      "                    'libgen.li.epub_181',\n",
      "              'score': 0.233633861,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_99',\n",
      "              'score': 0.229163587,\n",
      "              'values': []}],\n",
      " 'namespace': '',\n",
      " 'usage': {'read_units': 6}}\n",
      "2025-01-03 20:12:10,760 - httpx - INFO - HTTP Request: POST https://api.mistral.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a3c5933aa0d4d6abe34f0fd0da81e5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-03 20:12:10,794 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/pinecone_plugins'])\n",
      "2025-01-03 20:12:10,795 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference\n",
      "2025-01-03 20:12:11,702 - __main__ - INFO - Retrieved results: {'matches': [{'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_52',\n",
      "              'score': 0.299743354,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_0',\n",
      "              'score': 0.269266874,\n",
      "              'values': []},\n",
      "             {'id': 'John Mongan - Programming Interviews Exposed_ Coding Your '\n",
      "                    'Way Through the Interview (2018, Wrox Press) - '\n",
      "                    'libgen.li.epub_181',\n",
      "              'score': 0.261410981,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_179',\n",
      "              'score': 0.261397511,\n",
      "              'values': []},\n",
      "             {'id': 'John Mongan - Programming Interviews Exposed_ Coding Your '\n",
      "                    'Way Through the Interview (2018, Wrox Press) - '\n",
      "                    'libgen.li.epub_5',\n",
      "              'score': 0.260998964,\n",
      "              'values': []}],\n",
      " 'namespace': '',\n",
      " 'usage': {'read_units': 6}}\n",
      "2025-01-03 20:12:29,665 - httpx - INFO - HTTP Request: POST https://api.mistral.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16877eed15f24f618caa04bcbedfe329",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-03 20:12:29,694 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/pinecone_plugins'])\n",
      "2025-01-03 20:12:29,706 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference\n",
      "2025-01-03 20:12:30,407 - __main__ - INFO - Retrieved results: {'matches': [{'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_7',\n",
      "              'score': 0.347293854,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_82',\n",
      "              'score': 0.276769549,\n",
      "              'values': []},\n",
      "             {'id': 'John Mongan - Programming Interviews Exposed_ Coding Your '\n",
      "                    'Way Through the Interview (2018, Wrox Press) - '\n",
      "                    'libgen.li.epub_5',\n",
      "              'score': 0.25493145,\n",
      "              'values': []},\n",
      "             {'id': 'John Mongan - Programming Interviews Exposed_ Coding Your '\n",
      "                    'Way Through the Interview (2018, Wrox Press) - '\n",
      "                    'libgen.li.epub_298',\n",
      "              'score': 0.239259318,\n",
      "              'values': []},\n",
      "             {'id': 'John Mongan - Programming Interviews Exposed_ Coding Your '\n",
      "                    'Way Through the Interview (2018, Wrox Press) - '\n",
      "                    'libgen.li.epub_6',\n",
      "              'score': 0.22306709,\n",
      "              'values': []}],\n",
      " 'namespace': '',\n",
      " 'usage': {'read_units': 6}}\n",
      "2025-01-03 20:12:42,090 - httpx - INFO - HTTP Request: POST https://api.mistral.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "128bd3ad822842e6bb259d93d80daa15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-03 20:12:42,117 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/pinecone_plugins'])\n",
      "2025-01-03 20:12:42,118 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference\n",
      "2025-01-03 20:12:42,953 - __main__ - INFO - Retrieved results: {'matches': [{'id': 'John Mongan - Programming Interviews Exposed_ Coding Your '\n",
      "                    'Way Through the Interview (2018, Wrox Press) - '\n",
      "                    'libgen.li.epub_181',\n",
      "              'score': 0.225637957,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_37',\n",
      "              'score': 0.225293145,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_48',\n",
      "              'score': 0.218880013,\n",
      "              'values': []},\n",
      "             {'id': 'Narayanan Vishwanathan - SQL and NoSQL Interview '\n",
      "                    'Questions_ Your essential guide to acing SQL and NoSQL '\n",
      "                    'job interviews (English Edition)-BPB Publications '\n",
      "                    '(2023).epub_4',\n",
      "              'score': 0.21693325,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_0',\n",
      "              'score': 0.213306174,\n",
      "              'values': []}],\n",
      " 'namespace': '',\n",
      " 'usage': {'read_units': 6}}\n",
      "2025-01-03 20:12:46,037 - httpx - INFO - HTTP Request: POST https://api.mistral.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f83449cd69a4174ad8c3be9a8fdfc1f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-03 20:12:46,068 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/pinecone_plugins'])\n",
      "2025-01-03 20:12:46,070 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference\n",
      "2025-01-03 20:12:46,776 - __main__ - INFO - Retrieved results: {'matches': [{'id': 'John Mongan - Programming Interviews Exposed_ Coding Your '\n",
      "                    'Way Through the Interview (2018, Wrox Press) - '\n",
      "                    'libgen.li.epub_181',\n",
      "              'score': 0.286468446,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_52',\n",
      "              'score': 0.271522701,\n",
      "              'values': []},\n",
      "             {'id': 'John Mongan - Programming Interviews Exposed_ Coding Your '\n",
      "                    'Way Through the Interview (2018, Wrox Press) - '\n",
      "                    'libgen.li.epub_222',\n",
      "              'score': 0.266051471,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_37',\n",
      "              'score': 0.244642496,\n",
      "              'values': []},\n",
      "             {'id': 'Narayanan Vishwanathan - SQL and NoSQL Interview '\n",
      "                    'Questions_ Your essential guide to acing SQL and NoSQL '\n",
      "                    'job interviews (English Edition)-BPB Publications '\n",
      "                    '(2023).epub_4',\n",
      "              'score': 0.234201759,\n",
      "              'values': []}],\n",
      " 'namespace': '',\n",
      " 'usage': {'read_units': 6}}\n",
      "2025-01-03 20:12:50,700 - httpx - INFO - HTTP Request: POST https://api.mistral.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9309e3d9ea0f4b18a377092c7349d4b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-03 20:12:50,728 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/pinecone_plugins'])\n",
      "2025-01-03 20:12:50,729 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference\n",
      "2025-01-03 20:12:51,500 - __main__ - INFO - Retrieved results: {'matches': [{'id': 'John Mongan - Programming Interviews Exposed_ Coding Your '\n",
      "                    'Way Through the Interview (2018, Wrox Press) - '\n",
      "                    'libgen.li.epub_239',\n",
      "              'score': 0.315796405,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_99',\n",
      "              'score': 0.303669482,\n",
      "              'values': []},\n",
      "             {'id': 'John Mongan - Programming Interviews Exposed_ Coding Your '\n",
      "                    'Way Through the Interview (2018, Wrox Press) - '\n",
      "                    'libgen.li.epub_5',\n",
      "              'score': 0.301161706,\n",
      "              'values': []},\n",
      "             {'id': 'John Mongan - Programming Interviews Exposed_ Coding Your '\n",
      "                    'Way Through the Interview (2018, Wrox Press) - '\n",
      "                    'libgen.li.epub_337',\n",
      "              'score': 0.301081628,\n",
      "              'values': []},\n",
      "             {'id': 'Narayanan Vishwanathan - SQL and NoSQL Interview '\n",
      "                    'Questions_ Your essential guide to acing SQL and NoSQL '\n",
      "                    'job interviews (English Edition)-BPB Publications '\n",
      "                    '(2023).epub_4',\n",
      "              'score': 0.288959086,\n",
      "              'values': []}],\n",
      " 'namespace': '',\n",
      " 'usage': {'read_units': 6}}\n",
      "2025-01-03 20:13:00,400 - httpx - INFO - HTTP Request: POST https://api.mistral.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc4d17a8c4e24011abee8b6bdf9ee955",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-03 20:13:00,428 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/pinecone_plugins'])\n",
      "2025-01-03 20:13:00,429 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference\n",
      "2025-01-03 20:13:01,159 - __main__ - INFO - Retrieved results: {'matches': [{'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_99',\n",
      "              'score': 0.229767829,\n",
      "              'values': []},\n",
      "             {'id': 'John Mongan - Programming Interviews Exposed_ Coding Your '\n",
      "                    'Way Through the Interview (2018, Wrox Press) - '\n",
      "                    'libgen.li.epub_181',\n",
      "              'score': 0.219566941,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_169',\n",
      "              'score': 0.219174668,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_179',\n",
      "              'score': 0.21738252,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_20',\n",
      "              'score': 0.214323163,\n",
      "              'values': []}],\n",
      " 'namespace': '',\n",
      " 'usage': {'read_units': 6}}\n",
      "2025-01-03 20:13:12,728 - httpx - INFO - HTTP Request: POST https://api.mistral.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee362ca22fa843faa5a8a8aa9a6dfa04",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-03 20:13:12,754 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/pinecone_plugins'])\n",
      "2025-01-03 20:13:12,755 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference\n",
      "2025-01-03 20:13:13,386 - __main__ - INFO - Retrieved results: {'matches': [{'id': 'John Mongan - Programming Interviews Exposed_ Coding Your '\n",
      "                    'Way Through the Interview (2018, Wrox Press) - '\n",
      "                    'libgen.li.epub_181',\n",
      "              'score': 0.338726044,\n",
      "              'values': []},\n",
      "             {'id': 'John Mongan - Programming Interviews Exposed_ Coding Your '\n",
      "                    'Way Through the Interview (2018, Wrox Press) - '\n",
      "                    'libgen.li.epub_222',\n",
      "              'score': 0.253786623,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_37',\n",
      "              'score': 0.242908761,\n",
      "              'values': []},\n",
      "             {'id': 'Narayanan Vishwanathan - SQL and NoSQL Interview '\n",
      "                    'Questions_ Your essential guide to acing SQL and NoSQL '\n",
      "                    'job interviews (English Edition)-BPB Publications '\n",
      "                    '(2023).epub_4',\n",
      "              'score': 0.235648945,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_52',\n",
      "              'score': 0.232623965,\n",
      "              'values': []}],\n",
      " 'namespace': '',\n",
      " 'usage': {'read_units': 6}}\n",
      "2025-01-03 20:13:21,486 - httpx - INFO - HTTP Request: POST https://api.mistral.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3937edd67f09464dbc9908684d549571",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-03 20:13:21,510 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/pinecone_plugins'])\n",
      "2025-01-03 20:13:21,512 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference\n",
      "2025-01-03 20:13:22,314 - __main__ - INFO - Retrieved results: {'matches': [{'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_48',\n",
      "              'score': 0.24254714,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_37',\n",
      "              'score': 0.232763305,\n",
      "              'values': []},\n",
      "             {'id': 'Narayanan Vishwanathan - SQL and NoSQL Interview '\n",
      "                    'Questions_ Your essential guide to acing SQL and NoSQL '\n",
      "                    'job interviews (English Edition)-BPB Publications '\n",
      "                    '(2023).epub_4',\n",
      "              'score': 0.210799202,\n",
      "              'values': []},\n",
      "             {'id': 'John Mongan - Programming Interviews Exposed_ Coding Your '\n",
      "                    'Way Through the Interview (2018, Wrox Press) - '\n",
      "                    'libgen.li.epub_222',\n",
      "              'score': 0.209570304,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_179',\n",
      "              'score': 0.198449522,\n",
      "              'values': []}],\n",
      " 'namespace': '',\n",
      " 'usage': {'read_units': 6}}\n",
      "2025-01-03 20:13:27,920 - httpx - INFO - HTTP Request: POST https://api.mistral.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5b80958109c4962ab1e2220deccc8ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-03 20:13:27,957 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/pinecone_plugins'])\n",
      "2025-01-03 20:13:27,958 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference\n",
      "2025-01-03 20:13:28,592 - __main__ - INFO - Retrieved results: {'matches': [{'id': 'John Mongan - Programming Interviews Exposed_ Coding Your '\n",
      "                    'Way Through the Interview (2018, Wrox Press) - '\n",
      "                    'libgen.li.epub_181',\n",
      "              'score': 0.326951474,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_37',\n",
      "              'score': 0.279266417,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_52',\n",
      "              'score': 0.278153151,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_48',\n",
      "              'score': 0.247268111,\n",
      "              'values': []},\n",
      "             {'id': 'John Mongan - Programming Interviews Exposed_ Coding Your '\n",
      "                    'Way Through the Interview (2018, Wrox Press) - '\n",
      "                    'libgen.li.epub_222',\n",
      "              'score': 0.225803226,\n",
      "              'values': []}],\n",
      " 'namespace': '',\n",
      " 'usage': {'read_units': 6}}\n",
      "2025-01-03 20:13:39,983 - httpx - INFO - HTTP Request: POST https://api.mistral.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61c671527bbf487eac53b07976ba9301",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-03 20:13:40,020 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/pinecone_plugins'])\n",
      "2025-01-03 20:13:40,021 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference\n",
      "2025-01-03 20:13:40,646 - __main__ - INFO - Retrieved results: {'matches': [{'id': 'John Mongan - Programming Interviews Exposed_ Coding Your '\n",
      "                    'Way Through the Interview (2018, Wrox Press) - '\n",
      "                    'libgen.li.epub_181',\n",
      "              'score': 0.296679169,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_37',\n",
      "              'score': 0.265440583,\n",
      "              'values': []},\n",
      "             {'id': 'John Mongan - Programming Interviews Exposed_ Coding Your '\n",
      "                    'Way Through the Interview (2018, Wrox Press) - '\n",
      "                    'libgen.li.epub_222',\n",
      "              'score': 0.261389196,\n",
      "              'values': []},\n",
      "             {'id': 'Narayanan Vishwanathan - SQL and NoSQL Interview '\n",
      "                    'Questions_ Your essential guide to acing SQL and NoSQL '\n",
      "                    'job interviews (English Edition)-BPB Publications '\n",
      "                    '(2023).epub_4',\n",
      "              'score': 0.239475504,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_6',\n",
      "              'score': 0.225782365,\n",
      "              'values': []}],\n",
      " 'namespace': '',\n",
      " 'usage': {'read_units': 6}}\n",
      "2025-01-03 20:13:46,443 - httpx - INFO - HTTP Request: POST https://api.mistral.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82b2706b44584e9d97d7999631086938",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-03 20:13:46,479 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/pinecone_plugins'])\n",
      "2025-01-03 20:13:46,480 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference\n",
      "2025-01-03 20:13:47,103 - __main__ - INFO - Retrieved results: {'matches': [{'id': 'John Mongan - Programming Interviews Exposed_ Coding Your '\n",
      "                    'Way Through the Interview (2018, Wrox Press) - '\n",
      "                    'libgen.li.epub_181',\n",
      "              'score': 0.291864961,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_37',\n",
      "              'score': 0.280926913,\n",
      "              'values': []},\n",
      "             {'id': 'Shlomo Kashani - Deep Learning Interviews Hundreds of '\n",
      "                    'fully solved job interview questions from a wide range of '\n",
      "                    'key topics in AI-Interviews AI (2020).epub_52',\n",
      "              'score': 0.269448191,\n",
      "              'values': []},\n",
      "             {'id': 'Narayanan Vishwanathan - SQL and NoSQL Interview '\n",
      "                    'Questions_ Your essential guide to acing SQL and NoSQL '\n",
      "                    'job interviews (English Edition)-BPB Publications '\n",
      "                    '(2023).epub_4',\n",
      "              'score': 0.249617338,\n",
      "              'values': []},\n",
      "             {'id': 'John Mongan - Programming Interviews Exposed_ Coding Your '\n",
      "                    'Way Through the Interview (2018, Wrox Press) - '\n",
      "                    'libgen.li.epub_222',\n",
      "              'score': 0.2483114,\n",
      "              'values': []}],\n",
      " 'namespace': '',\n",
      " 'usage': {'read_units': 6}}\n",
      "2025-01-03 20:13:51,498 - httpx - INFO - HTTP Request: POST https://api.mistral.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Function to load questions from JSON file\n",
    "def load_questions(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        return json.load(file)\n",
    "\n",
    "# Function to save answers to JSON file\n",
    "def save_answers(answers, file_path):\n",
    "    with open(file_path, 'w', encoding='utf-8') as file:\n",
    "        json.dump(answers, file, ensure_ascii=False, indent=4)\n",
    "\n",
    "# Function to get answers from RAG\n",
    "def get_answers(questions):\n",
    "    answers = {}\n",
    "    for q_id, question in questions.items():\n",
    "        # Step 1: Retrieve relevant documents from the vector database\n",
    "        retrieved_docs = retrieve_documents(question)\n",
    "\n",
    "        # Step 2: Generate a response using Mistral API\n",
    "        answer = generate_response(question, retrieved_docs)\n",
    "\n",
    "        answers[q_id] = answer\n",
    "    return answers\n",
    "\n",
    "# Load questions from file\n",
    "questions_file_path = '/home/bullat/projects/rag/Interview-2.0/question_for_test.json'\n",
    "questions = load_questions(questions_file_path)\n",
    "\n",
    "# Get answers from RAG\n",
    "answers = get_answers(questions)\n",
    "\n",
    "# Save answers to file\n",
    "answers_file_path = '/home/bullat/projects/rag/Interview-2.0/answers.json'\n",
    "save_answers(answers, answers_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-03 20:13:51,560 - sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: cpu\n",
      "2025-01-03 20:13:51,561 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: paraphrase-MiniLM-L6-v2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9accaa075ec943b4877f19c6210a4fe2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54196e584ca349f7bb72142462d23de4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question ID: 0\n",
      "Generated Answer: Алгоритм бинарного поиска — это эффективный алгоритм для поиска элемента в отсортированном массиве. Он основан на последовательном делении массива пополам до тех пор, пока не будет найден искомый элемент или массив станет пустым. Благодаря этому подходу, алгоритм бинарного поиска позволяет найти элемент за логарифмическое время, что значительно быстрее, чем линейный поиск. Алгоритм широко используется в различных областях, таких как информатика, математика и инженерия.\n",
      "Reference Answer: Алгоритм бинарного поиска - это метод поиска элемента в отсортированном массиве, который делит массив пополам и проверяет центральный элемент, повторяя процесс с левой или правой частью массива до нахождения элемента.\n",
      "Cosine Similarity: 0.9782422780990601\n",
      "BLEU Score: 0.06190867264354498\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81edbcd253904851a06a175cd8632507",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8b7001666ec426692543768f3f23257",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question ID: 1\n",
      "Generated Answer: Графовые нейронные сети (GNN) являются разновидностью искусственных нейронных сетей, которые используются для анализа графовых данных. Они позволяют обрабатывать данные, представленные в виде графа, где каждая вершина и ребро имеют свои признаки. GNN можно использовать для решения различных задач, таких как классификация вершин, кластеризация графов, рекомендательные системы и т.д.\n",
      "\n",
      "GNN состоят из нескольких слоёв, каждый из которых выполняет операцию агрегирования и обновления. На первом шаге каждая вершина обновляет своё представление, используя собственные признаки и признаки соседних вершин. Затем происходит агрегирование представлений вершин, связанных ребром, и обновление представления каждой вершины на основе агрегированных признаков. Этот процесс повторяется несколько раз, пока все вершины не конвергируют к стабильным представлениям.\n",
      "\n",
      "GNN могут быть рекурсивными или итеративными. Рекурсивные GNN используют рекурсивные формулы для агрегирования признаков, в то время как итеративные GNN используют итеративные алгоритмы, такие как градуированное сходство или конволюцию.\n",
      "\n",
      "GNN имеют несколько преимуществ перед традиционными нейронными сетями. Они могут эффективно обрабатывать данные с переменным размером входа и выхода, а также учитывать структуру данных и связности между ними. Кроме того, они могут быть эффективно обучены с помощью стандартных методов оптимизации.\n",
      "Reference Answer: Графовые нейронные сети (GNN) - это разновидность нейронных сетей, разработанных для обработки данных, представленных в виде графов. Они применяются для задач, где связи между объектами так же важны, как и сами объекты, например, в социальных сетях или молекулярных структурах.\n",
      "Cosine Similarity: 0.980859637260437\n",
      "BLEU Score: 0.02123430979264945\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8e0adbc3acb4f4d90e723d62eee2276",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee61b1762a4945b089ab2191ca48f386",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question ID: 2\n",
      "Generated Answer: Машинное обучение (Machine Learning) — это подход в области искусственного интеллекта, который позволяет компьютерным системам автоматически улучшать свои способности к выполнению определённых задач, не требуя явного программирования. Он основан на создании алгоритмов, которые могут обучаться из данных, выявляя тенденции и закономерности.\n",
      "\n",
      "В анализе данных машинное обучение используется для построения моделей, которые могут предсказывать результаты или обнаруживать скрытые структуры в данных. Это может быть полезно для различных задач, таких как классификация, регрессия, обнаружение аномалий и рекомендательные системы. Например, машинное обучение может быть использовано для предиктивированния цены дома на основе его характеристик, или для определения вероятности того, что пользователь покупает определённый продукт на основе его предыдущего поведения.\n",
      "\n",
      "В зависимости от типа задачи и доступных данных, могут быть использованы различные алгоритмы машинного обучения, такие как линейная регрессия, логистическая регрессия, решающие деревья, случайные леса, нейронные сети и т.д.\n",
      "\n",
      "В целом, машинное обучение является мощным инструментом для анализа данных, который может помочь в принятии более информированных решений и создании более эффективных систем.\n",
      "Reference Answer: Машинное обучение - это область искусственного интеллекта, которая фокусируется на разработке алгоритмов, которые позволяют компьютерам обучаться на данных. Оно применяется в анализе данных для прогнозирования, кластеризации, классификации и поиска скрытых закономерностей.\n",
      "Cosine Similarity: 0.5818259119987488\n",
      "BLEU Score: 3.3725713511715596e-155\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3905edaeb4b454fbea4104a3da2d971",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "872d65edb1b444a5a2b0d53c67c96aeb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question ID: 3\n",
      "Generated Answer: In machine learning, there are two main types of learning: supervised and unsupervised.\n",
      "\n",
      "Supervised learning, also known as learning with a teacher, is a type of machine learning where the algorithm is trained on a labeled dataset. This means that for each input, there is a corresponding output or label that the algorithm is trying to predict. The goal of supervised learning is to find a mapping function that can accurately predict the output for new, unseen inputs.\n",
      "\n",
      "Unsupervised learning, on the other hand, is a type of machine learning where the algorithm is not provided with any labeled data. Instead, the algorithm must find patterns and relationships within the data itself. The goal of unsupervised learning is to identify and extract structure from the data, such as finding clusters or dimensionality reduction.\n",
      "\n",
      "In summary, the main difference between supervised and unsupervised learning is the presence or absence of labeled data. Supervised learning uses labeled data to train a model to predict outputs, while unsupervised learning uses unlabeled data to find patterns and structure within the data.\n",
      "\n",
      "(Note: The above text was generated by translating the English explanation into Russian using a machine translation model, so please excuse any errors or awkward phrasing).\n",
      "Reference Answer: Обучение с учителем предполагает наличие размеченных данных для тренировки модели, где каждому входному сигналу соответствует целевой выход. Обучение без учителя не использует размеченные данные и направлено на выявление скрытых структур в данных, таких как кластеры или ассоциации.\n",
      "Cosine Similarity: 0.08179911226034164\n",
      "BLEU Score: 0\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59b4fa21be7848d0b6a74ab90252c69c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b70739d583e34c3aba6efd17beba44b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question ID: 4\n",
      "Generated Answer: Регрессия - это тип статистической модели, который используется для предсказания непрерывной целевой переменной на основе одной или нескольких предикторных переменных. Существует несколько типов регрессии, таких как:\n",
      "\n",
      "1. Линейная регрессия: это самый простой тип регрессии, который предполагает линейную зависимость между предикторными переменными и целевой переменной.\n",
      "2. Логистическая регрессия: это тип регрессии, который используется для моделирования вероятностей двух возможных исходов.\n",
      "3. Полиномиальная регрессия: это тип регрессии, который используется для моделирования нелинейных зависимостей между предикторными переменными и целевой переменной.\n",
      "4. Степенная регрессия: это тип регрессии, который используется для моделирования экспоненциальной зависимости между предикторными переменными и целевой переменной.\n",
      "5. Ранговая регрессия: это тип непараметрической регрессии, который используется для моделирования зависимости между переменными, когда функциональная форма зависимости неизвестна.\n",
      "6. Мультивариантная регрессия: это тип регрессии, который используется для предсказания одной непрерывной целевой переменной на основе нескольких предикторных переменных.\n",
      "7. Логистическая мультивариантная регрессия: это тип регрессии, который используется для моделирования зависимости между несколькими предикторными переменными и одной целевой переменной, которая представляет собой категориальную переменную с двумя или более уникальными уровнями.\n",
      "\n",
      "Вышеперечисленные типы регрессии могут быть использованы для решения различных задач предсказания и моделирования в различных областях, таких как экономика, финансы, маркетинг, медицина и многих других.\n",
      "Reference Answer: Регрессия - это метод моделирования зависимостей между переменными. Основные типы регрессии включают линейную регрессию, полиномиальную регрессию, логистическую регрессию и регрессию по методу наименьших квадратов.\n",
      "Cosine Similarity: 0.9017075300216675\n",
      "BLEU Score: 6.073975078544988e-79\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8db629d1d4e7486b9812e7ef9fad4006",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eada49d2f50540df8ae32003fc6e4110",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question ID: 5\n",
      "Generated Answer: To evaluate the accuracy of a machine learning model, there are several metrics that you can use, including:\n",
      "\n",
      "1. Confusion matrix: This is a table that summarizes the predictions made by a classification model. It can be used to calculate other metrics such as accuracy, precision, recall, and F1 score.\n",
      "2. Accuracy: This is the proportion of correct predictions made by the model. It is calculated by dividing the number of correct predictions by the total number of predictions.\n",
      "3. Precision: This is the proportion of true positive predictions (i.e., the model correctly predicted that the instance belongs to the positive class) out of all positive predictions made by the model.\n",
      "4. Recall: This is the proportion of true positive predictions out of all actual positive instances in the data.\n",
      "5. F1 score: This is the harmonic mean of precision and recall. It is a more balanced metric that takes into account both false positives and false negatives.\n",
      "6. Receiver Operating Characteristic (ROC) curve: This is a plot of the true positive rate against the false positive rate at different classification thresholds. It can be used to evaluate the performance of a binary classification model.\n",
      "7. Area Under the Curve (AUC): This is the area under the ROC curve. It measures the ability of a model to distinguish between positive and negative instances. A higher AUC indicates better performance.\n",
      "\n",
      "It's worth noting that the choice of metric depends on the specific problem and the business objective. For example, in a fraud detection problem, precision might be more important than recall, as it's better to have fewer false positives. On the other hand, in a medical diagnosis problem, recall might be more important than precision, as it's better to catch as many true positives as possible, even if it means having more false positives.\n",
      "Reference Answer: Точность модели машинного обучения оценивается с помощью различных метрик, таких как точность (accuracy), полнота (recall), F-мера, среднеквадратическая ошибка (MSE) и коэффициент детерминации (R²).\n",
      "Cosine Similarity: 0.2786029875278473\n",
      "BLEU Score: 0\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c66f31b6c94a4beb882c9041e5fd6167",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f39008d31b08412d8e7f4fd0b04319a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question ID: 6\n",
      "Generated Answer: Переобучение (overfitting) - это ситуация, когда модель машинного обучения учится слишком хорошо на тренировочном наборе данных и не может эффективно генерировать предсказания для новых данных. Переобучение может привести к неточным и ненадежным результатам.\n",
      "\n",
      "Чтобы избежать переобучения, можно применить несколько подходов:\n",
      "\n",
      "1. Увеличение количества данных. Более представительный набор данных может помочь модели лучшеgeneralize на новые данные.\n",
      "2. Регуляризация. Регуляризация - это техника, которая добавляет штрафы к функции потерь модели, чтобы предотвратить переобучение. Наиболее распространенными типами регуляризации являются L1 и L2-регуляризация.\n",
      "3. Проверка на валидационном наборе данных. Проверка модели на отдельном наборе данных (валидационном наборе) может помочь определить, переобучилась ли модель или нет. Если модель имеет высокую точность на тренировочном наборе данных, но низкую точность на валидационном наборе, это может быть признаком переобучения.\n",
      "4. Уменьшение сложности модели. Более простые модели менее подвержены переобучению, так как они имеют меньше параметров, которые нужно обучить. Можно попробовать уменьшить количество скрытых единиц в нейронной сети или уменьшить глубину дерева решений.\n",
      "5. Кросс-валидация. Кросс-валидация - это техника, которая позволяет более надежным образом оценить точность модели, разделяя данные на несколько folds и обучая модель несколько раз, каждый раз используя разные folds для обучения и тестирования.\n",
      "6. Early stopping. Early stopping - это техника, которая останавливает обучение модели, когда ее производительность на валидационном наборе данных перестает улучшаться. Это позволяет избежать переобучения, так как модель не будет продолжать обучаться на тренировочном наборе данных, когда ее производительность на валидационном наборе уже достигла максимума.\n",
      "Reference Answer: Переобучение происходит, когда модель слишком точно подстраивается под обучающие данные, теряя способность обобщать новые данные. Чтобы избежать переобучения, используют методы регуляризации, кросс-валидацию и увеличение объема тренировочных данных.\n",
      "Cosine Similarity: 0.9070553779602051\n",
      "BLEU Score: 5.308750645119313e-79\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d1bb9ef7aa2496989f8a6232bac79b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5566288a200b4591940eec1280824897",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question ID: 7\n",
      "Generated Answer: Отложенная выборка (англ. delayed sampling) - это техника, используемая в машинном обучении для улучшения обучающего алгоритма. Суть ее заключается в том, что вместо использования немедленно доступных данных для обучения алгоритма, мы храним их и используем впоследствии. Это может помочь уменьшить корреляцию между соседними образцами данных, что может привести к более стабильному и эффективному обучению.\n",
      "\n",
      "Примеры использования отложенной выборки включают в себя рекуррентное обучение нейронных сетей, где мы можем хранить предыдущие входные данные и использовать их для обучения сети в будущем, а также алгоритмы усиленного обучения, где мы можем использовать отложенную выборку для создания более разнообразных и информированных обучающих данных.\n",
      "\n",
      "Однако, при использовании отложенной выборки необходимо учитывать, что хранение данных может занимать дополнительное время и память, и что использование старых данных для обучения может привести к устареванию модели. Поэтому важно найти баланс между преимуществами и недостатками отложенной выборки и использовать ее в соответствии с требованиями конкретной задачи.\n",
      "Reference Answer: Отложенная выборка - это часть данных, которая используется для проверки модели после тренировки, но не участвует в процессе обучения, позволяя оценить её способность к обобщению на новые данные.\n",
      "Cosine Similarity: 0.7303051948547363\n",
      "BLEU Score: 2.5471828821575346e-155\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37bdc194b81641a6be143376cbcfb5e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c12e6dcdebb41cfaf7255626248568f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question ID: 8\n",
      "Generated Answer: Нормализация данных - это процесс организации данных в базах данных, чтобы минимизировать повторение и избежать изменений данных в нескольких местах. Нормализация помогает избежать проблемы изменения данных в одной таблице, которые могут привести к несогласованности или потере данных в другой таблице. Нормализация также помогает улучшить производительность запросов и упростить поддержание баз данных. Нормализация является одной из основных практик дизайна реляционных баз данных.\n",
      "\n",
      "Translation:\n",
      "\n",
      "Normalization of data is the process of organizing data in databases to minimize repetition and avoid changes to data in multiple places. Normalization helps avoid problems of changing data in one table that can lead to inconsistency or loss of data in another table. Normalization also helps improve query performance and simplify database maintenance. Normalization is one of the main practices of relational database design.\n",
      "Reference Answer: Нормализация данных - это процесс преобразования данных к единому масштабу для улучшения сходимости алгоритмов машинного обучения и повышения точности моделей.\n",
      "Cosine Similarity: 0.979779839515686\n",
      "BLEU Score: 0.029661889734388342\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29814099720947bc92cb8c249bd7b25a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b98f403bbced4c62be1b6da78e7b924e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question ID: 9\n",
      "Generated Answer: Метод k-ближайших соседей (k-NN) является алгоритмом машинного обучения, используемым для классификации и регрессии. В этом методе предполагается, что объекты в наборе данных расположены так, что соседние объекты имеют схожие свойства.\n",
      "\n",
      "В алгоритме k-NN используется метрика, такая как евклидова дистанция, для определения к ближайшим соседям данной точки в наборе данных. Затем, в зависимости от задачи, либо вычисляется среднее значение этих соседей (для регрессии), либо выполняется голосование по классам (для классификации).\n",
      "\n",
      "В классификации k-NN, каждый из k соседей голосует за класс, к которому принадлежит. Точка классифицируется в зависимости от большинства голосов соседей. Чем больше k, тем более гладкая граница разделения классов, но при этом метод становится более медленным. Чем меньше k, тем более чувствителен метод к шуму и выбросам.\n",
      "\n",
      "В целом, метод k-NN прост и эффективен для решения задач классификации и регрессии, но он требует большого объема памяти для хранения всего набора данных и может быть медленным для больших наборов данных.\n",
      "Reference Answer: Метод ближайших соседей (k-NN) классифицирует объекты по их ближайшим соседям в пространстве признаков. Классу объекта присваивается тот, к которому относится большинство из k ближайших соседей.\n",
      "Cosine Similarity: 0.9659041166305542\n",
      "BLEU Score: 3.2870859166661105e-155\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "edac7cc916a94dec85c23235e47cca1a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc20a8ff3e8b4e6bbc3d71ed3b5ffc50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question ID: 10\n",
      "Generated Answer: Решающее дерево - это вид машинного обучения, который используется для классификации и регрессии. Оно строит модель, которая представляет собой дерево решений, где каждый узел corresponds к признаку, а каждое раскрытие corresponds к определенному значению этого признака. Решающее дерево используется для предсказания исхода на основе ввода новых значений признаков. Оно может быть полезно для понимания взаимосвязи между входными переменными и исходом, а также для выявления важных признаков.\n",
      "\n",
      "Translation: A decision tree is a type of machine learning used for classification and regression. It builds a model that represents a tree of decisions where each node corresponds to a feature and each expansion corresponds to a specific value of that feature. A decision tree is used to predict the outcome based on new input feature values. It can be useful for understanding the relationship between input variables and the outcome, as well as for identifying important features.\n",
      "Reference Answer: Решающее дерево - это модель машинного обучения, которая представляет собой дерево решений и используется для задач классификации и регрессии. Оно состоит из узлов, которые представляют признаки, и ветвей, которые представляют условия разделения данных.\n",
      "Cosine Similarity: 0.9922162294387817\n",
      "BLEU Score: 0.053081087128885145\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c12b7979db24588956976b1915ef50e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca0a252c73904c0bb5cbcf884b34aaf8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question ID: 11\n",
      "Generated Answer: Алгоритмы кластеризации данных включают в себя:\n",
      "\n",
      "1. К-средних\n",
      "2. Иерархическая кластеризация\n",
      "3. DBSCAN (Density-Based Spatial Clustering of Applications with Noise)\n",
      "4. Спектральная кластеризация\n",
      "5. OPTICS (Ordering Points To Identify the Clustering Structure)\n",
      "6.mean-shift\n",
      "7.Густотная волновая кластеризация (Density-Based Wave Clustering)\n",
      "8.Fuzzy C-Means (FCM)\n",
      "9.Высокоскоростная кластеризация (Fast Clustering)\n",
      "\n",
      "Эти алгоритмы используются для разбиения данных на группы (кластеры) по сходству, без использования меток или предварительного знания о данных. Каждый алгоритм имеет свои сильные и слабые стороны, поэтому выбор зависит от конкретной задачи и характеристик данных.\n",
      "\n",
      "(Note: The above response is in Russian)\n",
      "\n",
      "Translation:\n",
      "\n",
      "1. K-means\n",
      "2. Hierarchical clustering\n",
      "3. DBSCAN (Density-Based Spatial Clustering of Applications with Noise)\n",
      "4. Spectral clustering\n",
      "5. OPTICS (Ordering Points To Identify the Clustering Structure)\n",
      "6. mean-shift\n",
      "7. Density-Based Wave Clustering\n",
      "8. Fuzzy C-Means (FCM)\n",
      "9. Fast Clustering\n",
      "\n",
      "These algorithms are used to partition data into groups (clusters) based on similarity, without using labels or prior knowledge of the data. Each algorithm has its strengths and weaknesses, so the choice depends on the specific task and characteristics of the data.\n",
      "Reference Answer: Для кластеризации данных используются алгоритмы, такие как k-средние (k-means), иерархическая кластеризация, DBSCAN и спектральная кластеризация.\n",
      "Cosine Similarity: 0.5143586993217468\n",
      "BLEU Score: 1.7082579826479949e-155\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af5bee1be8064850811e0ff2aa4b5015",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "382babda4a174fe5a94737a6cc732308",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question ID: 12\n",
      "Generated Answer: Метрика MSE (медианная квадратичная ошибка, Mean Squared Error) - это мера распространенности, которая измеряет среднее квадратичное отклонение предсказаний модели от действительных значений. Она широко используется в машинном обучении и статистике для оценки качества регрессионных моделей. MSE рассчитывается путем взвешивания квадрата разницы между каждым предсказанием и его соответствующим наблюдением, а затем деления суммы на количество наблюдений. Наименьшее значение MSE соответствует лучшему соответствию модели действительным данным.\n",
      "\n",
      "В контексте машинного обучения MSE используется в качестве функции потерь для обучения регрессионных моделей, таких как линейная регрессия и полиномиальная регрессия. MSE также используется в задачах фильтрации сигналов, компрессии данных и прогнозирования временных рядов.\n",
      "\n",
      "В целом, MSE является одной из самых широко используемых метрик для оценки качества регрессионных моделей, и ее легко интерпретировать и использовать в практических приложениях.\n",
      "Reference Answer: Метрика MSE (Mean Squared Error) измеряет среднеквадратическую ошибку предсказаний модели и используется для оценки моделей регрессии.\n",
      "Cosine Similarity: 0.9544228315353394\n",
      "BLEU Score: 3.4853715717914597e-155\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa56a8ad7cf440b4af80621961e00998",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3736793198134a5d982ca6f67ecfeecd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question ID: 13\n",
      "Generated Answer: The term \"сдвиг данных\" refers to the presence of a systematic difference between the means of the features in the training and test datasets. This can lead to poor model performance on the test dataset. To combat this issue, data preprocessing techniques such as mean subtraction can be used. Mean subtraction involves subtracting the mean of the training dataset from each feature, resulting in a dataset with a mean of zero. This can help to eliminate any systematic differences between the training and test datasets and improve model performance. This technique is also known as \"центрирование данных\" or \"data centering\".\n",
      "Reference Answer: Сдвиг данных - это изменение распределения данных во времени. Для борьбы с ним используют адаптивные модели и регулярные обновления данных, используемых для обучения модели.\n",
      "Cosine Similarity: 0.16144880652427673\n",
      "BLEU Score: 0\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ceb48c05fef490599514f3dfde1d92f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0837a42eff94cbf89ff7af60c991653",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question ID: 14\n",
      "Generated Answer: Методы ансамблевого обучения (ensemble learning methods) — это подход в машинном обучении, который заключается в комбинировании нескольких моделей для получения лучшего прогноза или решения задачи. Этот подход основан на идее, что несколько слабых моделей могут быть объединены в одну сильную модель, которая будет более точна и устойчива к ошибкам. К наиболее распространенным методам ансамблевого обучения относятся bootstrap агрегирование (bagging), boosting и стекingt (stacking).\n",
      "\n",
      "Bagging (Bootstrap Aggregating) — это метод, который заключается в создании нескольких моделей, обученных на различных выборках данных, сгенерированных с помощью метода bootstrap. Затем прогнозы всех моделей объединяются путем средневзвешенного взвешивания или голосования. Наиболее известный алгоритм, использующий метод bagging — это Random Forest.\n",
      "\n",
      "Boosting — это метод, который заключается в последовательном обучении нескольких моделей. Каждая следующая модель обучается на ошибках предыдущей модели, чтобы уменьшить их. К наиболее популярным алгоритмам boosting относятся AdaBoost и Gradient Boosting.\n",
      "\n",
      "Stacking (Stacked Generalization) — это метод, который заключается в комбинировании прогнозов нескольких моделей, обученных на одних и тех же данных. Затем эти прогнозы используются как входные данные для другой модели, называемой метамоделью, которая делает окончательный прогноз. Метамодель может быть любой моделью машинного обучения, но часто используются линейные модели, такие как линейная регрессия или логистическая регрессия.\n",
      "\n",
      "В целом, методы ансамблевого обучения могут значительно улучшить точность и устойчивость моделей машинного обучения, особенно когда имеется мало данных или данные содержат много шума.\n",
      "Reference Answer: Методы ансамблевого обучения объединяют несколько моделей для улучшения их точности и устойчивости. Основные методы включают bagging, boosting и stacking.\n",
      "Cosine Similarity: 0.5568109750747681\n",
      "BLEU Score: 5.470469607895306e-79\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c20eb8f1bbd4743a286c903244b5c0f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c6877d4208f4d8e9a52698f1d579e69",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question ID: 15\n",
      "Generated Answer: The knowledge base provided does not contain information on the workings of a random forest algorithm in English, let alone Russian. Therefore, I am unable to provide an answer in the language of the user's question.\n",
      "\n",
      "However, I can provide you with a general explanation of how a random forest algorithm works:\n",
      "\n",
      "Алгоритм случайного леса (random forest) — это один из наиболее эффективных и популярных методов машинного обучения, используемый для решения задач классификации и регрессии. Он основан на методе ансамблирования, который заключается в комбинировании нескольких моделей машинного обучения для получения более точного результата.\n",
      "\n",
      "Алгоритм случайного леса комбинирует несколько деревьев решений, каждое из которых обучается на случайном подмножестве данных и переменных. Для классификации нового объекта каждое дерево дает свое предсказание, а окончательный результат определяется голосованием большинства деревьев.\n",
      "\n",
      "Одной из ключевых особенностей алгоритма случайного леса является использование метода bagging (bootstrap aggregating), который позволяет уменьшить переобучение модели и улучшить ее общую точность. Кроме того, случайный лес обладает хорошей устойчивостью к шуму в данных и способностью автоматически определять важность переменных.\n",
      "\n",
      "В русскоязычной литературе алгоритм случайного леса часто называется случайным лесом, случайным лесом Бреймана или методом ансамблирования деревьев решений.\n",
      "\n",
      "I hope you find this helpful! If you have any further questions, please let me know.\n",
      "Reference Answer: Алгоритм случайного леса использует множество решающих деревьев для создания ансамбля, где каждое дерево обучается на случайной выборке данных с заменой, а предсказания дерева объединяются для получения окончательного результата.\n",
      "Cosine Similarity: 0.3101350963115692\n",
      "BLEU Score: 6.667661631561177e-79\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1402e77555f46798fcd400755786bb0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e5e653ceb474bd8abbdb5907942de74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question ID: 16\n",
      "Generated Answer: Нейронные сети - это математические модели, основанные на структуре и функционировании человеческого мозга. Они используются для обработки и анализа больших объемов данных, таких как изображения, звуки и тексты. Нейронные сети могут обучаться извлекать полезную информацию из данных, самостоятельно определяя важные особенности и закономерности. В области анализа данных нейронные сети используются для решения задач классификации, регрессии, кластеризации и распознавания образов. Они могут помочь предсказать результаты, основываясь на предыдущих данных, и обнаружить закономерности, которые невозможно увидеть с помощью традиционных статистических методов.\n",
      "\n",
      "Translation:\n",
      "Neural networks are mathematical models based on the structure and functioning of the human brain. They are used to process and analyze large amounts of data such as images, sounds, and texts. Neural networks can learn to extract useful information from data by determining important features and patterns on their own. In the field of data analysis, neural networks are used to solve tasks of classification, regression, clustering, and image recognition. They can help predict results based on previous data and detect patterns that cannot be seen using traditional statistical methods.\n",
      "Reference Answer: Нейронные сети - это модели, вдохновленные биологическими нейронами, которые используются для обработки и анализа сложных данных. Они применяются в задачах, таких как распознавание изображений, обработка естественного языка и предсказание временных рядов.\n",
      "Cosine Similarity: 0.9634917378425598\n",
      "BLEU Score: 0.03842889278641735\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8693b64b26ef458e9de25edb854f2fdc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b9520fd17d943978a8a0ef3783e72c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question ID: 17\n",
      "Generated Answer: Я знаю следующие типы активационных функций:\n",
      "\n",
      "1. Сигмоидная функция (logistic function)\n",
      "2. Функция реctified linear unit (ReLU)\n",
      "3. Леaking ReLU (LReLU)\n",
      "4. Parametric ReLU (PReLU)\n",
      "5. Соftmax функция\n",
      "6. Tanh функция\n",
      "7. Функция линейного активатора.\n",
      "\n",
      "Они используются в нейронных сетях для введения нелинейности и повышения их способности к моделированию сложных функций.\n",
      "Reference Answer: Типы активационных функций включают сигмоидную функцию, гиперболический тангенс (tanh), функцию ReLU (Rectified Linear Unit), Leaky ReLU и функцию Softmax.\n",
      "Cosine Similarity: 0.7630223035812378\n",
      "BLEU Score: 9.641193013181824e-232\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d97faf366bf4c87a4b1f479c4d75e54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b26ceda289a947fbb132033d53bc5eec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question ID: 18\n",
      "Generated Answer: Алгоритм градиентного спуска используется для нахождения минимума функции. Он работает следующим образом:\n",
      "\n",
      "1. Начальное приближение: Выбирается начальное приближение параметра, для которого будет выполняться поиск минимума функции.\n",
      "2. Вычисление градиента: Вычисляется градиент функции в выбранном начальном приближении. Градиент функции показывает направление, в котором функция возрастает наиболее быстро.\n",
      "3. Обновление параметра: Параметр обновляется путем вычитания из него произведения градиента и скорости обучения (learning rate). Скорость обучения определяет величину шага, который нужно сделать в направлении, противоположном направлению градиента.\n",
      "4. Повторение шагов 2-3: Шаги 2-3 повторяются до тех пор, пока величина градиента не станет достаточно мала, что означает, что мы приблизились к минимуму функции.\n",
      "\n",
      "В целом, алгоритм градиентного спуска движется в направлении наибольшего убывания функции, делая шаги в направлении, противоположном направлению градиента функции, пока не найдет её минимум.\n",
      "Reference Answer: Алгоритм градиентного спуска оптимизирует параметры модели, уменьшая ошибку путем итеративного обновления параметров в направлении, противоположном градиенту функции потерь.\n",
      "Cosine Similarity: 0.8706256747245789\n",
      "BLEU Score: 9.353183277790857e-79\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ebd4d02fa07418faf298b448e7f164b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1584415545cd4d2d95767ae590dcdc46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question ID: 19\n",
      "Generated Answer: Функция потерь (или функция ошибки) - это математическая функция, которая используется для измерения разницы между предсказанным значением и фактическим значением. Она используется для оценки качества модели машинного обучения и определения, насколько хорошо модель учится на данных. Функция потерь также используется для оптимизации параметров модели путем минимизации ее значения.\n",
      "\n",
      "Например, в задачах регрессии часто используется среднеквадратическое отклонение (MSE) в качестве функции потерь, а в задачах классификации - логарифмическая функция потерь (log loss). Выбор функции потерь зависит от конкретной задачи и типа данных.\n",
      "\n",
      "В целом, функция потерь играет ключевую роль в процессе обучения машинного обучения, поскольку она позволяет определить, насколько хорошо модель справляется с задачей предсказания и как ее можно улучшить путем изменения ее параметров.\n",
      "Reference Answer: Функция потерь измеряет, насколько точны предсказания модели. Она используется для оптимизации модели путем минимизации потерь, например, среднеквадратическая ошибка (MSE) или кросс-энтропия.\n",
      "Cosine Similarity: 0.9595435857772827\n",
      "BLEU Score: 1.3875070899219204e-78\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37bff5a490554b00a3d545878e64cfa9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6bae38597414ad9a34a39ba65d8e4ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question ID: 20\n",
      "Generated Answer: Глубокое обучение (deep learning) - это подраздел машинного обучения, который использует искусственные нейронные сети с многослойными архитектурами для обучения компьютера распознавать сложные модели и образцы в данных. Основное различие между глубоким обучением и традиционным машинным обучением заключается в том, что глубокое обучение может автоматически выявлять характеристики (features) из данных, тогда как в традиционном машинном обучении требуется ручное выделение характеристик. Глубокое обучение особенно эффективно для анализа неструктурированных данных, таких как изображения, звуки и текст, и позволяет создавать более точные и устойчивые модели предсказаний.\n",
      "\n",
      "Translation:\n",
      "Deep learning (deep learning) is a subfield of machine learning that uses artificial neural networks with multi-layered architectures to teach a computer to recognize complex models and patterns in data. The main difference between deep learning and traditional machine learning is that deep learning can automatically extract features from data, while in traditional machine learning, manual feature extraction is required. Deep learning is especially effective for analyzing unstructured data such as images, sounds, and text, and allows for the creation of more accurate and robust prediction models.\n",
      "Reference Answer: Глубокое обучение - это подмножество машинного обучения, которое использует многослойные нейронные сети для обработки и анализа данных. Оно отличается от машинного обучения большей сложностью моделей и способностью извлекать сложные признаки из данных.\n",
      "Cosine Similarity: 0.6970600485801697\n",
      "BLEU Score: 3.2901487819953286e-155\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "afb2545c3d8444bd8e5865aa768fd9c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "188e9b7171cd4b8abe98949bd905eb2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question ID: 21\n",
      "Generated Answer: Сверточная нейронная сеть (CNN) - это тип искусственных нейронных сетей, который широко используется в задачах обработки изображений и видео. Он состоит из нескольких слоев, каждый из которых выполняет конволюцию, которая представляет собой операцию математического преобразования изображения с использованием фильтра или ядра.\n",
      "\n",
      "Конволюционный слой принимает входное изображение и фильтр, и выполняет элементно-производительное умножение между ними, двигая фильтр по всему изображению. Результат этой операции называется картой активации или характеристической картой. Затем к характеристической карте применяется функция активации, например, ReLU (функция прямого линейного единичного изменения), которая вводит нелинейность в модель.\n",
      "\n",
      "Следующим слоем в CNN обычно является пул-слой, который уменьшает размерность характеристической карты, сохраняя при этом основную информацию. Существует несколько типов пул-слоев, но самые популярные из них - максимальное и среднее пулирование.\n",
      "\n",
      "После нескольких конволюционных и пул-слоев CNN заканчивается полносвязным (фуллинком) слоем, который сопоставляет веса и смещения для получения конечного результата.\n",
      "\n",
      "Одним из основных преимуществ CNN над традиционными нейронными сетями является то, что он способен выявлять локальные особенности изображений, такие как углы и края, и использовать их для классификации или других задач. Кроме того, CNN требует меньше параметров, чем полносвязная нейронная сеть, что делает ее более эффективной и простой в обучении.\n",
      "\n",
      "Вот пример кода на PyTorch для создания простого CNN для классификации изображений:\n",
      "```python\n",
      "import torch\n",
      "import torch.nn as nn\n",
      "\n",
      "# Создаем класс для CNN\n",
      "class SimpleCNN(nn.Module):\n",
      "  def __init__(self):\n",
      "    super(SimpleCNN, self).__init__()\n",
      "    self.conv1 = nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1)\n",
      "    self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
      "    self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
      "    self.fc1 = nn.Linear(64 * 7 * 7, 128)\n",
      "    self.fc2 = nn.Linear(128, 10)\n",
      "    \n",
      "  def forward(self, x):\n",
      "    x = self.pool(F.relu(self.conv1(x)))\n",
      "    x = self.pool(F.relu(self.conv2(x)))\n",
      "    x = x.view(-1, 64 * 7 * 7)\n",
      "    x = F.relu(self.fc1(x))\n",
      "    x = self.fc2(x)\n",
      "    return x\n",
      "\n",
      "# Создаем экземпляр CNN\n",
      "model = SimpleCNN()\n",
      "```\n",
      "В этом примере мы создаем простой CNN с двумя конволюционными слоями, двумя пул-слоями и двумя полносвязными слоями. Первый конволюционный слой имеет 32 фильтра размером 3x3, второй конволюционный слой имеет 64 фильтра размером 3x3. Пул-слои уменьшают размерность характеристических карт в два раза, сохраняя при этом основную информацию. Полносвязные слои преобразуют характеристические карты в конечный результат, например, вероятности классов для задачи классификации изображений.\n",
      "Reference Answer: Сверточная нейронная сеть (CNN) использует сверточные слои для извлечения признаков из данных, особенно из изображений. Она применяется в задачах распознавания образов, классификации изображений и сегментации.\n",
      "Cosine Similarity: 0.9689666628837585\n",
      "BLEU Score: 0.010308260643928303\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10c4bd8b8b774a958ef7455c1cb5305d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "960b9f0e758e4196804dee18b378a807",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question ID: 22\n",
      "Generated Answer: Рекуррентная нейронная сеть (RNN) — это тип искусственных нейронных сетей, который используется для обработки последовательностей данных, таких как речи, текст и временные ряды. RNN отличается от других видов нейронных сетей тем, что она имеет \"длинную короткоterm memory\", что позволяет ей помнить предыдущие входы в сеть и использовать эту информацию для обработки текущих входов.\n",
      "\n",
      "RNN широко используется в приложениях, таких как распознавание речи, машинный перевод, генерация текста и предсказание временных рядов. Например, RNN может быть использована для моделирования языка человека, чтобы генерировать реалистичный звучащий текст, или для предсказания цен на акции на основе исторических данных.\n",
      "\n",
      "Однако RNN также имеет свои ограничения, такие как проблема \"затухания градиентов\", которая затрудняет обучение сети на длинных последовательностях данных. Чтобы решить эту проблему, были разработаны более продвинутые архитектуры, такие как LSTM (двухслойная сеть с длинной короткоterm memory) и GRU (универсальная gates рекуррентная единица). Эти архитектуры улучшают способность RNN сохранять информацию на более длительные периоды времени и делают их более эффективными для обработки длинных последовательностей данных.\n",
      "Reference Answer: Рекуррентная нейронная сеть (RNN) учитывает временную последовательность данных и используется для задач, связанных с временными рядами, например, предсказание временных рядов и обработка последовательностей.\n",
      "Cosine Similarity: 0.9450975060462952\n",
      "BLEU Score: 0.020562625019216\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b03a1b6e718b40f1832f71a3787fc353",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1acb44afe1a44599f007014d278b1b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question ID: 23\n",
      "Generated Answer: LSTM (Long Short-Term Memory) нейронные сети являются разновидностью рекуррентных нейронных сетей (RNN), предназначенных для решения задач, требующих \"длительной памяти\". В отличие от традиционных RNN, LSTM сети могут хранить информацию на значительно более длительный период времени.\n",
      "\n",
      "LSTM состоит из специальных блоков памяти, называемых ячейками памяти, которые регулируются тремя входными вратами: входным, забывающим и выходным. Эти ворота регулируют поток информации в ячейку памяти, из ячейки памяти и из ячейки памяти далее в сеть соответственно.\n",
      "\n",
      "1. Входное ворота определяет, какую информацию следует сохранить в ячейке памяти. Оно вычисляет весовую сумму входных значений и предыдущего состояния скрытого слоя, а затем применяет функцию активации сигмоида, чтобы определить степень сохранения входящих значений.\n",
      "2. Забывающее ворота определяет, какую информацию следует \"забыть\" из ячейки памяти. Оно также вычисляет весовую сумму входных значений и предыдущего состояния скрытого слоя, а затем применяет функцию активации сигмоида, чтобы определить степень \"забывания\" ранее сохраненных значений.\n",
      "3. Выходное ворота определяет, какую информацию следует вывести из ячейки памяти. Оно вычисляет весовую сумму входных значений, предыдущего состояния скрытого слоя и содержимого ячейки памяти, а затем применяет функцию активации сигмоида, чтобы определить степень вывода сохраненной информации.\n",
      "\n",
      "LSTM сети используются в широком спектре приложений, включая обработку естественного языка, распознавание речи, предсказание временных рядов и генерацию музыки.\n",
      "Reference Answer: LSTM (Long Short-Term Memory) нейронные сети - это разновидность RNN, которая может хранить долгосрочные зависимости в данных. Они используются для задач, где важны длительные зависимости, например, в обработке текста.\n",
      "Cosine Similarity: 0.9842776656150818\n",
      "BLEU Score: 0.026894788037874658\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0425ac75d47f42eeb975a39ae5f19d4d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff48ce6e99c14c689383939f327e4cc5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question ID: 24\n",
      "Generated Answer: Гиперпараметры в машинном обучении - это параметры алгоритма, которые определяются перед началом тренировки модели и не изменяются в процессе обучения. Они могут включать такие вещи, какlearning rate, количество скрытых единиц в нейронной сети, или глубину решающего дерева.\n",
      "\n",
      "Оптимизация гиперпараметров - это процесс нахождения лучшего набора гиперпараметров для конкретной задачи. Это может быть сделано несколькими способами, такими как градиентный спуск, поиск с помощью решета или поиск с помощью рандомизированного ограничения. Также можно использовать более продвинутые методы, такие как Bayesian optimization или evolutionary algorithms.\n",
      "\n",
      "Важно отметить, что оптимизация гиперпараметров может быть дорогостоящей и времяемкой операцией, особенно для больших моделей. Поэтому часто используют предварительно обученные модели или предобученные веса, которые уже были оптимизированы для определенного класса задач.\n",
      "\n",
      "(Translation: Hyperparameters in machine learning are parameters of the algorithm that are determined before the start of training the model and do not change during training. They can include things like learning rate, number of hidden units in a neural network, or depth of a decision tree.\n",
      "\n",
      "Hyperparameter optimization is the process of finding the best set of hyperparameters for a specific task. This can be done in several ways, such as gradient descent, grid search, or random search. More advanced methods, such as Bayesian optimization or evolutionary algorithms, can also be used.\n",
      "\n",
      "It is important to note that hyperparameter optimization can be an expensive and time-consuming operation, especially for large models. Therefore, pre-trained models or pre-trained weights are often used, which have already been optimized for a certain class of tasks.)\n",
      "Reference Answer: Гиперпараметры - это параметры модели, которые задаются до обучения и не изменяются во время обучения, такие как скорость обучения и количество слоев. Их оптимизация осуществляется с помощью методов, таких как сеточный поиск и байесовская оптимизация.\n",
      "Cosine Similarity: 0.9720908403396606\n",
      "BLEU Score: 7.453682599970878e-79\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2b050201317498c863f47c47ec15078",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7854d830835b4281b8f3428446b87f49",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question ID: 25\n",
      "Generated Answer: Кросс-валидация (англ. Cross-validation) — это метод оценки производительности моделей машинного обучения. Он используется для того, чтобы убедиться, что модель хорошо генерализуется и будет эффективна на новых, не виданных ей ранее данных.\n",
      "\n",
      "Кросс-валидация работает следующим образом: обучающая выборка разделяется на k подвыборок (фолдов). Каждый фолд по очереди используется в качестве тестовой выборки, а остальные фолды объединяются и используются для обучения модели. Этот процесс повторяется k раз, и в конце концов мы получаем k оценок производительности модели. Среднее или медиана этих оценок используется в качестве финальной оценки производительности модели.\n",
      "\n",
      "Кросс-валидация необходима, потому что простое разделение данных на обучающую и тестовую выборки может привести к оптимистичной оценке производительности модели. Это происходит потому, что модель может запоминать специфические особенности обучающей выборки, но не будет хорошо генерализоваться на новые данные. Кросс-валидация помогает минимизировать эту проблему, поскольку она гарантирует, что каждая точка данных используется как минимум один раз для тестирования модели.\n",
      "\n",
      "Кроме того, кросс-валидация может помочь определить оптимальные параметры модели. Например, мы можем использовать кросс-валидацию для выбора лучшего значения параметра регуляризации для линейной регрессии или лучшего количества узлов в дереве решений.\n",
      "\n",
      "В целом, кросс-валидация является важным инструментом для оценки производительности моделей машинного обучения и может помочь избежать переобучения модели.\n",
      "Reference Answer: Кросс-валидация - это метод оценки модели, при котором данные делятся на несколько подвыборок. Модель обучается на одной подвыборке и проверяется на другой, позволяя оценить её обобщающую способность.\n",
      "Cosine Similarity: 0.7004709839820862\n",
      "BLEU Score: 4.735797536524749e-79\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1873cd4f2ae8422098bf28d9df7915d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a1753752590413fa68661e8932073ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question ID: 26\n",
      "Generated Answer: Методы уменьшения размерности, такие как PCA (приincipal component analysis), используются для преобразования большого количества переменных в меньшее количество, сохраняя при этом максимум информации. PCA выполняет это, вычисляя principale компоненты данных и проецируя их на новые оси, которые представляют собой линейную комбинацию исходных переменных. Новые оси (компоненты) отсортированы по убыванию их вариации, что позволяет отбросить те из них, которые не несут значимой информации. Таким образом, PCA уменьшает размерность данных, сохраняя при этом их основную структуру.\n",
      "Reference Answer: Методы уменьшения размерности, такие как PCA (Principal Component Analysis), уменьшают количество признаков в данных, сохраняя при этом как можно больше информации. Они используются для визуализации и ускорения работы моделей.\n",
      "Cosine Similarity: 0.9784644246101379\n",
      "BLEU Score: 0.10407583317524882\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e44c4c355624758ab548d8d618af689",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7363bc6406c64db19d185ff9c9139246",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question ID: 27\n",
      "Generated Answer: В контексте SVM (Супорт-векторной машины), гиперплоскость является линией или гиперлинией, которая отделяет две классы данных в многомерном пространстве. Она определяется как набор точек, для которых скалярное произведение вектора нормали к гиперплоскости и вектора координат точки равняется некоторой константе. Супорт-векторная машина старается найти гиперплоскость, которая максимально отделяет классы и минимизирует ошибки классификации.\n",
      "Reference Answer: Гиперплоскость в контексте SVM (Support Vector Machine) - это плоскость, разделяющая данные на разные классы, обеспечивая максимальное расстояние между классами для улучшения точности классификации.\n",
      "Cosine Similarity: 0.7473481893539429\n",
      "BLEU Score: 3.1389158403182592e-155\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57512ee288a84bfe8989a0235e38d1ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b647a737f1b4945bc5b06dfbe9e32ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question ID: 28\n",
      "Generated Answer: В работе с пропущенными данными в наборе данных существует несколько подходов. Вот некоторые из них:\n",
      "\n",
      "1. Удаление строк или столбцов с пропущенными значениями. Этот подход может быть полезен, если количество пропущенных данных относительно невелико и их удаление не повлияет на значимость результатов анализа.\n",
      "2. Заполнение пропущенных значений средними, медианными или модами значениями из соответствующего столбца. Этот подход может быть полезен, если пропущенные значения распределены случайным образом и их количество относительно невелико.\n",
      "3. Заполнение пропущенных значений с помощью методов машинного обучения, таких как регрессия или кластеризация. Эти методы используют информацию из других строк или столбцов для предсказания пропущенных значений.\n",
      "4. Использование многоуровневых моделей, которые могут учитывать неопределенность, связанную с пропущенными данными. Эти модели позволяют оценивать вероятность того, что пропущенные значения принадлежат к определенному классу или диапазону значений.\n",
      "\n",
      "Выбор подхода зависит от конкретной задачи и особенностей данных. В некоторых случаях можно использовать комбинацию нескольких подходов.\n",
      "Reference Answer: Для работы с пропущенными данными применяются методы, такие как удаление пропущенных значений, замена на среднее или медианное значение, и использование моделей для предсказания пропущенных значений.\n",
      "Cosine Similarity: 0.9569121599197388\n",
      "BLEU Score: 0.026409840011395055\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f313972e98e4fe7b0ef7bd57ccc6e64",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34b90e6c33e848968d2d5a7a87cde500",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question ID: 29\n",
      "Generated Answer: Свертка (convolution) в нейронных сетях - это операция, которая позволяет обнаруживать локальные особенности входных данных. Она широко используется в задачах обработки изображений, звука и других сигналов. В контексте нейронных сетей свертка выполняется путем применения фильтра (также называемого ядром или kernel) к входным данным с определенным шагом (stride). Выходной сигнал представляет собой сумму элементов умноженных на веса фильтра для каждой позиции, где фильтр применяется к входным данным. Свертка помогает уменьшить размерность входных данных и выявить важные особенности, которые могут быть полезны для последующего анализа.\n",
      "\n",
      "Translation:\n",
      "Convolution (convolution) in neural networks is an operation that allows detecting local features in input data. It is widely used in tasks of image, sound and other signal processing. In the context of neural networks, convolution is performed by applying a filter (also called a kernel) to the input data with a certain step (stride). The output signal represents the sum of the elements multiplied by the filter weights for each position where the filter is applied to the input data. Convolution helps reduce the dimensionality of input data and reveal important features that may be useful for subsequent analysis.\n",
      "Reference Answer: Свертка в нейронных сетях - это операция, применяемая в сверточных слоях для извлечения локальных признаков из данных, таких как изображения. Она используется для создания карт признаков.\n",
      "Cosine Similarity: 0.9509998559951782\n",
      "BLEU Score: 0.02838431417456251\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4750c1d1021f4a259f376a153fe3cefc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11ff5ab16fa94467944180c141cab24a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question ID: 30\n",
      "Generated Answer: Метод опорных векторов (SVM) — это алгоритм машинного обучения, используемый для классификации и регрессии. Он основан на принципе найти гиперплоскость, которая максимально отделяет две группы данных в n-мерном пространстве.\n",
      "\n",
      " SVМ использует опорные вектора, которые являются точками данных, расположенными близко к границе разделения. Эти опорные векторы определяют положение и направление гиперплоскости. Задача SVМ состоит в нахождении оптимальной гиперплоскости, которая максимизирует расстояние (марину) между ней и ближайшими точками данных (опорными векторами).\n",
      "\n",
      " SVМ может также использовать ядра для преобразования данных в более высокую размерность, если линейное разделение невозможно в исходном пространстве. Этот подход позволяет SVМ выполнять нелинейную классификацию путем линейной классификации в преобразованном пространстве.\n",
      "\n",
      " В целом, метод опорных векторов является мощным и эффективным алгоритмом машинного обучения, который хорошо работает с большими наборами данных и может быть использован для решения задач классификации и регрессии.\n",
      "Reference Answer: Метод опорных векторов (SVM) - это алгоритм классификации, который ищет гиперплоскость, максимально разделяющую данные на классы. Он эффективен для задач классификации и регрессии.\n",
      "Cosine Similarity: 0.9353466033935547\n",
      "BLEU Score: 0.042578495737409794\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e594c93a91024552af1032e5caddcf31",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86b3c9c6f8b84f44a5be70a45778e09d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question ID: 31\n",
      "Generated Answer: Регуляризация - это метод машинного обучения, который используется для предотвращения переобучения модели. Он работает путем добавления штрафного слагаемого к функции потерь модели, которое увеличивает сопротивление модели к изменениям при training данных. Регуляризация помогает уменьшить веса модели, уменьшая их значения, что приводит к уменьшению ее сложности и увеличению ее способности к generalization.\n",
      "\n",
      "Translation:\n",
      "Regularization is a machine learning method used to prevent overfitting of a model. It works by adding a penalty term to the model's loss function, which increases the model's resistance to changes in training data. Regularization helps reduce the weights of the model, decreasing their values, resulting in a decrease in the model's complexity and an increase in its ability to generalize.\n",
      "\n",
      "Note: The provided knowledge base does not contain any information related to the user's question. Therefore, I have generated an answer based on general knowledge about machine learning.\n",
      "Reference Answer: Регуляризация - это метод, используемый для предотвращения переобучения модели путем добавления штрафных значений к функции потерь, что ограничивает сложность модели. Виды регуляризации включают L1 и L2.\n",
      "Cosine Similarity: 0.9872078895568848\n",
      "BLEU Score: 1.0746190994230175e-78\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7346aeaaa71948378697b3249bcfd5f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2c67562c9b64f9787ca8fc2f39083d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question ID: 32\n",
      "Generated Answer: Я использую библиотеки TensorFlow и PyTorch для машинного обучения. TensorFlow имеет мощную экосистему и хорошую поддержку от Google, что делает его отличным выбором для крупных проектов и производственных задач. PyTorch, с другой стороны, известен своей простотой и удобством использования, что позволяет быстро прототипировать и экспериментировать с моделями глубокого обучения.\n",
      "\n",
      "Translation:\n",
      "I use the libraries TensorFlow and PyTorch for machine learning. TensorFlow has a powerful ecosystem and great support from Google, making it an excellent choice for large projects and production tasks. PyTorch, on the other hand, is known for its simplicity and ease of use, allowing for quick prototyping and experimentation with deep learning models.\n",
      "\n",
      "Note: The provided knowledge base does not contain information about machine learning libraries. The answer is generated based on general knowledge.\n",
      "Reference Answer: Библиотеки для машинного обучения, такие как TensorFlow, PyTorch, scikit-learn и Keras, используются из-за их эффективности, гибкости и поддержки широкого спектра алгоритмов и инструментов.\n",
      "Cosine Similarity: 0.9094886183738708\n",
      "BLEU Score: 2.083962447278344e-155\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a67623698cb74090aa8bf28f2bd2102b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8e2ae053c2e4f4ab9e663544674a89b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question ID: 33\n",
      "Generated Answer: Баггинг и бустинг - это два разных подхода к построению ансамблей моделей машинного обучения. Баггинг (Bootstrap Aggregating) является методом уменьшения дисперсии модели, а бустинг (Boosting) - методом уменьшения смещения. Баггинг создает несколько моделей путем случайного выборки подмножеств данных из основного набора данных, а затем объединяет их для получения финальной прогнозирующей модели. Бустинг, с другой стороны, строит модель пошагово, при этом каждый последующий шаг пытается улучшить ошибки предыдущего шага путем увеличения веса экземпляров, которые были неверно классифицированы в предыдущей модели. В результате ансамбль бустинга обычно имеет лучшую точность, чем отдельные модели, из которых он состоит.\n",
      "Reference Answer: Bagging и boosting - это методы ансамблевого обучения. Bagging уменьшает вариацию модели, комбинируя результаты нескольких моделей, обученных на случайных подвыборках данных. Boosting улучшает точность модели, последовательно обучая модели на ошибках предыдущих моделей.\n",
      "Cosine Similarity: 0.758857786655426\n",
      "BLEU Score: 2.4143894668765366e-155\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94245cc3fe2a4a3792b31de733542336",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c689e165e6e940b3b4700dc2c12d7b07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question ID: 34\n",
      "Generated Answer: В машинном обучении существует несколько способов определения важности признаков в модели. Один из самых распространенных методов - это использование механизма регуляризации L1 (Lasso) или L2 (Ridge), которые способствуют уменьшению незначительных коэффициентов до нуля, тем самым выделяя важные признаки. Другой способ - это использование методов, основанных на дереве решений, таких как Random Forest или XGBoost, которые предоставляют оценку важности признаков на основе частоты их использования в деревьях. Еще один метод - это частичное обратное распространение ошибки (Partial Dependence Plot, PDP), который позволяет оценить, как изменение значений одного или нескольких признаков влияет на предсказание модели. Наконец, можно использовать статистические методы, такие как коэффициент корреляции Пирсона или коэффициент детерминации R-квадрат, чтобы определить связь между признаком и целевой переменной.\n",
      "\n",
      "Выбор метода определения важности признаков зависит от типа модели, размера данных и конкретных целей задачи. Этот процесс может быть итеративным, и часто необходимо экспериментировать с различными методами, чтобы найти наиболее подходящий под задачу.\n",
      "\n",
      "Полезные ссылки:\n",
      "\n",
      "* [Регуляризация L1 (Lasso)](https://habr.com/ru/post/269683/)\n",
      "* [Регуляризация L2 (Ridge)](https://habr.com/ru/post/269683/)\n",
      "* [Random Forest](https://habr.com/ru/post/269715/)\n",
      "* [XGBoost](https://habr.com/ru/post/270243/)\n",
      "* [Частичное обратное распространение ошибки (Partial Dependence Plot, PDP)](https://towardsdatascience.com/partial-dependence-plots-6e1d369db21)\n",
      "* [Коэффициент корреляции Пирсона](https://studopedia.ru/10_61672_korrelyaciya-pearsona-i-spearmana-obuchenie.html)\n",
      "* [Коэффициент детерминации R-квадрат](https://studopedia.ru/12_142880_r-kvadrat-determinaciya-obuchenie.html)\n",
      "Reference Answer: Для определения важности признаков используются методы, такие как случайные леса, методы отбора признаков на основе статистических тестов и методы оценки вклада признаков в производительность модели.\n",
      "Cosine Similarity: 0.9532150626182556\n",
      "BLEU Score: 1.0144727480820937e-78\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db059b1b7f4b4cfbaf95369352637429",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c3f21fe726b4426b10c36e38f18ee26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question ID: 35\n",
      "Generated Answer: ROC-кривая (кривая характеристик оператора приёмника) - это график, показывающий зависимость чувствительности (true positive rate, TPR) от специфичности (true negative rate, TNR) бинарного классификатора. Чувствительность измеряет долю правильно классифицированных положительных примеров, а специфичность - долю правильно классифицированных отрицательных примеров. ROC-кривая используется для оценки качества моделей бинарной классификации.\n",
      "\n",
      "Интерпретация ROC-кривой:\n",
      "\n",
      "1. Чем ближе AUC (площадь под ROC-кривой) к 1, тем лучше классификатор. AUC может быть трактовано как вероятность того, что классификатор правильно определит случайные положительный и отрицательный примеры.\n",
      "2. Если AUC = 0,5, это означает, что классификатор имеет то же самое качество, что и случайное предсказание.\n",
      "3. Конкавная форма ROC-кривой является характерной для большинства моделей. Если кривая практически идеальна, то это может указывать на переобучение модели.\n",
      "4. Обычно чувствительность измеряется по оси Y, а 1-специфичность (false positive rate, FPR) - по оси X.\n",
      "Reference Answer: ROC-кривая (Receiver Operating Characteristic) показывает зависимость между долей верно предсказанных положительных примеров и долей неверно предсказанных отрицательных примеров. Она используется для оценки качества бинарных классификаторов.\n",
      "Cosine Similarity: 0.573750376701355\n",
      "BLEU Score: 0.023095050422988244\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b6b694721cf460fbc0c477c0dfdff89",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63f7449564164155b9e1997116d8b513",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question ID: 36\n",
      "Generated Answer: F-score (F1-score) - это метрика качества二классовой классификации, которая учитывает как точность (precision), так и полноту (recall) модели. Она определяется как гармоническое среднее precision и recall:\n",
      "\n",
      "F-score = 2 \\* (precision \\* recall) / (precision + recall)\n",
      "\n",
      "Прежде чем рассчитать F-score, нужно определить true positives (TP), false positives (FP) и false negatives (FN). Затем precision и recall можно рассчитать следующим образом:\n",
      "\n",
      "precision = TP / (TP + FP)\n",
      "recall = TP / (TP + FN)\n",
      "\n",
      "С помощью этих значений можно найти F-score. Значение F-score находится в диапазоне от 0 до 1, где 1 соответствует идеальной классификации, а 0 - полному отсутствию классификации.\n",
      "\n",
      "F-score широко используется для оценки производительности алгоритмов машинного обучения, особенно в задачах бинарной классификации.\n",
      "Reference Answer: F-score - это метрика, объединяющая точность (precision) и полноту (recall). Она рассчитывается как гармоническое среднее между точностью и полнотой, позволяя оценить эффективность модели при наличии несбалансированных классов.\n",
      "Cosine Similarity: 0.8957623243331909\n",
      "BLEU Score: 9.016313278427483e-79\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "120d8b268ba248be8a49e9c3668ce318",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93e1a5c8388d455cb25b2d7657d0187c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question ID: 37\n",
      "Generated Answer: Дисбаланс классов - это ситуация, когда в наборе данных для машинного обучения классы не имеют одинакового представительства. Это может привести к тому, что модель будет склонна предсказывать более частотный класс, даже если он не является правильным.\n",
      "\n",
      "Существует несколько подходов для борьбы с дисбалансом классов:\n",
      "\n",
      "1. Увеличение размера данных для малого класса: можно добавить синтетические данные или использовать аугментацию данных.\n",
      "2. Изменение весов классов: можно увеличить вес редкого класса, чтобы модель училась предсказывать его более точно.\n",
      "3. Изменение порога классификации: если наши классы не являются взаимоисключающимися, то можно использовать порог, отличный от 0,5, чтобы изменить баланс между ложноотрицательными и ложноположительными ошибками.\n",
      "4. Использование алгоритмов, устойчивых к дисбалансу классов: некоторые алгоритмы, такие как Random Forest, более устойчивы к дисбалансу классов, чем другие, такие как логистическая регрессия.\n",
      "5. Использование метрик, которые не зависят от баланса классов: вместо метрик, таких как точность, можно использовать F1-меру, которая учитывает как точность, так и полноту.\n",
      "\n",
      "Выбор подхода зависит от конкретного случая и требует тестирования нескольких подходов, чтобы определить, какой из них работает лучше.\n",
      "Reference Answer: Дисбаланс классов - это ситуация, когда один класс данных существенно преобладает над другим. Это может повлиять на работу моделей машинного обучения, поскольку модель будет склонна к предсказаниям преобладающего класса. Для борьбы с этим применяются методы балансировки данных, такие как синтетическое увеличение меньшего класса (SMOTE), взвешивание классов и использование ансамблевых методов.\n",
      "Cosine Similarity: 0.9805507659912109\n",
      "BLEU Score: 0.04441762608582054\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f9652c1a82f42b5a304aca5f02822d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a86017108f11413c90019da03c5367dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question ID: 38\n",
      "Generated Answer: Точность (precision) и полнота (recall) являются двумя важными метриками для оценки качества модели машинного обучения в задачах классификации.\n",
      "\n",
      "Точность измеряет долю правильно классифицированных позитивных примеров среди всех предсказанных позитивных примеров. Это можно выразить следующим образом:\n",
      "\n",
      "Precision = True Positives / (True Positives + False Positives)\n",
      "\n",
      "Полнота измеряет долю правильно классифицированных позитивных примеров среди всех реальных позитивных примеров. Это можно выразить следующим образом:\n",
      "\n",
      "Recall = True Positives / (True Positives + False Negatives)\n",
      "\n",
      "Точность и полнота часто используются вместе для оценки моделей машинного обучения, поскольку они дают разные представления о качестве модели. Например, модель с высокой точностью может иметь низкую полноту, что означает, что она хорошо классифицирует позитивные примеры, но может пропускать многие из них. Аналогичным образом, модель с высокой полнотой может иметь низкую точность, что означает, что она может выдавать много ложноположительных результатов.\n",
      "\n",
      "В идеале, мы хотим иметь модель, которая имеет высокую точность и высокую полноту, но это может быть сложно достичь для некоторых задач. В таких случаях можно использовать метрику F1-мер, которая является средним гармоническим точности и полноты. F1-мер изменяется от 0 до 1, где 1 означает идеальную модель.\n",
      "Reference Answer: Точность (precision) измеряет долю истинно положительных предсказаний среди всех положительных предсказаний модели. Полнота (recall) измеряет долю истинно положительных предсказаний среди всех реальных положительных примеров. Высокая точность означает, что модель редко ошибается в своих положительных предсказаниях, а высокая полнота означает, что модель выявляет почти все реальные положительные случаи.\n",
      "Cosine Similarity: 0.9398249983787537\n",
      "BLEU Score: 9.290199290186685e-79\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "854e3848449b44888c4c9ba427e5df3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00239caa61a84d188c641fdfa57b0e84",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question ID: 39\n",
      "Generated Answer: Кросс-энтропия (англ. cross-entropy) — это мера дисперсии двух распределений вероятностей. Она широко используется в машинном обучении для оценки качества модели, которая предсказывает распределение вероятностей. Кросс-энтропия измеряет ожидаемую величину информации, необходимой для того, чтобы определить, какой элемент был выбран из распределения вероятностей, если известно другое распределение. Чем меньше кросс-энтропия, тем лучше модель соответствует реальным данным. Кросс-энтропия также используется в алгоритме обратного распространения ошибки для обновления весов нейронов в нейронных сетях.\n",
      "\n",
      "In English:\n",
      "\n",
      "Cross-entropy (English cross-entropy) is a measure of the dispersion of two probability distributions. It is widely used in machine learning to assess the quality of a model that predicts a probability distribution. Cross-entropy measures the expected value of the information required to determine which element was selected from the probability distribution, given another distribution. The lower the cross-entropy, the better the model matches the real data. Cross-entropy is also used in the backpropagation algorithm to update the weights of neurons in neural networks.\n",
      "\n",
      "Note: The answer is provided only in the language of the user's question, which is Russian. The English translation is provided for reference.\n",
      "Reference Answer: Кросс-энтропия - это функция потерь, используемая в задачах классификации. Она измеряет расхождение между истинным распределением меток и предсказанным распределением вероятностей модели. Используется для оптимизации моделей, таких как логистическая регрессия и нейронные сети.\n",
      "Cosine Similarity: 0.6922940015792847\n",
      "BLEU Score: 7.817228731469945e-232\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66d9fab6bf3f4c47bf2ff2ea21536817",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cba4a7e129604d5090845a3930b8dc09",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question ID: 40\n",
      "Generated Answer: Мне нужно сначала определить, о какой конкретно модели речь идет в вопросе пользователя. Если речь идет о модели данных в контексте баз данных, я бы объяснил ее следующим образом:\n",
      "\n",
      "\"Модель данных - это представление структуры данных, используемых в системе. Она определяет, как данные хранятся, организуются и связаны между собой. В контексте баз данных, модель данных может быть представлена в виде диаграммы сущностей-связей (Entity-Relationship Diagram, ERD) или схемы базы данных. Эта диаграмма или схема показывает, как таблицы или сущности связаны между собой и какие данные хранятся в каждой таблице или сущности. Модель данных также определяет правила и ограничения для данных, чтобы гарантировать их целостность и согласованность.\"\n",
      "\n",
      "(Translation: I first need to determine which specific model the user is referring to in their question. If they are referring to a data model in the context of databases, I would explain it as follows:\n",
      "\n",
      "\"A data model is a representation of the structure of data used in a system. It defines how data is stored, organized, and related to each other. In the context of databases, a data model can be represented in the form of an Entity-Relationship Diagram (ERD) or database schema. This diagram or schema shows how tables or entities are related to each other and what data is stored in each table or entity. The data model also defines rules and constraints for the data to ensure its integrity and consistency.\")\n",
      "\n",
      "Note: The provided document does not contain any information about data models or how to explain them, so I had to generate an answer based on general knowledge.\n",
      "Reference Answer: Для объяснения модели коллегам или заинтересованным сторонам важно использовать понятный язык, визуализации и примеры. Можно начать с общей концепции модели, объяснив, какие данные использовались, какие были выбраны признаки и какова цель модели. Затем можно продемонстрировать результаты моделей с помощью графиков и метрик, таких как точность, полнота и ROC-кривые.\n",
      "Cosine Similarity: 0.9596164226531982\n",
      "BLEU Score: 1.6069522629556127e-155\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "805f3e91f68140d09e73ea66a43947c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "acb0b6e9a87c4fc5a8928bf7eb410e3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question ID: 41\n",
      "Generated Answer: Я использую различные подходы для визуализации данных, включая графики, диаграммы, гистограммы, heatmap, трехмерные графики и т.д. Я также использую библиотеки, такие как Matplotlib, Seaborn, Plotly и Bokeh в Python для создания этих визуализаций. В зависимости от конкретной задачи и характеристик данных, я выбираю самый подходящий подход для обеспечения наиболее эффективного представления данных.\n",
      "\n",
      "Translation:\n",
      "I use various approaches for data visualization, including charts, diagrams, histograms, heatmaps, 3D charts, etc. I also use libraries such as Matplotlib, Seaborn, Plotly, and Bokeh in Python to create these visualizations. Depending on the specific task and characteristics of the data, I choose the most suitable approach to ensure the most effective representation of the data.\n",
      "Reference Answer: Для визуализации данных используются различные подходы, включая гистограммы, диаграммы рассеяния, тепловые карты и boxplot. Эти визуализации помогают выявить тенденции, аномалии и зависимости в данных, а также объяснить результаты анализа и моделей машинного обучения.\n",
      "Cosine Similarity: 0.9371834397315979\n",
      "BLEU Score: 1.0244914152188952e-231\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f27efd625bb148ec91c69fc514a6c558",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6426791eba054519a857ecaf0842343b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question ID: 42\n",
      "Generated Answer: Бутстрепинг и кросс-валидация - это две техники, которые используются для оценки моделей машинного обучения.\n",
      "\n",
      "Бутстрепинг (bootstrap) - это метод, который заключается в создании нескольких выборок из первоначальной выборки с заменкой. Затем на каждой выборке обучается модель, и в итоге получается несколько моделей. После этого средние значения предсказаний этих моделей используются как окончательное предсказание.\n",
      "\n",
      "Кросс-валидация (cross-validation) - это метод, который заключается в разделении первоначальной выборки на несколько частей. Затем модель обучается на одной части и тестируется на другой части. Этот процесс повторяется several times, используя разные части выборки для обучения и тестирования. В итоге средние значения метрик качества модели используются как окончательная оценка.\n",
      "\n",
      "Таким образом, основное различие между бутстрепингом и кросс-валидацией заключается в том, что бутстрепинг создает несколько моделей на разных выборках, а кросс-валидация использует одну модель, обученную на разных частях выборки. Кроме того, бутстрепинг использует замену, в то время как кросс-валидация нет.\n",
      "Reference Answer: Бутстрепинг - это метод оценки статистической точности, который заключается в многократном выборке с заменой из исходного набора данных и построении оценок на основе этих выборок. Кросс-валидация - это метод оценки модели, при котором данные делятся на несколько подвыборок, модель обучается на одной подвыборке и проверяется на другой.\n",
      "Cosine Similarity: 0.9264898300170898\n",
      "BLEU Score: 0.03486928543519588\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2055ddefaf19430aa4b84d7dc3a8e24d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42ed3227aba948639ba7bdbef0cd11c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question ID: 43\n",
      "Generated Answer: Что такое t-SNE и зачем он нужен?\n",
      "\n",
      "t-SNE (t-Distributed Stochastic Neighbor Embedding) - это алгоритм визуализации данных, который используется для преобразования высокоразмерных данных в низкоразмерное пространство для отображения. Он основан на методе статистического обучения, который обеспечивает уменьшение размерности данных, сохраняя их структуру и связность.\n",
      "\n",
      "t-SNE полезен для визуализации сложных данных, таких как изображения, тексты и другие высокоразмерные данные. Он может помочь в обнаружении кластеров, выделении аномалий и понимании структуры данных. Кроме того, t-SNE может быть использован для предварительного анализа данных перед обучением моделей машинного обучения, чтобы лучше понять данные и выбрать подходящую модель.\n",
      "\n",
      "Таким образом, t-SNE является мощным инструментом для визуализации и анализа высокоразмерных данных, который может помочь в получении ценных инights и улучшении моделей машинного обучения.\n",
      "Reference Answer: t-SNE (t-Distributed Stochastic Neighbor Embedding) - это метод уменьшения размерности, который используется для визуализации многомерных данных в двумерном или трехмерном пространстве. Он сохраняет локальные структуры данных, что позволяет лучше понимать взаимосвязи между объектами.\n",
      "Cosine Similarity: 0.930223286151886\n",
      "BLEU Score: 0.0691995714832746\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0a4ba297d784f7db9f06aea588b4e8e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1873e23910d543d7b986f25064a0b45c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question ID: 44\n",
      "Generated Answer: Нейролингвистическое программирование (NLP) используется для решения различных задач обработки естественного языка. Некоторые из них включают:\n",
      "\n",
      "1. Разрешение кореференции: определение, когда несколько слов или фраз в тексте ссылаются на один и тот же объект.\n",
      "2. Выделение именованных сущностей (Named Entity Recognition, NER): обнаружение и классификация имён людей, организаций, местоположений и т.д. в тексте.\n",
      "3. Обработка языка на основе правил: использование специально оформленных правил для анализа и генерации текста.\n",
      "4. Машинный перевод: автоматический перевод текста с одного языка на другой.\n",
      "5. Понимание намерений: определение того, какую цель преследует пользователь, когда он говорит или пишет что-то.\n",
      "6. Классификация текста: определение категории, к которой относится данный текст.\n",
      "7. Суммаризация текста: создание краткого изложения длинного текста.\n",
      "8. Анализ тональности: определение эмоционального заряда текста, например, положительного, отрицательного или нейтрального.\n",
      "Reference Answer: С помощью NLP (обработка естественного языка) решаются такие задачи, как классификация текстов, анализ тональности, извлечение информации, машинный перевод, генерация текста и диалоговые системы. Эти задачи помогают анализировать и обрабатывать большие объемы текстовых данных.\n",
      "Cosine Similarity: 0.9300588965415955\n",
      "BLEU Score: 8.180400126889395e-232\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7d7fba4619644bfb7eaa0d59e4925e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a80f91bd47c74ac29dd9d07b610ff623",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question ID: 45\n",
      "Generated Answer: Токенизация в NLP - это процесс разбиения текста на более мелкие единицы, называемые токенами. Обычно токенами являются слова, но они также могут быть фразами или символами. Токенизация используется для преобразования неструктурированных данных текста в структурированные данные, которые могут быть использованы машинами для обработки естественного языка.\n",
      "\n",
      "Translation:Tokenization in NLP is the process of breaking down text into smaller units called tokens. Usually, tokens are words, but they can also be phrases or symbols. Tokenization is used to transform unstructured text data into structured data that can be used by machines for natural language processing.\n",
      "Reference Answer: Токенизация в NLP - это процесс разбиения текста на более мелкие элементы, такие как слова или символы. Эти элементы, называемые токенами, используются в дальнейшей обработке и анализе текста.\n",
      "Cosine Similarity: 0.972531259059906\n",
      "BLEU Score: 0.10951572022228621\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02728311340f46b59a1c825b2b9703cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd8ae75d00484f3c801cc289488104ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question ID: 46\n",
      "Generated Answer: Метод TF-IDF (Term Frequency-Inverse Document Frequency) широко используется в обработке естественного языка и информационном реtrieve для определения важности слова в документе или коллекции документов.\n",
      "\n",
      "TF (Term Frequency) представляет собой частоту появления термина (слова) в документе, измеренную как отношение количества появлений термина к общему количеству терминов в документе.\n",
      "\n",
      "IDF (Inverse Document Frequency) представляет собой обратную частоту документа и определяется как логарифм отношения количества документов в коллекции к количеству документов, содержащих данный термин.\n",
      "\n",
      "TF-IDF является произведением TF и IDF, и может быть вычислено по следующей формуле:\n",
      "\n",
      "TF-IDF = TF \\* IDF = (количество появлений термина в документе / общее количество терминов в документе) \\* log(количество документов в коллекции / количество документов, содержащих данный термин)\n",
      "\n",
      "Чем выше значение TF-IDF для термина в документе, тем более важным является этот термин для этого документа. Метод TF-IDF является эффективным способом представления текстовых документов как векторов, которые могут быть использованы в различных задачах, таких как классификация текстов, поиск информации и др.\n",
      "\n",
      "Вышеприведенное объяснение переведено с английского языка, поэтому возможно содержит ошибки.\n",
      "Reference Answer: Метод TF-IDF (Term Frequency-Inverse Document Frequency) измеряет важность термина в документе относительно всего корпуса документов. Он состоит из двух компонентов: частоты термина (TF), которая измеряет, как часто термин встречается в документе, и обратной частоты документа (IDF), которая уменьшает вес часто встречающихся терминов в корпусе. Этот метод используется для преобразования текста в числовые векторы для анализа.\n",
      "Cosine Similarity: 0.9846895933151245\n",
      "BLEU Score: 0.04593802453524049\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e116613718e4fa1b89a74cc508ca3c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5be294f6a324b28b7f890c27e57763c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question ID: 47\n",
      "Generated Answer: Word2Vec is a popular machine learning technique used for natural language processing (NLP). It is a two-layer neural network that is trained to reconstruct the linguistic context of words. The resulting word embeddings capture semantic meaning, allowing words with similar meaning to have a similar representation. Word2Vec can be used for various NLP tasks, such as text classification, sentiment analysis, and machine translation.\n",
      "\n",
      "Word2Vec используется для создания векторных представлений слов, которые отражают их семантическое значение. Это двухслойная нейронная сеть, обученная восстановить языковой контекст слов. В результате обработки Word2Vec получаются встроенные представления слов, которые могут быть использованы в различных задачах обработки естественного языка, таких как классификация текстов, анализ настроений и машинный перевод.\n",
      "Reference Answer: Word2Vec - это метод представления слов в виде векторов плотности, который учитывает контекст слов в тексте. Он используется для построения моделей, способных понимать семантические отношения между словами и улучшать качество задач обработки естественного языка, таких как классификация текстов и машинный перевод.\n",
      "Cosine Similarity: 0.40297162532806396\n",
      "BLEU Score: 0.05948762726718464\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4dd58ddfd8a456b8b3987200f709c61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28e11eb15cf04dbd8b9cdbacaaf068c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question ID: 48\n",
      "Generated Answer: Когда оцениваете качество классификатора в задаче NLP, существует несколько метрик, которые можно использовать. Вот некоторые из них:\n",
      "\n",
      "1. Точность (Precision): Это отношение количества правильно классифицированных экземпляров к общему количеству экземпляров, которые были классифицированы как положительные.\n",
      "2. Высокое качество (Recall): Это отношение количества правильно классифицированных экземпляров к общему количеству экземпляров, которые должны были быть классифицированы как положительные.\n",
      "3. F1-мерa: Это среднее гармоническое точности и высокого качества. F1-мерa является одной из наиболее распространенных метрик для оценки качества классификатора.\n",
      "4. Матрица ошибок: Это таблица, которая показывает количество правильно и неправильно классифицированных экземпляров. Матрица ошибок может помочь понять, где классификатор имеет трудности.\n",
      "5. Подъем (Lift): Это отношение количества правильно классифицированных экземпляров к количеству правильно классифицированных экземпляров, если бы вы классифицировали экземпляры случайным образом. Подъем может помочь определить, насколько хорошо классификатор работает по сравнению с случайным решением.\n",
      "6. ROC-кривая: Это график, который показывает точность классификатора в зависимости от порога, используемого для определения, является ли экземпляр положительным или отрицательным. ROC-кривая может помочь определить, насколько хорошо классификатор различает положительные и отрицательные экземпляры.\n",
      "\n",
      "Выбор метрики зависит от конкретной задачи и требований к классификатору. Например, если вам важно найти как можно больше положительных экземпляров, вы можете использовать метрику высокого качества. Если вам важно минимизировать количество ложноположительных экземпляров, вы можете использовать метрику точности. В некоторых случаях вы можете использовать несколько метрик, чтобы получить более полную картину качества классификатора.\n",
      "Reference Answer: Качество классификатора в задаче NLP оценивается с помощью метрик, таких как точность (accuracy), точность (precision), полнота (recall), F-мера и AUC-ROC. Эти метрики позволяют оценить, насколько хорошо модель классифицирует текстовые данные.\n",
      "Cosine Similarity: 0.8563147783279419\n",
      "BLEU Score: 5.177523731328522e-79\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9569ccf2b3364adab30e3ce0048ad921",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "990b01d4e4fa43d3b2f2f2f61facc887",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question ID: 49\n",
      "Generated Answer: Энтропия в контексте теории информации - это мера неопределенности или случайности в передаваемой информации. Она была введена Клодом Шенноном в 1948 году и измеряется в битах. Энтропия может быть использована для оценки эффективности кодирования данных и для определения минимального количества битов, необходимого для передачи сообщения.\n",
      "Reference Answer: Энтропия в контексте теории информации - это мера неопределенности или случайности в системе. Она используется для оценки количества информации, необходимой для описания состояния системы, и применяется в задачах, таких как построение решающих деревьев и выбор признаков.\n",
      "Cosine Similarity: 0.9672008156776428\n",
      "BLEU Score: 0.2787839092707202\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e1a9087a77f464a9a4090109b31804d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d47900b275f40a19f5529e12072f628",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question ID: 50\n",
      "Generated Answer: Для анализа временных рядов можно использовать различные методы. Вот несколько из них:\n",
      "\n",
      "1. Визуализация: графики позволяют легко увидеть тенденции, сезонность и аномалии в данных.\n",
      "2. Оценка тренда: линейная или нелинейная регрессия может быть использована для определения основного тренда в данных.\n",
      "3. Оценка сезонности: сезонные компоненты могут быть определены с помощью методов, таких как декомпозиция Тригонометрической или метод движущейся средней.\n",
      "4. Преобразование данных: если данные нестационарны, то их можно преобразовать в стационарные с помощью логарифмического преобразования, дифференцирования или других методов.\n",
      "5. Арма и Арima модели: эти модели используются для прогнозирования временных рядов, учитывая автокорреляцию и сезонность.\n",
      "6. Машинное обучение: алгоритмы машинного обучения, такие как рекуррентные нейронные сети (RNN) и длинные краткосрочные память (LSTM), могут быть использованы для прогнозирования временных рядов.\n",
      "\n",
      "Важно отметить, что для правильного анализа временных рядов необходимо хорошо понимать их структуру и характеристики, а также использовать подходящие методы и инструменты.\n",
      "\n",
      "(Translation: To analyze time series, various methods can be used. Here are some of them:\n",
      "\n",
      "1. Visualization: graphs allow you to easily see trends, seasonality, and anomalies in the data.\n",
      "2. Trend estimation: linear or nonlinear regression can be used to determine the main trend in the data.\n",
      "3. Seasonality estimation: seasonal components can be determined using methods such as trigonometric decomposition or the moving average method.\n",
      "4. Data transformation: if the data is non-stationary, they can be transformed into stationary using logarithmic transformation, differentiation, or other methods.\n",
      "5. Arma and Arima models: these models are used to forecast time series, taking into account autocorrelation and seasonality.\n",
      "6. Machine learning: machine learning algorithms, such as recurrent neural networks (RNN) and long short-term memory (LSTM), can be used to forecast time series.\n",
      "\n",
      "It is important to note that to correctly analyze time series, it is necessary to have a good understanding of their structure and characteristics, as well as use appropriate methods and tools.)\n",
      "Reference Answer: Для анализа временных рядов используются методы, такие как скользящее среднее, автокорреляция, сезонная декомпозиция и модели ARIMA. Эти методы позволяют выявлять тенденции, сезонные колебания и зависимости во временных рядах.\n",
      "Cosine Similarity: 0.9641772508621216\n",
      "BLEU Score: 0.011119367388738203\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45c900c0855b43f58bcac026f4468059",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18a63de084644f56bb94ecc352989088",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question ID: 51\n",
      "Generated Answer: Скользящее среднее (moving average) это статистическая мера центральной тенденции, которая используется для анализа временных рядов. Оно вычисляется как среднее значение нескольких последовательных наблюдений за определенный период времени. Скользящее среднее может помочь сгладить шумы в данных и обнаружить тренды или циклические компоненты в данных. Оно широко используется в области финансов для прогнозирования цен акций и в других областях для прогнозирования временных рядов.\n",
      "\n",
      "(Moving average is a statistical measure of central tendency used to analyze time series. It is calculated as the average value of several consecutive observations over a certain period of time. Moving average can help smooth out noise in the data and detect trends or cyclical components in the data. It is widely used in finance to forecast stock prices and in other areas to forecast time series.)\n",
      "\n",
      "In the provided knowledge base, there is no information related to the user's question. However, the answer provided above is a general explanation of what moving average is and how it is used.\n",
      "Reference Answer: Скользящее среднее - это метод сглаживания временного ряда путем усреднения значений за определенный период. Оно используется для устранения шума и выявления долгосрочных тенденций в данных.\n",
      "Cosine Similarity: 0.6610596179962158\n",
      "BLEU Score: 3.0230836341842412e-155\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68ddf0c699814474aaa88dba6949ff86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "796ca015b9954ec79494b184a0b8221f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question ID: 52\n",
      "Generated Answer: ARIMA-модель (авторегрессионная интегрированная движущаяся средняя модель) - это статистическая модель временных рядов, которая используется для прогнозирования будущих значений на основе предыдущих наблюдений. Она широко применяется в области экономики, финансов, предпринимательства и других областях, где требуется анализ и прогноз временных рядов. ARIMA-модель состоит из трёх основных компонентов: авторегрессионной части (AR), интегрированной части (I) и части движущейся средней (MA). Эти компоненты позволяют модели учитывать автокорреляцию, тренды и сезонные компоненты временных рядов.\n",
      "\n",
      "ARIMA-модель применяется в различных сферах, таких как прогнозирование продаж, оценка рисков, моделирование финансовых рынков и анализ экономических показателей. Например, в сфере продаж ARIMA-модель может использоваться для прогнозирования будущих продаж на основе исторических данных. В финансах модель может использоваться для прогнозирования курсов валют или котировок акций. В сфере экономики ARIMA-модель может быть использована для прогнозирования роста ВВП, уровня инфляции и других макроэкономических показателей.\n",
      "\n",
      "Однако, важно помнить, что ARIMA-модель является только одним из многих инструментов для прогнозирования временных рядов, и её использование должно основываться на тщательном анализе конкретной ситуации и наличии соответствующих данных. Кроме того, ARIMA-модель может иметь ограничения в прогнозировании сложных временных рядов с нелинейными трендами и сезонными компонентами.\n",
      "Reference Answer: ARIMA-модель (Autoregressive Integrated Moving Average) используется для анализа и прогнозирования временных рядов. Она состоит из трех компонентов: авторегрессии (AR), интегрирования (I) и скользящего среднего (MA), которые позволяют моделировать различные типы временных зависимостей.\n",
      "Cosine Similarity: 0.6328405737876892\n",
      "BLEU Score: 3.3579422968089585e-155\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e806d79f12c24212938592ba30b577d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ea1918d25d249e680711f9bbfe750da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question ID: 53\n",
      "Generated Answer: К сожалению, в базе знаний нет информации об обработке больших данных для подготовки к собеседованию на позицию инженера по машинному обучению. Возможно, вы найдете полезной следующую информацию:\n",
      "\n",
      "Обработка больших данных в контексте машинного обучения включает в себя несколько шагов, таких как сбор, очистка, преобразование и анализ данных. Вот некоторые рекомендации по работе с большими данными:\n",
      "\n",
      "1. Используйте распределенные системы обработки данных, такие как Apache Hadoop и Apache Spark. Они позволяют эффективно обрабатывать большие объемы данных на кластере компьютеров.\n",
      "2. Используйте алгоритмы машинного обучения, которые могут работать с разреженными матрицами, такие как алгоритмы gradient boosting и алгоритмы случайных лесов.\n",
      "3. Используйте подходы, основанные на подвыборках данных, такие как мини-батчи и онлайн-обучение.\n",
      "4. Используйте оптимизацию памяти, например, сжатие данных, удаление дубликатов и уменьшение размера данных.\n",
      "5. Используйте облачные решения, такие как Amazon S3 и Google Cloud Storage, для хранения и обработки больших объемов данных.\n",
      "\n",
      "Надеюсь, эта информация поможет вам в подготовке к собеседованию на позицию инженера по машинному обучению. Если у вас есть другие вопросы, пожалуйста, спрашивайте.\n",
      "Reference Answer: Работа с большими данными включает использование распределенных систем хранения и обработки данных, таких как Hadoop и Spark. Эти системы позволяют эффективно обрабатывать большие объемы данных, обеспечивая масштабируемость и высокую производительность.\n",
      "Cosine Similarity: 0.9172755479812622\n",
      "BLEU Score: 0.038683199974542753\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a144e6d9cc9f4fa48bf1943e4dc7072c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c9f84b309e3420880ead45a736d3638",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question ID: 54\n",
      "Generated Answer: Я знаю несколько инструментов для работы с большими данными. Вот некоторые из них:\n",
      "\n",
      "1. Apache Hadoop - это framwork для распределенной обработки больших данных. Он состоит из двух основных компонентов: Hadoop Distributed File System (HDFS) и MapReduce. HDFS позволяет хранить большие объемы данных на нескольких узлах, а MapReduce позволяет параллельно обрабатывать эти данные.\n",
      "2. Apache Spark - это инструмент для быстрой обработки больших данных. Он может работать на Hadoop, но также и на других платформах. Spark поддерживает различные типы обработки данных, в том числе батчинг, потоковую обработку и машинное обучение.\n",
      "3. Apache Hive - это инструмент для хранения и обработки данных, которые хранятся в Hadoop. Он предоставляет SQL-подобный интерфейс для выполнения запросов к данным, которые хранятся в HDFS.\n",
      "4. Apache Pig - это инструмент для обработки больших данных, который использует язык программирования Pig Latin. Pig Latin позволяет выполнять сложные операции над большими объемами данных, используя простой и интуитивно понятный синтаксис.\n",
      "5. Apache Cassandra - это распределенная база данных NoSQL, которая используется для хранения и обработки больших объемов данных. Cassandra может работать на нескольких узлах и обеспечивает высокую доступность и масштабируемость.\n",
      "6. Apache Kafka - это распределенная платформа для обработки потоковых данных. Она может обрабатывать большие объемы данных в реальном времени и обеспечивает высокую пропускную способность и низкую задержку.\n",
      "7. Apache Flink - это инструмент для обработки потоковых и батч-данных. Он может работать на Hadoop и других платформах и поддерживает различные типы обработки данных, в том числе машинное обучение и обработку графов.\n",
      "\n",
      "Это лишь некоторые из инструментов для работы с большими данными, которые я знаю. Выберите тот, который лучше всего подходит для ваших потребностей и задач.\n",
      "Reference Answer: Для работы с большими данными используются инструменты, такие как Apache Hadoop, Apache Spark, Apache Flink, и базы данных, такие как Apache Cassandra, MongoDB и HDFS. Эти инструменты обеспечивают распределенную обработку и хранение данных.\n",
      "Cosine Similarity: 0.8319802284240723\n",
      "BLEU Score: 4.8298967739282307e-79\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38690cc3d9474f94accf20897d6b6b24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6891767e58b47f289087d6676ae04d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question ID: 55\n",
      "Generated Answer: Конечно, я объясню разницу между Hadoop и Spark на русском языке.\n",
      "\n",
      "Hadoop и Spark - это две популярные платформы для обработки больших данных, но они отличаются по своим возможностям и подходу к обработке данных.\n",
      "\n",
      "Hadoop - это открытое решение для хранения и обработки больших данных, которое использует модель хранения данных на основе распределенной файловой системы (HDFS) и модель обработки данных, основанную на MapReduce. MapReduce - это парадигма обработки данных, которая состоит из двух основных шагов: Map и Reduce. Map-функция применяется к каждому элементу входных данных для создания пар \"ключ-значение\", а Reduce-функция объединяет пары с одинаковыми ключами и выполняет операции агрегирования.\n",
      "\n",
      "Spark, с другой стороны, является платформой обработки больших данных, которая также использует распределенную архитектуру, но отличается более эффективным механизмом обработки данных. Spark использует память для хранения данных, что позволяет ему выполнять операции анализа данных в реальном времени или почти в реальном времени. Spark также поддерживает более широкий спектр операций, чем Hadoop, включая машинное обучение, графовую обработку и потоковую обработку данных.\n",
      "\n",
      "Таким образом, основное различие между Hadoop и Spark заключается в том, что Hadoop использует дисковое хранение и MapReduce для обработки данных, в то время как Spark использует память и более широкий спектр операций для обработки данных.\n",
      "Reference Answer: Hadoop и Spark - это платформы для обработки больших данных. Hadoop использует модель MapReduce для распределенной обработки данных, а Spark предлагает более быструю и гибкую обработку данных в памяти, что делает его подходящим для сложных аналитических задач.\n",
      "Cosine Similarity: 0.921006441116333\n",
      "BLEU Score: 0.04379627393048726\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "909bd73201cf4e0e8678f2348ca60ffe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ebbe09f393db4953b21a1bd12a22f59c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question ID: 56\n",
      "Generated Answer: Here is the answer to the user's question:\n",
      "\n",
      "Когда проектируется архитектура ETL-процесса, следует учитывать несколько ключевых факторов, таких как источники данных, виды данных, требования к качеству данных, способ хранения данных, цели использования данных и возможные проблемы безопасности. Также важно определить порядок выполнения операций ETL и выбрать подходящие инструменты и технологии для их реализации.\n",
      "\n",
      "Ниже приведены общие шаги по проектированию архитектуры ETL-процесса:\n",
      "\n",
      "1. Идентификация источников данных и их характеристик: определение типов данных, форматов файлов, расположения и доступности источников данных.\n",
      "2. Определение требований к качеству данных: определение критериев очистки, фильтрации, преобразования и сопоставления данных.\n",
      "3. Определение целей использования данных: определение того, как данные будут использоваться для принятия решений, анализа или отчетности.\n",
      "4. Выбор подходящего способа хранения данных: определение типа базы данных (реляционная, NoSQL, справочная и т.д.), структуры таблиц и индексов, а также способов обеспечения безопасности и надежности данных.\n",
      "5. Выбор инструментов и технологий для реализации ETL-процесса: определение языка программирования, средств интеграции данных, средств контроля качества данных и средств мониторинга ETL-процесса.\n",
      "6. Определение порядка выполнения операций ETL: определение последовательности выполнения операций экстракции, трансформации и загрузки данных, а также определение точек отказа и методов восстановления.\n",
      "7. Проверка и оптимизация ETL-процесса: проверка правильности и эффективности выполнения операций ETL, оптимизация запросов и увеличение производительности.\n",
      "8. Документирование ETL-процесса: создание технической документации, в которой описывается архитектура ETL-процесса, используемые инструменты и технологии, а также инструкции по его использованию и обслуживанию.\n",
      "Reference Answer: Архитектура ETL (Extract, Transform, Load) процесса включает извлечение данных из источников, их преобразование в требуемый формат и загрузку в целевую систему. Она проектируется с учетом требований к качеству данных, производительности и масштабируемости.\n",
      "Cosine Similarity: 0.6064910888671875\n",
      "BLEU Score: 6.09406839934854e-79\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "daf20798e85f404bada0a829ce6b7c81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "295b199757974af79dd7c9c9a092b9c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question ID: 57\n",
      "Generated Answer: Потоковая обработка данных (Stream processing) — это обработка больших объемов данных в реальном времени или близком к реальному времени, по мере их поступления, без необходимости хранить все данные в памяти. Она используется для анализа, filtration, и преобразования данных в потоке, а также для создания реальных приложений, таких как мониторинг сети, обнаружение фродa, и прогнозирование.\n",
      "\n",
      "Note: This is a translation of the following English text:\n",
      "Stream processing is the real-time or near-real-time processing of large volumes of data, typically in a continuous stream or flow. It involves the analysis, filtration, and transformation of data as it arrives, without the need to store all the data in memory. It is used to create real-time applications such as network monitoring, fraud detection, and prediction.\n",
      "\n",
      "Please note that the provided knowledge base does not contain information on stream processing, so I had to retrieve the information from an external source.\n",
      "Reference Answer: Потоковая обработка данных - это процесс обработки данных в реальном времени по мере их поступления. Она используется для задач, где важна оперативная обработка данных, таких как мониторинг, анализ событий и обработка потоков данных.\n",
      "Cosine Similarity: 0.718538761138916\n",
      "BLEU Score: 0.03790580991772758\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66003ca659384f37a7c256e24980c248",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3b19f2dcaeb456c917128ec09c684d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question ID: 58\n",
      "Generated Answer: Конечно, я могу помочь вам с этим вопросом. Вот некоторые способы, в которых можно использовать облачные технологии в анализе данных:\n",
      "\n",
      "1. Хранение данных: Облачные технологии предоставляют масштабируемые и безопасные решения для хранения больших объемов данных. Вы можете использовать решения, такие как Amazon S3, Google Cloud Storage или Microsoft Azure Storage, для хранения данных в объектном формате.\n",
      "2. Обработка данных: Облачные технологии позволяют легко масштабировать вычислительные ресурсы для обработки больших объемов данных. Вы можете использовать платформы, такие как Amazon EMR, Google Cloud Dataflow или Microsoft Azure HDInsight, для выполнения распределенных вычислений.\n",
      "3. Анализ данных: Облачные технологии предоставляют мощные средства для анализа данных, такие как машинное обучение, искусственный интеллект и биг-данные. Вы можете использовать инструменты, такие как Amazon SageMaker, Google Cloud AI Platform или Microsoft Azure Machine Learning, для создания и развертывания моделей машинного обучения.\n",
      "4. Визуализация данных: Облачные технологии позволяют легко визуализировать данные с помощью инструментов, таких как Tableau, PowerBI или Google Data Studio. Вы можете использовать эти инструменты для создания интерактивных отчетов и дашбордов.\n",
      "5. Коллаборация: Облачные технологии позволяют легко сотрудничать с коллегами и клиентами, разделяя данные и результаты анализа. Вы можете использовать платформы, такие как Google Drive, Dropbox или Microsoft OneDrive, для хранения и обмена файлами.\n",
      "\n",
      "В целом, облачные технологии предоставляют много возможностей для улучшения процесса анализа данных, позволяя легко хранить, обрабатывать, анализировать и визуализировать большие объемы данных, а также легко сотрудничать с другими людьми.\n",
      "Reference Answer: Облачные технологии используются для хранения, обработки и анализа данных, предоставляя гибкость, масштабируемость и доступность ресурсов. Популярные облачные платформы включают Amazon Web Services (AWS), Microsoft Azure и Google Cloud Platform.\n",
      "Cosine Similarity: 0.9387578964233398\n",
      "BLEU Score: 2.764631735255783e-155\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25bb95a682d24a8eb599ee5294f6ea50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bfadb8e301a144a090a6fe1f1251a490",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question ID: 59\n",
      "Generated Answer: Data lake - это центральное хранилище для хранения больших объемов неструктурированных и полуструктурированных данных в их первоначальном формате. Он используется для хранения данных из различных источников, таких как социальные сети, устройства Интернета вещей (IoT) и другие. Data lake позволяет хранить данные в масштабах, недоступных для традиционных баз данных, и обеспечивает простой доступ к ним для анализа и обработки. Он является ключевым компонентом стратегии больших данных и помогает компаниям получить ценные информации и инсайты из своих данных.\n",
      "\n",
      "(Translation: A data lake is a centralized repository for storing large volumes of unstructured and semi-structured data in their raw format. It is used to store data from various sources, such as social networks, Internet of Things (IoT) devices, and others. Data lake allows for storing data at scale that is not available for traditional databases, and it provides easy access to them for analysis and processing. It is a key component of a big data strategy and helps companies gain valuable insights and information from their data.)\n",
      "\n",
      "Note: The provided knowledge base does not include information about data lakes, so the answer is a general explanation based on my knowledge as a large language model.\n",
      "Reference Answer: Data lake - это хранилище, которое позволяет хранить большие объемы необработанных данных в их исходном формате. Оно необходимо для интеграции и анализа различных типов данных, таких как структурированные, полуструктурированные и неструктурированные данные.\n",
      "Cosine Similarity: 0.9883497357368469\n",
      "BLEU Score: 0.0231465063621906\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5b560c36ce34e6aa0c315d9212e6006",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aaf7a18ff6dd4d8d8a7f2d24a3b88c93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question ID: 60\n",
      "Generated Answer: Мы рассмотрим различные типы NoSQL баз данных и их принцип работы в разделе 2 нашей книги. Там вы узнаете о различиях NoSQL и реляционных баз данных, а также об архитектурном сдвиге. Этот раздел служит отличной основой для подготовки к интервью по NoSQL.\n",
      "\n",
      "Далее, в разделе 3 мы сосредоточимся на MongoDB, одной из самых популярных NoSQL баз данных. Мы рассмотрим ее принцип работы, архитектуру, механизм шардинга и способы выполнения запросов.\n",
      "\n",
      "В разделе 4 мы рассмотрим Cassandra, широкостолбцовую NoSQL базу данных, которая часто используется в отчетных приложениях. Мы узнаем оpartitioning key и clustering key, механизме разделения данных и способах достижения различных уровней точности с помощью Cassandra.\n",
      "\n",
      "В разделе 5 мы рассмотрим Redis, NoSQL базу данных, которая часто используется в senior-позициях, связанных с кешированием. Мы узнаем о ее принципе работы, архитектуре и различных механизмах выполнения запросов. Также мы рассмотрим области применения Redis.\n",
      "\n",
      "В разделе 6 мы рассмотрим HBase, которая является важной компонентой в мире Big Data / Hadoop. Мы узнаем, как она интегрируется с Hadoop и как выполнять запросы к ней. Также мы рассмотрим различные вспомогательные инструменты, используемые администраторами для мониторинга HBase.\n",
      "\n",
      "В разделе 7 мы рассмотрим Elasticsearch, которую многие организации используют для выполнения различных задач, включая поиск и хранение журналов. Мы узнаем о ее экосистеме, включая Kibana и Logstash, а также о примерах использования, таких как хранение журналов.\n",
      "\n",
      "Наконец, в разделе 8 мы рассмотрим Neo4j, лидера на рынке графовых NoSQL баз данных. Мы узнаем о ее принципе работы, разработке узлов, ребер и отношений, а также о применении в реальных сценариях, таких как социальные сети.\n",
      "Reference Answer: Работа с NoSQL базами данных, такими как MongoDB, Cassandra и Redis, включает хранение и обработку больших объемов данных с гибкой схемой. Эти базы данных обеспечивают высокую производительность и масштабируемость для работы с разнообразными типами данных.\n",
      "Cosine Similarity: 0.8676031231880188\n",
      "BLEU Score: 9.284754366272044e-232\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c5dbc03c67f46789ca16e84b3240688",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52185d7861124ee88ef4ce292ae8a88f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question ID: 61\n",
      "Generated Answer: Графовые базы данных - это тип баз данных, который используется для хранения и обработки графов, где данные представлены в виде узлов (вершин) и связей (рёбер) между ними. Графовые базы данных хорошо подходят для моделирования сложных связей между объектами, таких как социальные сети, сети компьютеров, пути перелета авиакомпаний и т.д. Они также используются в рекомендательных системах, таких как системы рекомендации товаров в интернет-магазинах. Примеры графовых баз данных включают Neo4j, Amazon Neptune и OrientDB.\n",
      "Reference Answer: Графовые базы данных, такие как Neo4j и Amazon Neptune, используются для хранения и обработки данных, представленных в виде графов. Они применяются в задачах, где важны связи между объектами, таких как социальные сети, рекомендации и анализ связей.\n",
      "Cosine Similarity: 0.6976016163825989\n",
      "BLEU Score: 0.12358652669114038\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a26a47c24644697917db04c74781083",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60dd7b6ea2cf45db9c1e5bf2f2414e38",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question ID: 62\n",
      "Generated Answer: Извините, но в моей базе знаний отсутствуют сведения об алгоритме PageRank. PageRank - это алгоритм ранжирования веб-страниц, разработанный компанией Google. Он определяет относительную важность веб-страницы, основываясь на количестве и качестве ссылок на нее. Алгоритм использует матрицу переходов между веб-страницами, чтобы рассчитать вероятность того, что пользователь выберет определенную страницу в процессе навигации по веб-сайту. Затем эти вероятности используются для определения ранга страницы.\n",
      "\n",
      "Однако моя база знаний не содержит информации об алгоритме PageRank. Если вам нужна помощь с другими вопросами по машинному обучению или программированию, я буду рад вам помочь.\n",
      "Reference Answer: Алгоритм PageRank используется для оценки важности веб-страниц на основе их ссылочной структуры. Он работает путем итеративного обновления значений PageRank для каждой страницы на основе ссылок, полученных от других страниц.\n",
      "Cosine Similarity: 0.9283914566040039\n",
      "BLEU Score: 9.309480961664223e-232\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "096b6ccca75644568d2ea09d1ccdfc2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d8b69da5233469296282c528eb5ce8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question ID: 63\n",
      "Generated Answer: BigQuery is a fully managed, serverless data warehouse solution offered by Google Cloud Platform. It allows users to analyze and process large datasets in a scalable and cost-effective manner. BigQuery uses SQL-like syntax for querying data and integrates seamlessly with other Google Cloud services, such as Google Cloud Storage and Google Analytics. It is commonly used for business intelligence, machine learning, and data analytics tasks.\n",
      "\n",
      "В BigQuery есть возможность создавать таблицы, загружать данные из различных источников, выполнять запросы и анализировать данные в реальном времени. Кроме того, BigQuery поддерживает работу с большими объемами данных и позволяет масштабировать вычислительные ресурсы в зависимости от потребностей.\n",
      "\n",
      "BigQuery также имеет возможность интеграции с другими инструментами и платформами, такими как Apache Beam, Apache Spark и Google Data Studio, что позволяет пользователям легко визуализировать и анализировать данные.\n",
      "\n",
      "В целом, BigQuery является мощным инструментом для хранения и анализа больших данных, который может помочь компаниям получать ценные бизнес-инсайты и принимать более информированные решения.\n",
      "Reference Answer: BigQuery - это облачный сервис для анализа больших данных, предоставляемый Google. Он используется для быстрого выполнения запросов на больших объемах данных и интеграции с другими инструментами для обработки и визуализации данных.\n",
      "Cosine Similarity: 0.3283372223377228\n",
      "BLEU Score: 0.025139420715063067\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56ee351239d14e23b3a86d217947ec9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "033290ba38204bf6af6abb5111aec671",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question ID: 64\n",
      "Generated Answer: Я сожалею, но я не могу ответить на эту вопрос, так как в моей базе знаний нет информации об использовании инструментов BI (бизнес-аналитики) для подготовки к собеседованию на позицию машинного инженера. Моя база знаний состоит из материалов, связанных с машинным обучением и глубоким обучением, включая книгу Шломо Кашани \"ДеEP ЛeaрниNG Интepвьюс\" и информацию о Дейвинге Философов. Я могу помочь вам с вопросами, связанными с этими темами.\n",
      "Reference Answer: Инструменты BI (бизнес-аналитики), такие как Tableau, Power BI и QlikView, используются для визуализации данных, создания отчетов и проведения анализа. Они помогают преобразовывать данные в понятные и полезные инсайты для бизнеса.\n",
      "Cosine Similarity: 0.8355429768562317\n",
      "BLEU Score: 1.0003688322288243e-231\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4cef5d60b3cd4ca9a128b842697affff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02e556f9beb44695a529e502808adbc5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question ID: 65\n",
      "Generated Answer: Для предсказания оттока клиентов можно использовать различные методы машинного обучения, такие как реgressión, классификация и анализ временных рядов. Одним из популярных методов является использование алгоритма случайного леса или gradient boosting, которые могут помочь улучшить точность предсказаний. Кроме того, можно применять методы детектирования аномалий, чтобы выявить нетипичные модели поведения клиентов, которые могут указывать на их возможный отток.\n",
      "\n",
      "В дополнение к этому, можно использовать различные техники предобработки данных, такие как очистка данных, нормализация и feature engineering, чтобы улучшить качество данных и повысить точность моделей.\n",
      "\n",
      "Также важно учитывать контекст и специфику бизнеса, чтобы выбрать наиболее подходящий метод и улучшить точность предсказаний. Например, в банковской сфере можно использовать исторические данные о транзакциях клиентов, чтобы выявить факторы, влияющие на их лояльность или отток.\n",
      "\n",
      "В целом, для предсказания оттока клиентов необходимо сочетать различные методы машинного обучения и техники предобработки данных, а также учитывать контекст и специфику бизнеса.\n",
      "Reference Answer: Методы предсказания оттока клиентов включают анализ поведения клиентов, создание прогнозных моделей с использованием машинного обучения и использование метрик, таких как коэффициент оттока (churn rate) и жизненная ценность клиента (CLV).\n",
      "Cosine Similarity: 0.9690607786178589\n",
      "BLEU Score: 1.0132846385712819e-78\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "215f3d9806fd4000b4004459f590ca89",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8c9996471d441b086b65c118833f01c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question ID: 66\n",
      "Generated Answer: Модель Маркова - это стохастическая модель, которая описывает процесс, в котором будущее состояние системы зависит только от ее текущего состояния и не зависит от ее предыдущих состояний. Эта модель широко используется в области искусственного интеллекта, машинного обучения и теории информации. Она находит применение в разных областях, например, в распознавании речи, обработке естественного языка, биоинформатике, финансах и многих других.\n",
      "Reference Answer: Модель Маркова - это статистическая модель, описывающая вероятностные переходы между состояниями в системе. Она используется в задачах, таких как предсказание последовательностей, анализ временных рядов и моделирование систем с дискретными состояниями.\n",
      "Cosine Similarity: 0.9706486463546753\n",
      "BLEU Score: 0.05294306808178317\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "008e2f57056747599057c15a2f181527",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ccb110cd39d3478bbbc5ec98b05ce6e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question ID: 67\n",
      "Generated Answer: В обработке аномалий в данных существует несколько подходов. Вот несколько распространенных методов:\n",
      "\n",
      "1. Статистические методы: можно использовать статистические показатели, такие как среднее, медиана и мода, чтобы определить аномалии. Например, значения, которые находятся на 3 стандартных отклонениях от среднего, могут быть классифицированы как аномалии.\n",
      "2. Машинное обучение: можно использовать алгоритмы машинного обучения, такие как к-средних, аномальное поведение может быть определено как точка, которая находится на значительном расстоянии от центроида ближайшей кластерной группы.\n",
      "3. Деревья решений: можно использовать алгоритмы построения деревьев решений, такие как CART или Random Forest, чтобы определить аномальные значения.\n",
      "4. Векторное представление: можно использовать методы векторного представления, такие как Word2Vec или Doc2Vec, чтобы преобразовать текстовые данные в векторное пространство, где аномальные значения могут быть определены с помощью различных методов кластеризации или классификации.\n",
      "\n",
      "Выбор метода зависит от типа данных и контекста задачи. В некоторых случаях может потребоваться комбинировать несколько методов, чтобы достичь лучших результатов.\n",
      "\n",
      "Кроме того, важно провести предварительную обработку данных, чтобы удалить или заменить пропуски, выровнять данные и удалить выбросы, которые могут влиять на результаты обработки аномалий.\n",
      "Reference Answer: Для обработки аномалий в данных используются методы, такие как контрольные карты, методы кластеризации, алгоритмы машинного обучения и статистические тесты. Эти методы позволяют выявлять и анализировать необычные и непредсказуемые данные.\n",
      "Cosine Similarity: 0.9455534219741821\n",
      "BLEU Score: 7.059980207738934e-79\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f42e639132844917a1d9e536a0e44e8f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d3392d5c2bf4cccb71079c53140ba50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question ID: 68\n",
      "Generated Answer: DBSCAN (Density-Based Spatial Clustering of Applications with Noise) - это алгоритм кластеризации, используемый в машинном обучении для группировки объектов, которые близки друг к другу в некотором пространстве. Алгоритм работает следующим образом:\n",
      "\n",
      "1. Выбирается случайная точка из данных.\n",
      "2. Для этой точки вычисляется число ближайших соседей, которые находятся в пределах заданного радиуса (параметр ε, epsilon).\n",
      "3. Если число соседей больше или равно минимальному количеству точек, необходимых для формирования кластера (параметр minPts), то эта точка и все её ближайшие соседи образуют ядро кластера.\n",
      "4. Затем для каждого из соседей точки из ядра кластера вычисляется число ближайших соседей. Если оно больше или равно minPts, то эти точки также добавляются к кластеру.\n",
      "5. Шаги 4 и 5 повторяются, пока не будут обработаны все точки, которые могут быть добавлены к кластеру.\n",
      "6. Выбирается следующая случайная точка из данных, которая ещё не была отнесена к какому-либо кластеру, и алгоритм повторяется с шага 2.\n",
      "7. Алгоритм завершается, когда все точки данных будут обработаны. Точки, которые не были отнесены ни к одному кластеру, считаются шумом и выбрасываются.\n",
      "\n",
      "DBSCAN обладает следующими преимуществами:\n",
      "\n",
      "* Может обнаруживать кластеры любой формы.\n",
      "* Не требует предварительного определения количества кластеров.\n",
      "* Имеет хорошую устойчивость к шуму и выбросам данных.\n",
      "\n",
      "Но у алгоритма есть и недостатки:\n",
      "\n",
      "* Зависит от правильного выбора параметров ε и minPts.\n",
      "* Эффективность снижается на больших наборах данных.\n",
      "* Не подходит для кластеризации данных с высокой размерностью.\n",
      "\n",
      "DBSCAN часто используется в задачах кластеризации времени серий, картографических данных, изображений и биологических данных.\n",
      "Reference Answer: Алгоритм DBSCAN (Density-Based Spatial Clustering of Applications with Noise) - это алгоритм кластеризации, который группирует объекты на основе плотности их распределения в пространстве. Он определяет кластеры как плотные области объектов, разделенные областями с низкой плотностью. DBSCAN не требует заранее задавать количество кластеров и может эффективно выявлять кластеры любой формы.\n",
      "Cosine Similarity: 0.9771288633346558\n",
      "BLEU Score: 0.05615598216870319\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad97d02ad5e14ead829409aeb6307d7b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab09fc35488a494e8c97f6844ed4cc2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question ID: 69\n",
      "Generated Answer: Метод k-средних (k-means) — это алгоритм кластеризации, который используется для разделения данных на k групп (кластеров) таким образом, чтобы данные внутри каждой группы были как можно более похожи, а различия между группами были максимальными. Алгоритм k-средних начинает с случайного выбора k точек, называемых центроидами, которые представляют начальные оценки центров кластеров. Затем он итеративно пересчитывает центроиды, перемещая их в центры масс своих соответствующих кластеров, и перераспределяет объекты данных между кластерами, чтобы каждый объект был отнесен к кластеру с ближайшим центроидом. Алгоритм завершается, когда центроиды перестают меняться или достигнуто максимальное количество итераций. Метод k-средних широко используется в машинном обучении, обработке изображений, биоинформатике и других областях.\n",
      "Reference Answer: Метод k-средних - это алгоритм кластеризации, который разделяет данные на k кластеров, минимизируя сумму квадратов расстояний между объектами и центроидами кластеров. Центроиды и кластеры обновляются итеративно до сходимости алгоритма. Метод используется для анализа данных и сегментации.\n",
      "Cosine Similarity: 0.8780832290649414\n",
      "BLEU Score: 0.03828635476051091\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "707480cd7e1b467a8fe79d9834a6744a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1286970027de4bcf9c3f9c36f5cc9210",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question ID: 70\n",
      "Generated Answer: Байесовская классификация - это метод машинного обучения, основанный на теореме Байеса и предположениях о распределениях вероятностей. Он используется для определения наиболее вероятного класса или категории для данной наблюдаемой переменной, исходя из ее характеристик и статистических данных о распределении вероятностей. Байесовская классификация широко используется в различных областях, таких как распознавание образов, обработка естественного языка и анализ данных. Она эффективна в условиях неполной или неточной информации, так как позволяет учитывать неопределенность и вероятности различных исходов.\n",
      "Reference Answer: Байесовская классификация - это метод классификации, основанный на теореме Байеса, которая описывает вероятностные отношения между признаками и классами. Модели байесовской классификации, такие как наивный байесовский классификатор, используются для задач классификации текста, спама и анализа тональности.\n",
      "Cosine Similarity: 0.9854422807693481\n",
      "BLEU Score: 0.06852557438947454\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46b33ffd8d764fab90d5df7f4dd9b564",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "557cb616d8e1457a8a35e8591379d921",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question ID: 71\n",
      "Generated Answer: Для проведения экспериментов с A/B тестированием необходимо выполнить следующие шаги:\n",
      "\n",
      "1. Определите цель эксперимента: Это может быть увеличение конверсии, повышение level of engagement или любая другая метрика, важная для вашего бизнеса.\n",
      "2. Разработайте гипотезу: Это предположение о том, что определенное изменение в вашем продукте или услуге повысит эффективность вашей цели.\n",
      "3. Разделите свою аудиторию на две группы: Контрольную группу (A) и экспериментальную группу (B). Контрольная группа не должна быть подвержена изменениям, а экспериментальная группа должна быть подвержена изменениям, которые вы хотите протестировать.\n",
      "4. Implement changes for the experimental group: Это могут быть изменения в дизайне, копирайтинге, функциональности и т.д.\n",
      "5. Собирайте и анализируйте данные: Следите за метрикой вашей цели и собирайте данные для каждой группы.\n",
      "6. Оцените статистическую значимость результатов: Это поможет вам определить, были ли различия между группами статистически значимыми или произошли они случайно.\n",
      "7. Действуйте в соответствии с результатами: Если результаты показывают статистически значимые улучшения для экспериментальной группы, следует внедрить изменения на постоянной основе. Если результаты не показывают статистически значимых улучшений, следует продолжить тестирование других гипотез.\n",
      "\n",
      "В целом, A/B тестирование позволяет вам сделать более информированные решения о том, что работает лучше для вашего бизнеса, основываясь на данных, а не на предположениях.\n",
      "Reference Answer: Эксперименты с A/B тестированием включают разделение пользователей на две группы, A и B, где группа A получает текущую версию продукта, а группа B - измененную версию. Результаты эксперимента сравниваются для оценки влияния изменений на ключевые метрики, такие как конверсия или удержание пользователей.\n",
      "Cosine Similarity: 0.9458228349685669\n",
      "BLEU Score: 5.917377599820946e-79\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a56536d7afad4c0fa4cc28192f0be2f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba46c770fdf44732a02deebf6ec88e47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question ID: 72\n",
      "Generated Answer: Конечно! Вот ответ на ваш вопрос на русском языке:\n",
      "\n",
      "Гипотезы в машинном обучении - это предположения о распределении данных или модели, которые мы хотим проверить. Существует два основных типа гипотез: нулевая гипотеза (H0) и альтернативная гипотеза (H1). Нулевая гипотеза обычно предполагает, что нет какой-либо зависимости или различия между двумя группами, а альтернативная гипотеза утверждает, что есть зависимость или различие.\n",
      "\n",
      "Проверка гипотез включает в себя несколько шагов. Во-первых, мы выбираем уровень значимости (например, 0,05), который определяет вероятность того, что мы отклоним нулевую гипотезу, когда она на самом деле правдива. Затем мы вычисляем статистическую величину, такую как t-статистика или F-статистика, которая позволяет нам оценить, насколько вероятно получение наших результатов при верной нулевой гипотезе. Наконец, мы сравниваем полученную статистическую величину с критическим значением, которое соответствует выбранному уровню значимости, и принимаем решение о том, следует ли отклонить нулевую гипотезу. Если статистическая величина превышает критическое значение, мы отклоняем нулевую гипотезу и принимаем альтернативную гипотезу. Если статистическая величина меньше или равна критическому значению, мы не отклоняем нулевую гипотезу.\n",
      "Reference Answer: Гипотезы - это предположения, которые проверяются в процессе исследования. Проверка гипотез включает формулирование нулевой и альтернативной гипотез, сбор данных и применение статистических тестов для оценки значимости результатов и принятия решения о принятии или отклонении гипотезы.\n",
      "Cosine Similarity: 0.9102621078491211\n",
      "BLEU Score: 7.221267509159756e-79\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3f3acf9a96b4fcba5c4e96b79a637ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60b4abb4484540638e4049caf25af784",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question ID: 73\n",
      "Generated Answer: В моей работе я использую различные статистические тесты, такие как t-тест, хи-квадратное распределение, ANOVA и другие, чтобы проверить гипотезы и получить надежные результаты.\n",
      "\n",
      "Translation:\n",
      "In my work, I use various statistical tests, such as the t-test, chi-square distribution, ANOVA, and others, to check hypotheses and obtain reliable results.\n",
      "Reference Answer: В своей работе я использую различные статистические тесты, такие как t-тест, ANOVA, хи-квадрат тест и тесты на нормальность распределения. Эти тесты помогают оценить значимость различий между группами, зависимости и распределения данных.\n",
      "Cosine Similarity: 0.964962363243103\n",
      "BLEU Score: 0.1748812694918866\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a32b107c83794873bdaa0f4095be637d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6fc96f730ce04400a80384e3b4eeef4e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question ID: 74\n",
      "Generated Answer: P-значение (p-value) - это вероятность того, что результаты исследования могут быть получены случайно, если гипотеза нулевой модели верна. Обычно принимается порог значимости α (например, 0,05), и если p-значение меньше α, то гипотеза нулевой модели отвергается. Если p-значение больше α, то гипотеза нулевой модели не отвергается. Важно понимать, что p-значение не говорит о том, насколько правдоподобна альтернативная гипотеза, а только о том, насколько правдоподобна гипотеза нулевой модели.\n",
      "\n",
      "Translation:\n",
      "\n",
      "P-value (p-value) is the probability that the results of the study can be obtained by chance if the null model hypothesis is true. Usually, a significance threshold α is taken (for example, 0.05), and if the p-value is less than α, the null model hypothesis is rejected. If the p-value is greater than α, the null model hypothesis is not rejected. It is important to understand that the p-value does not say how plausible the alternative hypothesis is, but only how plausible the null model hypothesis is.\n",
      "Reference Answer: p-значение - это вероятность получения результатов, равных или более экстремальных, чем наблюдаемые, при условии, что нулевая гипотеза верна. Низкое p-значение указывает на значимые различия, что позволяет отвергнуть нулевую гипотезу.\n",
      "Cosine Similarity: 0.8337840437889099\n",
      "BLEU Score: 5.78282832030522e-79\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9cb38e337e840eba3b5a2c42fe20f89",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b25f40e9b5854e7589983c5549d2e48d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question ID: 75\n",
      "Generated Answer: Building confidence intervals involves finding a range of values that is likely to contain the true population parameter with a certain level of confidence. The steps to build a confidence interval are as follows:\n",
      "\n",
      "1. Choose the confidence level: This is usually expressed as a percentage, such as 95% or 99%.\n",
      "2. Find the critical value: This is the value from the t-distribution or standard normal distribution that corresponds to the chosen confidence level and the sample size.\n",
      "3. Calculate the standard error: This is the standard deviation of the sampling distribution of the sample mean.\n",
      "4. Calculate the margin of error: This is the product of the critical value and the standard error.\n",
      "5. Find the confidence interval: This is the range of values that is likely to contain the true population parameter. It is calculated as the sample mean plus or minus the margin of error.\n",
      "\n",
      "In formula form, the confidence interval can be expressed as:\n",
      "\n",
      "CI = X̄ ± Z\\*(σ/√n)\n",
      "\n",
      "where X̄ is the sample mean, Z is the critical value, σ is the population standard deviation (if known) or the sample standard deviation (if σ is unknown), and n is the sample size.\n",
      "\n",
      "Note that the above steps assume that the sample is drawn from a normally distributed population or that the sample size is large enough to use the central limit theorem. If these assumptions are not met, then alternative methods may be needed to build a confidence interval.\n",
      "Reference Answer: Для построения доверительных интервалов я использую статистические методы, такие как бутстрепинг и стандартная ошибка выборки. Доверительный интервал показывает диапазон значений, в котором с заданной вероятностью находится истинное значение параметра.\n",
      "Cosine Similarity: -0.033881206065416336\n",
      "BLEU Score: 0\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "895869ad2cc54423a6ef46711f962bac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6bfaa095f1a47cbb70b42072a5944b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question ID: 76\n",
      "Generated Answer: Я использую различные методы визуализации данных, такие как диаграммы рассеяния, гистограммы, графики линий, столбчатые диаграммы, дерева решений и т.д. Зависит от того, что вы хотите показать и какие данные у вас есть.\n",
      "\n",
      "(Translation: I use various data visualization methods, such as scatter plots, histograms, line charts, bar charts, decision trees, etc. It depends on what you want to show and what data you have.)\n",
      "Reference Answer: Для визуализации данных я использую методы, такие как гистограммы, диаграммы рассеяния, тепловые карты, boxplot и линейные графики. Эти методы помогают визуально представлять распределения данных, взаимосвязи и тренды.\n",
      "Cosine Similarity: 0.9706457853317261\n",
      "BLEU Score: 4.0541307874617305e-155\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a68b39c1fd2340bd8e46d65ba5275b90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "249846a243564ea188998dde3b0606fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question ID: 77\n",
      "Generated Answer: Гистограмма - это графическое представление распределения данных, которое используется для визуализации частот набора значений. Она строится как столбчатый график, где высота каждого столбца соответствует количеству элементов в наборе данных, которые попадают в определенный диапазон (интервал) значений. Гистограммы часто используются в машинном обучении для изучения распределения характеристик объектов в данных, что помогает выявить особенности, закономерности и аномалии в данных. Это может быть полезно для предобработки данных, подбора алгоритмов машинного обучения и оценки их качества.\n",
      "Reference Answer: Гистограмма - это график, представляющий распределение данных. Она используется для визуализации частоты значений в наборе данных и позволяет выявлять тенденции, аномалии и распределения.\n",
      "Cosine Similarity: 0.9830702543258667\n",
      "BLEU Score: 1.6997681625988895e-78\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e14b948ea57a4177bcbed81f50e1eea1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3dbf6c136e94ae69d2e87909f661a36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question ID: 78\n",
      "Generated Answer: Пожалуйста, переформулируйте вопрос, так как я не нахожу в базе знаний информацию о диаграммах рассеяния. Если ваш вопрос связан с машинным обучением или подготовкой к собеседованию на позицию инженера по машинному обучению, я буду рад помочь.\n",
      "\n",
      "However, since you asked about interpreting scatter plots, I will provide a general answer in Russian:\n",
      "\n",
      "Диаграмма рассеяния (scatter plot) используется для визуализации взаимосвязи между двумя переменными. На оси X часто отображается независимая переменная, а на оси Y - зависимая переменная. Каждая точка на диаграмме представляет собой пару значений (x, y) для наблюдения. Вы можете интерпретировать диаграмму рассеяния, определяя тип зависимости (линейная, квадратичная, экспоненциальная и т.д.), а также обнаруживая любые выбросы или закономерности в данных.\n",
      "Reference Answer: Диаграмма рассеяния отображает взаимосвязь между двумя переменными. По её точкам можно определить корреляцию, выявить тренды и аномалии, а также понять характер связи между переменными.\n",
      "Cosine Similarity: 0.9739910364151001\n",
      "BLEU Score: 8.55240112478065e-79\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5912640b215b487fb25c7da40f596f39",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5d308a3db7146ee83b3e5bb23e74fa4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question ID: 79\n",
      "Generated Answer: Корреляционный анализ - это метод статистического исследования, который используется для определения степени связи между двумя или более переменными. Он позволяет оценить, влияет ли изменение одной переменной на изменение другой переменной и в какой степени. Корреляционный анализ не предполагает причинно-следственной связи между переменными, он только показывает, существует ли связь между ними.\n",
      "\n",
      "Translation:\n",
      "Correlation analysis is a statistical research method used to determine the degree of association between two or more variables. It allows you to evaluate whether the change of one variable affects the change of another variable and to what extent. Correlation analysis does not imply a causal relationship between variables, it only shows whether there is a relationship between them.\n",
      "Reference Answer: Корреляционный анализ оценивает степень взаимосвязи между переменными. Коэффициент корреляции показывает, насколько сильно и в каком направлении связаны переменные, помогая выявлять зависимые и независимые факторы.\n",
      "Cosine Similarity: 0.9789295792579651\n",
      "BLEU Score: 2.744892298225602e-155\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "730083fbb2b84545a8af09030d938939",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5cacc5e74e924ae7bc47b9854c5f6959",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question ID: 80\n",
      "Generated Answer: Издатель \"BPB Publications\" не предоставляет информацию на русском языке о строительстве тепловых карт и их значении. Тем не менее, я могу предоставить общий ответ на этот вопрос.\n",
      "\n",
      "Тепловая карта - это графическое представление данных, на котором используются различные оттенки цвета, чтобы показать интенсивность или концентрацию какого-либо явления. В контексте машинного обучения, тепловые карты часто используются для визуализации важности весов нейронной сети или значений пикселей изображения для определенного класса.\n",
      "\n",
      "Создание тепловых карт может включать в себя различные шаги, такие как нормализация данных, выбор палитры цветов и настройка масштаба цветов. Существует несколько библиотек Python, которые можно использовать для создания тепловых карт, включая Seaborn, Matplotlib и Plotly.\n",
      "\n",
      "Например, для создания тепловой карты весов нейронной сети, можно использовать следующий код:\n",
      "```python\n",
      "import seaborn as sns\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "# Загрузка весов нейронной сети\n",
      "weights = ...\n",
      "\n",
      "# Нормализация весов\n",
      "weights_norm = (weights - weights.min()) / (weights.max() - weights.min())\n",
      "\n",
      "# Создание тепловой карты\n",
      "sns.heatmap(weights_norm, cmap='viridis')\n",
      "plt.show()\n",
      "```\n",
      "В этом примере используется библиотека Seaborn для создания тепловой карты весов нейронной сети. Веса нормализуются, чтобы уменьшить динамический диапазон значений, а затем создается тепловая карта с использованием палитры цветов 'viridis'.\n",
      "\n",
      "Тепловые карты могут быть полезны для понимания того, как модель машинного обучения делает свои выводы, и для обнаружения потенциальных проблем, таких как переобучение или сбой градиента.\n",
      "Reference Answer: Тепловые карты представляют данные в виде цветовых шкал, показывая интенсивность значений. Они используются для визуализации корреляций, матриц данных и распределений, помогая выявлять взаимосвязи и аномалии.\n",
      "Cosine Similarity: 0.7949693202972412\n",
      "BLEU Score: 5.0831398366108044e-79\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00939656c902401880628b7869e0cd61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f9bf72eabcc413e955932b01d727086",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question ID: 81\n",
      "Generated Answer: Боксплот (англ. box plot или box-and-whisker plot) — это вид статистической диаграммы, который позволяет отобразить распределение данных, а также данные выбросов и аутлаеров. Он состоит из нескольких элементов:\n",
      "\n",
      "1. Верхняя и нижняя границы бокса представляют первый и третий квартили (25-я и 75-я percentile) данных соответственно.\n",
      "2. Линия внутри бокса называется медианой и определяется как второй квартиль (50-я percentile) данных, то есть middle value.\n",
      "3. Линии, выходящие из бокса, называются усами (whiskers). Они показывают диапазон данных, за исключением возможных выбросов и аутлаеров. Обычно длина усов равна 1,5 интерквартильного размаха (IQR), где IQR - разница между третьим и первым квартилями.\n",
      "4. Отдельные точки за пределами усов называются выбросами (outliers). Они представляют собой значения, которые находятся далеко от остальных данных.\n",
      "\n",
      "Интерпретация боксплота позволяет быстро получить представление о распределении данных и выявить возможные аномалии. Например, при сильном асимметричном распределении боксплот будет иметь удлиненные \"усы\" в сторону выбросов, а значительное количество выбросов может указывать на проблемы с данными.\n",
      "Reference Answer: Boxplot (коробчатая диаграмма) - это график, который визуализирует распределение данных через их квартили. Он показывает медиану, интерквартильный размах, выбросы и симметричность распределения, помогая анализировать и сравнивать наборы данных.\n",
      "Cosine Similarity: 0.8379611372947693\n",
      "BLEU Score: 8.972141065609098e-232\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ede3b087e4a341f0bc7f244adf7cd465",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df2e5e8948b1495f99c06ac4b7f3b0cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question ID: 82\n",
      "Generated Answer: Matplotlib - это популярная библиотека Python для создания графиков и диаграмм. Вы можете использовать её для визуализации данных, создания диаграмм, гистограмм, скатов, 3D-графиков и многого другого.\n",
      "\n",
      "Чтобы построить график с помощью Matplotlib, вам нужно выполнить следующие шаги:\n",
      "\n",
      "1. Импортируйте библиотеку Matplotlib:\n",
      "```\n",
      "import matplotlib.pyplot as plt\n",
      "```\n",
      "2. Создайте список или массив данных для оси X и Y. Например, чтобы создать график функции y = x^2, вы можете использовать NumPy для создания массивов:\n",
      "```\n",
      "import numpy as np\n",
      "x = np.linspace(0, 10, 100)\n",
      "y = x**2\n",
      "```\n",
      "3. Нарисуйте график, используя функцию `plt.plot()`:\n",
      "```\n",
      "plt.plot(x, y)\n",
      "```\n",
      "4. Добавьте заголовок и метки осей, используя функции `plt.title()` и `plt.xlabel()` / `plt.ylabel()`:\n",
      "```\n",
      "plt.title('График функции y = x^2')\n",
      "plt.xlabel('X')\n",
      "plt.ylabel('Y')\n",
      "```\n",
      "5. Отобразите график, используя функцию `plt.show()`:\n",
      "```\n",
      "plt.show()\n",
      "```\n",
      "\n",
      "Вот полный пример кода:\n",
      "```\n",
      "import matplotlib.pyplot as plt\n",
      "import numpy as np\n",
      "\n",
      "x = np.linspace(0, 10, 100)\n",
      "y = x**2\n",
      "\n",
      "plt.plot(x, y)\n",
      "plt.title('График функции y = x^2')\n",
      "plt.xlabel('X')\n",
      "plt.ylabel('Y')\n",
      "plt.show()\n",
      "```\n",
      "Этот код создаст график функции y = x^2 и отобразит его в новом окне.\n",
      "\n",
      "Обратите внимание, что в этом примере мы использовали NumPy для создания массивов данных. Matplotlib работает хорошо с NumPy, и многие из его функций предназначены для работы с массивами NumPy.\n",
      "\n",
      "Также есть другие способы визуализации данных в Matplotlib, например, с помощью гистограмм, диаграмм разброса и т.д. Вы можете изучить документацию Matplotlib, чтобы узнать больше о других возможностях визуализации данных.\n",
      "\n",
      "Источник:\n",
      "\n",
      "* [Matplotlib documentation](https://matplotlib.org/stable/contents.html)\n",
      "* [NumPy documentation](https://numpy.org/doc/stable/)\n",
      "\n",
      "(Пожалуйста, обратите внимание, что я - система искусственного интеллекта и могу ошибаться. Этот ответ основан на моей текущей базе знаний, но для получения наиболее точной и актуальной информации рекомендуется проверить официальную документацию Matplotlib.)\n",
      "Reference Answer: Для построения графиков с помощью matplotlib я использую функции этой библиотеки для создания гистограмм, линейных графиков, диаграмм рассеяния и других видов визуализаций. Matplotlib позволяет настроить внешний вид графиков и добавить аннотации.\n",
      "Cosine Similarity: 0.7528203725814819\n",
      "BLEU Score: 2.2623188739701583e-155\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aeab0a45094145939376f510cba4b1b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8faca5fa49b4150828444e64c6d87a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question ID: 83\n",
      "Generated Answer: Seaborn - это библиотека Python для визуализации данных, основанная на Matplotlib. Она предоставляет высокоуровневый интерфейс для создания интерактивных и информированных графиков. Преимущества Seaborn включают:\n",
      "\n",
      "1. Простота использования: Seaborn имеет интуитивно понятный API, который упрощает создание complex и профессионально выглядящих графиков.\n",
      "2. Встроенные темы: Seaborn предоставляет несколько встроенных тем, которые можно использовать для улучшения внешнего вида графиков.\n",
      "3. Поддержка статистических графиков: Seaborn включает в себя множество статистических графиков, таких как гистограммы, box plots, heatmaps, и так далее.\n",
      "4. Интеграция с Pandas: Seaborn хорошо работает с Pandas DataFrames, что упрощает визуализацию данных.\n",
      "5. Нативная поддержка графиков с несколькими переменными: Seaborn предоставляет встроенные средства для создания графиков с несколькими переменными, таких как pairplot и jointplot.\n",
      "\n",
      "Overall, Seaborn is a powerful and easy-to-use library for creating informative and attractive visualizations of data in Python.\n",
      "Reference Answer: Seaborn - это библиотека для визуализации данных, построенная на основе matplotlib. Она предоставляет высокоуровневый интерфейс для создания привлекательных и информативных графиков, таких как тепловые карты, boxplot и pairplot, с меньшим количеством кода.\n",
      "Cosine Similarity: 0.853624701499939\n",
      "BLEU Score: 0.07285403611672249\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "951172b4fd4346039ccb7991a6863d9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f57084f76a684869b3caf3cf2855bf64",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question ID: 84\n",
      "Generated Answer: Извините, но в вашем вопросе не упоминается библиотека Plotly, и я не нахожу информации о ней в моей базе знаний. Однако, я могу попытаться найти информацию об этой библиотеке на других ресурсах и предоставить вам краткий обзор на русском языке.\n",
      "\n",
      "Plotly - это популярная библиотека визуализации данных для Python, которая позволяет создавать интерактивные графики и диаграммы. Эта библиотека широко используется для анализа данных, машинного обучения, статистики и прочих приложений.\n",
      "\n",
      "Одной из основных особенностей Plotly является возможность создавать интерактивные графики, которые можно манипулировать и изменять прямо в браузере. Это позволяет легко исследовать данные и обнаруживать закономерности.\n",
      "\n",
      "Библиотека Plotly поддерживает различные типы графиков, включая линейные диаграммы, столбчатые диаграммы, гистограммы, сетчатые диаграммы, диаграммы рассеяния, трехмерные графики и многое другое. Кроме того, Plotly позволяет создавать удивительные анимации и превращать графики в GIF-файлы.\n",
      "\n",
      "Для работы с библиотекой Plotly необходимо установить ее с помощью pip:\n",
      "```\n",
      "pip install plotly\n",
      "```\n",
      "Затем можно импортировать необходимые компоненты и создавать графики:\n",
      "```python\n",
      "import plotly.express as px\n",
      "\n",
      "# Создаем данные\n",
      "df = px.data.iris()\n",
      "\n",
      "# Создаем график\n",
      "fig = px.scatter(df, x=\"sepal_width\", y=\"sepal_length\", color=\"species\")\n",
      "\n",
      "# Отображаем график\n",
      "fig.show()\n",
      "```\n",
      "В этом примере мы импортируем модуль plotly.express, создаем данные с помощью встроенного набора данных \"iris\", создаем рассеяние точек и отображаем его с помощью метода show().\n",
      "\n",
      "Таким образом, библиотека Plotly является мощным инструментом для визуализации данных, который позволяет создавать интерактивные и эффектные графики с минимальными усилиями.\n",
      "Reference Answer: Библиотека Plotly используется для создания интерактивных графиков и визуализаций. Она позволяет создавать динамичные и настраиваемые визуализации, такие как линейные графики, гистограммы и тепловые карты, которые можно взаимодействовать и анализировать в режиме реального времени.\n",
      "Cosine Similarity: 0.9301857948303223\n",
      "BLEU Score: 2.78948298228769e-155\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0935c4254de5492ebdeea16002085849",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d97ad0907e94981aa34b7d8aebcc9b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question ID: 85\n",
      "Generated Answer: Pandas - это библиотека Python для анализа данных. Она предоставляет инструменты для управления данными и conducting analytics. Она широко используется в области машинного обучения и анализа больших данных. Pandas позволяет легко читать, манипулировать и записывать данные в различных форматах, включая CSV, Excel, SQL и многие другие. Она также предоставляет функции для очистки данных, их визуализации и преобразования. Pandas используется для создания датафреймов, которые представляют собой таблицы с индексированными строками и столбцами. Эти датафреймы можно использовать для выполнения различных операций, таких как сортировка, фильтрация, группировка и т.д. Кроме того, Pandas предоставляет функции для выполнения статистических вычислений и создания графиков.\n",
      "Reference Answer: Pandas - это библиотека для обработки и анализа данных в Python. Она предоставляет структуры данных, такие как DataFrame и Series, и функции для чтения, фильтрации, агрегирования и манипуляции данными, что делает её незаменимой для анализа данных.\n",
      "Cosine Similarity: 0.9441595077514648\n",
      "BLEU Score: 0.04850786355215963\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79127622ffbd41a28c15b027fb2d81b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5be445fb1be401f9936bdc6ff1c7b60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question ID: 86\n",
      "Generated Answer: В NumPy массивы данных представляются в виде объектов многомерных массивов ndarray. Вы можете создавать массивы с помощью функции np.array(), например:\n",
      "\n",
      "```\n",
      "import numpy as np\n",
      "arr = np.array([1, 2, 3, 4, 5])\n",
      "```\n",
      "\n",
      "Вы также можете создать многомерные массивы, указав список списков или список кортежей как аргумент функции np.array(). Например:\n",
      "\n",
      "```\n",
      "import numpy as np\n",
      "arr_2d = np.array([[1, 2, 3], [4, 5, 6]])\n",
      "```\n",
      "\n",
      "В NumPy есть много функций для работы с массивами данных, например:\n",
      "\n",
      "* np.sum() - возвращает сумму элементов массива;\n",
      "* np.mean() - возвращает среднее значение элементов массива;\n",
      "* np.max() - возвращает максимальное значение элементов массива;\n",
      "* np.min() - возвращает минимальное значение элементов массива;\n",
      "* np.argmax() - возвращает индекс максимального элемента массива;\n",
      "* np.argmin() - возвращает индекс минимального элемента массива.\n",
      "\n",
      "Вы также можете выполнять операции над массивами, например:\n",
      "\n",
      "* Сложение: arr1 + arr2;\n",
      "* Вычитание: arr1 - arr2;\n",
      "* Умножение: arr1 \\* arr2;\n",
      "* Деление: arr1 / arr2;\n",
      "* Возведение в степень: arr1 ** 2.\n",
      "\n",
      "В NumPy также есть функции для создания специализированных массивов, например:\n",
      "\n",
      "* np.zeros() - создает массив заполненный нулями;\n",
      "* np.ones() - создает массив заполненный единицами;\n",
      "* np.eye() - создает единичную матрицу;\n",
      "* np.arange() - создает массив с последовательностью чисел.\n",
      "\n",
      "Например:\n",
      "\n",
      "```\n",
      "import numpy as np\n",
      "arr_zeros = np.zeros((3, 3))\n",
      "arr_ones = np.ones((3, 3))\n",
      "arr_eye = np.eye(3)\n",
      "arr_arange = np.arange(10)\n",
      "```\n",
      "\n",
      "Вы также можете изменять форму массива с помощью функции np.reshape(). Например:\n",
      "\n",
      "```\n",
      "import numpy as np\n",
      "arr = np.arange(12)\n",
      "arr = arr.reshape((3, 4))\n",
      "```\n",
      "\n",
      "В этом примере массив из 12 элементов преобразовывается в двумерный массив размером 3x4.\n",
      "\n",
      "В NumPy также есть функции для выбора элементов из массива, например:\n",
      "\n",
      "* np.ndarray[i] - возвращает i-ый элемент массива;\n",
      "* np.ndarray[i, j] - возвращает элемент массива с индексами i и j;\n",
      "* np.ndarray[::-1] - возвращает массив в обратном порядке;\n",
      "* np.ndarray[i:j] - возвращает срезы массива от i-го элемента до j-го (не включая j-й элемент);\n",
      "* np.ndarray[i:j:k] - возвращает срезы массива от i-го элемента до j-го с шагом k.\n",
      "\n",
      "Например:\n",
      "\n",
      "```\n",
      "import numpy as np\n",
      "arr = np.arange(10)\n",
      "print(arr[4]) # печатает 5-ый элемент массива\n",
      "print(arr[4:7]) # печатает срез массива от 5-го до 8-го элемента (не включая 8-й элемент)\n",
      "print(arr[::2]) # печатает массив с шагом 2\n",
      "```\n",
      "\n",
      "В NumPy также есть функции для работы с осями массивов, например:\n",
      "\n",
      "* np.sum(arr, axis=0) - возвращает сумму элементов массива по оси 0;\n",
      "* np.sum(arr, axis=1) - возвращает сумму элементов массива по оси 1.\n",
      "\n",
      "Например:\n",
      "\n",
      "```\n",
      "import numpy as np\n",
      "arr_2d = np.array([[1, 2, 3], [4, 5, 6]])\n",
      "print(np.sum(arr_2d, axis=0)) # печатает [5, 7, 9]\n",
      "print(np.sum(arr_2d, axis=1)) # печатает [6, 15]\n",
      "```\n",
      "\n",
      "В этом примере функция np.sum() вызывается с аргументом axis, который указывает ось, по которой нужно произвести операцию. В первом примере сумма элементов массива вычисляется по оси 0, а во втором примере - по оси 1.\n",
      "\n",
      "В NumPy также есть функции для сортировки массивов, например:\n",
      "\n",
      "* np.sort(arr) - сортирует массив в порядке возрастания;\n",
      "* np.argsort(arr) - возвращает индексы элементов массива в порядке возрастания.\n",
      "\n",
      "Например:\n",
      "\n",
      "```\n",
      "import numpy as np\n",
      "arr = np.array([3, 1, 4, 1, 5, 9])\n",
      "arr_sorted = np.sort(arr)\n",
      "print(arr_sorted) # печатает [1, 1, 3, 4, 5, 9]\n",
      "indices = np.argsort(arr)\n",
      "print(indices) # печатает [1, 4, 0, 2, 5, 3]\n",
      "```\n",
      "\n",
      "В этом примере функция np.sort() сортирует массив в порядке возрастания, а функция np.argsort() возвращает индексы элементов массива в порядке возрастания.\n",
      "\n",
      "В NumPy также есть функции для поиска уникальных элементов массива, например:\n",
      "\n",
      "* np.unique(arr) - возвращает уникальные элементы массива;\n",
      "* np.in1d(arr1, arr2) - возвращает массив логических значений, указывающих, присутствуют ли элементы arr1 в arr2.\n",
      "\n",
      "Например:\n",
      "\n",
      "```\n",
      "import numpy as np\n",
      "arr = np.array([1, 2, 3, 1, 2, 4, 5, 6, 4, 7, 8, 9, 7, 8, 9])\n",
      "unique_arr = np.unique(arr)\n",
      "print(unique_arr) # печатает [1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "result = np.in1d(arr, unique_arr)\n",
      "print(result) # печатает [ True,  True,  True,  True,  True,  True, False, False,  True, False, False, False, False, False, False]\n",
      "```\n",
      "\n",
      "В этом примере функция np.unique() возвращает уникальные элементы массива, а функция np.in1d() возвращает массив логических значений, указывающих, присутствуют ли элементы arr в unique\\_arr.\n",
      "\n",
      "В NumPy также есть функции для нахождения индексов максимальных и минимальных элементов массива, например:\n",
      "\n",
      "* np.argmax(arr) - возвращает индекс максимального элемента массива;\n",
      "* np.argmin(arr) - возвращает индекс минимального элемента массива.\n",
      "\n",
      "Например:\n",
      "\n",
      "```\n",
      "import numpy as np\n",
      "arr = np.array([3, 1, 4, 1, 5, 9])\n",
      "max_index = np.argmax(arr)\n",
      "min_index = np.argmin(arr)\n",
      "print(max_index) # печатает 5\n",
      "print(min_index) # печатает 1\n",
      "```\n",
      "\n",
      "В этом примере функция np.argmax() возвращает индекс максимального элемента массива, а функция np.argmin() возвращает индекс минимального элемента массива.\n",
      "\n",
      "В NumPy также есть функции для нахождения максимальных и минимальных значений массива по осям, например:\n",
      "\n",
      "* np.amax(arr, axis=0) - возвращает максимальные значения массива по оси 0;\n",
      "* np.amin(arr, axis=1) - возвращает минимальные значения массива по оси 1.\n",
      "\n",
      "Например:\n",
      "\n",
      "```\n",
      "import numpy as np\n",
      "arr_2d = np.array([[1, 2, 3], [4, 5, 6]])\n",
      "max_values = np.amax(arr_2d, axis=0)\n",
      "min_values = np.amin(arr_2d, axis=1)\n",
      "print(max_values) # печатает [4, 5, 6]\n",
      "print(min_values) # печатает [1, 2, 3]\n",
      "```\n",
      "\n",
      "В этом примере функция np.amax() возвращает максимальные значения массива по оси 0, а функция np.amin() возвращает минимальные значения массива по оси 1.\n",
      "\n",
      "В NumPy также есть функции для обрезания массивов, например:\n",
      "\n",
      "* np.clip(arr, a, b) - обрезает массив таким образом, что все элементы меньше a заменяются на a, а все элементы больше b заменяются на b.\n",
      "\n",
      "Например:\n",
      "\n",
      "```\n",
      "import numpy as np\n",
      "arr = np.array([-1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n",
      "clipped_arr = np.clip(arr, 2, 8)\n",
      "print(clipped_arr) # печатает [2, 2, 3, 4, 5, 6, 7, 8, 8, 8]\n",
      "```\n",
      "\n",
      "В этом примере функция np.clip() обрезает массив таким образом, что все элементы меньше 2 заменяются на 2, а все элементы больше 8 заменяются на 8.\n",
      "\n",
      "В NumPy также есть функции для порогового преобразования массивов, например:\n",
      "\n",
      "* np.where(condition, x, y) - возвращает элементы массива x, если condition является истиной, иначе возвращает элементы массива y.\n",
      "\n",
      "Например:\n",
      "\n",
      "```\n",
      "import numpy as np\n",
      "arr = np.array([1, 2, 3, 4, 5])\n",
      "result = np.where(arr > 2, 10, arr)\n",
      "print(result) # печатает [1, 2, 10, 10, 10]\n",
      "```\n",
      "\n",
      "В этом примере функция np.where() возвращает элементы массива arr, если элемент больше 2, иначе возвращает 10.\n",
      "\n",
      "В NumPy также есть функции для генерации случайных чисел, например:\n",
      "\n",
      "* np.random.rand(d0, d1, ..., dn) - генерирует массив размерности (d0, d1, ..., dn) с плавающей точкой, заполненный случайными числами в диапазоне [0, 1).\n",
      "* np.random.randint(low, high, size) - генерирует массив размерности size с целыми числами, заполненный случайными числами в диапазоне [low, high).\n",
      "\n",
      "Например:\n",
      "\n",
      "```\n",
      "import numpy as np\n",
      "arr_rand = np.random.rand(3, 3)\n",
      "arr_randint = np.random.randint(10, size=(3, 3))\n",
      "print(arr_rand) # печатает случайный массив размерности 3x3 с плавающей точкой\n",
      "print(arr_randint) # печатает случайный массив размерности 3x3 с целыми числами в диапазоне [0, 10)\n",
      "```\n",
      "\n",
      "В этом примере функция np.random.rand() генерирует массив размерности 3x3 с плавающей точкой, заполненный случайными числами в диапазоне [0, 1), а функция np.random.randint() генерирует массив размерности 3x3 с целыми числами, заполненный случайными числами в диапазоне [0, 10).\n",
      "\n",
      "В NumPy также есть функции для генерации случайных матриц, например:\n",
      "\n",
      "* np.random.normal(loc, scale, size) - генерирует массив размерности size с плавающей точкой, заполненный случайными числами, распределенными по закону нормального распределения с математическим ожиданием loc и стандартным отклонением scale.\n",
      "\n",
      "Например:\n",
      "\n",
      "```\n",
      "import numpy as np\n",
      "arr_normal = np.random.normal(0, 1, size=(3, 3))\n",
      "print(arr_normal) # печатает случайный массив размерности 3x3 с плавающей точкой, заполненный случайными числами, распределенными по закону нормального распределения с математическим ожиданием 0 и стандартным отклонением 1\n",
      "```\n",
      "\n",
      "В этом примере функция np.random.normal() генерирует массив размерности 3x3 с плавающей точкой, заполненный случайными числами, распределенными по закону нормального распределения с математическим ожиданием 0 и стандартным отклонением 1.\n",
      "\n",
      "В NumPy также есть функции для генерации случайных матриц с определенными свойствами, например:\n",
      "\n",
      "* np.random.permutation(n) - генерирует массив размерности n с целыми числами, содержащий все числа от 0 до n-1 в случайном порядке.\n",
      "\n",
      "Например:\n",
      "\n",
      "```\n",
      "import numpy as np\n",
      "arr_perm = np.random.permutation(10)\n",
      "print(arr_perm) # печатает случайный массив размерности 10 с целыми числами, содержащий все числа от 0 до 9 в случайном порядке\n",
      "```\n",
      "\n",
      "В этом примере функция np.random.permutation() генерирует массив размерности 10 с целыми числами, содержащий все числа от 0 до 9 в случайном порядке.\n",
      "\n",
      "В NumPy также есть функции для генерации случайных матриц с определенными свойствами, например:\n",
      "\n",
      "* np.random.shuffle(x) - перемешивает элементы массива x в случайном порядке.\n",
      "\n",
      "Например:\n",
      "\n",
      "```\n",
      "import numpy as np\n",
      "arr = np.array([1, 2, 3, 4, 5])\n",
      "np.random.shuffle(arr)\n",
      "print(arr) # печатает случайный массив размерности 5 с целыми числами, содержащий все числа от 1 до 5 в случайном порядке\n",
      "```\n",
      "\n",
      "В этом примере функция np.random.shuffle() перемешивает элементы массива arr в случайном порядке.\n",
      "\n",
      "В NumPy также есть функции для генерации матриц с определенными свойствами, например:\n",
      "\n",
      "* np.identity(n) - создает квадратную матрицу размерности nxn, содержащую единицы на диагонали и нули вне диагонали.\n",
      "\n",
      "Например:\n",
      "\n",
      "```\n",
      "import numpy as np\n",
      "arr_identity = np.identity(3)\n",
      "print(arr_identity) # печатает матрицу размерности 3x3, содержащую единицы на диагонали и нули вне диагонали\n",
      "```\n",
      "\n",
      "В этом примере функция np.identity() создает квадратную матрицу размерности 3x3, содержащую единицы на диагонали и нули вне диагонали.\n",
      "\n",
      "В NumPy также есть функции для генерации матриц с определенными свойствами, например:\n",
      "\n",
      "* np.eye(n, k) - создает квадратную матрицу размерности nxn, содержащую единицы на диагонали, смещенную на k единиц вниз или вверх.\n",
      "\n",
      "Например:\n",
      "\n",
      "```\n",
      "import numpy as np\n",
      "arr_eye = np.eye(3, 1)\n",
      "print(arr_eye) # печатает матрицу размерности 3x3, содержащую единицы на диагонали, смещенную на 1 единицу вниз\n",
      "```\n",
      "\n",
      "В этом примере функция np.eye() создает квадратную матрицу размерности 3x3, содержащую единицы на диагонали, смещенную на 1 единицу вниз.\n",
      "\n",
      "В NumPy также есть функции для генерации матриц с определенными свойствами, например:\n",
      "\n",
      "* np.zeros((n, m)) - создает матрицу размерности nxm, заполненную нулями.\n",
      "* np.ones((n, m)) - создает матрицу размерности nxm, заполненную единицами.\n",
      "\n",
      "Например:\n",
      "\n",
      "```\n",
      "import numpy as np\n",
      "arr_zeros = np.zeros((3, 3))\n",
      "arr_ones = np.ones((3, 3))\n",
      "print(arr_zeros) # печатает матрицу размерности 3x3, заполненную нулями\n",
      "print(arr_ones) # печатает матрицу размерности 3x3, заполненную единицами\n",
      "```\n",
      "\n",
      "В этом примере функция np.zeros() создает матрицу размерности 3x3, заполненную нулями, а функция np.ones() создает матрицу размерности 3x3, заполненную единицами.\n",
      "\n",
      "В NumPy также есть функции для генерации матриц с определенными свойствами, например:\n",
      "\n",
      "* np.full((n, m), value) - создает матрицу размерности nxm, заполненную заданным значением value.\n",
      "\n",
      "Например:\n",
      "\n",
      "```\n",
      "import numpy as np\n",
      "arr_full = np.full((3, 3), 5)\n",
      "print(arr_full) # печатает матрицу размерности 3x3, заполненную пятерками\n",
      "```\n",
      "\n",
      "В этом примере функция np.full() создает матрицу размерности 3x3, заполненную пятерками.\n",
      "\n",
      "В NumPy также есть функции для генерации матриц с определенными свойствами, например:\n",
      "\n",
      "* np.arange(start, stop, step) - создает массив размерности (stop - start) // step + 1, заполненный числами от start до stop - 1 с шагом step.\n",
      "\n",
      "Например:\n",
      "\n",
      "```\n",
      "import numpy as np\n",
      "arr_arange = np.arange(0, 10, 2)\n",
      "print(arr_arange) # печатает массив размерности 5, заполненный числами от 0 до 9 с шагом 2\n",
      "```\n",
      "\n",
      "В этом примере функция np.arange() создает массив размерности 5, заполненный числами от 0 до 9 с шагом 2.\n",
      "\n",
      "В NumPy также есть функции для генерации матриц с определенными свойствами, например:\n",
      "\n",
      "* np.linspace(start, stop, num) - создает массив размерности num, заполненный числами от start до stop с шагом (stop - start) / (num - 1).\n",
      "\n",
      "Например:\n",
      "\n",
      "```\n",
      "import numpy as np\n",
      "arr_linspace = np.linspace(0, 1, 5)\n",
      "print(arr_linspace) # печатает массив размерности 5, заполненный числами от 0 до 1 с шагом 0.25\n",
      "```\n",
      "\n",
      "В этом примере функция np.linspace() создает массив размерности 5, заполненный числами от 0 до 1 с шагом 0.25.\n",
      "\n",
      "В NumPy также есть функции для генерации матриц с определенными свойствами, например:\n",
      "\n",
      "* np.logspace(start, stop, num, base=10.0) - создает массив размерности num, заполненный числами от 10**start до 10**stop с шагом (10**stop - 10**start) / (num - 1).\n",
      "\n",
      "Например:\n",
      "\n",
      "```\n",
      "import numpy as np\n",
      "arr_logspace = np.logspace(0, 3, 5)\n",
      "print(arr_logspace) # печатает массив размерности 5, заполненный числами от 1 до 1000 с шагом 10\n",
      "```\n",
      "\n",
      "В этом примере функция np.logspace() создает массив размерности 5, заполненный числами от 1 до 1000 с шагом 10.\n",
      "\n",
      "В NumPy также есть функции для генерации матриц с определенными свойствами, например:\n",
      "\n",
      "* np.fromfunction(function, shape) - создает массив размерности shape, заполненный результатами вычислений функции function для каждого элемента массива.\n",
      "\n",
      "Например:\n",
      "\n",
      "```\n",
      "import numpy as np\n",
      "def f(x, y):\n",
      "    return x + y\n",
      "arr_fromfunction = np.fromfunction(f, (3, 3))\n",
      "print(arr_fromfunction) # печатает матрицу размерности 3x3, заполненную суммами индексов x и y\n",
      "```\n",
      "\n",
      "В этом примере функция np.fromfunction() создает массив размерности 3x3, заполненный результатами вычислений функции f для каждого элемента массива.\n",
      "\n",
      "В NumPy также есть функции для генерации матриц с определенными свойствами, например:\n",
      "\n",
      "* np.diag(v, k=0) - создает диагональную матрицу размерности len(v) x len(v), заполненную значениями вектора v и смещенную на k единиц вниз или вверх.\n",
      "\n",
      "Например:\n",
      "\n",
      "```\n",
      "import numpy as np\n",
      "arr_diag = np.diag([1, 2, 3, 4])\n",
      "print(arr_diag) # печатает матрицу размерности 4x4, заполненную значениями вектора [1, 2, 3, 4] на диагонали и нулями вне диагонали\n",
      "```\n",
      "\n",
      "В этом примере функция np.diag() создает диагональную матрицу размерности 4x4, заполненную значениями вектора [1, 2, 3, 4] на диагонали и нулями вне диагонали.\n",
      "\n",
      "В NumPy также есть функции для генерации матриц с определенными свойствами, например:\n",
      "\n",
      "* np.tri(n, k=0) - создает треугольную матрицу размерности n x n, заполненную единицами выше или ниже главной диагонали в зависимости от знака k.\n",
      "\n",
      "Например:\n",
      "\n",
      "```\n",
      "import numpy as np\n",
      "arr_tri = np.tri(3, k=1)\n",
      "print(arr_tri) # печатает матрицу размерности 3x3, заполненную единицами ниже главной диагонали\n",
      "```\n",
      "\n",
      "В этом примере функция np.tri() создает треугольную матрицу размерности 3x3, заполненную единицами ниже главной диагонали.\n",
      "\n",
      "В NumPy также есть функции для генерации матриц с определенными свойствами, например:\n",
      "\n",
      "* np.triu(m, k=0) - создает верхнюю треугольную матрицу размерности m x m, заполненную единицами выше главной диагонали в зависимости от знака k.\n",
      "\n",
      "Например:\n",
      "\n",
      "```\n",
      "import numpy as np\n",
      "arr_triu = np.triu(3, k=1)\n",
      "print(arr_triu) # печатает матрицу размерности 3x3, заполненную единицами выше главной диагонали\n",
      "```\n",
      "\n",
      "В этом примере функция np.triu() создает верхнюю треугольную матрицу размерности 3x3, заполненную единицами выше главной диагонали.\n",
      "\n",
      "В NumPy также есть функции для генерации матриц с определенными свойствами, например:\n",
      "\n",
      "* np.tril(m, k=0) - создает нижнюю треугольную матрицу размерности m x m, заполненную единицами ниже главной диагонали в зависимости от знака k.\n",
      "\n",
      "Например:\n",
      "\n",
      "```\n",
      "import numpy as np\n",
      "arr_tril = np.tril(3, k=1)\n",
      "print(arr_tril) # печатает матрицу размерности 3x3, заполненную единицами ниже главной диагонали\n",
      "```\n",
      "\n",
      "В этом примере функция np.tril() создает нижнюю треугольную матрицу размерности 3x3, заполненную единицами ниже главной диагонали.\n",
      "\n",
      "В NumPy также есть функции для генерации матриц с определенными свойствами, например:\n",
      "\n",
      "* np.fliplr(m) - переворачивает матрицу m по горизонтали.\n",
      "* np.flipud(m) - переворачивает матрицу m по вертикали.\n",
      "\n",
      "Например:\n",
      "\n",
      "```\n",
      "import numpy as np\n",
      "arr = np.array([[1, 2, 3], [4, 5, 6]])\n",
      "arr_fliplr = np.fliplr(arr)\n",
      "arr_flipud = np.flipud(arr)\n",
      "print(arr_fliplr) # печатает матрицу размерности 2x3, заполненную числами [3, 2, 1, 6, 5, 4]\n",
      "print(arr_flipud) # печатает матрицу размерности 2x3, заполненную числами [6, 5, 4, 3, 2, 1]\n",
      "```\n",
      "\n",
      "В этом примере функция np.fliplr() переворачивает матрицу arr по горизонтали, а функция np.flipud() переворачивает матрицу arr по вертикали.\n",
      "\n",
      "В NumPy также есть функции для генерации матриц с определенными свойствами, например:\n",
      "\n",
      "* np.rot90(m, k=1) - поворачивает матрицу m на 90 градусов против часовой стрелки k раз.\n",
      "\n",
      "Например:\n",
      "\n",
      "```\n",
      "import numpy as np\n",
      "arr = np.array([[1, 2, 3], [4, 5, 6]])\n",
      "arr_rot90 = np.rot90(arr, k=2)\n",
      "print(arr_rot90) # печатает матрицу размерности 2x3, заполненную числами [3, 6, 2, 5, 1, 4]\n",
      "```\n",
      "\n",
      "В этом примере функция np.rot90() поворачивает матрицу arr на 90 градусов против часовой стрелки 2 раза.\n",
      "\n",
      "В NumPy также есть функции для генерации матриц с определенными свойствами, например:\n",
      "\n",
      "* np.tile(A, reps) - создает матрицу, состоящую из repeats[i] копий строки i матрицы A.\n",
      "\n",
      "Например:\n",
      "\n",
      "```\n",
      "import numpy as np\n",
      "arr = np.array([[1, 2], [3, 4]])\n",
      "arr_tile = np.tile(arr, (2, 3))\n",
      "print(arr_tile) # печатает матрицу размерности 4x6, заполненную повторениями строк матрицы arr\n",
      "```\n",
      "\n",
      "В этом примере функция np.tile() создает матрицу размерности 4x6, заполненную повторениями строк матрицы arr.\n",
      "\n",
      "В NumPy также есть функции для генерации матриц с определенными свойствами, например:\n",
      "\n",
      "* np.repeat(A, reps, axis) - создает матрицу, состоящую из repeats[i] копий элемента i матрицы A вдоль указанной оси axis.\n",
      "\n",
      "Например:\n",
      "\n",
      "```\n",
      "import numpy as np\n",
      "arr = np.array([1, 2, 3])\n",
      "arr_repeat = np.repeat(arr, 3, axis=0)\n",
      "print(arr_repeat) # печатает матрицу размерности 3x3, заполненную повторениями элементов матрицы arr\n",
      "```\n",
      "\n",
      "В этом примере функция np.repeat() создает матрицу размерности 3x3, заполненную повторениями элементов матрицы arr.\n",
      "\n",
      "В NumPy также есть функции для генерации матриц с определенными свойствами, например:\n",
      "\n",
      "* np.resize(A, new\\_shape) - возвращает матрицу, содержащую те же элементы, что и матрица A, но с размером new\\_shape.\n",
      "\n",
      "Например:\n",
      "\n",
      "```\n",
      "import numpy as np\n",
      "arr = np.array([1, 2, 3, 4, 5])\n",
      "arr_resize = np.resize(arr, (2, 5))\n",
      "print(arr_resize) # печатает матрицу размерности 2x5, заполненную элементами матрицы arr\n",
      "```\n",
      "\n",
      "В этом примере функция np.resize() возвращает матрицу размерности 2x5, заполненную элементами матрицы arr.\n",
      "\n",
      "В NumPy также есть функции для генерации матриц с определенными свойствами, например:\n",
      "\n",
      "* np.pad(array, pad\\_width, mode='constant', constant\\_values=0) - добавляет padding к матрице array с заданными значениями constant\\_values.\n",
      "\n",
      "Например:\n",
      "\n",
      "```\n",
      "import numpy as np\n",
      "arr = np.array([[1, 2, 3], [4, 5, 6]])\n",
      "arr_pad = np.pad(arr, ((1, 1), (2, 2)), mode='constant', constant_values=0)\n",
      "print(arr_pad) # печатает матрицу размерности 4x7, заполненную нулями и элементами матрицы arr\n",
      "```\n",
      "\n",
      "В этом примере функция np.pad() добавляет padding к матрице arr с заданными значениями constant\\_values=0.\n",
      "\n",
      "В NumPy также есть функции для генерации матриц с определенными свойствами, например:\n",
      "\n",
      "* np.concatenate((a1, a2, ...), axis=0) - конкатенирует матрицы a1, a2, ... вдоль указанной оси axis.\n",
      "\n",
      "Например:\n",
      "\n",
      "```\n",
      "import numpy as np\n",
      "arr1 = np.array([[1, 2], [3, 4]])\n",
      "arr2 = np.array([[5, 6], [7, 8]])\n",
      "arr_concat = np.concatenate((arr1, arr2), axis=0)\n",
      "print(arr_concat) # печатает матрицу размерности 4x2, заполненную элементами матриц arr1 и arr2\n",
      "```\n",
      "\n",
      "В этом примере функция np.concatenate() конкатенирует матрицы arr1 и arr2 вдоль оси 0.\n",
      "\n",
      "В NumPy также есть функции для генерации матриц с определенными свойствами, например:\n",
      "\n",
      "* np.stack((a1, a2, ...), axis=0) - stack матрицы a1, a2, ... вдоль указанной оси axis.\n",
      "\n",
      "Например:\n",
      "\n",
      "```\n",
      "import numpy as np\n",
      "arr1 = np.array([[1, 2], [3, 4]])\n",
      "arr2 = np.array([[5, 6], [7, 8]])\n",
      "arr_stack = np.stack((arr1, arr2), axis=0)\n",
      "print(arr_stack) # печатает матрицу размерности 2x2x2, заполненную элементами матриц arr1 и arr2\n",
      "```\n",
      "\n",
      "В этом примере функция np.stack() stack матрицы arr1 и arr2 вдоль оси 0.\n",
      "\n",
      "В NumPy также есть функции для генерации матриц с определенными свойствами, например:\n",
      "\n",
      "* np.vstack((a1, a2, ...)) - stack матрицы a1, a2, ... вертикально.\n",
      "* np.hstack((a1, a2, ...)) - stack матрицы a1, a2, ... горизонтально.\n",
      "\n",
      "Например:\n",
      "\n",
      "```\n",
      "import numpy as np\n",
      "arr1 = np.array([[1, 2], [3, 4]])\n",
      "arr2 = np.array([[5, 6], [7, 8]])\n",
      "arr_vstack = np.vstack((arr1, arr2))\n",
      "arr_hstack = np.hstack((arr1, arr2))\n",
      "print(arr_vstack) # печатает матрицу размерности 4x2, заполненную элементами матриц arr1 и arr2\n",
      "print(arr_hstack) # печатает матрицу размерности 2x4, заполненную элементами матриц arr1 и arr2\n",
      "```\n",
      "\n",
      "В этом примере функция np.vstack() stack матрицы arr1 и arr2 вертикально, а функция np.hstack() stack матрицы arr1 и arr2 горизонтально.\n",
      "\n",
      "В NumPy также есть функции для генерации матриц с определенными свойствами, например:\n",
      "\n",
      "* np.dstack((a1, a2, ...)) - stack матрицы a1, a2, ... depth-wise.\n",
      "\n",
      "Например:\n",
      "\n",
      "```\n",
      "import numpy as np\n",
      "arr1 = np.array([[1, 2], [3, 4]])\n",
      "arr2 = np.array([[5, 6], [7, 8]])\n",
      "arr_dstack = np.dstack((arr1, arr2))\n",
      "print(arr_dstack) # печатает матрицу размерности 2x2x2, заполненную элементами матриц arr1 и arr2\n",
      "```\n",
      "\n",
      "В этом примере функция np.dstack() stack матрицы arr1 и arr2 depth-wise.\n",
      "\n",
      "В NumPy также есть функции для генерации матриц с определенными свойствами, например:\n",
      "\n",
      "* np.split(array, indices\\_or\\_sections, axis=0) - разбивает матрицу array на несколько матриц по указанным индексам indices\\_or\\_sections или секциям sections вдоль оси axis.\n",
      "\n",
      "Например:\n",
      "\n",
      "```\n",
      "import numpy as np\n",
      "arr = np.array([1, 2, 3, 4, 5, 6, 7, 8])\n",
      "arr_split = np.split(arr, [3, 6], axis=0)\n",
      "print(arr_split) # печатает список из трех матриц размерностей 3x1, 3x1 и 2x1\n",
      "```\n",
      "\n",
      "В этом примере функция np.split() разбивает матрицу arr на три матрицы по указанным индексам 3 и 6 вдоль оси 0.\n",
      "\n",
      "В NumPy также есть функции для генерации матриц с определенными свойствами, например:\n",
      "\n",
      "* np.vsplit(array, indices\\_or\\_sections) - разбивает матрицу array на несколько матриц по указанным индексам indices\\_or\\_sections или секциям sections вертикально.\n",
      "* np.hsplit(array, indices\\_or\\_sections) - разбивает матрицу array на несколько матриц по указанным индексам indices\\_or\\_sections или секциям sections горизонтально.\n",
      "\n",
      "Например:\n",
      "\n",
      "```\n",
      "import numpy as np\n",
      "arr = np.array([[1, 2], [3, 4], [5, 6], [7, 8]])\n",
      "arr_vsplit = np.vsplit(arr, [2])\n",
      "arr_hsplit = np.hsplit(arr, [2])\n",
      "print(arr_vsplit) # печатает список из двух матриц размерностей 2x2 и 2x2\n",
      "print(arr_hsplit) # печатает список из четырех матриц размерностей 2x1\n",
      "```\n",
      "\n",
      "В этом примере функция np.vsplit() разбивает матрицу arr на две матрицы по указанному индексу 2 вертикально, а функция np.hsplit() разбивает матрицу arr на четыре матрицы по указанному индексу 2 горизонтально.\n",
      "\n",
      "В NumPy также есть функции для генерации матриц с определенными свойствами, например:\n",
      "\n",
      "* np.array\\_split(array, indices\\_or\\_sections, axis=0) - разбивает матрицу array на несколько матриц по указанным индексам indices\\_or\\_sections или секциям sections вдоль оси axis.\n",
      "\n",
      "Например:\n",
      "\n",
      "```\n",
      "import numpy as np\n",
      "arr = np.array([1, 2, 3, 4, 5, 6, 7, 8])\n",
      "arr_split = np.array_split(arr, 3, axis=0)\n",
      "print(arr_split) # печатает список из трех матриц размерностей 3x1, 2x1 и 3x1\n",
      "```\n",
      "\n",
      "В этом примере функция np.array\\_split() разбивает матрицу arr на три матрицы по указанным секциям 3, 2 и 3 вдоль оси 0.\n",
      "\n",
      "В NumPy также есть функции для генерации матриц с определенными свойствами, например:\n",
      "\n",
      "* np.resize\\_grid(grid, new\\_shape) - возвращает сетку grid с новыми размерами new\\_shape.\n",
      "\n",
      "Например:\n",
      "\n",
      "```\n",
      "import numpy as np\n",
      "grid = np.array([[1, 2, 3], [4, 5, 6]])\n",
      "grid_resize = np.resize_grid(grid, (2, 2, 3))\n",
      "print(grid_resize) # печатает сетку размерности 2x2x3, заполненную элементами сетки grid\n",
      "```\n",
      "\n",
      "В этом примере функция np.resize\\_grid() возвращает сетку grid с новыми размерами (2, 2, 3).\n",
      "\n",
      "В NumPy также есть функции для генерации матриц с определенными свойствами, например:\n",
      "\n",
      "* np.mgrid[start:stop:step, ...] - создает сетку из N массивов, каждый из которых содержит координаты по оси в соответствии с указанными шагами.\n",
      "\n",
      "Например:\n",
      "\n",
      "```\n",
      "import numpy as np\n",
      "grid = np.mgrid[0:5:2, 0:3:1]\n",
      "print(grid) # печатает сетку размерности 2x3x2, заполненную координатами по осям\n",
      "```\n",
      "\n",
      "В этом примере функция np.mgrid() создает сетку размерности 2x3x2, заполненную координатами по осям.\n",
      "\n",
      "В NumPy также есть функции для генерации матриц с определенными свойствами, например:\n",
      "\n",
      "* np.ogrid[start:stop:step, ...] - создает сетку из N массивов, каждый из которых содержит координаты по оси в соответствии с указанными шагами.\n",
      "\n",
      "Например:\n",
      "\n",
      "```\n",
      "import numpy as np\n",
      "grid = np.ogrid[0:5:2, 0:3:1]\n",
      "print(grid) # печатает сетку размерности 2x3x2, заполненную координатами по осям\n",
      "```\n",
      "\n",
      "В этом примере функция np.ogrid() создает сетку размерности 2x3x2, заполненную координатами по осям.\n",
      "\n",
      "В NumPy также есть функции для генерации матриц с определенными свойствами, например:\n",
      "\n",
      "* np.meshgrid(x, y, indexing='xy') - создает сетку из двух массивов, каждый из которых содержит координаты по оси x и y соответственно.\n",
      "\n",
      "Например:\n",
      "\n",
      "```\n",
      "import numpy as np\n",
      "x = np.array([0, 1, 2])\n",
      "y = np.array([3, 4, 5])\n",
      "grid = np.meshgrid(x, y)\n",
      "print(grid) # печатает сетку размерности 3x3x2, заполненную координатами по осям x и y\n",
      "```\n",
      "\n",
      "В этом примере функция np.meshgrid() создает сетку размерности 3x3x2, заполненную координатами по осям x и y.\n",
      "\n",
      "В NumPy также есть функции для генерации матриц с определенными свойствами, например:\n",
      "\n",
      "* np.fromiter(iterable, dtype, count=-1) - создает массив из итератора iterable с указанным типом dtype и количеством элементов count.\n",
      "\n",
      "Например:\n",
      "\n",
      "```\n",
      "import numpy as np\n",
      "iterable = (1, 2, 3, 4, 5)\n",
      "arr = np.fromiter(iterable, dtype=int, count=5)\n",
      "print(arr) # печатает массив размерности 5x1, заполненный элементами итератора iterable\n",
      "```\n",
      "\n",
      "В этом примере функция np.fromiter() создает массив размерности 5x1, заполненный элементами итератора iterable.\n",
      "\n",
      "В NumPy также есть функции для генерации матриц с определенными свойствами, например:\n",
      "\n",
      "* np.genfromtxt(fname, dtype=None, delimiter=None, skip\\_header=0, skip\\_footer=0, skip\\_rows=0, usecols=None, names=None, encoding=None, max\\_rows=None) - читает данные из файла fname в виде CSV или другого текстового формата и возвращает массив данных.\n",
      "\n",
      "Например:\n",
      "\n",
      "```\n",
      "import numpy as np\n",
      "arr = np.genfromtxt('data.csv', delimiter=',', skip_header=1)\n",
      "print(arr) # печатает массив данных, читанный из файла data.csv\n",
      "```\n",
      "\n",
      "В этом примере функция np.genfromtxt() читает данные из файла data.csv в виде CSV и возвращает массив данных.\n",
      "\n",
      "В NumPy также есть функции для генерации матриц с определенными свойствами, например:\n",
      "\n",
      "* np.savetxt(fname, X, fmt='%.18e', delimiter=' ', newline='\\n', header='', footer='', comments='# ') - записывает данные массива X в файл fname в виде CSV или другого текстового формата.\n",
      "\n",
      "Например:\n",
      "\n",
      "```\n",
      "import numpy as np\n",
      "arr = np.array([[1, 2], [3, 4]])\n",
      "np.savetxt('data.csv', arr, delimiter=',', fmt='%d')\n",
      "```\n",
      "\n",
      "В этом примере функция np.savetxt() записывает данные массива arr в файл data.csv в виде CSV.\n",
      "\n",
      "В NumPy также есть функции для генерации матриц с определенными свойствами, например:\n",
      "\n",
      "* np.loadtxt(fname, dtype=<type 'float'>, comments='#', delimiter=None, converters=None, skiprows=0, usecols=None, unpack=False, ndmin=0) - читает данные из файла fname в виде CSV или другого текстового формата и возвращает массив данных.\n",
      "\n",
      "Например:\n",
      "\n",
      "```\n",
      "import numpy as np\n",
      "arr = np.loadtxt('data.csv', delimiter=',')\n",
      "print(arr) # печатает массив данных, читанный из файла data.csv\n",
      "```\n",
      "\n",
      "В этом примере функция np.loadtxt() читает данные из файла data.csv в виде CSV и возвращает массив данных.\n",
      "\n",
      "В NumPy также есть функции для генерации матриц с определенными свойствами, например:\n",
      "\n",
      "* np.fromfile(file, dtype=float, count=-1, sep='') - читает данные из файла file в виде бинарного формата и возвращает массив данных.\n",
      "\n",
      "Например:\n",
      "\n",
      "```\n",
      "import numpy as np\n",
      "arr = np.fromfile('data.bin', dtype=int)\n",
      "print(arr) # печатает массив данных, читанный из файла data.bin\n",
      "```\n",
      "\n",
      "В этом примере функция np.fromfile() читает данные из файла data.bin в виде бинарного формата и возвращает массив данных.\n",
      "\n",
      "В NumPy также есть функции для генерации матриц с определенными свойствами, например:\n",
      "\n",
      "* np.save(file, arr, allow\\_pickle=True, fix\\_imports=True) - сохраняет массив arr в файл file в виде бинарного формата.\n",
      "\n",
      "Например:\n",
      "\n",
      "```\n",
      "import numpy as np\n",
      "arr = np.array([[1, 2], [3, 4]])\n",
      "np.save('data.npy', arr)\n",
      "```\n",
      "\n",
      "В этом примере функция np.save() сохраняет массив arr в файл data.npy в виде бинарного формата.\n",
      "\n",
      "В NumPy также есть функции для генерации матриц с определенными свойствами, например:\n",
      "\n",
      "* np.load(file, allow\\_pickle=True, fix\\_imports=True) - загружает массив данных из файла file, сохраненного в виде бинарного формата.\n",
      "\n",
      "Например:\n",
      "\n",
      "```\n",
      "import numpy as np\n",
      "arr = np.load('data.npy')\n",
      "print(arr) # печатает массив данных, загруженный из файла data.npy\n",
      "```\n",
      "\n",
      "В этом примере функция np.load() загружает массив данных из файла data.npy, сохраненного в виде бинарного формата.\n",
      "\n",
      "В NumPy также есть функции для генерации матриц с определенными свойствами, например:\n",
      "\n",
      "* np.memmap(filename, dtype=float, mode='r+', shape=None) - создает массив, связанный с файлом filename в памяти и загружает его в массив.\n",
      "\n",
      "Например:\n",
      "\n",
      "```\n",
      "import numpy as np\n",
      "arr = np.memmap('data.dat', dtype=int, mode='r+', shape=(100, 100))\n",
      "print(arr) # печатает массив данных, сохраненный в файле data.dat\n",
      "```\n",
      "\n",
      "В этом примере функция np.memmap() создает массив, связанный с файлом data.dat в памяти и загружает его в массив.\n",
      "\n",
      "В NumPy также есть функции для генерации матриц с определенными свойствами, например:\n",
      "\n",
      "* np.savez(file, *args, **kwds) - сохраняет several arrays into a single file in uncompressed .npz format.\n",
      "\n",
      "Например:\n",
      "\n",
      "```\n",
      "import numpy as np\n",
      "arr1 = np.array([[1, 2], [3, 4]])\n",
      "arr2 = np.array([[5, 6], [7, 8]])\n",
      "np.savez('data.npz', arr1=arr1, arr2=arr2)\n",
      "```\n",
      "\n",
      "В этом примере функция np.savez() сохраняет несколько массивов arr1 и arr2 в один файл data.npz в несжатом формате .npz.\n",
      "\n",
      "В NumPy также есть функции для генерации матриц с определенными свойствами, например:\n",
      "\n",
      "* np.load(file, allow\\_pickle=True, fix\\_imports=True) - загружает массив данных из файла file, сохраненного в виде бинарного формата.\n",
      "\n",
      "Например:\n",
      "\n",
      "```\n",
      "import numpy as np\n",
      "arr = np.load('data.npz')['arr1']\n",
      "print(arr) # печатает массив данных, загруженный из файла data.npz\n",
      "```\n",
      "\n",
      "В этом примере функция np.load() загружает массив данных из файла data.npz, сохраненного в виде бинарного формата.\n",
      "\n",
      "В NumPy также есть функции для генерации матриц с определенными свойствами, например:\n",
      "\n",
      "* np.savez\\_compressed(file, *args, **kwds) - сохраняет several arrays into a single file in compressed .npz format.\n",
      "\n",
      "Например:\n",
      "\n",
      "```\n",
      "import numpy as np\n",
      "arr1 = np.array([[1, 2], [3, 4]])\n",
      "arr2 = np.array([[5, 6], [7, 8]])\n",
      "np.savez_compressed('data.npz', arr1=arr1, arr2=arr2)\n",
      "```\n",
      "\n",
      "В этом примере функция np.savez\\_compressed() сохраняет несколько массивов arr1 и arr2 в один файл data.npz в сжатом формате .npz.\n",
      "\n",
      "В NumPy также есть функции для генерации матриц с определенными свойствами, например:\n",
      "\n",
      "* np.lib.format.open\\_memmap(filename, mode='r', dtype=<type 'numpy.float64'>, shape=None) - открывает файл filename в формате memmap и возвращает объект, похожий на файловый объект.\n",
      "\n",
      "Например:\n",
      "\n",
      "```\n",
      "import numpy as np\n",
      "arr = np.lib.format.open_memmap('data.dat', mode='r', dtype=int, shape=(100, 100))\n",
      "print(arr) # печатает массив данных, сохраненный в файле data.dat\n",
      "```\n",
      "\n",
      "В этом примере функция np.lib.format.open\\_memmap() открывает файл data.dat в формате memmap и возвращает объект, похожий на файловый объект.\n",
      "\n",
      "В NumPy также есть функции для генерации матриц с определенными свойствами, например:\n",
      "\n",
      "* np.lib.format.fortran\\_order - устанавливает порядок байтов 'C' или 'Fortran' для записи или чтения файлов.\n",
      "\n",
      "Например:\n",
      "\n",
      "```\n",
      "import numpy as np\n",
      "arr = np.array([[1, 2], [3, 4]])\n",
      "np.save('data.npy', arr, order=np.lib.format.fortran_order)\n",
      "```\n",
      "\n",
      "В этом примере функция np.lib.format.fortran\\_order() устанавливает порядок байтов 'Fortran' для записи файла data.npy.\n",
      "\n",
      "В NumPy также есть функции для генерации матриц с определенными свойствами, например:\n",
      "\n",
      "* np.lib.format.write\\_array(fid, array, dtype, repeat=0) - записывает массив array в файл fid в формате '.raw'.\n",
      "\n",
      "Например:\n",
      "\n",
      "```\n",
      "import numpy as np\n",
      "arr = np.array([[1, 2], [3, 4]])\n",
      "with open('data.raw', 'wb') as f:\n",
      "    np.lib.format.write_array(f, arr, dtype=np.int32)\n",
      "```\n",
      "\n",
      "В этом примере функция np.lib.format.write\\_array() записывает массив arr в файл data.raw в формате '.raw'.\n",
      "\n",
      "В NumPy также есть функции для генерации матриц с определенными свойствами, например:\n",
      "\n",
      "* np.lib.format.read\\_array(fid, dtype) - читает массив данных из файла fid, записанного в формате '.raw', и возвращает массив данных.\n",
      "\n",
      "Например:\n",
      "\n",
      "```\n",
      "import numpy as np\n",
      "with open('data.raw', 'rb') as f:\n",
      "    arr = np.lib.format.read_array(f, dtype=np.int32)\n",
      "print(arr) # печатает массив данных, загруженный из файла data.raw\n",
      "```\n",
      "\n",
      "В этом примере функция np.lib.format.read\\_array() читает массив данных из файла data.raw, записанного в формате '.raw', и возвращает массив данных.\n",
      "\n",
      "В NumPy также есть функции для генерации матриц с определенными свойствами, например:\n",
      "\n",
      "* np.lib.format.recarray\\_fromfile(fid, dtype, shape=0) - читает структурированный массив данных из файла fid и возвращает объект recarray.\n",
      "\n",
      "Например:\n",
      "\n",
      "```\n",
      "import numpy as np\n",
      "dtype = [('name', 'S10'), ('age', '<i4'), ('height', '<f8')]\n",
      "with open('data.dat', 'rb') as f:\n",
      "    arr = np.lib.format.recarray_fromfile(f, dtype=dtype, shape=100)\n",
      "print(arr) # печатает структурированный массив данных, загруженный из файла data.dat\n",
      "```\n",
      "\n",
      "В этом примере функция np.lib.format.recarray\\_fromfile() читает структурированный массив данных из файла data.dat и возвращает объект recarray.\n",
      "\n",
      "В NumPy также есть функции для генерации матриц с определенными свойствами, например:\n",
      "\n",
      "* np.lib.format.recarray\\_tofile(fid, array, format='%s') - записывает структурированный массив данных array в файл fid.\n",
      "\n",
      "Например:\n",
      "\n",
      "```\n",
      "import numpy as np\n",
      "dtype = [('name', 'S10'), ('age', '<i4'), ('height', '<f8')]\n",
      "arr = np.array([('Alice', 25, 1.65), ('Bob', 30, 1.80), ('Charlie', 35, 1.70)], dtype=dtype)\n",
      "with open('data.dat', 'wb') as f:\n",
      "    np.lib.format.recarray_tofile(f, arr, format='%s')\n",
      "```\n",
      "\n",
      "В этом примере функция np.lib.format.recarray\\_tofile() записывает структурированный массив данных array в файл data.dat.\n",
      "\n",
      "В NumPy также есть функции для генерации матриц с определенными свойствами, например:\n",
      "\n",
      "* np.lib.format.search\\_header(fid, header, endian='<') - ищет заголовок header в файле fid и возвращает его позицию.\n",
      "\n",
      "Например:\n",
      "\n",
      "```\n",
      "import numpy as np\n",
      "with open('data.dat', 'rb') as f:\n",
      "    pos = np.lib.format.search_header(f, b'DATA')\n",
      "f.seek(pos)\n",
      "arr = np.fromfile(f, dtype=int)\n",
      "print(arr) # печатает массив данных, начиная с заголовка 'DATA' в файле data.dat\n",
      "```\n",
      "\n",
      "В этом примере функция np.lib.format.search\\_header() ищет заголовок 'DATA' в файле data.dat и возвращает его позицию. Затем функция np.fromfile() читает массив данных, начиная с заголовка 'DATA' в файле data.dat.\n",
      "\n",
      "В NumPy также есть функции для генерации матриц с определенными свойствами, например:\n",
      "\n",
      "* np.lib.format.write\\_header(fid, header, endian='<') - записывает заголовок header в файл fid.\n",
      "\n",
      "Например:\n",
      "\n",
      "```\n",
      "import numpy as np\n",
      "with open('data.dat', 'wb') as f:\n",
      "    np.lib.format.write_header(f, b'DATA', endian='<')\n",
      "    np.array([1, 2, 3], dtype=int).tofile(f)\n",
      "```\n",
      "\n",
      "В этом примере функция np.lib.format.write\\_header() записывает заголовок 'DATA' в файл data.dat. Затем функция np.array().tofile() записывает массив данных в файл data.dat.\n",
      "\n",
      "В NumPy также есть функции для генерации матриц с определенными свойствами, например:\n",
      "\n",
      "* np.lib.format.read\\_magic(fid) - читает magic number из файла fid и возвращает его.\n",
      "\n",
      "Например:\n",
      "\n",
      "```\n",
      "import numpy as np\n",
      "with open('data.npy', 'rb') as f:\n",
      "    magic = np.lib.format.read_magic(f)\n",
      "print(magic) # печатает magic number файла data.npy\n",
      "```\n",
      "\n",
      "В этом примере функция np.lib.format.read\\_magic() читает magic number из файла data.npy и возвращает его.\n",
      "\n",
      "В NumPy также есть функции для генерации матриц с определенными свойствами, например:\n",
      "\n",
      "* np.lib.format.write\\_magic(fid, magic) - записывает magic number magic в файл fid.\n",
      "\n",
      "Например:\n",
      "\n",
      "```\n",
      "import numpy as np\n",
      "with open('data.npy', 'wb') as f:\n",
      "    np.lib.format.write_magic(f, np.NPY\\_MAGIC\\_NONE)\n",
      "    np.array([1, 2, 3], dtype=int).tofile(f)\n",
      "```\n",
      "\n",
      "В этом примере функция np.lib.format.write\\_magic() записывает magic number np.NPY\\_MAGIC\\_NONE в файл data.npy. Затем функция np.array().tofile() записывает массив данных в файл data.npy.\n",
      "\n",
      "В NumPy также есть функции для генерации матриц с определенными свойствами, например:\n",
      "\n",
      "* np.lib.format.guess\\_array\\_type(fid, max\\_header\\_bytes=64) - угадывает тип массива данных, записанного в файле fid, и возвращает его.\n",
      "\n",
      "Например:\n",
      "\n",
      "```\n",
      "import numpy as np\n",
      "with open('data.dat', 'rb') as f:\n",
      "    dtype = np.lib.format.guess_array_type(f)\n",
      "arr = np.fromfile(f, dtype=dtype)\n",
      "print(arr) # печатает массив данных, угаданный функцией guess\\_array\\_type()\n",
      "```\n",
      "\n",
      "В этом примере функция np.lib.format.guess\\_array\\_type() угадывает тип массива данных, записанного в файле data.dat, и возвращает его. Затем функция np.fromfile() читает массив данных с угаданным типом.\n",
      "\n",
      "В NumPy также есть функции для генерации матриц с определенными свойствами, например:\n",
      "\n",
      "* np.lib.format.deserialize(fid) - десериализует объект Python, записанный в файл fid, и возвращает его.\n",
      "\n",
      "Например:\n",
      "\n",
      "```\n",
      "import numpy as np\n",
      "with open('data.pkl', 'rb') as f:\n",
      "    obj = np.lib.format.deserialize(f)\n",
      "print(obj) # печатает объект Python, десериализованный из файла data.pkl\n",
      "```\n",
      "\n",
      "В этом примере функция np.lib.format.deserialize() десериализует объект Python, записанный в файл data.pkl, и возвращает его.\n",
      "\n",
      "В NumPy также есть функции для генерации матриц с определенными свойствами, например:\n",
      "\n",
      "* np.lib.format.serialize(fid, obj) - сериализует объект Python obj и записывает его в файл fid.\n",
      "\n",
      "Например:\n",
      "\n",
      "```\n",
      "import numpy as np\n",
      "obj = np.array([1, 2, 3], dtype=int)\n",
      "with open('data.pkl', 'wb') as f:\n",
      "    np.lib.format.serialize(f, obj)\n",
      "```\n",
      "\n",
      "В этом примере функция np.lib.format.serialize() сериализует объект Python obj и записывает его в файл data.pkl.\n",
      "\n",
      "В NumPy также есть функции для генерации матриц с определенными свойствами, например:\n",
      "\n",
      "* np.lib.format.open\\_memmap\\_file(filename, mode='r', shape=None, dtype=<type 'numpy.float64'>, order='C') - открывает файл filename в формате memmap и возвращает объект, похожий на файловый объект.\n",
      "\n",
      "Например:\n",
      "\n",
      "```\n",
      "import numpy as np\n",
      "arr = np.lib.format.open_memmap_file('data.dat', mode='r', dtype=int, shape=(100, 100))\n",
      "print(arr) # печатает массив данных, сохраненный в файле data.dat\n",
      "```\n",
      "\n",
      "В этом примере функция np.lib.format.open\\_memmap\\_file() открывает файл data.dat в формате memmap и возвращает объект, похожий на файловый объект.\n",
      "\n",
      "В NumPy также есть функции для генерации матриц с определенными свойствами, например:\n",
      "\n",
      "* np.lib.format.open\\_memmap(filename, mode='r', dtype=<type 'numpy.float64'>, shape=None) - открывает файл filename в формате memmap и возвращает объект, похожий на файловый объект.\n",
      "\n",
      "Например:\n",
      "\n",
      "```\n",
      "import numpy as np\n",
      "arr = np.lib.format.open_memmap('data.dat', mode='r', dtype=int, shape=(100, 100))\n",
      "print(arr) # печатает массив данных, сохраненный в файле data.dat\n",
      "```\n",
      "\n",
      "В этом примере функция np.lib.format.open\\_memmap() открывает файл data.dat в формате memmap и возвращает объект, похожий на файловый объект.\n",
      "\n",
      "В NumPy также есть функции для генерации матриц с определенными свойствами, например:\n",
      "\n",
      "* np.lib.format.fortran\\_order - устанавливает порядок байтов 'C' или 'Fortran' для записи или чтения файлов.\n",
      "\n",
      "Например:\n",
      "\n",
      "```\n",
      "import numpy as np\n",
      "arr = np.array([[1, 2], [3, 4]])\n",
      "np.save('data.npy', arr, order=np.lib.format.fortran_order)\n",
      "```\n",
      "\n",
      "В этом примере функция np.lib.format.fortran\\_order() устанавливает порядок байтов 'Fortran' для записи файла data.npy.\n",
      "\n",
      "В NumPy также есть функции для генерации матриц с определенными свойствами, например:\n",
      "\n",
      "* np.lib.format.python\\_native\\_byteorder - возвращает текущий порядок байтов Python.\n",
      "\n",
      "Например:\n",
      "\n",
      "```\n",
      "import numpy as np\n",
      "byteorder = np.lib.format.python_native_byteorder()\n",
      "print(byteorder) # печатает текущий порядок байтов Python\n",
      "```\n",
      "\n",
      "В этом примере функция np.lib.format.python\\_native\\_byteorder() возвращает текущий порядок байтов Python.\n",
      "\n",
      "В NumPy также есть функции для генерации матриц с определенными свойствами, например:\n",
      "\n",
      "* np.lib.format.swapped\\_byteorder - устанавливает порядок байтов 'C' или 'Fortran' для записи или чтения файлов.\n",
      "\n",
      "Например:\n",
      "\n",
      "```\n",
      "import numpy as np\n",
      "arr = np.array([[1, 2], [3, 4]])\n",
      "np.save('data.npy', arr, order=np.lib.format.swapped_byteorder)\n",
      "```\n",
      "\n",
      "В этом примере функция np.lib.format.swapped\\_byteorder() устанавливает порядок байтов 'C' для записи файла data.npy, если текущий порядок байтов Python 'Fortran', и наоборот.\n",
      "\n",
      "В NumPy также есть функции для генерации матриц с определенными свойствами, например:\n",
      "\n",
      "* np.lib.format.byteswap(a) - меняет порядок байтов в массиве a.\n",
      "\n",
      "Например:\n",
      "\n",
      "```\n",
      "import numpy as np\n",
      "arr = np.array([[1, 2], [3, 4]], dtype=np.int16)\n",
      "arr_swapped = np.lib.format.byteswap(arr)\n",
      "print(arr_swapped) # печатает массив данных, у которого порядок байтов был изменен\n",
      "```\n",
      "\n",
      "В этом примере функция np.lib.format.byteswap() меняет порядок байтов в массиве arr.\n",
      "\n",
      "В NumPy также есть функции для генерации матриц с определенными свойствами, например:\n",
      "\n",
      "* np.lib.format.byte\\_bounds(a) - возвращает границы каждого элемента массива a в байтах.\n",
      "\n",
      "Например:\n",
      "\n",
      "```\n",
      "import numpy as np\n",
      "arr = np.array([[1, 2], [3, 4]], dtype=np.int16)\n",
      "bounds = np.lib.format.byte_bounds(arr)\n",
      "print(bounds) # печатает границы каждого элемента массива arr в байтах\n",
      "```\n",
      "\n",
      "В этом примере функция np.lib.format.byte\\_bounds() возвращает границы каждого элемента массива arr в байтах.\n",
      "\n",
      "В NumPy также есть функции для генерации матриц с определенными свойствами, например:\n",
      "\n",
      "* np.lib.format.contiguous\\_segments(a) - возвращает список сегментов, из которых состоит массив a, если он не является контигуозным.\n",
      "\n",
      "Например:\n",
      "\n",
      "```\n",
      "import numpy as np\n",
      "arr = np.array([[1, 2], [3, 4]], dtype=np.int16)\n",
      "arr = np.lib.stride_tricks.as_strided(arr, shape=(4,), strides=(2,))\n",
      "segments = np.lib.format.contiguous_segments(arr)\n",
      "print(segments) # печатает список сегментов, из которых состоит массив arr\n",
      "```\n",
      "\n",
      "В этом примере функция np.lib.format.contiguous\\_segments() возвращает список сегментов, из которых состоит массив arr, если он не является контигуозным.\n",
      "\n",
      "В NumPy также есть функции для генерации матриц с определенными свойствами, например:\n",
      "\n",
      "* np.lib.format.alignment\\_offset(a, offset=8) - возвращает смещение offsets, необходимое для выравнивания элементов массива a по границе alignment.\n",
      "\n",
      "Например:\n",
      "\n",
      "```\n",
      "import numpy as np\n",
      "arr = np.array([[1, 2], [3, 4]], dtype=np.int16)\n",
      "offset = np.lib.format.alignment_offset(arr, offset=8)\n",
      "print(offset) # печатает смещение, необходимое для выравнивания элементов массива arr по границе 8 байтов\n",
      "```\n",
      "\n",
      "В этом примере функция np.lib.format.alignment\\_offset() возвращает смещение, необходимое для выравнивания элементов массива arr по границе 8 байтов.\n",
      "\n",
      "В NumPy также есть функции для генерации матриц с определенными свойствами, например:\n",
      "\n",
      "* np.lib.format.aligned\\_copy(src, dst, alignment=8) - копирует данные из массива src в массив dst, выровняв их по границе alignment.\n",
      "\n",
      "Например:\n",
      "\n",
      "```\n",
      "import numpy as np\n",
      "src = np.array([[1, 2], [3, 4]], dtype=np.int16)\n",
      "dst = np.empty_like(src)\n",
      "np.lib.format.aligned_copy(src, dst, alignment=8)\n",
      "print(dst) # печатает массив данных, скопированный с выравниванием по границе 8 байтов\n",
      "```\n",
      "\n",
      "В этом примере функция np.lib.format.aligned\\_copy() копирует данные из массива src в массив dst, выровняв их по границе 8 байтов.\n",
      "\n",
      "В NumPy также есть функции для генерации матриц с определенными свойствами, например:\n",
      "\n",
      "* np.lib.format.aligned\\_alloc(shape, dtype=float, alignment=8) - выделяет память под массив данных, выравненный по границе alignment.\n",
      "\n",
      "Например:\n",
      "\n",
      "```\n",
      "import numpy as np\n",
      "arr = np.lib.format.aligned_alloc(shape=(100, 100), dtype=np.int16, alignment=8)\n",
      "print(arr) # печатает массив данных, выделенный с выравниванием по границе 8 байтов\n",
      "```\n",
      "\n",
      "В этом примере функция np.lib.format.aligned\\_alloc() выделяет память под массив данных, выровненный по границе 8 байтов.\n",
      "\n",
      "В NumPy также есть функции для генерации матриц с определенными свойствами, например:\n",
      "\n",
      "* np.lib.format.aligned\\_zeros(shape, dtype=float, alignment=8) - создает массив нулей, выровненный по границе alignment.\n",
      "\n",
      "Например:\n",
      "\n",
      "```\n",
      "import numpy as np\n",
      "arr = np.lib.format.aligned_zeros(shape=(100, 100), dtype=np.int16, alignment=8)\n",
      "print(arr) # печатает массив нулей, выровненный по границе 8 байтов\n",
      "```\n",
      "\n",
      "В этом примере функция np.lib.format.aligned\\_zeros() создает массив нулей, выровненный по границе 8 байтов.\n",
      "\n",
      "В NumPy также есть функции для генерации матриц с определенными свойствами, например:\n",
      "\n",
      "* np.lib.format.zeros(shape, dtype=float) - создает массив нулей заданной формы и типа.\n",
      "\n",
      "Например:\n",
      "\n",
      "```\n",
      "import numpy as np\n",
      "arr = np.lib.format.zeros(shape=(100, 100), dtype=np.int16)\n",
      "print(arr) # печатает массив нулей заданной формы и типа\n",
      "```\n",
      "\n",
      "В этом примере функция np.lib.format.zeros() создает массив нулей заданной формы и типа.\n",
      "\n",
      "В NumPy также есть функции для генерации матриц с определенными свойствами, например:\n",
      "\n",
      "* np.lib.format.empty(shape, dtype=float) - создает пустой массив заданной формы и типа.\n",
      "\n",
      "Например:\n",
      "\n",
      "```\n",
      "import numpy as np\n",
      "arr = np.lib.format.empty(shape=(100, 100), dtype=np.int16)\n",
      "print(arr) # печатает пустой массив заданной формы и типа\n",
      "```\n",
      "\n",
      "В этом примере функция np.lib.format.empty() создает пустой массив заданной формы и типа.\n",
      "\n",
      "В NumPy также есть функции для генерации матриц с определенными свойствами, например:\n",
      "\n",
      "* np.lib.format.empty\\_like(a, dtype=None, order='K') - создает пустой массив, похожий на массив a.\n",
      "\n",
      "Например:\n",
      "\n",
      "```\n",
      "import numpy as np\n",
      "arr = np.array([[1, 2], [3, 4]], dtype=np.int16)\n",
      "arr_empty = np.lib.format.empty_like(arr)\n",
      "print(arr_empty) # печатает пустой массив, похожий на массив arr\n",
      "```\n",
      "\n",
      "В этом примере функция np.lib.format.empty\\_like() создает пустой массив, похожий на массив arr.\n",
      "\n",
      "В NumPy также есть функции для генерации матриц с определенными свойствами, например:\n",
      "\n",
      "* np.lib.format.zeros\\_like(a, dtype=None, order='K') - создает массив нулей, похожий на массив a.\n",
      "\n",
      "Например:\n",
      "\n",
      "```\n",
      "import numpy as np\n",
      "arr = np.array([[1, 2], [3, 4]], dtype=np.int16)\n",
      "arr_zeros = np.lib.format.zeros_like(arr)\n",
      "print(arr_zeros) # печатает массив нулей, похожий на массив arr\n",
      "```\n",
      "\n",
      "В этом примере функция np.lib.format.zeros\\_like() создает массив нулей, похожий на массив arr.\n",
      "\n",
      "В NumPy также есть функции для генерации матриц с определенными свойствами, например:\n",
      "\n",
      "* np.lib.format.ones(shape, dtype=float) - создает массив единиц заданной формы и типа.\n",
      "\n",
      "Например:\n",
      "\n",
      "```\n",
      "import numpy as np\n",
      "arr = np.lib.format.ones(shape=(100, 100), dtype=np.int16)\n",
      "print(arr) # печатает массив единиц заданной формы и типа\n",
      "```\n",
      "\n",
      "В этом примере функция np.lib.format.ones() создает массив единиц заданной формы и типа.\n",
      "\n",
      "В NumPy также есть функции для генерации матриц с определенными свойствами, например:\n",
      "\n",
      "* np.lib.format.ones\\_like(a, dtype=None, order='K') - создает массив единиц, похожий на массив a.\n",
      "\n",
      "Например:\n",
      "\n",
      "```\n",
      "import numpy as np\n",
      "arr = np.array([[1, 2], [3, 4]], dtype=np.int16)\n",
      "arr_ones = np.lib.format.ones_like(arr)\n",
      "print(arr_ones) # печатает массив единиц, похожий на массив arr\n",
      "```\n",
      "\n",
      "В этом примере функция np.lib.format.ones\\_like() создает массив единиц, похожий на массив arr.\n",
      "\n",
      "В NumPy также есть функции для генерации матриц с определенными свойствами, например:\n",
      "\n",
      "* np.lib.format.eye(N, M=None, k=0, dtype=<type 'float'>) - создает единичную матрицу заданной размерности.\n",
      "\n",
      "Например:\n",
      "\n",
      "```\n",
      "import numpy as np\n",
      "arr = np.lib.format.eye(N=3)\n",
      "print(arr) # печатает единичную матрицу заданной размерности\n",
      "```\n",
      "\n",
      "В этом примере функция np.lib.format.eye() создает единичную матрицу заданной размерности.\n",
      "\n",
      "В NumPy также есть функции для генерации матриц с определенными свойствами, например:\n",
      "\n",
      "* np.lib.format.identity(n, dtype=float) - создает единичную матрицу заданной размерности.\n",
      "\n",
      "Например:\n",
      "\n",
      "```\n",
      "import numpy as np\n",
      "arr = np.lib.format.identity(n=3)\n",
      "print(arr) # печатает единичную матрицу заданной размерности\n",
      "```\n",
      "\n",
      "В этом примере функция np.lib.format.identity() создает единичную матрицу заданной размерности.\n",
      "\n",
      "В NumPy также есть функции для генерации матриц с определенными свойствами, например:\n",
      "\n",
      "* np.lib.format.full(shape, fill\\_value, dtype=None, order='C') - создает массив заданной формы, заполненный значением fill\\_value.\n",
      "\n",
      "Например:\n",
      "\n",
      "```\n",
      "import numpy as np\n",
      "arr = np.lib.format.full(shape=(100, 100), fill_value=5, dtype=np.int16)\n",
      "print(arr) # печатает массив заданной формы, заполненный значением 5\n",
      "```\n",
      "\n",
      "В этом примере функция np.lib.format.full() создает массив заданной формы, заполненный значением 5.\n",
      "\n",
      "В NumPy также есть функции для генерации матриц с определенными свойствами, например:\n",
      "\n",
      "* np.lib.format.full\\_like(a, fill\\_value, dtype=None, order='K') - создает массив, похожий на массив a, заполненный значением fill\\_value.\n",
      "\n",
      "Например:\n",
      "\n",
      "```\n",
      "import numpy as np\n",
      "arr = np.array([[1, 2], [3, 4]], dtype=np.int16)\n",
      "arr_full = np.lib.format.full_like(arr, fill_value=5)\n",
      "print(arr_full) # печатает массив, похожий на массив arr, заполненный значением 5\n",
      "```\n",
      "\n",
      "В этом примере функция np.lib.format.full\\_like() создает массив, похожий на массив arr, заполненный значением 5.\n",
      "\n",
      "В NumPy также есть функции для генерации матриц с определенными свойствами, например:\n",
      "\n",
      "* np.lib.format.arange(start, stop, step, dtype=None) - создает массив заданного диапазона значений.\n",
      "\n",
      "Например:\n",
      "\n",
      "```\n",
      "import numpy as np\n",
      "arr = np.lib.format.arange(start=0, stop=10, step=2, dtype=np.int16)\n",
      "print(arr) # печатает массив заданного диапазона значений\n",
      "```\n",
      "\n",
      "В этом примере функция np.lib.format.arange() создает массив заданного диапазона значений.\n",
      "\n",
      "В NumPy также есть функции для генерации матриц с определенными свойствами, например:\n",
      "\n",
      "* np.lib.format.linspace(start, stop, num, endpoint=True, retstep=False, dtype=None) - создает массив заданного диапазона значений с равномерным распределением.\n",
      "\n",
      "Например:\n",
      "\n",
      "```\n",
      "import numpy as np\n",
      "arr = np.lib.format.linspace(start=0, stop=10, num=5, dtype=np.int16)\n",
      "print(arr) # печатает массив заданного диапазона значений с равномерным распределением\n",
      "```\n",
      "\n",
      "В этом примере функция np.lib.format.linspace() создает массив заданного диапазона значений с равномерным распределением.\n",
      "\n",
      "В NumPy также есть функции для генерации матриц с определенными свойствами, например:\n",
      "\n",
      "* np.lib.format.logspace(start, stop, num, endpoint=True, base=10.0, dtype=None) - создает массив заданного диапазона значений с логарифмическим распределением.\n",
      "\n",
      "Например:\n",
      "\n",
      "```\n",
      "import numpy as np\n",
      "arr = np.lib.format.logspace(start=0, stop=10, num=5, base=2, dtype=np.int16)\n",
      "print(arr) # печатает массив заданного диапазона значений с логарифмическим распределением\n",
      "```\n",
      "\n",
      "В этом примере функция np.lib.format.logspace() создает массив заданного диапазона значений с логарифмическим распределением.\n",
      "\n",
      "В NumPy также есть функции для генерации матриц с определенными свойствами, например:\n",
      "\n",
      "* np.lib.format.geomspace(start, stop, num, endpoint=True, dtype=None) - создает массив заданного диапазона значений с геометрическим распределением.\n",
      "\n",
      "Например:\n",
      "\n",
      "```\n",
      "import numpy as np\n",
      "arr = np.lib.format.geomspace(start=1, stop=100, num=5, dtype=np.int16)\n",
      "print(arr) # печатает массив заданного диапазона значений с геометрическим распределением\n",
      "```\n",
      "\n",
      "В этом примере функция np.lib.format.geomspace() создает массив заданного диапазона значений с геометрическим распределением.\n",
      "\n",
      "В NumPy также есть функции для генерации матриц с определенными свойствами, например:\n",
      "\n",
      "* np.lib.format.rand(d0, d1, ..., dn) - создает массив заданной размерности, заполненный случайными числами.\n",
      "\n",
      "Например:\n",
      "\n",
      "```\n",
      "import numpy as np\n",
      "arr = np.lib.format.rand(100, 100)\n",
      "print(arr) # печатает массив заданной размерности, заполненный случайными числами\n",
      "```\n",
      "\n",
      "В этом примере функция np.lib.format.rand() создает массив заданной размерности, заполненный случайными числами.\n",
      "\n",
      "В NumPy также есть функции для генерации матриц с определенными свойствами, например:\n",
      "\n",
      "* np.lib.format.randint(low, high=None, size=None, dtype='l') - создает массив заданной размерности, заполненный случайными целыми числами.\n",
      "\n",
      "Например:\n",
      "\n",
      "```\n",
      "import numpy as np\n",
      "arr = np.lib.format.randint(low=0, high=100, size=(100, 100))\n",
      "print(arr) # печатает массив заданной размерности, заполненный случайными целыми числами\n",
      "```\n",
      "\n",
      "В этом примере функция np.lib.format.randint() создает массив заданной размерности, заполненный случайными целыми числами.\n",
      "\n",
      "В NumPy также есть функции для генерации матриц с определенными свойствами, например:\n",
      "\n",
      "* np.lib.format.random\\_sample(size=None) - создает массив заданной размерности, заполненный случайными числами.\n",
      "\n",
      "Например:\n",
      "\n",
      "```\n",
      "import numpy as np\n",
      "arr = np.lib.format.random_sample(size=(100, 100))\n",
      "print(arr) # печатает массив заданной размерности, заполненный случайными числами\n",
      "```\n",
      "\n",
      "В этом примере функция np.lib.format.random\\_sample() создает массив заданной размерности, заполненный случайными числами.\n",
      "\n",
      "В NumPy также есть функции для генерации матриц с определенными свойствами, например:\n",
      "\n",
      "* np.lib.format.random\\_samples(size) - создает массив заданной размерности, заполненный случайными числами.\n",
      "\n",
      "Например:\n",
      "\n",
      "```\n",
      "import numpy as np\n",
      "arr = np.lib.format.random_samples(size=(100, 100))\n",
      "print(arr) # печатает массив заданной размерности, заполненный случайными числами\n",
      "```\n",
      "\n",
      "В этом примере функция np.lib.format.random\\_samples() создает массив заданной размерности, заполненный случайными числами.\n",
      "\n",
      "В NumPy также есть функции для генерации матриц с определенными свойствами, например:\n",
      "\n",
      "* np.lib.format.random\\_sample\\_bivariate\\_normal(mean, cov, size) - создает массив заданной размерности, заполненный случайными числами, распределенными бивариатно-нормально.\n",
      "\n",
      "Например:\n",
      "\n",
      "```\n",
      "import numpy as np\n",
      "mean = np.array([0, 0])\n",
      "cov = np.array([[1, 0], [0, 1]])\n",
      "arr = np.lib.format.random_sample_bivariate_normal(mean, cov, size=(100, 100))\n",
      "print(arr) # печатает массив заданной размерности, заполненный случайными числами, распределенными бивариатно-нормально\n",
      "```\n",
      "\n",
      "В этом примере функция np.lib.format.random\\_sample\\_bivariate\\_normal() создает массив заданной размерности, заполненный случайными числами, распределенными бивариатно-нормально.\n",
      "\n",
      "В NumPy также есть функции для генерации матриц с определенными свойствами, например:\n",
      "\n",
      "* np.lib.format.random\\_integers(low, high=None, size=None) - создает массив заданной размерности, заполненный случайными целыми числами.\n",
      "\n",
      "Например:\n",
      "\n",
      "```\n",
      "import numpy as np\n",
      "arr = np.lib.format.random_integers(low=0, high=100, size=(100, 100))\n",
      "print(arr) # печатает массив заданной размерности, заполненный случайными целыми числами\n",
      "```\n",
      "\n",
      "В этом примере функция np.lib.format.random\\_integers() создает массив заданной размерности, заполненный случайными целыми числами.\n",
      "\n",
      "В NumPy также есть функции для генерации матриц с определенными свойствами, например:\n",
      "\n",
      "* np.lib.format.random\\_permutation(x) - создает массив, полученный из массива x путём случайной перестановки его элементов.\n",
      "\n",
      "Например:\n",
      "\n",
      "```\n",
      "import numpy as np\n",
      "arr = np.array([1, 2, 3, 4, 5])\n",
      "arr_perm = np.lib.format.random_permutation(arr)\n",
      "print(arr_perm) # печатает массив, полученный из массива arr путём случайной перестановки его элементов\n",
      "```\n",
      "\n",
      "В этом примере функция np.lib.format.random\\_permutation() создает массив, полученный из массива arr путём случайной перестановки его элементов.\n",
      "\n",
      "В NumPy также есть функции для генерации матриц с определенными свойствами, например:\n",
      "\n",
      "* np.lib.format.random\\_choice(a, size=None, replace=True, p=None) - создает массив заданной размерности, заполненный случайно выбранными элементами из массива a.\n",
      "\n",
      "Например:\n",
      "\n",
      "```\n",
      "import numpy as np\n",
      "arr = np.array([1, 2, 3, 4, 5])\n",
      "arr_choice = np.lib.format.random_choice(arr, size=(100, 100), replace=True)\n",
      "print(arr_choice) # печатает массив заданной размерности, заполненный случайно выбранными элементами из массива arr\n",
      "```\n",
      "\n",
      "В этом примере функция np.lib.format.random\\_choice() создает массив заданной размерности, заполненный случайно выбранными элементами из массива arr.\n",
      "\n",
      "В NumPy также есть функции для генерации матриц с определенными свойствами, например:\n",
      "\n",
      "* np.lib.format.random\\_shuffle(x) - перемешивает элементы массива x в случайном порядке.\n",
      "\n",
      "Например:\n",
      "\n",
      "```\n",
      "import numpy as np\n",
      "arr = np.array([1, 2, 3, 4, 5])\n",
      "np.lib.format.random_shuffle(arr)\n",
      "print(arr) # печатает массив, элементы которого перемешаны в случайном порядке\n",
      "```\n",
      "\n",
      "В этом примере функция np.lib.format.random\\_shuffle() перемешивает элементы массива arr в случайном порядке.\n",
      "\n",
      "В NumPy также есть функции для генерации матриц с определенными свойствами, например:\n",
      "\n",
      "* np.lib.format.random\\_bytes(length) - создает массив заданной длины, заполненный случайными байтами.\n",
      "\n",
      "Например:\n",
      "\n",
      "```\n",
      "import numpy as np\n",
      "arr = np.lib.format.random_bytes(length=100)\n",
      "print(arr) # печатает массив заданной длины, заполненный случайными байтами\n",
      "```\n",
      "\n",
      "В этом примере функция np.lib.format.random\\_bytes() создает массив заданной длины, заполненный случайными байтами.\n",
      "\n",
      "В NumPy также есть функции для генерации матриц с определенными свойствами, например:\n",
      "\n",
      "* np.lib.format.random\\_seed(seed=None) - устанавливает seed генератора случайных чисел.\n",
      "\n",
      "Например:\n",
      "\n",
      "```\n",
      "import numpy as np\n",
      "np.lib.format.random_seed(seed=1)\n",
      "arr = np.lib.format.rand(100, 100)\n",
      "print(arr) # печатает массив заданной размерности, заполненный случайными числами, сгенерированными с заданным seed\n",
      "```\n",
      "\n",
      "В этом примере функция np.lib.format.random\\_seed() устанавливает seed генератора случайных чисел, а затем создает массив заданной размерности, заполненный случайными числами, сгенерированными с заданным seed.\n",
      "\n",
      "В NumPy также есть функции для генерации матриц с определенными свойствами, например:\n",
      "\n",
      "* np.lib.format.standard\\_normal(size) - создает массив заданной размерности, заполненный случайными числами, распределенными стандартно-нормально.\n",
      "\n",
      "Например:\n",
      "\n",
      "```\n",
      "import numpy as np\n",
      "arr = np.lib.format.standard_normal(size=(100, 100))\n",
      "print(arr) # печатает массив заданной размерности, заполненный случайными числами, распределенными стандартно-нормально\n",
      "```\n",
      "\n",
      "В этом примере функция np.lib.format.standard\\_normal() создает массив заданной размерности, заполненный случайными числами, распределенными стандартно-нормально.\n",
      "\n",
      "В NumPy также есть функции для генерации матриц с определенными свойствами, например:\n",
      "\n",
      "* np.lib.format.normal(loc=0.0, scale=1.0, size=None) - создает массив заданной размерности, заполненный случайными числами, распределенными нормально.\n",
      "\n",
      "Например:\n",
      "\n",
      "```\n",
      "import numpy as np\n",
      "arr = np.lib.format.normal(loc=0, scale=1, size=(100, 100))\n",
      "print(arr) # печатает массив заданной размерности, заполненный случайными числами, распределенными нормально\n",
      "```\n",
      "\n",
      "В этом примере функция np.lib.format.normal() создает массив заданной размерности, заполненный случайными числами, распределенными нормально.\n",
      "\n",
      "В NumPy также есть функции для генерации матриц с определенными свойствами, например:\n",
      "\n",
      "* np.lib.format.exponential(scale=1.0, size=None) - создает массив заданной размерности, заполненный случайными числами, распределенными экспоненциально.\n",
      "\n",
      "Например:\n",
      "\n",
      "```\n",
      "import numpy as np\n",
      "arr = np.lib.format.exponential(scale=1, size=(100, 100))\n",
      "print(arr) # печатает массив заданной размерности, заполненный случайными числами, распределенными экспоненциально\n",
      "```\n",
      "\n",
      "В этом примере функция np.lib.format.exponential() создает массив заданной размерности, заполненный случайными числами, распределенными экспоненциально.\n",
      "\n",
      "В NumPy также есть функции для генерации матриц с определенными свойствами, например:\n",
      "\n",
      "* np.lib.format.gamma(shape, scale=1.0, size=None) - создает массив заданной размерности, заполненный случайными числами, распределенными гамма-распределением.\n",
      "\n",
      "Например:\n",
      "\n",
      "```\n",
      "import numpy as np\n",
      "arr = np.lib.format.gamma(shape=2, scale=1, size=(100, 100))\n",
      "print(arr) # печатает массив заданной размерности, заполненный случайными числами, распределенными гамма-распределением\n",
      "```\n",
      "\n",
      "В этом примере функция np.lib.format.gamma() создает массив заданной размерности, заполненный случайными числами, распределенными гамма-распределением.\n",
      "\n",
      "В NumPy также есть функции для генерации матриц с определенными свойствами, например:\n",
      "\n",
      "* np.lib.format.beta(a, b, size=None) - создает массив заданной размерности, заполненный случайными числами, распределенными бета-распределением.\n",
      "\n",
      "Например:\n",
      "\n",
      "```\n",
      "import numpy as np\n",
      "arr = np.lib.format.beta(a=2, b=2, size=(100, 100))\n",
      "print(arr) # печатает массив заданной размерности, заполненный случайными числами, распределенными бета-распределением\n",
      "```\n",
      "\n",
      "В этом примере функция np.lib.format.beta() создает массив заданной размерности, заполненный случайными числами, распределенными бета-распределением.\n",
      "\n",
      "В NumPy также есть функции для генерации матриц с определенными свойствами, например:\n",
      "\n",
      "* np.lib.format.poisson(lam=1.0, size=None) - создает массив заданной размерности, заполненный случайными числами, распределенными по распределению Пуассона.\n",
      "\n",
      "Например:\n",
      "\n",
      "```\n",
      "import numpy as np\n",
      "arr = np.lib.format.poisson(lam=2, size=(100, 100))\n",
      "print(arr) # печатает массив заданной размерности, заполненный случайными числами, распределенными по распределению Пуассона\n",
      "```\n",
      "\n",
      "В этом примере функция np.lib.format.poisson() создает массив заданной размерности, заполненный случайными числами, распределенными по распределению Пуассона.\n",
      "\n",
      "В NumPy также есть функции для генерации матриц с определенными свойствами, например:\n",
      "\n",
      "* np.lib.format.uniform(low=0.0, high=1.0, size=None) - создает массив заданной размерности, заполненный случайными числами, распределенными равномерно.\n",
      "\n",
      "Например:\n",
      "\n",
      "```\n",
      "import numpy as np\n",
      "arr = np.lib.format.uniform(low=0, high=1, size=(100, 100))\n",
      "print(arr) # печатает массив заданной размерности, заполненный случайными числами, распределенными равномерно\n",
      "```\n",
      "\n",
      "В этом примере функция np.lib.format.uniform() создает массив заданной размерности, заполненный случайными числами, распределенными равномерно.\n",
      "\n",
      "В NumPy также есть функции для генерации матриц с определенными свойствами, например:\n",
      "\n",
      "* np.lib.format.randint(low, high=None, size=None, dtype='l') - создает массив заданной размерности, заполненный случайными целыми числами.\n",
      "\n",
      "Например:\n",
      "\n",
      "```\n",
      "import numpy as np\n",
      "arr = np.lib.format.randint(low=0, high=100, size=(100, 100))\n",
      "print(arr) # печатает массив заданной размерности, заполненный случайными целыми числами\n",
      "```\n",
      "\n",
      "В этом примере функция np.lib.format.randint() создает массив заданной размерности, заполненный случайными целыми числами.\n",
      "\n",
      "В NumPy также есть функции для генерации матриц с определенными свойствами, например:\n",
      "\n",
      "* np.lib.format.randint(low, high=None, size=None, dtype='l') - создает массив заданной размерности, заполненный случайными целыми числами.\n",
      "\n",
      "Например:\n",
      "\n",
      "```\n",
      "import numpy as np\n",
      "arr = np.lib.format.randint(low=0, high=100, size=(100, 100))\n",
      "print(arr) # печатает массив заданной размерности, заполненный случайными целыми числами\n",
      "```\n",
      "\n",
      "В этом примере функция np.lib.format.randint() создает массив заданной размерности, заполненный случайными целыми числами.\n",
      "\n",
      "В NumPy также есть функции для генерации матриц с определенными свойствами, например:\n",
      "\n",
      "* np.lib.format.random\\_sample(size=None) - создает массив заданной размерности, заполненный случайными числами.\n",
      "\n",
      "Например:\n",
      "\n",
      "```\n",
      "import numpy as np\n",
      "arr = np.lib.format.random_sample(size=(100, 100))\n",
      "print(arr) # печатает массив заданной размерности, заполненный случайными числами\n",
      "```\n",
      "\n",
      "В этом примере функция np.lib.format.random\\_sample() создает массив заданной размерности, заполненный случайными числами.\n",
      "\n",
      "В NumPy также есть функции для генерации матриц с определенными свойствами, например:\n",
      "\n",
      "* np.lib.format.random\\_sample\\_bivariate\\_normal(mean, cov, size) - создает массив заданной размерности, заполненный случайными числами, распределенными бивариатно-нормально.\n",
      "\n",
      "Например:\n",
      "\n",
      "```\n",
      "import numpy as np\n",
      "mean = np.array([0, 0])\n",
      "cov = np.array([[1, 0], [0, 1]])\n",
      "arr = np.lib.format.random_sample_bivariate_normal(mean, cov, size=(100, 100))\n",
      "print(arr) # печатает массив заданной размерности, заполненный случайными числами, распределенными бивариатно-нормально\n",
      "```\n",
      "\n",
      "В этом примере функция np.lib.format.random\\_sample\\_bivariate\\_normal() создает массив заданной размерности, заполненный случайными числами, распределенными бивариатно-нормально.\n",
      "\n",
      "В NumPy также есть функции для генерации матриц с определенными свойствами, например:\n",
      "\n",
      "* np.lib.format.random\\_integers(low, high=None, size=None) - создает массив заданной размерности, заполненный случайными целыми числами.\n",
      "\n",
      "Например:\n",
      "\n",
      "```\n",
      "import numpy as np\n",
      "arr = np.lib.format.random_integers(low=0, high=100, size=(100, 100))\n",
      "print(arr) # печатает массив заданной размерности, заполненный случайными целыми числами\n",
      "```\n",
      "\n",
      "В этом примере функция np.lib.format.random\\_integers() создает массив заданной размерности, заполненный случайными целыми числами.\n",
      "\n",
      "В NumPy также есть функции для генерации матриц с определенными свойствами, например:\n",
      "\n",
      "* np.lib.format.random\\_permutation(x) - создает массив, полученный из массива x путём случайной перестановки его элементов.\n",
      "\n",
      "Например:\n",
      "\n",
      "```\n",
      "import numpy as np\n",
      "arr = np.array([1, 2, 3, 4, 5])\n",
      "arr_perm = np.lib.format.random_permutation(arr)\n",
      "print(arr_perm) # печатает массив, полученный из массива arr путём случайной перестановки его элементов\n",
      "```\n",
      "\n",
      "В этом примере функция np.lib.format.random\\_permutation() создает массив, полученный из массива arr путём случайной перестановки его элементов.\n",
      "\n",
      "В NumPy также есть функции для генерации матриц с определенными свойствами, например:\n",
      "\n",
      "* np.lib.format.random\\_choice(a, size=None, replace=True, p=None) - создает массив заданной размерности, заполненный случайно выбранными элементами из массива a.\n",
      "\n",
      "Например:\n",
      "\n",
      "```\n",
      "import numpy as np\n",
      "arr = np.array([1, 2, 3, 4, 5])\n",
      "arr\\_choice = np.lib.format.random\\_choice(arr, size=(100, 100), replace=True)\n",
      "print(arr\\_choice) # печатает массив заданной размерности, заполненный случайно выбранными элементами из массива arr\n",
      "```\n",
      "\n",
      "В этом примере функция np.lib.format.random\\_choice() создает массив заданной размерности, заполненный случайно выбранными элементами из массива arr.\n",
      "\n",
      "В NumPy также есть функции для генерации матриц с определенными свойствами, например:\n",
      "\n",
      "* np.lib.format.random\\_shuffle(x) - перемешивает элементы массива x в случайном порядке.\n",
      "\n",
      "Например:\n",
      "\n",
      "```\n",
      "import numpy as np\n",
      "arr = np.array([1, 2, 3, 4, 5])\n",
      "np.lib.format.random_shuffle(arr)\n",
      "print(arr) # печатает массив, элементы которого перемешаны в случайном порядке\n",
      "```\n",
      "\n",
      "В этом примере функция np.lib.format.random\\_shuffle() перемешивает элементы массива arr в случайном порядке.\n",
      "\n",
      "В NumPy также есть функции для генерации матриц с определенными свойствами, например:\n",
      "\n",
      "* np.lib.format.random\\_seed(seed=None) - устанавливает seed генератора случайных чисел.\n",
      "\n",
      "Например:\n",
      "\n",
      "```\n",
      "import numpy as np\n",
      "np.lib.format.random_seed(seed=1)\n",
      "arr = np.lib.format.rand(100, 100)\n",
      "print(arr) # печатает массив заданной размерности, заполненный случайными числами, сгенерированными с заданным seed\n",
      "```\n",
      "\n",
      "В этом примере функция np.lib.format.random\\_seed() устанавливает seed генератора случайных чисел, а затем создает массив заданной размерности, заполненный случайными числами, сгенерированными с заданным seed.\n",
      "\n",
      "В NumPy также есть функции для генерации матриц с определенными свойствами, например:\n",
      "\n",
      "* np.lib.format.random\\_sample(size=None) - создает массив заданной размерности, заполненный случайными числами.\n",
      "\n",
      "Например:\n",
      "\n",
      "```\n",
      "import numpy as np\n",
      "arr = np.lib.format.random_sample(size=(100, 100))\n",
      "print(arr) # печатает массив заданной размерности, заполненный случайными числами\n",
      "```\n",
      "\n",
      "В этом примере функция np.lib.format.random\\_sample() создает массив заданной размерности, заполненный случайными числами.\n",
      "\n",
      "В NumPy также есть функции для генерации матриц с определенными свойствами, например:\n",
      "\n",
      "* np.lib.format.standard\\_normal(size) - создает массив заданной размерности, заполненный случайными числами, распределенными стандартно-нормально.\n",
      "\n",
      "Например:\n",
      "\n",
      "```\n",
      "import numpy as np\n",
      "arr = np.lib.format.standard_normal(size=(100, 100))\n",
      "print(arr) # печатает массив заданной размерности, заполненный случайными числами, распределенными стандартно-нормально\n",
      "```\n",
      "\n",
      "В этом примере функция np.lib.format.standard\\_normal() создает массив заданной размерности, заполненный случайными числами, распределенными стандартно-нормально.\n",
      "\n",
      "В NumPy также есть функции для генерации матриц с определенными свойствами, например:\n",
      "\n",
      "* np.lib.format.normal(loc=0.0, scale=1.0, size=None) - создает массив заданной размерности, заполненный случайными числами, распределенными нормально.\n",
      "\n",
      "Например:\n",
      "\n",
      "```\n",
      "import numpy as np\n",
      "arr = np.lib.format.normal(loc=0, scale=1, size=(100, 100))\n",
      "print(arr) # печатает массив заданной размерности, заполненный случайными числами, распределенными нормально\n",
      "```\n",
      "\n",
      "В этом примере функция np.lib.format.normal() создает массив заданной размерности, заполненный случайными числами, распределенными нормально.\n",
      "\n",
      "В NumPy также есть функции для генерации матриц с определенными свойствами, например:\n",
      "\n",
      "* np.lib.format.exponential(scale=1.0, size=None) - создает массив заданной размерности, заполненный случайными числами, распределенными экспоненциально.\n",
      "\n",
      "Например:\n",
      "\n",
      "```\n",
      "import numpy as np\n",
      "arr = np.lib.format.exponential(scale=1, size=(100, 100))\n",
      "print(arr) # печатает массив заданной размерности, заполненный случайными числами, распределенными экспоненциально\n",
      "```\n",
      "\n",
      "В этом примере функция np.lib.format.exponential() создает массив заданной размерности, заполненный случайными числами, распределенными экспоненциально.\n",
      "\n",
      "В NumPy также есть функции для генерации матриц с определенными свойствами, например:\n",
      "\n",
      "* np.lib.format.gamma(shape, scale=1.0, size=None) - создает массив заданной размерности, заполненный случайными числами, распределенными гамма-распределением.\n",
      "\n",
      "Например:\n",
      "\n",
      "```\n",
      "import numpy as np\n",
      "arr = np.lib.format.gamma(shape=2, scale=1, size=(100, 100))\n",
      "print(arr) # печатает массив заданной размерности, заполненный случайными числами, распределенными гамма-распределением\n",
      "```\n",
      "\n",
      "В этом примере функция np.lib.format.gamma() создает массив заданной размерности, заполненный случайными числами, распределенными гамма-распределением.\n",
      "\n",
      "В NumPy также есть функции для генерации матриц с определенными свойствами, например:\n",
      "\n",
      "* np.lib.format.beta(a, b, size=None) - создает массив заданной размерности, заполненный случайными числами, распределенными бета-распределением.\n",
      "\n",
      "Например:\n",
      "\n",
      "```\n",
      "import numpy as np\n",
      "arr = np.lib.format.beta(a=2, b=2, size=(100, 100))\n",
      "print(arr) # печатает массив заданной размерности, заполненный случайными числами, распределенными бета-распределением\n",
      "```\n",
      "\n",
      "В этом примере функция np.lib.format.beta() создает массив заданной размерности, заполненный случайными числами, распределенными бета-распределением.\n",
      "\n",
      "В NumPy также есть функции для генерации матриц с определенными свойствами, например:\n",
      "\n",
      "* np.lib.format.poisson(lam=1.0, size=None) - создает массив заданной размерности, заполненный случайными числами, распределенными по распределению Пуассона.\n",
      "\n",
      "Например:\n",
      "\n",
      "```\n",
      "import numpy as np\n",
      "arr = np.lib.format.poisson(lam=2, size=(100, 100))\n",
      "print(arr) # печатает массив заданной размерности, заполненный случайными числами, распределенными по распределению Пуассона\n",
      "```\n",
      "\n",
      "В этом примере функция np.lib.format.poisson() создает массив заданной размерности, заполненный случайными числами, распределенными по распределению Пуассона.\n",
      "\n",
      "В NumPy также есть функции для генерации матриц с определенными свойствами, например:\n",
      "\n",
      "* np.lib.format.uniform(low=0.0, high=1.0, size=None) - создает массив заданной размерности, заполненный случайными числами, распределенными равномерно.\n",
      "\n",
      "Например:\n",
      "\n",
      "```\n",
      "import numpy as np\n",
      "arr = np.lib.format.uniform(low=0, high=1, size=(100, 100))\n",
      "print(arr) # печатает массив заданной размерности, заполненный случайными числами, распределенными равномерно\n",
      "```\n",
      "\n",
      "В этом примере функция np.lib.format.uniform() создает массив заданной размерности, заполненный случайными числами, распределенными равномерно.\n",
      "\n",
      "В NumPy также есть функции для генерации матриц с определенными свойствами, например:\n",
      "\n",
      "* np.lib.format.randint(low, high=None, size=None, dtype='l') - создает массив заданной размерности, заполненный случайными целыми числами.\n",
      "\n",
      "Например:\n",
      "\n",
      "```\n",
      "import numpy as np\n",
      "arr = np.lib.format.randint(low=0, high=100, size=(100, 100))\n",
      "print(arr) # печатает массив заданной размерности, заполненный случайными целыми числами\n",
      "```\n",
      "\n",
      "В этом примере функция np.lib.format.randint() создает массив заданной размерности, заполненный случайными целыми числами.\n",
      "\n",
      "В NumPy также есть функции для генерации матриц с определенными свойствами, например:\n",
      "\n",
      "* np.lib.format.randint(low, high=None, size=None, dtype='l') - создает массив заданной размерности, заполненный случайными целыми числами.\n",
      "\n",
      "Например:\n",
      "\n",
      "```\n",
      "import numpy as np\n",
      "arr = np.lib.format.randint(low=0, high=100, size=(100, 100))\n",
      "print(arr) # печатает массив заданной размерности, заполненный случайными целыми числами\n",
      "```\n",
      "\n",
      "В этом примере функция np.lib.format.randint() создает массив заданной размерности, заполненный случайными целыми числами.\n",
      "\n",
      "В NumPy также есть функции для генерации матриц с определенными свойствами, например:\n",
      "\n",
      "* np.lib.format.random\\_sample(size=None) - создает массив заданной размерности, заполненный случайными числами.\n",
      "\n",
      "Например:\n",
      "\n",
      "```\n",
      "import numpy as np\n",
      "arr = np.lib.format.random_sample(size=(100, 100))\n",
      "print(arr) # печатает массив заданной размерности, заполненный случайными числами\n",
      "```\n",
      "\n",
      "В этом примере функция np.lib.format.random\\_sample() создает массив заданной размерности, заполненный случайными числами.\n",
      "\n",
      "В NumPy также есть функции для генерации матриц с определенными свойствами, например:\n",
      "\n",
      "* np.lib.format.random\\_sample\\_bivariate\\_normal(mean, cov, size) - создает массив заданной размерности, заполненный случайными числами, распределенными бивариатно-нормально.\n",
      "\n",
      "Например:\n",
      "\n",
      "```\n",
      "import numpy as np\n",
      "mean = np.array([0, 0])\n",
      "cov = np.array([[1, 0], [0, 1]])\n",
      "arr = np.lib.format.random_sample_bivariate_normal(mean, cov, size=(100, 100))\n",
      "print(arr) # печатает массив заданной размерности, заполненный случайными числами, распределенными бивариатно-нормально\n",
      "```\n",
      "\n",
      "В этом примере функция np.lib.format.random\\_sample\\_bivariate\\_normal() создает массив заданной размерности, заполненный случайными числами, распределенными бивариатно-нормально.\n",
      "\n",
      "В NumPy также есть функции для генерации матриц с определенными свойствами, например:\n",
      "\n",
      "* np.lib.format.random\\_integers(low, high=None, size=None) - создает массив заданной размерности, заполненный случайными целыми числами.\n",
      "\n",
      "Например:\n",
      "\n",
      "```\n",
      "import numpy as np\n",
      "arr = np.lib.format.random_integers(low=0, high=100, size=(100, 100))\n",
      "print(arr) # печатает массив заданной размерности, заполненный случайными целыми числами\n",
      "```\n",
      "\n",
      "В этом примере функция np.lib.format.random\\_integers() создает массив заданной размерности, заполненный случайными целыми числами.\n",
      "\n",
      "В NumPy также есть функции для генерации матриц с определенными свойствами, например:\n",
      "\n",
      "* np.lib.format.random\\_permutation(x) - создает массив, полученный из массива x путём случайной перестановки его элементов.\n",
      "\n",
      "Например:\n",
      "\n",
      "```\n",
      "import numpy as np\n",
      "arr = np.array([1, 2, 3, 4, 5])\n",
      "arr\\_perm = np.lib.format.random_permutation(arr)\n",
      "print(arr\\_perm) # печатает массив, полученный из массива arr путём случайной перестановки его элементов\n",
      "```\n",
      "\n",
      "В этом примере функция np.lib.format.random\\_permutation() создает массив, полученный из массива arr путём случайной перестановки его элементов.\n",
      "\n",
      "В NumPy также есть функции для генерации матриц с определенными свойствами, например:\n",
      "\n",
      "* np.lib.format.random\\_choice(a, size=None, replace=True, p=None) - создает массив заданной размерности, заполненный случайно выбранными элементами из массива a.\n",
      "\n",
      "Например:\n",
      "\n",
      "```\n",
      "import numpy as np\n",
      "arr = np.array([1, 2, 3, 4, 5])\n",
      "arr\\_choice = np.lib.format.random_choice(arr, size=(100, 100), replace=True)\n",
      "print(arr\\_choice) # печатает массив заданной размерности, заполненный случайно выбранными элементами из массива arr\n",
      "```\n",
      "\n",
      "В этом примере функция np.lib.format.random\\_choice() создает массив заданной размерности, заполненный случайно выбранными элементами из массива arr.\n",
      "\n",
      "В NumPy также есть функции для генерации матриц с определенными свойствами, например:\n",
      "\n",
      "* np.lib.format.random\\_shuffle(x) - перемешивает элементы массива x в случайном порядке.\n",
      "\n",
      "Например:\n",
      "\n",
      "```\n",
      "import numpy as np\n",
      "arr = np.array([1, 2, 3, 4, 5])\n",
      "np.lib.format.random_shuffle(arr)\n",
      "print(arr) # печатает массив, элементы которого перемешаны в случайном порядке\n",
      "```\n",
      "\n",
      "В этом примере функция np.lib.format.random\\_shuffle() перемешивает элементы массива arr в случайном порядке.\n",
      "\n",
      "В NumPy также есть функции для генерации матриц с определенными свойствами, например:\n",
      "\n",
      "* np.lib.format.random\\_seed(seed=None) - устанавливает seed генератора случайных чисел.\n",
      "\n",
      "Например:\n",
      "\n",
      "```\n",
      "import numpy as np\n",
      "np.lib.format.random_seed(seed=1)\n",
      "arr = np.lib.format.rand(100, 100)\n",
      "print(arr) # печатает массив заданной размерности, заполненный случайными числами, сгенерированными с заданным seed\n",
      "```\n",
      "\n",
      "В этом примере функция np.lib.format.random\\_seed() устанавливает seed генератора случайных чисел, а затем создает массив заданной размерности, заполненный случайными числами, сгенерированными с заданным seed.\n",
      "\n",
      "В NumPy также есть функции для генерации матриц с определенными свойствами, например:\n",
      "\n",
      "* np.lib.format.random\\_sample(size=None) - создает массив заданной размерности, заполненный случайными числами.\n",
      "\n",
      "Например:\n",
      "\n",
      "```\n",
      "import numpy as np\n",
      "arr = np.lib.format.random_sample(size=(100, 100))\n",
      "print(arr) # печатает массив заданной размерности, заполненный случайными числами\n",
      "```\n",
      "\n",
      "В этом примере функция np.lib.format.random\\_sample() создает массив заданной размерности, заполненный случайными числами.\n",
      "\n",
      "В NumPy также есть функции для генерации матриц с определенными свойствами, например:\n",
      "\n",
      "* np.lib.format.standard\\_normal(size) - создает массив заданной размерности, заполненный случайными числами, распределенными стандартно-нормально.\n",
      "\n",
      "Например:\n",
      "\n",
      "```\n",
      "import numpy as np\n",
      "arr = np.lib.format.standard_normal(size=(100, 100))\n",
      "print(\n",
      "Reference Answer: Для работы с массивами данных в NumPy я использую функции для создания, манипуляции и анализа массивов. NumPy предоставляет эффективные операции и методы для работы с многомерными массивами, позволяя выполнять математические и статистические вычисления.\n",
      "Cosine Similarity: 0.598955512046814\n",
      "BLEU Score: 4.733769152927651e-80\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1d7e69bcc6d4b059e823e3025c8a1a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "246d8d636e9f47609731ec49951fbf0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question ID: 87\n",
      "Generated Answer: Я использую различные методы для обработки текстовых данных, такие как токенизация, лемматизация, удаление стоп-слов и stemming. Также я могу выполнять анализ sentiments, тематическое моделирование и классификацию текстов. Кроме этого, я могу использовать методы машинного обучения, такие как регрессия, классификация и кластерный анализ для анализа текстовых данных.\n",
      "\n",
      "Translation:\n",
      "I use various methods for processing text data, such as tokenization, lemmatization, removal of stop words, and stemming. I can also perform sentiment analysis, topic modeling, and text classification. In addition, I can use machine learning methods such as regression, classification, and cluster analysis to analyze text data.\n",
      "Reference Answer: Для обработки текстовых данных я использую методы, такие как токенизация, удаление стоп-слов, стемминг и лемматизация. Эти методы позволяют преобразовать текст в числовую форму для дальнейшего анализа и моделирования.\n",
      "Cosine Similarity: 0.8497726917266846\n",
      "BLEU Score: 1.0110407443309522e-78\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2c5ef5ccf03402db54a98771a08bcf3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2b247f69a1c4da3ac814f22e3d8fca3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question ID: 88\n",
      "Generated Answer: Препроцессинг данных - это процесс подготовки данных перед их использованием в машинном обучении. Он включает в себя различные шаги, такие как очистка данных, нормализация, стандартизация, одномерное и многомерное масштабирование, кодирование категориальных переменных и т.д. Препроцессинг данных необходим для того, чтобы сделать данные более удобными для работы алгоритмов машинного обучения, улучшить их качество и точность моделей, а также ускорить обучение моделей. Кроме того, препроцессинг помогает избавиться от нежелательных артефактов и шума в данных, которые могут влиять на результаты модели.\n",
      "Reference Answer: Препроцессинг данных - это этап подготовки данных перед их анализом. Он включает очистку данных, нормализацию, удаление выбросов и преобразование признаков, что необходимо для улучшения качества и производительности моделей машинного обучения.\n",
      "Cosine Similarity: 0.9834572076797485\n",
      "BLEU Score: 0.07038089344152346\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22b17aeb23964ead962daf6dbc5b0180",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c61eff12270b4efb8c0ecc14fe17f38a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question ID: 89\n",
      "Generated Answer: Конечно, я могу помочь с этим. Scikit-learn — это популярная библиотека машинного обучения для Python, которая предоставляет множество алгоритмов для моделирования данных. Вот общий процесс использования scikit-learn для моделирования данных:\n",
      "\n",
      "1. Подготовка данных: перед началом моделирования вам необходимо подготовить данные, которые вы хотите использовать для обучения модели. Это может включать в себя очистку данных, нормализацию и преобразование данных, а также разделение данных на наборы для обучения и тестирования.\n",
      "2. Выбор модели: Scikit-learn предоставляет множество алгоритмов для моделирования данных, включая линейную регрессию, логистическую регрессию, случайные леса и нейронные сети. Выберите модель, которая подходит для ваших данных и задачи.\n",
      "3. Обучение модели: после того как вы подготовили данные и выбрали модель, вы можете использовать функцию `fit()` из Scikit-learn, чтобы обучить модель на ваших данных.\n",
      "4. Оценка модели: после обучения модели вам нужно оценить её точность, используя набор тестовых данных. Вы можете использовать функцию `score()` из Scikit-learn для оценки точности модели.\n",
      "5. Предсказание: после оценки модели вы можете использовать её для предсказания новых данных, используя функцию `predict()` из Scikit-learn.\n",
      "\n",
      "Например, вот простой пример использования Scikit-learn для линейной регрессии:\n",
      "```\n",
      "from sklearn.linear_model import LinearRegression\n",
      "from sklearn.datasets import load_boston\n",
      "from sklearn.model_selection import train_test_split\n",
      "\n",
      "# Загружаем данные\n",
      "boston = load_boston()\n",
      "X = boston.data\n",
      "y = boston.target\n",
      "\n",
      "# Разделяем данные на наборы для обучения и тестирования\n",
      "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
      "\n",
      "# Создаём экземпляр модели линейной регрессии\n",
      "lr = LinearRegression()\n",
      "\n",
      "# Обучаем модель на данных\n",
      "lr.fit(X_train, y_train)\n",
      "\n",
      "# Оцениваем точность модели на тестовых данных\n",
      "score = lr.score(X_test, y_test)\n",
      "print('Точность модели:', score)\n",
      "\n",
      "# Делаем предсказания для новых данных\n",
      "new_data = [[11.0, 22.0, 13.0, 1.0, 0.0, 14.0, 309.0, 1.0, 396.9, 4.98]]\n",
      "predictions = lr.predict(new_data)\n",
      "print('Предсказание:', predictions[0])\n",
      "```\n",
      "В этом примере мы загружаем данные о стоимости жилья в Бостоне, разделяем их на наборы для обучения и тестирования, создаём экземпляр модели линейной регрессии и обучаем модель на наборе данных для обучения. Затем мы оцениваем точность модели на тестовых данных и делаем предсказания для новых данных.\n",
      "Reference Answer: Для моделирования данных с помощью scikit-learn я использую функции библиотеки для создания, обучения и оценки моделей машинного обучения. Scikit-learn предоставляет широкий набор алгоритмов и инструментов для классификации, регрессии и кластеризации.\n",
      "Cosine Similarity: 0.9025750160217285\n",
      "BLEU Score: 2.3038507637034374e-155\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33fa1d23fa894d758b92240bffdfab94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8418e3c991e1435ead344a698047b4fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question ID: 90\n",
      "Generated Answer: Разведывательный анализ данных (EDA) - это процесс изучения, понимания и обобщения данных с целью выявить шаблоны, тенденции, аномалии и связи в данных. EDA является важным шагом в любом проекте машинного обучения или анализа данных, так как он помогает нам получить представление о данных и выбрать подходящую модель для их анализа.\n",
      "\n",
      "Вы можете проводить EDA с помощью различных инструментов и методов, таких как визуализация данных, статистические методы и техники машинного обучения. Вот некоторые шаги, которые вы можете выполнить в рамках EDA:\n",
      "\n",
      "1. Подготовка данных: перед началом EDA вам нужно подготовить данные, очистить их от ошибок и пропусков, а также преобразовать их в подходящий формат.\n",
      "2. Выполнение статистического анализа: вы можете использовать различные статистические методы, чтобы получить представление о распределении данных, их центральных тенденциях и разбросе.\n",
      "3. Визуализация данных: вы можете использовать различные методы визуализации, такие как гистограммы, графики рассеяния и диаграммы бокс-плот, чтобы отобразить данные и выявить шаблоны и связи.\n",
      "4. Изучение кореляций: вы можете использовать различные методы, чтобы изучить взаимосвязь между переменными и выявить зависимости.\n",
      "5. Идентификация аномалий: вы можете использовать методы машинного обучения, такие как кластеризация и выделение аномалий, чтобы обнаружить необычные или нетипичные данные.\n",
      "\n",
      "Общий процесс EDA не является формальным или структурированным, и он может варьироваться в зависимости от задачи и данных. Цель EDA - получить представление о данных и выбрать подходящую модель для их анализа.\n",
      "Reference Answer: Разведывательный анализ данных (EDA) включает предварительное исследование данных для выявления их основных характеристик. Я использую визуализации, такие как гистограммы и диаграммы рассеяния, и статистические методы для понимания структуры данных и выявления закономерностей.\n",
      "Cosine Similarity: 0.9771027565002441\n",
      "BLEU Score: 0.021344653106343425\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e2795f724b74dc6a21026d1b07629f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f95313bafbd840e089d9b94dc61a9a47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question ID: 91\n",
      "Generated Answer: Визуализация данных - это представление данных в графической или визуальной форме. Она помогает лучше понимать и анализировать информацию, выявлять тенденции, закономерности и связи между различными данными. Визуализация данных также упрощает коммуникацию результатов анализа с другими людьми, поскольку графики и диаграммы легче воспринимаются, чем таблицы или текстовые отчеты.\n",
      "Reference Answer: Визуализация данных - это процесс представления данных в графическом или визуальном формате. Она помогает лучше понять распределения, взаимосвязи и тренды в данных, облегчая интерпретацию результатов анализа.\n",
      "Cosine Similarity: 0.9903457164764404\n",
      "BLEU Score: 0.0842816865856957\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2724bbbb6c154389a3865c6a597b228a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61a1b7351b7240b9973e35da0481381c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question ID: 92\n",
      "Generated Answer: Я использую различные методы для очистки данных, такие как удаление пропусков, стандартизация данных, удаление дубликатов и устранение ошибок в данных. Кроме того, я также могу использовать более продвинутые методы, такие как машинное обучение и правила бизнес-логики, для обнаружения и исправления ошибок в данных.\n",
      "\n",
      "Translation: I use various methods for cleaning data, such as removing missing values, standardizing data, removing duplicates, and fixing errors in the data. In addition, I can also use more advanced methods, such as machine learning and business logic rules, to detect and correct errors in the data.\n",
      "Reference Answer: Для очистки данных я использую методы, такие как удаление пропущенных значений, исправление ошибок, нормализация и кодирование категориальных признаков. Эти методы улучшают качество данных и повышают точность моделей.\n",
      "Cosine Similarity: 0.9829021096229553\n",
      "BLEU Score: 1.163336738221918e-78\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b0092022363486d887c7f15c43864ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f09fb931c23346ffa8490293e3227e25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question ID: 93\n",
      "Generated Answer: Feature engineering - это процесс создания новых функций или изменения существующих функций в данных, чтобы улучшить модель машинного обучения. Он включает в себя различные техники, такие как нормализация, стандартизация, выделение новой функциональности и удаление ненужных функций.\n",
      "\n",
      "Вы можете проводить feature engineering следующими шагами:\n",
      "\n",
      "1. Понимание данных: изучите данные, чтобы понять, какие функции могут быть полезны для модели машинного обучения.\n",
      "2. Предобработка данных: выполните нормализацию или стандартизацию данных, чтобы устранить изменения масштаба и сделать функции сопоставимыми.\n",
      "3. Выделение новой функциональности: создайте новые функции, которые могут помочь модели машинного обучения лучше понять данные.\n",
      "4. Удаление ненужных функций: удалите функции, которые не имеют отношения к целевой переменной, или функции, которые имеют высокую степень корреляции с другими функциями.\n",
      "5. Оценка качества функций: используйте различные методы, такие как анализ корреляции и значимости функций, чтобы определить, какие функции являются наиболее важными для модели машинного обучения.\n",
      "\n",
      "В целом, feature engineering является важным шагом в процессе машинного обучения, так как он может значительно повлиять на то, насколько хорошо модель будет работать.\n",
      "Reference Answer: Feature engineering - это процесс создания новых признаков из исходных данных. Он включает выбор значимых признаков, преобразование существующих и создание новых на основе знаний о данных, что помогает улучшить производительность моделей.\n",
      "Cosine Similarity: 0.9856960773468018\n",
      "BLEU Score: 0.04120044420507428\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b13f3cd66e1d4bdf9307ef0e2c4b3eec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3694caabe1824630a44113b83b95c19b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question ID: 94\n",
      "Generated Answer: Метод главных компонент (Principal Component Analysis, PCA) - это algoritm линейной алгебры, который используется для реduction dimensionality данных. Он позволяет преобразовать многомерные данные в набор fewer dimensions, сохраняя при этом большую часть информации оригинальных данных.\n",
      "\n",
      "PCA работает следующим образом:\n",
      "\n",
      "1. Он находит directions в пространстве данных, которые имеют the greatest variance (называемые главными компонентами).\n",
      "2. Затем он projecteт the original data onto these directions, так что каждый data point представлен в terms of его coordinates вдоль главных компонент.\n",
      "3. Наконец, PCA позволяет сделать выбор, сколько главных компонент использовать для представления данных. Чем меньше используется главных компонент, тем меньше будет dimensionality выходных данных, но и больше информации будет потеряно.\n",
      "\n",
      "PCA часто используется в машинном обучении для reduction dimensionality данных перед training моделей, так как это может улучшить производительность и помочь предотвратить overfitting.\n",
      "\n",
      "Надеюсь, это помогло! Если у вас есть другие вопросы, не стесняйтесь спрашивать.\n",
      "\n",
      "(Translation: The Principal Component Analysis (PCA) method is a linear algebra algorithm used for reducing the dimensionality of data. It allows transforming multidimensional data into a set of fewer dimensions while retaining most of the original data's information.\n",
      "\n",
      "PCA works as follows:\n",
      "\n",
      "1. It finds directions in the data space that have the greatest variance (called principal components).\n",
      "2. Then it projects the original data onto these directions so that each data point is represented in terms of its coordinates along the principal components.\n",
      "3. Finally, PCA allows making a choice of how many principal components to use for representing the data. The fewer principal components used, the lower the dimensionality of the output data, but the more information will be lost.\n",
      "\n",
      "PCA is often used in machine learning for reducing the dimensionality of data before training models, as this can improve performance and help prevent overfitting.\n",
      "\n",
      "I hope this helped! If you have any other questions, don't hesitate to ask.)\n",
      "Reference Answer: Метод главных компонент (PCA) - это метод уменьшения размерности, который преобразует данные в новое пространство признаков, сохраняя как можно больше информации. Он используется для визуализации данных и ускорения работы моделей.\n",
      "Cosine Similarity: 0.7318769097328186\n",
      "BLEU Score: 5.106343786779963e-79\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68e97e97ffb347f1b8cadca334337d9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e56f51cd7244a1c8dce48e008d8ba5c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question ID: 95\n",
      "Generated Answer: В машинном обучении существует несколько способов обработки выбросов в данных. Наиболее распространенные методы включают:\n",
      "\n",
      "1. Удаление выбросов: это простой и быстрый способ, но он может привести к потере важной информации.\n",
      "2. Заменять выбросы средним или медианой: это можно сделать, если выбросы являются крайними значениями, но не ситуацией, которую необходимо учитывать в модели.\n",
      "3. Использование алгоритмов, устойчивых к выбросам: некоторые алгоритмы, такие как регрессия лоasso, более устойчивы к выбросам, чем другие алгоритмы.\n",
      "4. Перестройка модели: если выбросы являются результатом структурной проблемы в модели, можно попробовать перестроить модель, чтобы сделать ее более устойчивой к выбросам.\n",
      "5. Использование ROBUSTREG для линейной регрессии: вместо использования наименее квадратичной ошибки как функции потерь можно использовать более устойчивую функцию, например Huber loss или Tukey's biweight loss.\n",
      "\n",
      "Выбор метода зависит от конкретной ситуации и характеристик данных. В некоторых случаях может быть полезно комбинировать несколько методов.\n",
      "Reference Answer: Для обработки выбросов в данных я использую методы, такие как удаление выбросов, логарифмическое преобразование и применение робастных методов оценки. Эти методы помогают улучшить качество данных и точность моделей.\n",
      "Cosine Similarity: 0.8944346904754639\n",
      "BLEU Score: 6.787980831923015e-79\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d36aebf7b974f68b4d606d0a34b28fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ddc1e6a11ed9479fbd85eb31320cbc87",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question ID: 96\n",
      "Generated Answer: Дискретизация - это процесс преобразования непрерывных данных в дискретные (отсчетные) данные. Этот процесс используется в машинном обучении и статистике для упрощения работы с данными и уменьшения загрузки на компьютерные ресурсы. Дискретизация помогает уменьшить шум в данных, улучшить интерпретацию результатов и обеспечить более эффективное хранение данных. Кроме того, некоторые алгоритмы машинного обучения могут работать только с дискретными данными.\n",
      "\n",
      "Translation:\n",
      "Discretization is the process of converting continuous data into discrete (countable) data. This process is used in machine learning and statistics to simplify working with data and reduce the load on computer resources. Discretization helps reduce noise in the data, improve interpretation of results, and provide more efficient data storage. In addition, some machine learning algorithms can only work with discrete data.\n",
      "Reference Answer: Дискретизация - это процесс преобразования непрерывных данных в категориальные. Она используется для упрощения анализа данных и моделей, а также для улучшения интерпретации результатов.\n",
      "Cosine Similarity: 0.977031946182251\n",
      "BLEU Score: 0.061822861514433544\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2cfbf8c0433e4008b4c1ceee6d4056ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04cd786bca0247afb0b6ada4df938018",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question ID: 97\n",
      "Generated Answer: К сожалению, в вашем вопросе нет конкретной информации о том, какой алгоритм градиентного бустинга вы хотите узнать. Однако, я могу дать вам общее описание работы алгоритмов градиентного бустинга.\n",
      "\n",
      "Алгоритм градиентного бустинга - это метод машинного обучения, который используется для решения задач регрессии и классификации. Он основан на идее построения модели как комбинации нескольких простых моделей, называемых деревьями решений, или иначе решающими деревьями.\n",
      "\n",
      "Алгоритм начинается с модели, которая является простой константой. Затем он итеративно строит деревья решений, каждое из которых пытается улучшить ошибку предсказания предыдущей модели. После построения каждого дерева, его веса настраиваются таким образом, чтобы минимизировать ошибку предсказания для текущей модели. Затем модель обновляется, добавляя к ней новое дерево с определенным весом.\n",
      "\n",
      "Этот процесс повторяется несколько раз, пока модель не достигнет требуемой точности. В конце концов, мы получаем модель, которая является комбинацией нескольких деревьев решений с разными весами. Эта модель может быть использована для предсказания значений целевой переменной для новых данных.\n",
      "\n",
      "Градиентный бустинг получил широкое распространение в последние годы, благодаря своей высокой точности и способности работать с большими массивами данных. Он также может быть легко распараллеливаться, что позволяет ускорить процесс обучения.\n",
      "\n",
      "Надеюсь, это дало вам общее представление о работе алгоритмов градиентного бустинга. Если у вас есть какие-либо конкретные вопросы, не стесняйтесь спрашивать.\n",
      "Reference Answer: Алгоритм градиентного бустинга использует ансамбль слабых моделей, таких как решающие деревья, которые последовательно обучаются на ошибках предыдущих моделей. Он эффективно улучшает точность предсказаний путем уменьшения ошибки на каждом этапе обучения.\n",
      "Cosine Similarity: 0.9523311257362366\n",
      "BLEU Score: 4.5758496668850784e-79\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bullat/miniconda3/envs/rag/lib/python3.11/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4def64c3831f49149c482af9683ef849",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd85282c18574a9091366b277183f7a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question ID: 98\n",
      "Generated Answer: Ансамблевые методы в машинном обучении - это подход, который комбинирует несколько моделей машинного обучения для улучшения overall performance. Эти методы могут быть использоваться для улучшения точности, стабильности, и уменьшения overfitting. Существует несколько типов ансамблевых методов, таких как bagging, boosting, и stacking. Bagging создает несколько копий обучающей выборки и тренирует независимые модели на каждой копии. Затем результаты комбинируются путем голосования или среднего значения. Boosting создает последовательность моделей, где каждая модель улучшает ошибки предыдущей модели. Stacking комбинирует несколько моделей путем использования их предсказаний в качестве входных данных для другой модели. Эти методы часто используются в Kaggle соревнованиях и могут значительно улучшить overall performance моделей.\n",
      "Reference Answer: Ансамблевые методы в машинном обучении объединяют несколько моделей для улучшения их точности и устойчивости. Основные методы включают bagging, boosting и stacking, которые помогают уменьшить переобучение и улучшить обобщающую способность моделей.\n",
      "Cosine Similarity: 0.6050275564193726\n",
      "BLEU Score: 0.04949355742373618\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5de10cc8b3b54a929434538d908addfd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "679646fcd9c44cb08a1d0c39e9bb3b31",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question ID: 99\n",
      "Generated Answer: To evaluate the quality of a model on test data, you can use various metrics such as accuracy, precision, recall, F1 score, area under the ROC curve (AUC-ROC), etc. These metrics help you measure the performance of your model and make informed decisions about its suitability for a particular task.\n",
      "\n",
      "In Russian:\n",
      "\n",
      "Для оценки качества модели на тестовых данных вы можете использовать различные метрики, такие как точность, полнота, точность, F1-мера, площадь под кривой ROC (AUC-ROC) и т.д. Эти метрики помогают вам измерить производительность модели и принять осмысленные решения о ее пригодности для конкретной задачи.\n",
      "Reference Answer: Для оценки качества модели на тестовых данных я использую метрики, такие как точность (accuracy), полнота (recall), F-мера и AUC-ROC. Эти метрики позволяют оценить, насколько хорошо модель справляется с задачей классификации или регрессии на новых данных.\n",
      "Cosine Similarity: 0.42467403411865234\n",
      "BLEU Score: 0.07870263453430151\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Load your data\n",
    "with open('/home/bullat/projects/rag/Interview-2.0/answers.json', 'r', encoding='utf-8') as f:\n",
    "    generated_answers = json.load(f)\n",
    "\n",
    "with open('/home/bullat/projects/rag/Interview-2.0/Answer_fact.json', 'r', encoding='utf-8') as f:\n",
    "    reference_answers = json.load(f)\n",
    "\n",
    "# Initialize the SentenceTransformer model\n",
    "model = SentenceTransformer('paraphrase-MiniLM-L6-v2')\n",
    "\n",
    "# Define function to calculate Cosine Similarity\n",
    "def calculate_cosine_similarity(generated, reference):\n",
    "    generated_vector = model.encode([generated])\n",
    "    reference_vector = model.encode([reference])\n",
    "    return cosine_similarity(generated_vector, reference_vector)[0][0]\n",
    "\n",
    "# Define function to calculate BLEU Score\n",
    "def calculate_bleu_score(generated, reference):\n",
    "    reference_tokens = [reference.split()]\n",
    "    generated_tokens = generated.split()\n",
    "    return sentence_bleu(reference_tokens, generated_tokens)\n",
    "\n",
    "# Calculate and print metrics\n",
    "for key in generated_answers.keys():\n",
    "    generated = generated_answers[key]\n",
    "    reference = reference_answers[key]\n",
    "    \n",
    "    cosine_sim = calculate_cosine_similarity(generated, reference)\n",
    "    bleu_score = calculate_bleu_score(generated, reference)\n",
    "    \n",
    "    print(f\"Question ID: {key}\")\n",
    "    print(f\"Generated Answer: {generated}\")\n",
    "    print(f\"Reference Answer: {reference}\")\n",
    "    print(f\"Cosine Similarity: {cosine_sim}\")\n",
    "    print(f\"BLEU Score: {bleu_score}\")\n",
    "    print()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/bullat/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "2025-01-03 20:24:03,151 - absl - INFO - Using default tokenizer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation Metrics:\n",
      "ROUGE-1: 0.1370\n",
      "ROUGE-2: 0.0718\n",
      "ROUGE-L: 0.1348\n",
      "BLEU: 0.0329\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from rouge_score import rouge_scorer\n",
    "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
    "import numpy as np\n",
    "import nltk\n",
    "\n",
    "# Download required NLTK data\n",
    "nltk.download('punkt')\n",
    "\n",
    "def load_json(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        return json.load(f)\n",
    "\n",
    "def simple_tokenize(text):\n",
    "    # Simple whitespace tokenization with punctuation handling\n",
    "    return [word.strip('.,!?()[]{}:;\"\\'') for word in text.split()]\n",
    "\n",
    "def calculate_metrics(pred_answers, true_answers):\n",
    "    scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=False)\n",
    "    smooth = SmoothingFunction()\n",
    "    metrics = {}\n",
    "    \n",
    "    rouge_scores = {'rouge1': [], 'rouge2': [], 'rougeL': []}\n",
    "    bleu_scores = []\n",
    "    \n",
    "    for key in pred_answers:\n",
    "        if key in true_answers:\n",
    "            rouge = scorer.score(true_answers[key], pred_answers[key])\n",
    "            for metric in rouge_scores:\n",
    "                rouge_scores[metric].append(rouge[metric].fmeasure)\n",
    "            \n",
    "            reference = [simple_tokenize(true_answers[key].lower())]\n",
    "            candidate = simple_tokenize(pred_answers[key].lower())\n",
    "            \n",
    "            if reference[0] and candidate:  # Check if tokens exist\n",
    "                bleu = sentence_bleu(reference, candidate, \n",
    "                                   smoothing_function=smooth.method1)\n",
    "                bleu_scores.append(bleu)\n",
    "    \n",
    "    # Calculate averages\n",
    "    metrics['rouge1'] = np.mean(rouge_scores['rouge1']) if rouge_scores['rouge1'] else 0\n",
    "    metrics['rouge2'] = np.mean(rouge_scores['rouge2']) if rouge_scores['rouge2'] else 0\n",
    "    metrics['rougeL'] = np.mean(rouge_scores['rougeL']) if rouge_scores['rougeL'] else 0\n",
    "    metrics['bleu'] = np.mean(bleu_scores) if bleu_scores else 0\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "# Load and evaluate\n",
    "pred_answers = load_json('/home/bullat/projects/rag/Interview-2.0/answers.json')\n",
    "true_answers = load_json('/home/bullat/projects/rag/Interview-2.0/Answer_fact.json')\n",
    "metrics = calculate_metrics(pred_answers, true_answers)\n",
    "\n",
    "print(\"\\nEvaluation Metrics:\")\n",
    "print(f\"ROUGE-1: {metrics['rouge1']:.4f}\")\n",
    "print(f\"ROUGE-2: {metrics['rouge2']:.4f}\")\n",
    "print(f\"ROUGE-L: {metrics['rougeL']:.4f}\")\n",
    "print(f\"BLEU: {metrics['bleu']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
